{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.1.2: Image Generation - SOLUTIONS\n",
    "\n",
    "This notebook contains complete solutions for the Style Transfer Pipeline challenge.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, PngImagePlugin\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline\n",
    "\n",
    "print(\"Loading ControlNet pipeline...\")\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"diffusers/controlnet-canny-sdxl-1.0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "pipe.enable_vae_slicing()\n",
    "\n",
    "print(\"‚úÖ Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Solution: Style Transfer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canny_edges(\n",
    "    image: Image.Image,\n",
    "    low_threshold: int = 100,\n",
    "    high_threshold: int = 200\n",
    ") -> Image.Image:\n",
    "    \"\"\"Extract Canny edges from an image.\"\"\"\n",
    "    img_array = np.array(image)\n",
    "    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    edges_rgb = np.stack([edges] * 3, axis=-1)\n",
    "    return Image.fromarray(edges_rgb)\n",
    "\n",
    "\n",
    "def save_with_metadata(\n",
    "    image: Image.Image,\n",
    "    filepath: Path,\n",
    "    prompt: str,\n",
    "    seed: int,\n",
    "    style_name: str,\n",
    ") -> None:\n",
    "    \"\"\"Save image with generation metadata.\"\"\"\n",
    "    metadata = PngImagePlugin.PngInfo()\n",
    "    metadata.add_text(\"prompt\", prompt)\n",
    "    metadata.add_text(\"seed\", str(seed))\n",
    "    metadata.add_text(\"style\", style_name)\n",
    "    metadata.add_text(\"timestamp\", datetime.now().isoformat())\n",
    "    metadata.add_text(\"model\", \"SDXL ControlNet\")\n",
    "    \n",
    "    image.save(filepath, pnginfo=metadata)\n",
    "\n",
    "\n",
    "def create_comparison_grid(\n",
    "    images: List[Image.Image],\n",
    "    labels: List[str],\n",
    "    cols: int = 3,\n",
    ") -> Image.Image:\n",
    "    \"\"\"Create a labeled comparison grid.\"\"\"\n",
    "    from PIL import ImageDraw, ImageFont\n",
    "    \n",
    "    n = len(images)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    \n",
    "    # Get max dimensions\n",
    "    max_w = max(img.width for img in images)\n",
    "    max_h = max(img.height for img in images)\n",
    "    \n",
    "    padding = 10\n",
    "    label_height = 30\n",
    "    \n",
    "    grid_width = cols * max_w + (cols + 1) * padding\n",
    "    grid_height = rows * (max_h + label_height) + (rows + 1) * padding\n",
    "    \n",
    "    grid = Image.new('RGB', (grid_width, grid_height), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(grid)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 18)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    for idx, (img, label) in enumerate(zip(images, labels)):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        \n",
    "        x = padding + col * (max_w + padding)\n",
    "        y = padding + row * (max_h + label_height + padding)\n",
    "        \n",
    "        # Paste image\n",
    "        grid.paste(img.resize((max_w, max_h)), (x, y + label_height))\n",
    "        \n",
    "        # Add label\n",
    "        text_x = x + max_w // 2\n",
    "        text_y = y + 5\n",
    "        draw.text((text_x, text_y), label[:30], fill=(0, 0, 0), font=font, anchor=\"mt\")\n",
    "    \n",
    "    return grid\n",
    "\n",
    "\n",
    "def style_transfer_pipeline(\n",
    "    reference_image: Image.Image,\n",
    "    styles: List[Dict[str, str]],\n",
    "    output_dir: str = \"style_transfer_outputs\",\n",
    "    controlnet_scale: float = 0.5,\n",
    "    num_inference_steps: int = 30,\n",
    "    base_seed: int = 42,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Apply multiple styles to a reference image using ControlNet.\n",
    "    \n",
    "    Args:\n",
    "        reference_image: Input image to transform\n",
    "        styles: List of dicts with 'name' and 'prompt' keys\n",
    "        output_dir: Directory to save results\n",
    "        controlnet_scale: ControlNet conditioning scale\n",
    "        num_inference_steps: Number of denoising steps\n",
    "        base_seed: Base random seed (incremented for each style)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results and metadata\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extract edge map\n",
    "    print(\"üìê Extracting edge map...\")\n",
    "    edge_map = get_canny_edges(reference_image)\n",
    "    \n",
    "    # Save edge map\n",
    "    edge_map.save(output_path / \"edge_map.png\")\n",
    "    \n",
    "    # Generate styled images\n",
    "    results = {\n",
    "        \"reference\": reference_image,\n",
    "        \"edge_map\": edge_map,\n",
    "        \"styles\": [],\n",
    "        \"images\": [edge_map],  # Include edge map in comparison\n",
    "        \"labels\": [\"Edge Map\"],\n",
    "    }\n",
    "    \n",
    "    negative_prompt = \"blurry, low quality, distorted, ugly, watermark, text\"\n",
    "    \n",
    "    for i, style in enumerate(styles):\n",
    "        style_name = style['name']\n",
    "        prompt = style['prompt']\n",
    "        seed = base_seed + i\n",
    "        \n",
    "        print(f\"\\nüé® Generating: {style_name}\")\n",
    "        print(f\"   Prompt: {prompt[:50]}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "        \n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=edge_map,\n",
    "            controlnet_conditioning_scale=controlnet_scale,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"   Generated in {elapsed:.1f}s\")\n",
    "        \n",
    "        # Save with metadata\n",
    "        filename = f\"{i+1:02d}_{style_name.lower().replace(' ', '_')}.png\"\n",
    "        save_with_metadata(image, output_path / filename, prompt, seed, style_name)\n",
    "        \n",
    "        # Store results\n",
    "        results['styles'].append({\n",
    "            'name': style_name,\n",
    "            'prompt': prompt,\n",
    "            'seed': seed,\n",
    "            'generation_time': elapsed,\n",
    "            'filename': filename,\n",
    "        })\n",
    "        results['images'].append(image)\n",
    "        results['labels'].append(style_name)\n",
    "    \n",
    "    # Create comparison grid\n",
    "    print(\"\\nüìä Creating comparison grid...\")\n",
    "    grid = create_comparison_grid(results['images'], results['labels'], cols=3)\n",
    "    grid.save(output_path / \"comparison_grid.png\")\n",
    "    \n",
    "    # Save metadata JSON\n",
    "    metadata = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'controlnet_scale': controlnet_scale,\n",
    "        'num_inference_steps': num_inference_steps,\n",
    "        'styles': results['styles'],\n",
    "    }\n",
    "    \n",
    "    with open(output_path / \"metadata.json\", 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    results['grid'] = grid\n",
    "    results['output_dir'] = str(output_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Complete! Results saved to: {output_path}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the pipeline\n",
    "\n",
    "# Create a simple reference image using SDXL\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "# First generate a reference image\n",
    "print(\"Creating reference image...\")\n",
    "base_pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "base_pipe = base_pipe.to(\"cuda\")\n",
    "\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "reference = base_pipe(\n",
    "    prompt=\"A simple house with a tree in front, clear sky, daytime\",\n",
    "    negative_prompt=\"complex, busy, cluttered\",\n",
    "    num_inference_steps=25,\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "\n",
    "# Free base pipeline\n",
    "del base_pipe\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define styles\n",
    "styles = [\n",
    "    {\n",
    "        \"name\": \"Van Gogh\",\n",
    "        \"prompt\": \"A house with a tree, in the style of Van Gogh's Starry Night, oil painting, swirling brushstrokes, vibrant colors\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Studio Ghibli\",\n",
    "        \"prompt\": \"A house with a tree, Studio Ghibli anime style, Hayao Miyazaki, beautiful detailed scene, soft colors\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Cyberpunk\",\n",
    "        \"prompt\": \"A futuristic house with a holographic tree, cyberpunk style, neon lights, rain, night scene\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Watercolor\",\n",
    "        \"prompt\": \"A house with a tree, watercolor painting, soft washes of color, artistic, delicate brushwork\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Low Poly\",\n",
    "        \"prompt\": \"A house with a tree, low poly 3D art style, geometric shapes, vibrant colors, minimalist\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Run the pipeline\n",
    "results = style_transfer_pipeline(\n",
    "    reference,\n",
    "    styles,\n",
    "    output_dir=\"style_transfer_outputs\",\n",
    "    controlnet_scale=0.5,\n",
    "    num_inference_steps=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the comparison grid\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(results['grid'])\n",
    "plt.axis('off')\n",
    "plt.title(\"Style Transfer Results\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nüìä Generation Summary:\")\n",
    "print(\"=\" * 60)\n",
    "for style in results['styles']:\n",
    "    print(f\"  {style['name']:15} - {style['generation_time']:.1f}s - seed: {style['seed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe, controlnet\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"‚úÖ Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
