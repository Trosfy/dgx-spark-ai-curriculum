{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.3.2: Weights & Biases Integration\n",
    "\n",
    "**Module:** 4.3 - MLOps & Experiment Tracking  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ⭐⭐ (Beginner-Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Set up Weights & Biases for experiment tracking\n",
    "- [ ] Create rich training dashboards with custom visualizations\n",
    "- [ ] Configure and run hyperparameter sweeps\n",
    "- [ ] Understand when to use W&B vs MLflow\n",
    "- [ ] Integrate W&B with popular training frameworks\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed: Task 4.3.1 (MLflow Setup)\n",
    "- Knowledge of: Python, basic ML training\n",
    "- A free W&B account (we'll create one if needed)\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "At OpenAI, Anthropic, and most AI research labs, Weights & Biases is the go-to tool for experiment tracking. Why?\n",
    "\n",
    "1. **Beautiful dashboards** - Instantly visualize training curves, compare runs\n",
    "2. **Hyperparameter sweeps** - Automated search with Bayesian optimization\n",
    "3. **Team collaboration** - Share experiments with one link\n",
    "4. **Integrations** - Works seamlessly with HuggingFace, PyTorch Lightning, etc.\n",
    "\n",
    "When Google DeepMind trained Gemini, when OpenAI trained GPT-4 - they tracked everything with tools like W&B.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5: What is Weights & Biases?\n",
    "\n",
    "> **Imagine you're training for a marathon.**\n",
    ">\n",
    "> You could scribble your times in a notebook... or you could use a fitness app that:\n",
    "> - Automatically tracks your runs with GPS\n",
    "> - Shows you beautiful charts of your progress\n",
    "> - Compares your training to other runners\n",
    "> - Suggests better training schedules\n",
    ">\n",
    "> Weights & Biases is that fitness app, but for training AI models. It automatically records everything, shows you pretty graphs, and helps you find the best \"training schedule\" (hyperparameters) for your model.\n",
    ">\n",
    "> **In AI terms:** W&B is a cloud-based experiment tracking platform that logs metrics, visualizes training progress, and helps optimize hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "## MLflow vs W&B: When to Use Each\n",
    "\n",
    "| Feature | MLflow | W&B |\n",
    "|---------|--------|-----|\n",
    "| **Hosting** | Self-hosted or Databricks | Cloud (free tier) |\n",
    "| **Visualization** | Basic UI | Rich, interactive dashboards |\n",
    "| **Sweeps** | Manual setup | Built-in with Bayesian optimization |\n",
    "| **Collaboration** | Requires server setup | Instant link sharing |\n",
    "| **Privacy** | Full control | Cloud-based (enterprise for air-gapped) |\n",
    "| **Best for** | Production pipelines | Research & development |\n",
    "\n",
    "**Recommendation:** Use W&B during development/research, MLflow for production deployment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting Up W&B\n",
    "\n",
    "First, let's install and configure Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install W&B\n",
    "!pip install wandb -q\n",
    "\n",
    "import wandb\n",
    "print(f\"W&B version: {wandb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to W&B\n",
    "# Option 1: Interactive login (opens browser)\n",
    "# wandb.login()\n",
    "\n",
    "# Option 2: Use API key directly (get from https://wandb.ai/authorize)\n",
    "# wandb.login(key=\"your-api-key\")\n",
    "\n",
    "# Option 3: For this tutorial, we'll use offline mode (no account needed)\n",
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"  # Remove this line to enable cloud sync\n",
    "\n",
    "print(\"W&B configured in offline mode for this tutorial.\")\n",
    "print(\"To enable cloud sync, run: wandb.login()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our training environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Your First W&B Experiment\n",
    "\n",
    "Let's create a training run with rich logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset (same as MLflow notebook)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "n_features = 20\n",
    "\n",
    "X = torch.randn(n_samples, n_features)\n",
    "true_weights = torch.randn(n_features)\n",
    "y = (X @ true_weights > 0).float()\n",
    "\n",
    "train_X, val_X = X[:800], X[800:]\n",
    "train_y, val_y = y[:800], y[800:]\n",
    "\n",
    "print(f\"Dataset ready: {n_samples} samples, {n_features} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb(\n",
    "    hidden_dim: int = 64,\n",
    "    learning_rate: float = 0.01,\n",
    "    dropout: float = 0.1,\n",
    "    epochs: int = 30,\n",
    "    batch_size: int = 32,\n",
    "    optimizer_type: str = \"adam\",\n",
    "    project_name: str = \"dgx-spark-classification\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a model with full W&B tracking.\n",
    "    \"\"\"\n",
    "    # Initialize a new W&B run\n",
    "    run = wandb.init(\n",
    "        project=project_name,\n",
    "        name=f\"{optimizer_type}-h{hidden_dim}-lr{learning_rate}\",\n",
    "        config={\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"dropout\": dropout,\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"optimizer\": optimizer_type,\n",
    "            \"architecture\": \"SimpleClassifier\",\n",
    "            \"dataset_size\": n_samples,\n",
    "            \"features\": n_features,\n",
    "            \"hardware\": \"DGX Spark (128GB)\"\n",
    "        },\n",
    "        tags=[\"tutorial\", \"classification\", optimizer_type],\n",
    "        reinit=True  # Allow multiple runs in same script\n",
    "    )\n",
    "    \n",
    "    # Access config through wandb.config for sweep compatibility\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Create model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleClassifier(n_features, config.hidden_dim, config.dropout).to(device)\n",
    "    \n",
    "    # Watch model to log gradients and parameters\n",
    "    wandb.watch(model, log=\"all\", log_freq=10)\n",
    "    \n",
    "    # Setup optimizer\n",
    "    if config.optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    elif config.optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=0.9)\n",
    "    elif config.optimizer == \"adamw\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Data loaders\n",
    "    train_dataset = TensorDataset(train_X.to(device), train_y.to(device))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            preds = (outputs > 0.5).float()\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_X.to(device))\n",
    "            val_preds = (val_outputs > 0.5).float()\n",
    "            val_acc = (val_preds == val_y.to(device)).float().mean().item()\n",
    "            val_loss = criterion(val_outputs, val_y.to(device)).item()\n",
    "        \n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train/loss\": avg_loss,\n",
    "            \"train/accuracy\": train_acc,\n",
    "            \"val/loss\": val_loss,\n",
    "            \"val/accuracy\": val_acc,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            # Save best model checkpoint\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            wandb.save(\"best_model.pt\")\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch:2d}: train_loss={avg_loss:.4f}, train_acc={train_acc:.4f}, val_acc={val_acc:.4f}\")\n",
    "    \n",
    "    # Log final summary metrics\n",
    "    wandb.run.summary[\"best_val_accuracy\"] = best_val_acc\n",
    "    wandb.run.summary[\"final_train_loss\"] = avg_loss\n",
    "    \n",
    "    # Log confusion matrix\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(val_X.to(device))\n",
    "        val_preds = (val_outputs > 0.5).float().cpu().numpy()\n",
    "        val_labels = val_y.numpy()\n",
    "    \n",
    "    wandb.log({\n",
    "        \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "            probs=None,\n",
    "            y_true=val_labels,\n",
    "            preds=val_preds,\n",
    "            class_names=[\"Negative\", \"Positive\"]\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nTraining complete! Best val accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    wandb.finish()\n",
    "    return model, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our first W&B experiment\n",
    "model, acc = train_with_wandb(\n",
    "    hidden_dim=64,\n",
    "    learning_rate=0.01,\n",
    "    epochs=30,\n",
    "    optimizer_type=\"adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "W&B automatically:\n",
    "1. Created a new project called \"dgx-spark-classification\"\n",
    "2. Logged all configuration parameters\n",
    "3. Tracked loss and accuracy curves at each epoch\n",
    "4. Recorded model gradients and parameters (via `wandb.watch`)\n",
    "5. Saved your best model checkpoint\n",
    "6. Generated a confusion matrix visualization\n",
    "\n",
    "In online mode, you'd get a link to view all this in a beautiful dashboard!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Comparing Multiple Runs\n",
    "\n",
    "Let's run a few more experiments to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple experiments\n",
    "experiments = [\n",
    "    {\"hidden_dim\": 32, \"learning_rate\": 0.001, \"optimizer_type\": \"adam\"},\n",
    "    {\"hidden_dim\": 128, \"learning_rate\": 0.01, \"optimizer_type\": \"sgd\"},\n",
    "    {\"hidden_dim\": 64, \"learning_rate\": 0.005, \"optimizer_type\": \"adamw\"},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for config in experiments:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running: {config}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    _, acc = train_with_wandb(**config, epochs=30)\n",
    "    results.append((config, acc))\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for config, acc in sorted(results, key=lambda x: -x[1]):\n",
    "    print(f\"Val Acc: {acc:.4f} | optimizer={config['optimizer_type']}, \"\n",
    "          f\"hidden={config['hidden_dim']}, lr={config['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Hyperparameter Sweeps\n",
    "\n",
    "One of W&B's killer features is automated hyperparameter search!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELI5: What is a Hyperparameter Sweep?\n",
    "\n",
    "> **Imagine you're making the perfect pizza.**\n",
    ">\n",
    "> You could try:\n",
    "> - Every possible oven temperature (300°, 325°, 350°...)\n",
    "> - Every baking time (10 min, 12 min, 15 min...)\n",
    "> - Every cheese amount (1 cup, 1.5 cups, 2 cups...)\n",
    ">\n",
    "> That's called a **grid search** - trying every combination. But that's 100+ pizzas!\n",
    ">\n",
    "> A smart approach: Try a few pizzas, see which direction makes them better, and focus your testing there. That's **Bayesian optimization** - W&B learns from each experiment to suggest better ones.\n",
    ">\n",
    "> **In AI terms:** A sweep automatically tries different hyperparameter combinations and uses the results to intelligently explore the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sweep configuration\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  # Options: grid, random, bayes\n",
    "    \"metric\": {\n",
    "        \"name\": \"val/accuracy\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"hidden_dim\": {\n",
    "            \"values\": [32, 64, 128, 256]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 0.0001,\n",
    "            \"max\": 0.1\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 0.5\n",
    "        },\n",
    "        \"optimizer\": {\n",
    "            \"values\": [\"adam\", \"sgd\", \"adamw\"]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [16, 32, 64]\n",
    "        }\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 5,\n",
    "        \"s\": 2\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Sweep Configuration:\")\n",
    "print(f\"  Method: {sweep_config['method']} (learns from results)\")\n",
    "print(f\"  Optimizing: {sweep_config['metric']['name']}\")\n",
    "print(f\"  Parameters to search:\")\n",
    "for param, config in sweep_config['parameters'].items():\n",
    "    print(f\"    - {param}: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train():\n",
    "    \"\"\"\n",
    "    Training function for W&B sweep.\n",
    "    Config is automatically injected by wandb.agent\n",
    "    \"\"\"\n",
    "    run = wandb.init()\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Create model with sweep config\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleClassifier(\n",
    "        n_features, \n",
    "        config.hidden_dim, \n",
    "        config.dropout\n",
    "    ).to(device)\n",
    "    \n",
    "    # Setup optimizer based on config\n",
    "    if config.optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    elif config.optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    train_dataset = TensorDataset(train_X.to(device), train_y.to(device))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_X.to(device))\n",
    "            val_preds = (val_outputs > 0.5).float()\n",
    "            val_acc = (val_preds == val_y.to(device)).float().mean().item()\n",
    "            val_loss = criterion(val_outputs, val_y.to(device)).item()\n",
    "        \n",
    "        wandb.log({\"val/accuracy\": val_acc, \"val/loss\": val_loss})\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run sweep (limited runs for demo)\n",
    "# Note: In online mode, this would run on W&B servers\n",
    "print(\"Creating sweep...\")\n",
    "print(\"(In offline mode, sweeps have limited functionality)\")\n",
    "print(\"\\nTo run a full sweep, enable online mode and run:\")\n",
    "print(\"\")\n",
    "print(\"  sweep_id = wandb.sweep(sweep_config, project='dgx-spark-sweep')\")\n",
    "print(\"  wandb.agent(sweep_id, sweep_train, count=20)\")\n",
    "print(\"\")\n",
    "print(\"This would run 20 experiments with Bayesian-optimized hyperparameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate sweep with a simple manual version\n",
    "import random\n",
    "\n",
    "print(\"Running mini-sweep demonstration (5 random configurations)...\\n\")\n",
    "\n",
    "sweep_results = []\n",
    "for i in range(5):\n",
    "    # Randomly sample hyperparameters\n",
    "    config = {\n",
    "        \"hidden_dim\": random.choice([32, 64, 128]),\n",
    "        \"learning_rate\": 10 ** random.uniform(-4, -1),\n",
    "        \"dropout\": random.uniform(0, 0.3),\n",
    "        \"optimizer_type\": random.choice([\"adam\", \"sgd\", \"adamw\"])\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial {i+1}: hidden={config['hidden_dim']}, lr={config['learning_rate']:.4f}, \"\n",
    "          f\"dropout={config['dropout']:.2f}, opt={config['optimizer_type']}\")\n",
    "    \n",
    "    _, acc = train_with_wandb(**config, epochs=15)\n",
    "    sweep_results.append((config, acc))\n",
    "\n",
    "# Find best\n",
    "best_config, best_acc = max(sweep_results, key=lambda x: x[1])\n",
    "print(f\"\\nBest configuration found:\")\n",
    "print(f\"  Accuracy: {best_acc:.4f}\")\n",
    "print(f\"  Config: {best_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: W&B with HuggingFace Transformers\n",
    "\n",
    "W&B integrates seamlessly with HuggingFace Trainer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: HuggingFace Trainer integration (code pattern, not executed)\n",
    "huggingface_example = '''\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import wandb\n",
    "\n",
    "# W&B is automatically enabled when installed!\n",
    "# Just set the report_to parameter\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    \n",
    "    # W&B Integration - that's it!\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"llama-finetune-v1\",\n",
    ")\n",
    "\n",
    "# Optionally initialize with more config\n",
    "wandb.init(\n",
    "    project=\"llm-finetuning\",\n",
    "    config={\n",
    "        \"model\": \"meta-llama/Llama-3.1-8B\",\n",
    "        \"dataset\": \"custom-instructions\",\n",
    "        \"lora_r\": 16,\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# All metrics automatically logged to W&B!\n",
    "trainer.train()\n",
    "'''\n",
    "\n",
    "print(\"HuggingFace Trainer + W&B Integration:\")\n",
    "print(\"=\"*50)\n",
    "print(huggingface_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Advanced W&B Features\n",
    "\n",
    "### Custom Visualizations and Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate logging different types of data\n",
    "run = wandb.init(\n",
    "    project=\"dgx-spark-demo\",\n",
    "    name=\"advanced-logging-demo\",\n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "# Log images\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "# Create a sample plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "x = np.linspace(0, 10, 100)\n",
    "ax.plot(x, np.sin(x), label='sin(x)')\n",
    "ax.plot(x, np.cos(x), label='cos(x)')\n",
    "ax.legend()\n",
    "ax.set_title('Sample Visualization')\n",
    "\n",
    "# Log the figure\n",
    "wandb.log({\"sample_plot\": wandb.Image(fig)})\n",
    "plt.close()\n",
    "\n",
    "# Log histograms\n",
    "data = np.random.normal(0, 1, 1000)\n",
    "wandb.log({\"weight_distribution\": wandb.Histogram(data)})\n",
    "\n",
    "# Log tables\n",
    "table = wandb.Table(\n",
    "    columns=[\"model\", \"accuracy\", \"loss\", \"params\"],\n",
    "    data=[\n",
    "        [\"small\", 0.85, 0.42, \"1M\"],\n",
    "        [\"medium\", 0.91, 0.28, \"10M\"],\n",
    "        [\"large\", 0.94, 0.18, \"100M\"],\n",
    "    ]\n",
    ")\n",
    "wandb.log({\"model_comparison\": table})\n",
    "\n",
    "# Log HTML\n",
    "html_content = \"\"\"\n",
    "<h2>Training Summary</h2>\n",
    "<ul>\n",
    "  <li>Best Accuracy: 94%</li>\n",
    "  <li>Training Time: 2 hours</li>\n",
    "  <li>GPU: DGX Spark (128GB)</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "wandb.log({\"summary_html\": wandb.Html(html_content)})\n",
    "\n",
    "print(\"Logged various data types:\")\n",
    "print(\"  - Matplotlib figure\")\n",
    "print(\"  - Histogram\")\n",
    "print(\"  - Table\")\n",
    "print(\"  - HTML\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alerts - notify when something important happens\n",
    "alert_example = '''\n",
    "# In online mode, you can set up alerts:\n",
    "\n",
    "# Alert when validation accuracy drops\n",
    "if val_acc < 0.8:\n",
    "    wandb.alert(\n",
    "        title=\"Low Accuracy Warning\",\n",
    "        text=f\"Validation accuracy dropped to {val_acc:.2f}\",\n",
    "        level=wandb.AlertLevel.WARN\n",
    "    )\n",
    "\n",
    "# Alert on training completion\n",
    "wandb.alert(\n",
    "    title=\"Training Complete\",\n",
    "    text=f\"Model achieved {best_acc:.2f} accuracy\",\n",
    "    level=wandb.AlertLevel.INFO\n",
    ")\n",
    "\n",
    "# Alert on crash/error\n",
    "try:\n",
    "    train_model()\n",
    "except Exception as e:\n",
    "    wandb.alert(\n",
    "        title=\"Training Failed\",\n",
    "        text=str(e),\n",
    "        level=wandb.AlertLevel.ERROR\n",
    "    )\n",
    "    raise\n",
    "'''\n",
    "\n",
    "print(\"W&B Alerts (online mode only):\")\n",
    "print(alert_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself\n",
    "\n",
    "Create a training run that:\n",
    "1. Uses a different model architecture (add more layers)\n",
    "2. Logs training curves and a confusion matrix\n",
    "3. Compares at least 3 different learning rate schedules\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Try using `torch.optim.lr_scheduler` with different schedulers like:\n",
    "- `StepLR` - decay LR by factor every N epochs\n",
    "- `CosineAnnealingLR` - cosine decay\n",
    "- `OneCycleLR` - learning rate warmup + decay\n",
    "\n",
    "Log the learning rate at each step with `wandb.log({\"lr\": scheduler.get_last_lr()[0]})`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Experiment with learning rate schedules and W&B logging\n",
    "\n",
    "# Starter code:\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, OneCycleLR\n",
    "\n",
    "schedulers_to_try = {\n",
    "    \"step\": lambda opt: StepLR(opt, step_size=10, gamma=0.5),\n",
    "    \"cosine\": lambda opt: CosineAnnealingLR(opt, T_max=30),\n",
    "    \"onecycle\": lambda opt: OneCycleLR(opt, max_lr=0.1, epochs=30, steps_per_epoch=25)\n",
    "}\n",
    "\n",
    "# Your experiment code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Forgetting to Finish Runs\n",
    "\n",
    "```python\n",
    "# Wrong - run stays open\n",
    "wandb.init(project=\"my-project\")\n",
    "wandb.log({\"loss\": 0.5})\n",
    "# Script ends but run isn't finished!\n",
    "\n",
    "# Right - always finish\n",
    "run = wandb.init(project=\"my-project\")\n",
    "wandb.log({\"loss\": 0.5})\n",
    "wandb.finish()  # or use with statement\n",
    "```\n",
    "**Why:** Unfinished runs can cause issues with subsequent experiments.\n",
    "\n",
    "### Mistake 2: Not Using Config for Sweeps\n",
    "\n",
    "```python\n",
    "# Wrong - hardcoded values don't work with sweeps\n",
    "def train():\n",
    "    lr = 0.01  # Ignores sweep config!\n",
    "    model = create_model(lr=lr)\n",
    "\n",
    "# Right - use wandb.config\n",
    "def train():\n",
    "    config = wandb.config\n",
    "    model = create_model(lr=config.learning_rate)\n",
    "```\n",
    "**Why:** Sweeps inject hyperparameters through `wandb.config`.\n",
    "\n",
    "### Mistake 3: Logging Too Frequently\n",
    "\n",
    "```python\n",
    "# Wrong - logging every step creates huge overhead\n",
    "for batch in dataloader:\n",
    "    loss = train_step(batch)\n",
    "    wandb.log({\"batch_loss\": loss})  # Every batch!\n",
    "\n",
    "# Right - log less frequently\n",
    "for i, batch in enumerate(dataloader):\n",
    "    loss = train_step(batch)\n",
    "    if i % 100 == 0:  # Every 100 batches\n",
    "        wandb.log({\"batch_loss\": loss})\n",
    "```\n",
    "**Why:** Excessive logging slows down training and bloats storage.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- How to set up W&B for experiment tracking\n",
    "- How to log metrics, plots, and tables\n",
    "- How to configure hyperparameter sweeps\n",
    "- How to integrate W&B with HuggingFace Transformers\n",
    "- When to use W&B vs MLflow\n",
    "\n",
    "---\n",
    "\n",
    "## Challenge (Optional)\n",
    "\n",
    "Set up a complete hyperparameter sweep that:\n",
    "1. Searches over model size, learning rate, optimizer, and batch size\n",
    "2. Uses Bayesian optimization\n",
    "3. Has early stopping for poor runs\n",
    "4. Creates a beautiful comparison dashboard\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [W&B Documentation](https://docs.wandb.ai/)\n",
    "- [W&B Sweeps Guide](https://docs.wandb.ai/guides/sweeps)\n",
    "- [HuggingFace + W&B Integration](https://docs.wandb.ai/guides/integrations/huggingface)\n",
    "- [W&B Reports](https://docs.wandb.ai/guides/reports) - Create shareable experiment summaries\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clean up W&B offline files (optional)\n",
    "# !rm -rf wandb/\n",
    "\n",
    "print(\"Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you can track experiments, let's learn how to **evaluate** your models properly! The next notebook covers running standard LLM benchmarks to compare models objectively.\n",
    "\n",
    "**Continue to:** [03-benchmark-suite.ipynb](03-benchmark-suite.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
