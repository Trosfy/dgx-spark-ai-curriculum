{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.5.2: Agent Playground - Solutions\n",
    "\n",
    "Complete solutions for the Agent Playground exercises.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1: Streaming Responses in Streamlit\n",
    "\n",
    "Show tokens as they're generated using `st.write_stream()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_chat = '''\n",
    "\"\"\"Streaming Chat in Streamlit\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import ollama\n",
    "\n",
    "st.set_page_config(page_title=\"Streaming Chat\", page_icon=\"âš¡\")\n",
    "st.title(\"âš¡ Streaming Chat\")\n",
    "\n",
    "# Initialize messages\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display history\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.write(msg[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Type a message...\"):\n",
    "    # Add user message\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(prompt)\n",
    "    \n",
    "    # Stream response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        def generate():\n",
    "            for chunk in ollama.chat(\n",
    "                model=\"llama3.2:3b\",\n",
    "                messages=st.session_state.messages,\n",
    "                stream=True\n",
    "            ):\n",
    "                yield chunk[\"message\"][\"content\"]\n",
    "        \n",
    "        # Use st.write_stream for token-by-token display\n",
    "        response = st.write_stream(generate())\n",
    "    \n",
    "    # Save response\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "'''\n",
    "\n",
    "print(\"Streaming chat solution:\")\n",
    "print(streaming_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2: Tool Latency Tracking\n",
    "\n",
    "Measure and display tool execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, Any, Callable\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "class LatencyTracker:\n",
    "    \"\"\"\n",
    "    Track latency of tool executions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.latencies: Dict[str, list] = {}\n",
    "    \n",
    "    def track(self, tool_name: str) -> Callable:\n",
    "        \"\"\"Decorator to track execution time.\"\"\"\n",
    "        def decorator(func: Callable) -> Callable:\n",
    "            @wraps(func)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                start = time.time()\n",
    "                result = func(*args, **kwargs)\n",
    "                elapsed = time.time() - start\n",
    "                \n",
    "                if tool_name not in self.latencies:\n",
    "                    self.latencies[tool_name] = []\n",
    "                self.latencies[tool_name].append(elapsed)\n",
    "                \n",
    "                return result\n",
    "            return wrapper\n",
    "        return decorator\n",
    "    \n",
    "    def get_stats(self, tool_name: str = None) -> Dict:\n",
    "        \"\"\"Get latency statistics.\"\"\"\n",
    "        if tool_name:\n",
    "            times = self.latencies.get(tool_name, [])\n",
    "            if not times:\n",
    "                return {\"error\": \"No data\"}\n",
    "            return {\n",
    "                \"tool\": tool_name,\n",
    "                \"count\": len(times),\n",
    "                \"avg_ms\": sum(times) / len(times) * 1000,\n",
    "                \"min_ms\": min(times) * 1000,\n",
    "                \"max_ms\": max(times) * 1000,\n",
    "            }\n",
    "        \n",
    "        # All tools\n",
    "        return {\n",
    "            name: self.get_stats(name)\n",
    "            for name in self.latencies\n",
    "        }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "tracker = LatencyTracker()\n",
    "\n",
    "@tracker.track(\"calculator\")\n",
    "def calculate(expression: str) -> str:\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return str(eval(expression))\n",
    "\n",
    "@tracker.track(\"web_search\")\n",
    "def web_search(query: str) -> str:\n",
    "    time.sleep(0.5)  # Simulate API call\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "# Test\n",
    "calculate(\"2 + 2\")\n",
    "calculate(\"10 * 5\")\n",
    "web_search(\"python\")\n",
    "\n",
    "print(\"Latency stats:\")\n",
    "print(tracker.get_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit visualization of latencies\n",
    "latency_page = '''\n",
    "\"\"\"Tool Latency Analytics Page\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "st.set_page_config(page_title=\"Tool Latency\", page_icon=\"â±ï¸\")\n",
    "st.title(\"â±ï¸ Tool Latency Analytics\")\n",
    "\n",
    "# Get latency data from session state\n",
    "if \"tool_latencies\" not in st.session_state:\n",
    "    st.session_state.tool_latencies = {}\n",
    "\n",
    "latencies = st.session_state.tool_latencies\n",
    "\n",
    "if latencies:\n",
    "    # Summary metrics\n",
    "    st.subheader(\"Summary\")\n",
    "    \n",
    "    cols = st.columns(len(latencies))\n",
    "    for i, (tool, times) in enumerate(latencies.items()):\n",
    "        avg_ms = sum(times) / len(times) * 1000\n",
    "        cols[i].metric(\n",
    "            f\"{tool}\",\n",
    "            f\"{avg_ms:.1f}ms\",\n",
    "            f\"{len(times)} calls\"\n",
    "        )\n",
    "    \n",
    "    st.subheader(\"Latency Distribution\")\n",
    "    \n",
    "    # Create DataFrame for chart\n",
    "    data = []\n",
    "    for tool, times in latencies.items():\n",
    "        for t in times:\n",
    "            data.append({\"Tool\": tool, \"Latency (ms)\": t * 1000})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Box plot style using bar chart\n",
    "    st.bar_chart(\n",
    "        df.groupby(\"Tool\")[\"Latency (ms)\"].mean()\n",
    "    )\n",
    "    \n",
    "    # Detailed table\n",
    "    st.subheader(\"Detailed Statistics\")\n",
    "    \n",
    "    stats_data = []\n",
    "    for tool, times in latencies.items():\n",
    "        stats_data.append({\n",
    "            \"Tool\": tool,\n",
    "            \"Calls\": len(times),\n",
    "            \"Avg (ms)\": f\"{sum(times)/len(times)*1000:.1f}\",\n",
    "            \"Min (ms)\": f\"{min(times)*1000:.1f}\",\n",
    "            \"Max (ms)\": f\"{max(times)*1000:.1f}\",\n",
    "        })\n",
    "    \n",
    "    st.dataframe(pd.DataFrame(stats_data), hide_index=True)\n",
    "    \n",
    "else:\n",
    "    st.info(\"No tool calls recorded yet. Chat with the agent to generate data!\")\n",
    "\n",
    "# Clear button\n",
    "if st.button(\"Clear Latency Data\"):\n",
    "    st.session_state.tool_latencies = {}\n",
    "    st.rerun()\n",
    "'''\n",
    "\n",
    "print(\"Latency analytics page:\")\n",
    "print(latency_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3: Conversation Branching\n",
    "\n",
    "Allow users to go back and try different responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_chat = '''\n",
    "\"\"\"Conversation Branching in Streamlit\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Dict\n",
    "import uuid\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    \"\"\"A message in the conversation tree.\"\"\"\n",
    "    id: str\n",
    "    role: str\n",
    "    content: str\n",
    "    parent_id: Optional[str] = None\n",
    "    children: List[str] = field(default_factory=list)\n",
    "\n",
    "\n",
    "class ConversationTree:\n",
    "    \"\"\"A tree structure for branching conversations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.messages: Dict[str, Message] = {}\n",
    "        self.root_id: Optional[str] = None\n",
    "        self.current_path: List[str] = []  # Current branch\n",
    "    \n",
    "    def add_message(self, role: str, content: str, parent_id: str = None) -> str:\n",
    "        \"\"\"Add a message to the tree.\"\"\"\n",
    "        msg_id = str(uuid.uuid4())[:8]\n",
    "        msg = Message(\n",
    "            id=msg_id,\n",
    "            role=role,\n",
    "            content=content,\n",
    "            parent_id=parent_id or (self.current_path[-1] if self.current_path else None)\n",
    "        )\n",
    "        \n",
    "        self.messages[msg_id] = msg\n",
    "        \n",
    "        # Set root or add as child\n",
    "        if msg.parent_id and msg.parent_id in self.messages:\n",
    "            self.messages[msg.parent_id].children.append(msg_id)\n",
    "        elif not self.root_id:\n",
    "            self.root_id = msg_id\n",
    "        \n",
    "        self.current_path.append(msg_id)\n",
    "        return msg_id\n",
    "    \n",
    "    def get_current_history(self) -> List[Message]:\n",
    "        \"\"\"Get messages in current branch.\"\"\"\n",
    "        return [self.messages[mid] for mid in self.current_path]\n",
    "    \n",
    "    def branch_from(self, message_id: str):\n",
    "        \"\"\"Start a new branch from a specific message.\"\"\"\n",
    "        # Find path to this message\n",
    "        new_path = []\n",
    "        current = message_id\n",
    "        \n",
    "        while current:\n",
    "            new_path.insert(0, current)\n",
    "            current = self.messages[current].parent_id\n",
    "        \n",
    "        self.current_path = new_path\n",
    "    \n",
    "    def get_branch_points(self) -> List[Dict]:\n",
    "        \"\"\"Get all messages with multiple children (branch points).\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"id\": msg.id,\n",
    "                \"content\": msg.content[:50] + \"...\",\n",
    "                \"branches\": len(msg.children)\n",
    "            }\n",
    "            for msg in self.messages.values()\n",
    "            if len(msg.children) > 1\n",
    "        ]\n",
    "\n",
    "\n",
    "# Streamlit App\n",
    "st.set_page_config(page_title=\"Branching Chat\", page_icon=\"ðŸŒ³\")\n",
    "st.title(\"ðŸŒ³ Branching Chat\")\n",
    "\n",
    "# Initialize tree\n",
    "if \"tree\" not in st.session_state:\n",
    "    st.session_state.tree = ConversationTree()\n",
    "\n",
    "tree = st.session_state.tree\n",
    "\n",
    "# Sidebar: Branch navigation\n",
    "with st.sidebar:\n",
    "    st.header(\"ðŸŒ¿ Branches\")\n",
    "    \n",
    "    branch_points = tree.get_branch_points()\n",
    "    if branch_points:\n",
    "        st.write(\"Messages with branches:\")\n",
    "        for bp in branch_points:\n",
    "            if st.button(f\"â†©ï¸ {bp[\\'content\\']}\", key=bp[\"id\"]):\n",
    "                tree.branch_from(bp[\"id\"])\n",
    "                st.rerun()\n",
    "    else:\n",
    "        st.info(\"No branches yet. Try regenerating a response!\")\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    st.write(f\"Messages: {len(tree.messages)}\")\n",
    "    st.write(f\"Current path: {len(tree.current_path)}\")\n",
    "\n",
    "# Display current branch\n",
    "for msg in tree.get_current_history():\n",
    "    with st.chat_message(msg.role):\n",
    "        st.write(msg.content)\n",
    "        \n",
    "        # Show branch indicator\n",
    "        if len(msg.children) > 1:\n",
    "            st.caption(f\"ðŸŒ¿ {len(msg.children)} branches\")\n",
    "        \n",
    "        # Regenerate button for assistant messages\n",
    "        if msg.role == \"assistant\" and msg.id == tree.current_path[-1]:\n",
    "            if st.button(\"ðŸ”„ Try different response\", key=f\"regen_{msg.id}\"):\n",
    "                # Go back to parent and regenerate\n",
    "                tree.branch_from(msg.parent_id)\n",
    "                st.session_state.regenerate = True\n",
    "                st.rerun()\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Type a message...\"):\n",
    "    tree.add_message(\"user\", prompt)\n",
    "    \n",
    "    # Generate response (mock)\n",
    "    import random\n",
    "    responses = [\n",
    "        f\"Response A: {prompt}\",\n",
    "        f\"Response B: {prompt}\",\n",
    "        f\"Response C: {prompt}\"\n",
    "    ]\n",
    "    response = random.choice(responses)\n",
    "    tree.add_message(\"assistant\", response)\n",
    "    \n",
    "    st.rerun()\n",
    "'''\n",
    "\n",
    "print(\"Branching chat solution:\")\n",
    "print(branching_chat[:2000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 4: Dynamic Tool Creation\n",
    "\n",
    "Allow users to define new tools through the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_tools = '''\n",
    "\"\"\"Dynamic Tool Creation Page\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import json\n",
    "\n",
    "st.set_page_config(page_title=\"Tool Builder\", page_icon=\"ðŸ”¨\")\n",
    "st.title(\"ðŸ”¨ Dynamic Tool Builder\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Create custom tools for the agent. Define the tool\\'s name, description,\n",
    "and a Python function to execute.\n",
    "\"\"\")\n",
    "\n",
    "# Initialize custom tools\n",
    "if \"custom_tools\" not in st.session_state:\n",
    "    st.session_state.custom_tools = {}\n",
    "\n",
    "# Tool creation form\n",
    "with st.expander(\"âž• Create New Tool\", expanded=True):\n",
    "    with st.form(\"new_tool\"):\n",
    "        tool_name = st.text_input(\n",
    "            \"Tool Name\",\n",
    "            placeholder=\"my_custom_tool\",\n",
    "            help=\"Use lowercase with underscores\"\n",
    "        )\n",
    "        \n",
    "        tool_description = st.text_area(\n",
    "            \"Description\",\n",
    "            placeholder=\"What does this tool do?\",\n",
    "            help=\"Clear description helps the agent decide when to use it\"\n",
    "        )\n",
    "        \n",
    "        tool_params = st.text_area(\n",
    "            \"Parameters (JSON)\",\n",
    "            value=\\'\\'\\'{\"param1\": \"string\", \"param2\": \"number\"}\\'\\'\\',\n",
    "            help=\"Define input parameters as JSON\"\n",
    "        )\n",
    "        \n",
    "        tool_code = st.text_area(\n",
    "            \"Python Code\",\n",
    "            value=\"\"\"def execute(params):\n",
    "    # Access params like: params[\"param1\"]\n",
    "    result = f\"Processed: {params}\"\n",
    "    return result\"\"\",\n",
    "            height=200,\n",
    "            help=\"Define the execute function\"\n",
    "        )\n",
    "        \n",
    "        submitted = st.form_submit_button(\"Create Tool\")\n",
    "        \n",
    "        if submitted and tool_name:\n",
    "            try:\n",
    "                # Validate JSON\n",
    "                params = json.loads(tool_params)\n",
    "                \n",
    "                # Store tool definition\n",
    "                st.session_state.custom_tools[tool_name] = {\n",
    "                    \"name\": tool_name,\n",
    "                    \"description\": tool_description,\n",
    "                    \"parameters\": params,\n",
    "                    \"code\": tool_code\n",
    "                }\n",
    "                \n",
    "                st.success(f\"Tool \\'{tool_name}\\' created!\")\n",
    "            except json.JSONDecodeError:\n",
    "                st.error(\"Invalid JSON in parameters\")\n",
    "\n",
    "# List existing custom tools\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"ðŸ“‹ Custom Tools\")\n",
    "\n",
    "if st.session_state.custom_tools:\n",
    "    for name, tool in st.session_state.custom_tools.items():\n",
    "        with st.expander(f\"ðŸ”§ {name}\"):\n",
    "            st.markdown(f\"**Description:** {tool[\\'description\\']}\")\n",
    "            st.markdown(\"**Parameters:**\")\n",
    "            st.json(tool[\"parameters\"])\n",
    "            st.markdown(\"**Code:**\")\n",
    "            st.code(tool[\"code\"], language=\"python\")\n",
    "            \n",
    "            col1, col2 = st.columns(2)\n",
    "            with col1:\n",
    "                if st.button(\"Test\", key=f\"test_{name}\"):\n",
    "                    # Execute the tool with sample params\n",
    "                    try:\n",
    "                        exec_globals = {}\n",
    "                        exec(tool[\"code\"], exec_globals)\n",
    "                        result = exec_globals[\"execute\"]({\n",
    "                            k: f\"test_{k}\" for k in tool[\"parameters\"]\n",
    "                        })\n",
    "                        st.success(f\"Result: {result}\")\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"Error: {e}\")\n",
    "            \n",
    "            with col2:\n",
    "                if st.button(\"Delete\", key=f\"del_{name}\"):\n",
    "                    del st.session_state.custom_tools[name]\n",
    "                    st.rerun()\n",
    "else:\n",
    "    st.info(\"No custom tools yet. Create one above!\")\n",
    "\n",
    "# Export tools\n",
    "st.markdown(\"---\")\n",
    "if st.session_state.custom_tools:\n",
    "    export_data = json.dumps(st.session_state.custom_tools, indent=2)\n",
    "    st.download_button(\n",
    "        \"ðŸ“¥ Export Tools\",\n",
    "        data=export_data,\n",
    "        file_name=\"custom_tools.json\",\n",
    "        mime=\"application/json\"\n",
    "    )\n",
    "'''\n",
    "\n",
    "print(\"Dynamic tool creation page:\")\n",
    "print(dynamic_tools[:2000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Streaming** dramatically improves perceived responsiveness\n",
    "2. **Latency tracking** helps identify performance bottlenecks\n",
    "3. **Conversation branching** enables exploration of alternatives\n",
    "4. **Dynamic tools** make the agent extensible by users\n",
    "\n",
    "These patterns make your agent playground more powerful and user-friendly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
