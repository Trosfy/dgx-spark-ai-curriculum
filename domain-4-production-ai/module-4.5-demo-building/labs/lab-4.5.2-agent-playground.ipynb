{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.5.2: Agent Playground with Streamlit\n",
    "\n",
    "**Module:** 4.5 - Demo Building & Prototyping  \n",
    "**Time:** 3 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê (Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Build multi-page Streamlit applications\n",
    "- [ ] Implement session state for conversation persistence\n",
    "- [ ] Visualize agent reasoning and tool calls\n",
    "- [ ] Use caching effectively for model loading\n",
    "- [ ] Deploy to Streamlit Cloud\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Module 3.6 (AI Agents)\n",
    "- Knowledge of: Python, basic Streamlit, agent concepts\n",
    "- Installed: `streamlit`, `ollama`\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "AI agents are powerful but **opaque**. When an agent takes 30 seconds to respond, what's happening inside? Which tools did it use? What was it \"thinking\"?\n",
    "\n",
    "Companies like [LangSmith](https://smith.langchain.com/) and [Weights & Biases](https://wandb.ai/) offer commercial solutions for agent observability. But for demos and debugging, a simple visualization tool is invaluable.\n",
    "\n",
    "In this lab, we'll build an \"Agent Playground\" that:\n",
    "- Shows tool calls in real-time\n",
    "- Displays the agent's \"thinking\" process\n",
    "- Lets users toggle tools on/off\n",
    "- Tracks conversation history\n",
    "\n",
    "---\n",
    "\n",
    "## üßí ELI5: Why Streamlit?\n",
    "\n",
    "> **Gradio vs Streamlit is like McDonald's vs Chipotle:**\n",
    ">\n",
    "> - **Gradio (McDonald's)**: Super fast, standard menu, you know exactly what you're getting. Great for quick demos with inputs‚Üíoutputs.\n",
    ">\n",
    "> - **Streamlit (Chipotle)**: More choices, you build your own thing, takes a bit longer but more customizable. Great for dashboards and multi-page apps.\n",
    ">\n",
    "> **When to use which:**\n",
    "> - Gradio: ML demos, API wrappers, quick prototypes\n",
    "> - Streamlit: Dashboards, data apps, complex multi-page experiences\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Streamlit Fundamentals\n",
    "\n",
    "### Understanding Streamlit's Execution Model\n",
    "\n",
    "**Critical concept:** Streamlit reruns your **entire script** whenever:\n",
    "- User interacts with a widget\n",
    "- Session state changes\n",
    "- You call `st.rerun()`\n",
    "\n",
    "This is very different from Gradio's event-driven model!\n",
    "\n",
    "### üßí ELI5: Streamlit's Rerun Model\n",
    "\n",
    "> Imagine you're drawing on an Etch-a-Sketch. Every time you turn a knob (user input), the screen **clears** and you redraw **everything** from scratch.\n",
    ">\n",
    "> That sounds slow, but Streamlit is smart - it caches expensive operations so you don't actually recalculate everything. Think of it as having a photo of your last drawing that you can quickly trace over.\n",
    "\n",
    "### Running Streamlit\n",
    "\n",
    "Unlike Gradio which runs in Jupyter, Streamlit apps run from the command line:\n",
    "\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "We'll write our code in cells and then combine into `.py` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# !pip install streamlit>=1.30.0 ollama>=0.1.0\n",
    "\n",
    "import streamlit as st\n",
    "print(f\"Streamlit version: {st.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Streamlit concepts - we'll write these to files\n",
    "# This cell shows the basic patterns\n",
    "\n",
    "basic_app = '''\n",
    "import streamlit as st\n",
    "\n",
    "# Page config must be first Streamlit command\n",
    "st.set_page_config(\n",
    "    page_title=\"My App\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Title\n",
    "st.title(\"Hello Streamlit!\")\n",
    "\n",
    "# Columns for side-by-side layout\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.header(\"Input\")\n",
    "    name = st.text_input(\"Your name\")\n",
    "    age = st.slider(\"Your age\", 0, 100, 25)\n",
    "    \n",
    "with col2:\n",
    "    st.header(\"Output\")\n",
    "    if name:\n",
    "        st.write(f\"Hello, {name}! You are {age} years old.\")\n",
    "    else:\n",
    "        st.write(\"Enter your name to see a greeting.\")\n",
    "\n",
    "# Sidebar\n",
    "with st.sidebar:\n",
    "    st.header(\"Settings\")\n",
    "    show_debug = st.checkbox(\"Show debug info\")\n",
    "    \n",
    "if show_debug:\n",
    "    st.write(\"Debug mode enabled!\")\n",
    "    st.json({\"name\": name, \"age\": age})\n",
    "'''\n",
    "\n",
    "print(\"Basic Streamlit app structure:\")\n",
    "print(basic_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Session State - The Key to Persistence\n",
    "\n",
    "Since Streamlit reruns everything, how do we keep data between reruns?\n",
    "\n",
    "**Answer: `st.session_state`** - a dictionary that persists across reruns.\n",
    "\n",
    "### üßí ELI5: Session State\n",
    "\n",
    "> Imagine you're playing a video game where the console resets every second. How do you keep your score?\n",
    ">\n",
    "> You write it on a sticky note (session_state) before the reset, and read it back after!\n",
    ">\n",
    "> - `st.session_state.score = 100` ‚Üí Write to sticky note\n",
    "> - `score = st.session_state.score` ‚Üí Read from sticky note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session state example\n",
    "session_state_app = '''\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Counter with Session State\")\n",
    "\n",
    "# Initialize state (only runs if key doesn't exist)\n",
    "if \"count\" not in st.session_state:\n",
    "    st.session_state.count = 0\n",
    "\n",
    "# Display current count\n",
    "st.write(f\"Count: {st.session_state.count}\")\n",
    "\n",
    "# Buttons modify session state\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "    if st.button(\"Increment\"):\n",
    "        st.session_state.count += 1\n",
    "        st.rerun()  # Force rerun to show new value\n",
    "        \n",
    "with col2:\n",
    "    if st.button(\"Decrement\"):\n",
    "        st.session_state.count -= 1\n",
    "        st.rerun()\n",
    "        \n",
    "with col3:\n",
    "    if st.button(\"Reset\"):\n",
    "        st.session_state.count = 0\n",
    "        st.rerun()\n",
    "\n",
    "# Show all session state (debugging)\n",
    "with st.expander(\"Session State Debug\"):\n",
    "    st.write(dict(st.session_state))\n",
    "'''\n",
    "\n",
    "print(\"Session state patterns:\")\n",
    "print(session_state_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat History with Session State\n",
    "\n",
    "For chat apps, we store the conversation history in session state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with session state\n",
    "chat_app = '''\n",
    "import streamlit as st\n",
    "import ollama\n",
    "\n",
    "st.title(\"üí¨ Simple Chat\")\n",
    "\n",
    "# Initialize message history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# Chat input (special Streamlit component)\n",
    "if prompt := st.chat_input(\"Say something...\"):\n",
    "    # Add user message\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(prompt)\n",
    "    \n",
    "    # Generate response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = ollama.chat(\n",
    "                model=\"llama3.2:3b\",\n",
    "                messages=st.session_state.messages\n",
    "            )\n",
    "            reply = response[\"message\"][\"content\"]\n",
    "            st.write(reply)\n",
    "    \n",
    "    # Add assistant message\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "# Clear button in sidebar\n",
    "with st.sidebar:\n",
    "    if st.button(\"Clear Chat\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "'''\n",
    "\n",
    "print(\"Chat app with session state:\")\n",
    "print(chat_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Caching - Speed Up Your App\n",
    "\n",
    "Loading models on every rerun would be impossibly slow. Streamlit provides two caching decorators:\n",
    "\n",
    "| Decorator | Use For | Persists Across |\n",
    "|-----------|---------|----------------|\n",
    "| `@st.cache_data` | Data, computations | Sessions |\n",
    "| `@st.cache_resource` | Models, connections | App lifetime |\n",
    "\n",
    "### üßí ELI5: Caching\n",
    "\n",
    "> **`@st.cache_data`** is like putting leftovers in the fridge. You made dinner (computed something), now you store it to eat later without cooking again.\n",
    ">\n",
    "> **`@st.cache_resource`** is like leaving the stove on (safely!). The stove (model) is ready to cook instantly without waiting to heat up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching examples\n",
    "caching_code = '''\n",
    "import streamlit as st\n",
    "import ollama\n",
    "import time\n",
    "\n",
    "# Cache expensive data computations\n",
    "@st.cache_data(ttl=3600)  # Cache for 1 hour\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load and process data. Cached based on filepath.\"\"\"\n",
    "    # This only runs once per unique filepath\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data.describe()\n",
    "\n",
    "# Cache model/client connections\n",
    "@st.cache_resource\n",
    "def get_ollama_client():\n",
    "    \"\"\"Initialize Ollama client once.\"\"\"\n",
    "    # This only runs once per app lifetime\n",
    "    return ollama.Client()\n",
    "\n",
    "@st.cache_resource\n",
    "def load_embedding_model():\n",
    "    \"\"\"Pre-load embedding model.\"\"\"\n",
    "    client = get_ollama_client()\n",
    "    # Warm up the model by running a test embedding\n",
    "    client.embeddings(model=\"qwen3-embedding:8b\", prompt=\"test\")\n",
    "    return client\n",
    "\n",
    "# Use in app\n",
    "st.title(\"Caching Demo\")\n",
    "\n",
    "# This is instant after first load\n",
    "client = get_ollama_client()\n",
    "\n",
    "# Show cache info\n",
    "st.write(\"Model loaded and cached!\")\n",
    "'''\n",
    "\n",
    "print(\"Caching patterns:\")\n",
    "print(caching_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Building the Agent Playground\n",
    "\n",
    "Now let's build our multi-page Agent Playground!\n",
    "\n",
    "### Multi-Page App Structure\n",
    "\n",
    "```\n",
    "agent_playground/\n",
    "‚îú‚îÄ‚îÄ Home.py                 # Main entry point\n",
    "‚îú‚îÄ‚îÄ pages/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 1_üí¨_Chat.py       # Agent chat interface\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 2_üîß_Tools.py      # Tool configuration\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 3_üìä_History.py    # Session history & analytics\n",
    "‚îú‚îÄ‚îÄ utils/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ agent.py           # Agent logic\n",
    "‚îî‚îÄ‚îÄ .streamlit/\n",
    "    ‚îî‚îÄ‚îÄ config.toml        # Streamlit configuration\n",
    "```\n",
    "\n",
    "Streamlit automatically creates navigation from files in `pages/`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the app structure\n",
    "app_dir = \"agent_playground\"\n",
    "os.makedirs(f\"{app_dir}/pages\", exist_ok=True)\n",
    "os.makedirs(f\"{app_dir}/utils\", exist_ok=True)\n",
    "os.makedirs(f\"{app_dir}/.streamlit\", exist_ok=True)\n",
    "\n",
    "print(f\"Created directory structure in {app_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the agent utility module\n",
    "agent_utils = '''\n",
    "\"\"\"Agent utilities for the playground.\"\"\"\n",
    "\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "from typing import Dict, List, Any, Optional, Callable\n",
    "import ollama\n",
    "\n",
    "\n",
    "# ===== TOOL DEFINITIONS =====\n",
    "\n",
    "AVAILABLE_TOOLS = {\n",
    "    \"calculator\": {\n",
    "        \"name\": \"calculator\",\n",
    "        \"description\": \"Perform mathematical calculations. Input should be a valid math expression.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The math expression to evaluate, e.g., \\'2 + 2\\' or \\'sin(3.14)\\'\"}\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    },\n",
    "    \"datetime\": {\n",
    "        \"name\": \"get_datetime\",\n",
    "        \"description\": \"Get the current date and time.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    \"weather\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get weather information for a location (mock data).\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city name, e.g., \\'San Francisco\\'\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    \"web_search\": {\n",
    "        \"name\": \"web_search\",\n",
    "        \"description\": \"Search the web for information (mock data).\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The search query\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# ===== TOOL IMPLEMENTATIONS =====\n",
    "\n",
    "def execute_calculator(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate a math expression.\"\"\"\n",
    "    try:\n",
    "        # Safe math namespace\n",
    "        safe_dict = {\n",
    "            \"__builtins__\": {},\n",
    "            \"abs\": abs, \"round\": round,\n",
    "            \"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan,\n",
    "            \"sqrt\": math.sqrt, \"log\": math.log, \"log10\": math.log10,\n",
    "            \"pi\": math.pi, \"e\": math.e,\n",
    "            \"pow\": pow, \"exp\": math.exp\n",
    "        }\n",
    "        result = eval(expression, safe_dict)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating \\'{expression}\\': {str(e)}\"\n",
    "\n",
    "\n",
    "def execute_datetime() -> str:\n",
    "    \"\"\"Get current date and time.\"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"Current date and time: %Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def execute_weather(location: str) -> str:\n",
    "    \"\"\"Mock weather data.\"\"\"\n",
    "    # In a real app, call a weather API\n",
    "    import random\n",
    "    conditions = [\"Sunny\", \"Cloudy\", \"Rainy\", \"Partly Cloudy\"]\n",
    "    temp = random.randint(50, 85)\n",
    "    return f\"Weather in {location}: {random.choice(conditions)}, {temp}¬∞F\"\n",
    "\n",
    "\n",
    "def execute_web_search(query: str) -> str:\n",
    "    \"\"\"Mock web search.\"\"\"\n",
    "    # In a real app, use a search API\n",
    "    return f\"Search results for \\'{query}\\': [Mock] Found 10 results about {query}. Top result: Wikipedia article on {query}.\"\n",
    "\n",
    "\n",
    "TOOL_EXECUTORS = {\n",
    "    \"calculator\": execute_calculator,\n",
    "    \"get_datetime\": execute_datetime,\n",
    "    \"get_weather\": execute_weather,\n",
    "    \"web_search\": execute_web_search\n",
    "}\n",
    "\n",
    "\n",
    "# ===== AGENT CLASS =====\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    A simple tool-using agent.\n",
    "    \n",
    "    This agent can:\n",
    "    1. Receive user messages\n",
    "    2. Decide which tools to use\n",
    "    3. Execute tools and incorporate results\n",
    "    4. Generate final response\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"llama3.2:3b\", enabled_tools: List[str] = None):\n",
    "        self.model = model\n",
    "        self.enabled_tools = enabled_tools or list(AVAILABLE_TOOLS.keys())\n",
    "        self.conversation_history: List[Dict] = []\n",
    "        self.tool_calls_log: List[Dict] = []\n",
    "        self.thinking_log: List[str] = []\n",
    "    \n",
    "    def get_active_tools(self) -> List[Dict]:\n",
    "        \"\"\"Get tool definitions for enabled tools.\"\"\"\n",
    "        return [\n",
    "            AVAILABLE_TOOLS[tool]\n",
    "            for tool in self.enabled_tools\n",
    "            if tool in AVAILABLE_TOOLS\n",
    "        ]\n",
    "    \n",
    "    def execute_tool(self, tool_name: str, args: Dict) -> str:\n",
    "        \"\"\"Execute a tool and return the result.\"\"\"\n",
    "        executor = TOOL_EXECUTORS.get(tool_name)\n",
    "        if not executor:\n",
    "            return f\"Unknown tool: {tool_name}\"\n",
    "        \n",
    "        try:\n",
    "            if tool_name == \"calculator\":\n",
    "                return executor(args.get(\"expression\", \"\"))\n",
    "            elif tool_name == \"get_datetime\":\n",
    "                return executor()\n",
    "            elif tool_name == \"get_weather\":\n",
    "                return executor(args.get(\"location\", \"Unknown\"))\n",
    "            elif tool_name == \"web_search\":\n",
    "                return executor(args.get(\"query\", \"\"))\n",
    "            else:\n",
    "                return f\"No executor for {tool_name}\"\n",
    "        except Exception as e:\n",
    "            return f\"Tool error: {str(e)}\"\n",
    "    \n",
    "    def chat(self, user_message: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a user message and generate a response.\n",
    "        \n",
    "        Returns a dict with:\n",
    "        - content: The final response text\n",
    "        - tool_calls: List of tools called\n",
    "        - thinking: Any reasoning/thinking text\n",
    "        \"\"\"\n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        })\n",
    "        \n",
    "        # Build system prompt with tool info\n",
    "        tools = self.get_active_tools()\n",
    "        tool_descriptions = \"\\n\".join([\n",
    "            f\"- {t['name']}: {t['description']}\"\n",
    "            for t in tools\n",
    "        ])\n",
    "        \n",
    "        system_prompt = f\"\"\"You are a helpful AI assistant with access to tools.\n",
    "\n",
    "Available tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "To use a tool, respond with:\n",
    "<tool>tool_name</tool>\n",
    "<args>{{\"param\": \"value\"}}</args>\n",
    "\n",
    "You can use multiple tools. After getting tool results, provide your final answer.\n",
    "If you don't need tools, just respond directly.\n",
    "\n",
    "Think step by step about what the user needs.\"\"\"\n",
    "        \n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        messages.extend(self.conversation_history)\n",
    "        \n",
    "        # First LLM call - decide on tools\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        assistant_content = response[\"message\"][\"content\"]\n",
    "        tool_calls = []\n",
    "        thinking = \"\"\n",
    "        \n",
    "        # Parse tool calls from response\n",
    "        import re\n",
    "        tool_pattern = r\"<tool>(.*?)</tool>\\s*<args>(.*?)</args>\"\n",
    "        matches = re.findall(tool_pattern, assistant_content, re.DOTALL)\n",
    "        \n",
    "        if matches:\n",
    "            # Extract thinking (text before first tool call)\n",
    "            first_tool_pos = assistant_content.find(\"<tool>\")\n",
    "            if first_tool_pos > 0:\n",
    "                thinking = assistant_content[:first_tool_pos].strip()\n",
    "            \n",
    "            # Execute tools\n",
    "            tool_results = []\n",
    "            for tool_name, args_str in matches:\n",
    "                tool_name = tool_name.strip()\n",
    "                try:\n",
    "                    args = json.loads(args_str.strip())\n",
    "                except:\n",
    "                    args = {}\n",
    "                \n",
    "                result = self.execute_tool(tool_name, args)\n",
    "                tool_call = {\n",
    "                    \"tool\": tool_name,\n",
    "                    \"args\": args,\n",
    "                    \"result\": result\n",
    "                }\n",
    "                tool_calls.append(tool_call)\n",
    "                tool_results.append(f\"Tool {tool_name} result: {result}\")\n",
    "            \n",
    "            # Add tool results and get final response\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_content})\n",
    "            messages.append({\"role\": \"user\", \"content\": \"Tool results:\\n\" + \"\\n\".join(tool_results) + \"\\n\\nNow provide your final answer based on these results.\"})\n",
    "            \n",
    "            final_response = ollama.chat(\n",
    "                model=self.model,\n",
    "                messages=messages\n",
    "            )\n",
    "            final_content = final_response[\"message\"][\"content\"]\n",
    "        else:\n",
    "            final_content = assistant_content\n",
    "        \n",
    "        # Log and update history\n",
    "        self.tool_calls_log.extend(tool_calls)\n",
    "        if thinking:\n",
    "            self.thinking_log.append(thinking)\n",
    "        \n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": final_content\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": final_content,\n",
    "            \"tool_calls\": tool_calls,\n",
    "            \"thinking\": thinking\n",
    "        }\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history.\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.tool_calls_log = []\n",
    "        self.thinking_log = []\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get agent statistics.\"\"\"\n",
    "        return {\n",
    "            \"messages\": len(self.conversation_history),\n",
    "            \"tool_calls\": len(self.tool_calls_log),\n",
    "            \"enabled_tools\": self.enabled_tools,\n",
    "            \"model\": self.model\n",
    "        }\n",
    "'''\n",
    "\n",
    "# Write agent utils\n",
    "with open(f\"{app_dir}/utils/agent.py\", \"w\") as f:\n",
    "    f.write(agent_utils)\n",
    "\n",
    "# Create __init__.py\n",
    "with open(f\"{app_dir}/utils/__init__.py\", \"w\") as f:\n",
    "    f.write(\"from .agent import Agent, AVAILABLE_TOOLS\\n\")\n",
    "\n",
    "print(\"Created agent utility module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create Home.py - Main entry point\n",
    "home_py = '''\n",
    "\"\"\"Agent Playground - Home Page\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Agent Playground\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Initialize session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"tool_calls\" not in st.session_state:\n",
    "    st.session_state.tool_calls = []\n",
    "if \"enabled_tools\" not in st.session_state:\n",
    "    st.session_state.enabled_tools = [\"calculator\", \"datetime\", \"weather\", \"web_search\"]\n",
    "if \"model\" not in st.session_state:\n",
    "    st.session_state.model = \"llama3.2:3b\"\n",
    "\n",
    "# Main content\n",
    "st.title(\"ü§ñ Agent Playground\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Welcome to the Agent Playground! This app lets you:\n",
    "\n",
    "- **Chat** with an AI agent that can use tools\n",
    "- **Visualize** the agent's reasoning process\n",
    "- **Configure** which tools are available\n",
    "- **Analyze** conversation history\n",
    "\n",
    "---\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "1. **Configure Tools** ‚Üí Go to üîß Tools to enable/disable tools\n",
    "2. **Start Chatting** ‚Üí Go to üí¨ Chat to interact with the agent\n",
    "3. **Review History** ‚Üí Go to üìä History to see analytics\n",
    "\n",
    "---\n",
    "\"\"\")\n",
    "\n",
    "# Quick stats\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "    st.metric(\n",
    "        \"Messages\",\n",
    "        len(st.session_state.messages),\n",
    "        help=\"Total messages in current conversation\"\n",
    "    )\n",
    "\n",
    "with col2:\n",
    "    st.metric(\n",
    "        \"Tool Calls\",\n",
    "        len(st.session_state.tool_calls),\n",
    "        help=\"Total tool invocations\"\n",
    "    )\n",
    "\n",
    "with col3:\n",
    "    st.metric(\n",
    "        \"Active Tools\",\n",
    "        len(st.session_state.enabled_tools),\n",
    "        help=\"Number of enabled tools\"\n",
    "    )\n",
    "\n",
    "# Sidebar info\n",
    "with st.sidebar:\n",
    "    st.markdown(\"### Current Settings\")\n",
    "    st.info(f\"**Model:** {st.session_state.model}\")\n",
    "    st.info(f\"**Tools:** {', '.join(st.session_state.enabled_tools) or 'None'}\")\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"*Built with Streamlit | Module 4.5*\")\n",
    "'''\n",
    "\n",
    "with open(f\"{app_dir}/Home.py\", \"w\") as f:\n",
    "    f.write(home_py)\n",
    "\n",
    "print(\"Created Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Chat page\n",
    "chat_page = '''\n",
    "\"\"\"Agent Playground - Chat Page\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent))\n",
    "from utils.agent import Agent, AVAILABLE_TOOLS\n",
    "\n",
    "st.set_page_config(page_title=\"Chat - Agent Playground\", page_icon=\"üí¨\", layout=\"wide\")\n",
    "\n",
    "st.title(\"üí¨ Agent Chat\")\n",
    "\n",
    "# Initialize agent in session state\n",
    "@st.cache_resource\n",
    "def get_agent(model: str, tools: tuple):\n",
    "    \"\"\"Create agent - cached by model and tools.\"\"\"\n",
    "    return Agent(model=model, enabled_tools=list(tools))\n",
    "\n",
    "# Get current settings\n",
    "model = st.session_state.get(\"model\", \"llama3.2:3b\")\n",
    "enabled_tools = st.session_state.get(\"enabled_tools\", list(AVAILABLE_TOOLS.keys()))\n",
    "\n",
    "# Create agent (tuple for hashability)\n",
    "agent = get_agent(model, tuple(enabled_tools))\n",
    "\n",
    "# Restore history from session state\n",
    "if st.session_state.messages:\n",
    "    agent.conversation_history = [\n",
    "        {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
    "        for m in st.session_state.messages\n",
    "    ]\n",
    "\n",
    "# Layout: Chat on left, Tool visualization on right\n",
    "chat_col, tool_col = st.columns([2, 1])\n",
    "\n",
    "with chat_col:\n",
    "    st.markdown(\"### Conversation\")\n",
    "    \n",
    "    # Chat container\n",
    "    chat_container = st.container(height=500)\n",
    "    \n",
    "    with chat_container:\n",
    "        # Display messages\n",
    "        for msg in st.session_state.messages:\n",
    "            with st.chat_message(msg[\"role\"]):\n",
    "                st.write(msg[\"content\"])\n",
    "                \n",
    "                # Show tool calls if present\n",
    "                if msg.get(\"tool_calls\"):\n",
    "                    with st.expander(\"üîß Tool Calls\", expanded=False):\n",
    "                        for tc in msg[\"tool_calls\"]:\n",
    "                            st.code(json.dumps(tc, indent=2), language=\"json\")\n",
    "                \n",
    "                # Show thinking if present\n",
    "                if msg.get(\"thinking\"):\n",
    "                    with st.expander(\"üí≠ Thinking\", expanded=False):\n",
    "                        st.markdown(msg[\"thinking\"])\n",
    "    \n",
    "    # Chat input\n",
    "    if prompt := st.chat_input(\"Ask the agent something...\"):\n",
    "        # Add user message\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        # Get agent response\n",
    "        with st.spinner(\"Agent is thinking...\"):\n",
    "            response = agent.chat(prompt)\n",
    "        \n",
    "        # Store response with metadata\n",
    "        st.session_state.messages.append(response)\n",
    "        \n",
    "        # Update tool calls log\n",
    "        if response.get(\"tool_calls\"):\n",
    "            st.session_state.tool_calls.extend(response[\"tool_calls\"])\n",
    "        \n",
    "        # Rerun to show new messages\n",
    "        st.rerun()\n",
    "    \n",
    "    # Clear button\n",
    "    if st.button(\"üóëÔ∏è Clear Chat\"):\n",
    "        st.session_state.messages = []\n",
    "        st.session_state.tool_calls = []\n",
    "        agent.clear_history()\n",
    "        st.rerun()\n",
    "\n",
    "with tool_col:\n",
    "    st.markdown(\"### üîß Tool Activity\")\n",
    "    \n",
    "    # Show enabled tools\n",
    "    st.markdown(\"**Enabled Tools:**\")\n",
    "    for tool in enabled_tools:\n",
    "        st.markdown(f\"- ‚úÖ {tool}\")\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Show recent tool calls\n",
    "    st.markdown(\"**Recent Tool Calls:**\")\n",
    "    \n",
    "    if st.session_state.tool_calls:\n",
    "        for i, tc in enumerate(reversed(st.session_state.tool_calls[-5:])):\n",
    "            with st.container(border=True):\n",
    "                st.markdown(f\"**{tc['tool']}**\")\n",
    "                st.caption(f\"Args: {tc.get('args', {})}\")\n",
    "                st.success(f\"Result: {tc.get('result', 'N/A')[:100]}...\")\n",
    "    else:\n",
    "        st.info(\"No tool calls yet. Ask the agent something that requires tools!\")\n",
    "    \n",
    "    # Example prompts\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"**Try these:**\")\n",
    "    examples = [\n",
    "        \"What is 25 * 4 + 100?\",\n",
    "        \"What time is it?\",\n",
    "        \"What's the weather in Tokyo?\",\n",
    "        \"Search for Python tutorials\"\n",
    "    ]\n",
    "    for ex in examples:\n",
    "        st.markdown(f\"- *{ex}*\")\n",
    "'''\n",
    "\n",
    "with open(f\"{app_dir}/pages/1_üí¨_Chat.py\", \"w\") as f:\n",
    "    f.write(chat_page)\n",
    "\n",
    "print(\"Created Chat page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create Tools configuration page\n",
    "tools_page = '''\n",
    "\"\"\"Agent Playground - Tools Configuration Page\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent))\n",
    "from utils.agent import AVAILABLE_TOOLS\n",
    "\n",
    "st.set_page_config(page_title=\"Tools - Agent Playground\", page_icon=\"üîß\", layout=\"wide\")\n",
    "\n",
    "st.title(\"üîß Tool Configuration\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Configure which tools the agent can use. Enable tools that match your use case.\n",
    "\"\"\")\n",
    "\n",
    "# Initialize enabled tools in session state\n",
    "if \"enabled_tools\" not in st.session_state:\n",
    "    st.session_state.enabled_tools = list(AVAILABLE_TOOLS.keys())\n",
    "\n",
    "# Tool toggle section\n",
    "st.markdown(\"### Enable/Disable Tools\")\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "tool_items = list(AVAILABLE_TOOLS.items())\n",
    "half = len(tool_items) // 2 + len(tool_items) % 2\n",
    "\n",
    "# Left column\n",
    "with col1:\n",
    "    for tool_key, tool_info in tool_items[:half]:\n",
    "        with st.container(border=True):\n",
    "            enabled = st.checkbox(\n",
    "                f\"**{tool_info['name']}**\",\n",
    "                value=tool_key in st.session_state.enabled_tools,\n",
    "                key=f\"tool_{tool_key}\"\n",
    "            )\n",
    "            st.caption(tool_info[\"description\"])\n",
    "            \n",
    "            # Update session state\n",
    "            if enabled and tool_key not in st.session_state.enabled_tools:\n",
    "                st.session_state.enabled_tools.append(tool_key)\n",
    "            elif not enabled and tool_key in st.session_state.enabled_tools:\n",
    "                st.session_state.enabled_tools.remove(tool_key)\n",
    "\n",
    "# Right column\n",
    "with col2:\n",
    "    for tool_key, tool_info in tool_items[half:]:\n",
    "        with st.container(border=True):\n",
    "            enabled = st.checkbox(\n",
    "                f\"**{tool_info['name']}**\",\n",
    "                value=tool_key in st.session_state.enabled_tools,\n",
    "                key=f\"tool_{tool_key}\"\n",
    "            )\n",
    "            st.caption(tool_info[\"description\"])\n",
    "            \n",
    "            if enabled and tool_key not in st.session_state.enabled_tools:\n",
    "                st.session_state.enabled_tools.append(tool_key)\n",
    "            elif not enabled and tool_key in st.session_state.enabled_tools:\n",
    "                st.session_state.enabled_tools.remove(tool_key)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Quick actions\n",
    "st.markdown(\"### Quick Actions\")\n",
    "\n",
    "quick_col1, quick_col2, quick_col3 = st.columns(3)\n",
    "\n",
    "with quick_col1:\n",
    "    if st.button(\"Enable All\", use_container_width=True):\n",
    "        st.session_state.enabled_tools = list(AVAILABLE_TOOLS.keys())\n",
    "        st.rerun()\n",
    "\n",
    "with quick_col2:\n",
    "    if st.button(\"Disable All\", use_container_width=True):\n",
    "        st.session_state.enabled_tools = []\n",
    "        st.rerun()\n",
    "\n",
    "with quick_col3:\n",
    "    if st.button(\"Reset to Default\", use_container_width=True):\n",
    "        st.session_state.enabled_tools = [\"calculator\", \"datetime\"]\n",
    "        st.rerun()\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Test tools section\n",
    "st.markdown(\"### üß™ Test Tools\")\n",
    "st.markdown(\"Test individual tools before using them with the agent.\")\n",
    "\n",
    "test_tool = st.selectbox(\n",
    "    \"Select tool to test\",\n",
    "    options=list(AVAILABLE_TOOLS.keys()),\n",
    "    format_func=lambda x: AVAILABLE_TOOLS[x][\"name\"]\n",
    ")\n",
    "\n",
    "if test_tool == \"calculator\":\n",
    "    expr = st.text_input(\"Expression\", value=\"2 + 2 * 3\")\n",
    "    if st.button(\"Calculate\"):\n",
    "        from utils.agent import execute_calculator\n",
    "        result = execute_calculator(expr)\n",
    "        st.success(result)\n",
    "\n",
    "elif test_tool == \"datetime\":\n",
    "    if st.button(\"Get Time\"):\n",
    "        from utils.agent import execute_datetime\n",
    "        result = execute_datetime()\n",
    "        st.success(result)\n",
    "\n",
    "elif test_tool == \"weather\":\n",
    "    location = st.text_input(\"Location\", value=\"San Francisco\")\n",
    "    if st.button(\"Get Weather\"):\n",
    "        from utils.agent import execute_weather\n",
    "        result = execute_weather(location)\n",
    "        st.success(result)\n",
    "\n",
    "elif test_tool == \"web_search\":\n",
    "    query = st.text_input(\"Search Query\", value=\"Python tutorials\")\n",
    "    if st.button(\"Search\"):\n",
    "        from utils.agent import execute_web_search\n",
    "        result = execute_web_search(query)\n",
    "        st.success(result)\n",
    "\n",
    "# Model settings\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"### ‚öôÔ∏è Model Settings\")\n",
    "\n",
    "if \"model\" not in st.session_state:\n",
    "    st.session_state.model = \"llama3.2:3b\"\n",
    "\n",
    "model = st.selectbox(\n",
    "    \"LLM Model\",\n",
    "    options=[\"llama3.2:1b\", \"llama3.2:3b\", \"qwen3:8b\", \"mistral:7b\"],\n",
    "    index=[\"llama3.2:1b\", \"llama3.2:3b\", \"qwen3:8b\", \"mistral:7b\"].index(st.session_state.model)\n",
    ")\n",
    "st.session_state.model = model\n",
    "\n",
    "st.info(f\"Current model: **{model}**\")\n",
    "'''\n",
    "\n",
    "with open(f\"{app_dir}/pages/2_üîß_Tools.py\", \"w\") as f:\n",
    "    f.write(tools_page)\n",
    "\n",
    "print(\"Created Tools page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create History/Analytics page\n",
    "history_page = '''\n",
    "\"\"\"Agent Playground - History & Analytics Page\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "st.set_page_config(page_title=\"History - Agent Playground\", page_icon=\"üìä\", layout=\"wide\")\n",
    "\n",
    "st.title(\"üìä Session History & Analytics\")\n",
    "\n",
    "# Initialize session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"tool_calls\" not in st.session_state:\n",
    "    st.session_state.tool_calls = []\n",
    "\n",
    "# Overview metrics\n",
    "st.markdown(\"### Overview\")\n",
    "\n",
    "col1, col2, col3, col4 = st.columns(4)\n",
    "\n",
    "with col1:\n",
    "    user_msgs = len([m for m in st.session_state.messages if m.get(\"role\") == \"user\"])\n",
    "    st.metric(\"User Messages\", user_msgs)\n",
    "\n",
    "with col2:\n",
    "    assistant_msgs = len([m for m in st.session_state.messages if m.get(\"role\") == \"assistant\"])\n",
    "    st.metric(\"Agent Responses\", assistant_msgs)\n",
    "\n",
    "with col3:\n",
    "    st.metric(\"Tool Calls\", len(st.session_state.tool_calls))\n",
    "\n",
    "with col4:\n",
    "    if st.session_state.tool_calls:\n",
    "        tool_counts = Counter(tc[\"tool\"] for tc in st.session_state.tool_calls)\n",
    "        most_common = tool_counts.most_common(1)[0][0] if tool_counts else \"N/A\"\n",
    "    else:\n",
    "        most_common = \"N/A\"\n",
    "    st.metric(\"Most Used Tool\", most_common)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Tool usage breakdown\n",
    "st.markdown(\"### Tool Usage Breakdown\")\n",
    "\n",
    "if st.session_state.tool_calls:\n",
    "    tool_counts = Counter(tc[\"tool\"] for tc in st.session_state.tool_calls)\n",
    "    \n",
    "    # Simple bar chart using Streamlit\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\n",
    "        \"Tool\": list(tool_counts.keys()),\n",
    "        \"Calls\": list(tool_counts.values())\n",
    "    })\n",
    "    st.bar_chart(df.set_index(\"Tool\"))\n",
    "else:\n",
    "    st.info(\"No tool calls recorded yet. Start chatting with the agent!\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Conversation history\n",
    "st.markdown(\"### Conversation History\")\n",
    "\n",
    "if st.session_state.messages:\n",
    "    for i, msg in enumerate(st.session_state.messages):\n",
    "        with st.expander(\n",
    "            f\"{i+1}. {'üë§ User' if msg.get('role') == 'user' else 'ü§ñ Agent'}: {msg.get('content', '')[:50]}...\",\n",
    "            expanded=False\n",
    "        ):\n",
    "            st.markdown(f\"**Role:** {msg.get('role', 'unknown')}\")\n",
    "            st.markdown(f\"**Content:** {msg.get('content', '')}\")\n",
    "            \n",
    "            if msg.get(\"tool_calls\"):\n",
    "                st.markdown(\"**Tool Calls:**\")\n",
    "                st.json(msg[\"tool_calls\"])\n",
    "            \n",
    "            if msg.get(\"thinking\"):\n",
    "                st.markdown(\"**Thinking:**\")\n",
    "                st.markdown(msg[\"thinking\"])\n",
    "else:\n",
    "    st.info(\"No conversation history yet.\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Export options\n",
    "st.markdown(\"### Export\")\n",
    "\n",
    "export_col1, export_col2 = st.columns(2)\n",
    "\n",
    "with export_col1:\n",
    "    if st.session_state.messages:\n",
    "        json_export = json.dumps({\n",
    "            \"messages\": st.session_state.messages,\n",
    "            \"tool_calls\": st.session_state.tool_calls\n",
    "        }, indent=2)\n",
    "        \n",
    "        st.download_button(\n",
    "            \"üì• Download as JSON\",\n",
    "            data=json_export,\n",
    "            file_name=\"agent_conversation.json\",\n",
    "            mime=\"application/json\"\n",
    "        )\n",
    "\n",
    "with export_col2:\n",
    "    if st.session_state.messages:\n",
    "        # Markdown export\n",
    "        md_lines = [\"# Agent Conversation\\n\"]\n",
    "        for msg in st.session_state.messages:\n",
    "            role = \"User\" if msg.get(\"role\") == \"user\" else \"Agent\"\n",
    "            md_lines.append(f\"## {role}\\n\")\n",
    "            md_lines.append(f\"{msg.get('content', '')}\\n\")\n",
    "            if msg.get(\"tool_calls\"):\n",
    "                md_lines.append(\"\\n**Tool Calls:**\\n\")\n",
    "                md_lines.append(f\"```json\\n{json.dumps(msg['tool_calls'], indent=2)}\\n```\\n\")\n",
    "        \n",
    "        st.download_button(\n",
    "            \"üìÑ Download as Markdown\",\n",
    "            data=\"\\n\".join(md_lines),\n",
    "            file_name=\"agent_conversation.md\",\n",
    "            mime=\"text/markdown\"\n",
    "        )\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Clear all data\n",
    "st.markdown(\"### Danger Zone\")\n",
    "\n",
    "if st.button(\"üóëÔ∏è Clear All History\", type=\"primary\"):\n",
    "    st.session_state.messages = []\n",
    "    st.session_state.tool_calls = []\n",
    "    st.success(\"All history cleared!\")\n",
    "    st.rerun()\n",
    "'''\n",
    "\n",
    "with open(f\"{app_dir}/pages/3_üìä_History.py\", \"w\") as f:\n",
    "    f.write(history_page)\n",
    "\n",
    "print(\"Created History page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create Streamlit config\n",
    "config_toml = '''\n",
    "[theme]\n",
    "primaryColor = \"#007bff\"\n",
    "backgroundColor = \"#ffffff\"\n",
    "secondaryBackgroundColor = \"#f8f9fa\"\n",
    "textColor = \"#262730\"\n",
    "font = \"sans serif\"\n",
    "\n",
    "[server]\n",
    "maxUploadSize = 50\n",
    "enableCORS = false\n",
    "\n",
    "[browser]\n",
    "gatherUsageStats = false\n",
    "'''\n",
    "\n",
    "with open(f\"{app_dir}/.streamlit/config.toml\", \"w\") as f:\n",
    "    f.write(config_toml)\n",
    "\n",
    "print(\"Created Streamlit config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create requirements.txt for deployment\n",
    "requirements = '''streamlit>=1.30.0\n",
    "ollama>=0.1.0\n",
    "pandas>=2.0.0\n",
    "'''\n",
    "\n",
    "with open(f\"{app_dir}/requirements.txt\", \"w\") as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"\\n‚úÖ Agent Playground created!\")\n",
    "print(f\"\\nTo run: cd {app_dir} && streamlit run Home.py\")\n",
    "print(\"\\nFile structure:\")\n",
    "for root, dirs, files in os.walk(app_dir):\n",
    "    level = root.replace(app_dir, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f'{subindent}{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Running and Testing the App\n",
    "\n",
    "### Running Locally\n",
    "\n",
    "```bash\n",
    "# Navigate to app directory\n",
    "cd agent_playground\n",
    "\n",
    "# Run Streamlit\n",
    "streamlit run Home.py\n",
    "```\n",
    "\n",
    "The app will open at `http://localhost:8501`\n",
    "\n",
    "### Running in Docker\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "EXPOSE 8501\n",
    "\n",
    "CMD [\"streamlit\", \"run\", \"Home.py\", \"--server.address\", \"0.0.0.0\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Deploying to Streamlit Cloud\n",
    "\n",
    "### Step 1: Push to GitHub\n",
    "\n",
    "```bash\n",
    "# Initialize git repo\n",
    "cd agent_playground\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial agent playground\"\n",
    "\n",
    "# Create repo on GitHub, then:\n",
    "git remote add origin https://github.com/YOUR_USERNAME/agent-playground.git\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "### Step 2: Connect to Streamlit Cloud\n",
    "\n",
    "1. Go to [share.streamlit.io](https://share.streamlit.io/)\n",
    "2. Click \"New app\"\n",
    "3. Select your GitHub repo\n",
    "4. Set main file path: `Home.py`\n",
    "5. Click \"Deploy\"\n",
    "\n",
    "### Step 3: Configure Secrets\n",
    "\n",
    "If your app needs secrets (API keys, etc.), add them in the Streamlit Cloud dashboard:\n",
    "\n",
    "```toml\n",
    "# secrets.toml (in Streamlit Cloud dashboard)\n",
    "OLLAMA_HOST = \"your-ollama-server.com\"\n",
    "```\n",
    "\n",
    "Access in code:\n",
    "```python\n",
    "import streamlit as st\n",
    "ollama_host = st.secrets[\"OLLAMA_HOST\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Not Using Session State\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - counter resets on every rerun\n",
    "counter = 0\n",
    "if st.button(\"Increment\"):\n",
    "    counter += 1\n",
    "st.write(counter)  # Always shows 0 or 1\n",
    "\n",
    "# ‚úÖ Right - use session state\n",
    "if \"counter\" not in st.session_state:\n",
    "    st.session_state.counter = 0\n",
    "\n",
    "if st.button(\"Increment\"):\n",
    "    st.session_state.counter += 1\n",
    "\n",
    "st.write(st.session_state.counter)  # Persists!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 2: Loading Models Without Caching\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - loads on every rerun (slow!)\n",
    "model = load_heavy_model()\n",
    "\n",
    "# ‚úÖ Right - cache the resource\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    return load_heavy_model()\n",
    "\n",
    "model = load_model()  # Cached!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 3: Putting st.set_page_config After Other Commands\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - page config must be first\n",
    "import streamlit as st\n",
    "st.title(\"My App\")\n",
    "st.set_page_config(page_title=\"My App\")  # Error!\n",
    "\n",
    "# ‚úÖ Right - page config first\n",
    "import streamlit as st\n",
    "st.set_page_config(page_title=\"My App\")\n",
    "st.title(\"My App\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 4: Widget Key Collisions\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - duplicate keys cause errors\n",
    "for i in range(3):\n",
    "    st.text_input(\"Name\")  # Same key for all!\n",
    "\n",
    "# ‚úÖ Right - unique keys\n",
    "for i in range(3):\n",
    "    st.text_input(\"Name\", key=f\"name_{i}\")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Streamlit's rerun execution model\n",
    "- ‚úÖ Session state for persistence\n",
    "- ‚úÖ Caching strategies for performance\n",
    "- ‚úÖ Multi-page app structure\n",
    "- ‚úÖ Agent reasoning visualization\n",
    "- ‚úÖ Deploying to Streamlit Cloud\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Challenge (Optional)\n",
    "\n",
    "Enhance the Agent Playground with:\n",
    "\n",
    "1. **Streaming responses** - Show tokens as they're generated\n",
    "2. **Tool latency tracking** - Measure and display how long each tool takes\n",
    "3. **Conversation branching** - Let users go back and try different responses\n",
    "4. **Custom tool creation** - UI to define new tools dynamically\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hints</summary>\n",
    "\n",
    "- For streaming: Use `st.write_stream()` with a generator\n",
    "- For latency: Wrap tool execution in `time.time()` calls\n",
    "- For branching: Store conversation tree in session state\n",
    "- For custom tools: Use `st.text_area` for JSON tool definitions\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [Streamlit Documentation](https://docs.streamlit.io/)\n",
    "- [Session State Guide](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.session_state)\n",
    "- [Multi-page Apps](https://docs.streamlit.io/develop/concepts/multipage-apps)\n",
    "- [Streamlit Components](https://streamlit.io/components)\n",
    "- [Deploy to Streamlit Cloud](https://docs.streamlit.io/deploy/streamlit-community-cloud)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files are created on disk - nothing to clean in memory\n",
    "print(\"‚úÖ Lab complete!\")\n",
    "print(f\"\\nApp files are in: {app_dir}/\")\n",
    "print(f\"To run: cd {app_dir} && streamlit run Home.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚û°Ô∏è Next Steps\n",
    "\n",
    "Continue to [Lab 4.5.3: Portfolio Demo](lab-4.5.3-portfolio-demo.ipynb) to create a polished demo for your capstone project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
