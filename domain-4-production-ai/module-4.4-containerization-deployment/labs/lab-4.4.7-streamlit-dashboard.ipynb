{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Lab 4.4.7: Building a Streamlit Dashboard\n",
    "\n",
    "**Module:** 4.4 - Containerization & Cloud Deployment  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ⭐⭐ (Beginner-Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- [ ] Build multi-page Streamlit applications\n",
    "- [ ] Implement chat interfaces with session state\n",
    "- [ ] Create real-time metric dashboards\n",
    "- [ ] Add model comparison features\n",
    "- [ ] Deploy to Streamlit Cloud\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic Python knowledge\n",
    "- Completed: Lab 4.4.6 (Gradio Demo)\n",
    "- Ollama running locally (optional, mock mode available)\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "**Why Streamlit over Gradio?**\n",
    "\n",
    "| Feature | Gradio | Streamlit |\n",
    "|---------|--------|----------|\n",
    "| Best for | ML demos | Data apps |\n",
    "| Multi-page | Limited | Native |\n",
    "| Charts | Basic | Plotly/Altair |\n",
    "| State mgmt | Limited | Full session state |\n",
    "| Customization | Themes | Full Python |\n",
    "\n",
    "**Use Streamlit when you need:**\n",
    "- Multi-page applications\n",
    "- Rich data visualizations\n",
    "- Complex state management\n",
    "- Internal tools/dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eli5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ELI5: What is Streamlit?\n",
    "\n",
    "> **Imagine you want to build a control panel for a spaceship...**\n",
    ">\n",
    "> Gradio is like a ready-made control panel - buttons, sliders, screens all pre-designed. Great for quick demos!\n",
    ">\n",
    "> **Streamlit is like a modular control panel kit.** You pick exactly which buttons, screens, and gauges you want, arrange them your way, and can build multi-room control centers (multi-page apps).\n",
    ">\n",
    "> **In AI terms:**\n",
    "> - Streamlit = Build custom dashboards with Python\n",
    "> - Session state = Remember things between button clicks\n",
    "> - Caching = Don't reload the model every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Streamlit if needed\n",
    "# !pip install streamlit>=1.30.0 plotly>=5.18.0\n",
    "\n",
    "import streamlit as st\n",
    "print(f\"Streamlit version: {st.__version__}\")\n",
    "\n",
    "# Note: Streamlit apps can't run directly in notebooks\n",
    "# We'll write the code to files and run with 'streamlit run'\n",
    "print(\"\\nStreamlit apps are run with: streamlit run app.py\")\n",
    "print(\"We'll create the files in this notebook and you can run them locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our demo utilities\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from scripts.demo_utils import (\n",
    "    StreamingLLMClient,\n",
    "    MockLLMClient,\n",
    "    create_streamlit_dashboard,\n",
    ")\n",
    "\n",
    "print(\"Demo utilities loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Your First Streamlit App\n",
    "\n",
    "Let's start with a simple \"Hello World\" Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part1-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Streamlit app\n",
    "hello_app = '''\n",
    "\"\"\"Simple Streamlit Hello World App.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Hello Streamlit\",\n",
    "    page_icon=\"\",\n",
    "    layout=\"centered\",\n",
    ")\n",
    "\n",
    "# Title and header\n",
    "st.title(\"Hello, Streamlit!\")\n",
    "st.markdown(\"Welcome to your first Streamlit app.\")\n",
    "\n",
    "# User input\n",
    "name = st.text_input(\"What's your name?\", \"World\")\n",
    "\n",
    "# Display greeting\n",
    "st.write(f\"Hello, {name}!\")\n",
    "\n",
    "# A simple button\n",
    "if st.button(\"Click me!\"):\n",
    "    st.balloons()\n",
    "    st.success(\"You clicked the button!\")\n",
    "\n",
    "# Sidebar\n",
    "st.sidebar.header(\"About\")\n",
    "st.sidebar.info(\"This is a simple Streamlit demo.\")\n",
    "'''\n",
    "\n",
    "# Save the app\n",
    "import os\n",
    "os.makedirs(\"../app-examples\", exist_ok=True)\n",
    "with open(\"../app-examples/hello_streamlit.py\", \"w\") as f:\n",
    "    f.write(hello_app)\n",
    "\n",
    "print(\"Saved: ../app-examples/hello_streamlit.py\")\n",
    "print(\"\\nRun with: streamlit run ../app-examples/hello_streamlit.py\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(hello_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-explain",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "| Element | Purpose |\n",
    "|---------|--------|\n",
    "| `st.set_page_config()` | Configure page title, icon, layout |\n",
    "| `st.title()` | Large heading |\n",
    "| `st.text_input()` | Text input field |\n",
    "| `st.button()` | Clickable button |\n",
    "| `st.sidebar` | Side panel for navigation/controls |\n",
    "\n",
    "**Key insight:** Streamlit reruns the entire script on every interaction!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Session State\n",
    "\n",
    "Since Streamlit reruns on every interaction, we need session state to persist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part2-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session state demo\n",
    "session_demo = '''\n",
    "\"\"\"Streamlit Session State Demo.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Session State Demo\")\n",
    "\n",
    "# Initialize session state\n",
    "if \"counter\" not in st.session_state:\n",
    "    st.session_state.counter = 0\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Counter example\n",
    "st.subheader(\"Counter\")\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    if st.button(\"Increment\"):\n",
    "        st.session_state.counter += 1\n",
    "\n",
    "with col2:\n",
    "    if st.button(\"Reset\"):\n",
    "        st.session_state.counter = 0\n",
    "\n",
    "st.metric(\"Count\", st.session_state.counter)\n",
    "\n",
    "# Message history example\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"Message History\")\n",
    "\n",
    "new_message = st.text_input(\"Add a message\")\n",
    "if st.button(\"Add\") and new_message:\n",
    "    st.session_state.messages.append(new_message)\n",
    "\n",
    "st.write(\"Messages:\")\n",
    "for i, msg in enumerate(st.session_state.messages):\n",
    "    st.write(f\"{i+1}. {msg}\")\n",
    "\n",
    "if st.button(\"Clear All\"):\n",
    "    st.session_state.messages = []\n",
    "    st.rerun()  # Force refresh\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/session_demo.py\", \"w\") as f:\n",
    "    f.write(session_demo)\n",
    "\n",
    "print(\"Saved: ../app-examples/session_demo.py\")\n",
    "print(\"\\nKEY CONCEPTS:\")\n",
    "print(\"  1. st.session_state persists across reruns\")\n",
    "print(\"  2. Always check 'if key not in st.session_state'\")\n",
    "print(\"  3. Use st.rerun() to force a refresh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Building a Chat Interface\n",
    "\n",
    "Let's build a chat interface with Streamlit's native chat components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part3-chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat interface\n",
    "chat_app = '''\n",
    "\"\"\"Streamlit Chat Interface with LLM.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import time\n",
    "import requests\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"AI Chat\",\n",
    "    page_icon=\"\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "st.title(\"AI Chat\")\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "\n",
    "def get_response(prompt: str) -> str:\n",
    "    \"\"\"Get response from LLM.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/chat\",\n",
    "            json={\n",
    "                \"model\": \"qwen3:8b\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"stream\": False,\n",
    "            },\n",
    "            timeout=60,\n",
    "        )\n",
    "        return response.json()[\"message\"][\"content\"]\n",
    "    except:\n",
    "        # Mock response for demo\n",
    "        return f\"[Mock] You said: {prompt}\"\n",
    "\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"What's on your mind?\"):\n",
    "    # Add user message\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    # Get AI response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = get_response(prompt)\n",
    "        st.markdown(response)\n",
    "    \n",
    "    # Add assistant message\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# Sidebar with options\n",
    "with st.sidebar:\n",
    "    st.header(\"Options\")\n",
    "    if st.button(\"Clear Chat\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    st.caption(f\"Messages: {len(st.session_state.messages)}\")\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/chat_streamlit.py\", \"w\") as f:\n",
    "    f.write(chat_app)\n",
    "\n",
    "print(\"Saved: ../app-examples/chat_streamlit.py\")\n",
    "print(\"\\nRun with: streamlit run ../app-examples/chat_streamlit.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Multi-Page Applications\n",
    "\n",
    "Streamlit supports native multi-page applications using a folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part4-multipage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-page app structure\n",
    "print(\"MULTI-PAGE APP STRUCTURE:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "my_app/\n",
    "├── app.py              # Main entry point\n",
    "├── pages/\n",
    "│   ├── 1_Chat.py       # Page 1\n",
    "│   ├── 2_Metrics.py    # Page 2\n",
    "│   └── 3_Settings.py   # Page 3\n",
    "└── utils/\n",
    "    └── helpers.py      # Shared utilities\n",
    "\n",
    "The number prefix (1_, 2_, 3_) controls page order.\n",
    "Streamlit automatically creates navigation in the sidebar.\n",
    "\"\"\")\n",
    "\n",
    "# Create multi-page structure\n",
    "import os\n",
    "os.makedirs(\"../app-examples/multipage/pages\", exist_ok=True)\n",
    "\n",
    "# Main app.py\n",
    "main_app = '''\n",
    "\"\"\"Multi-page Streamlit App - Main Entry.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"ML Dashboard\",\n",
    "    page_icon=\"\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "st.title(\"ML Model Dashboard\")\n",
    "st.markdown(\"Welcome! Use the sidebar to navigate between pages.\")\n",
    "\n",
    "# Quick overview\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "    st.info(\"**Chat**\\n\\nInteract with the model\")\n",
    "\n",
    "with col2:\n",
    "    st.info(\"**Metrics**\\n\\nView performance data\")\n",
    "\n",
    "with col3:\n",
    "    st.info(\"**Settings**\\n\\nConfigure the model\")\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/multipage/app.py\", \"w\") as f:\n",
    "    f.write(main_app)\n",
    "\n",
    "# Page 1: Chat\n",
    "page_chat = '''\n",
    "\"\"\"Chat Page.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Chat\")\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.write(msg[\"content\"])\n",
    "\n",
    "if prompt := st.chat_input(\"Message\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": f\"Echo: {prompt}\"})\n",
    "    st.rerun()\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/multipage/pages/1_Chat.py\", \"w\") as f:\n",
    "    f.write(page_chat)\n",
    "\n",
    "# Page 2: Metrics\n",
    "page_metrics = '''\n",
    "\"\"\"Metrics Page.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "st.title(\"Metrics\")\n",
    "\n",
    "# Key metrics\n",
    "col1, col2, col3 = st.columns(3)\n",
    "col1.metric(\"Requests\", \"1,234\", \"+12%\")\n",
    "col2.metric(\"Avg Latency\", \"145ms\", \"-8ms\")\n",
    "col3.metric(\"GPU Usage\", \"67%\", \"+5%\")\n",
    "\n",
    "# Sample chart\n",
    "st.subheader(\"Latency Over Time\")\n",
    "data = pd.DataFrame({\n",
    "    \"Time\": range(100),\n",
    "    \"Latency\": [100 + random.randint(-20, 20) for _ in range(100)],\n",
    "})\n",
    "st.line_chart(data.set_index(\"Time\"))\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/multipage/pages/2_Metrics.py\", \"w\") as f:\n",
    "    f.write(page_metrics)\n",
    "\n",
    "# Page 3: Settings\n",
    "page_settings = '''\n",
    "\"\"\"Settings Page.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Settings\")\n",
    "\n",
    "st.subheader(\"Model Configuration\")\n",
    "model = st.selectbox(\"Model\", [\"qwen3:8b\", \"mistral:7b\", \"codellama:7b\"])\n",
    "temperature = st.slider(\"Temperature\", 0.0, 2.0, 0.7)\n",
    "max_tokens = st.number_input(\"Max Tokens\", 100, 4096, 512)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "if st.button(\"Save Settings\", type=\"primary\"):\n",
    "    st.success(\"Settings saved!\")\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/multipage/pages/3_Settings.py\", \"w\") as f:\n",
    "    f.write(page_settings)\n",
    "\n",
    "print(\"Created multi-page app structure:\")\n",
    "print(\"  - app-examples/multipage/app.py\")\n",
    "print(\"  - app-examples/multipage/pages/1_Chat.py\")\n",
    "print(\"  - app-examples/multipage/pages/2_Metrics.py\")\n",
    "print(\"  - app-examples/multipage/pages/3_Settings.py\")\n",
    "print(\"\\nRun with: streamlit run ../app-examples/multipage/app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Advanced Features - Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part5-caching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching for performance\n",
    "caching_demo = '''\n",
    "\"\"\"Streamlit Caching Demo.\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "st.title(\"Caching Demo\")\n",
    "\n",
    "# ============================================\n",
    "# @st.cache_data - Cache data computations\n",
    "# Good for: DataFrames, API responses, calculations\n",
    "# ============================================\n",
    "\n",
    "@st.cache_data(ttl=3600)  # Cache for 1 hour\n",
    "def expensive_computation(n: int) -> int:\n",
    "    \"\"\"Simulate an expensive computation.\"\"\"\n",
    "    time.sleep(2)  # Simulate slow operation\n",
    "    return sum(range(n))\n",
    "\n",
    "\n",
    "st.subheader(\"@st.cache_data\")\n",
    "n = st.number_input(\"Number\", 1, 1000000, 1000)\n",
    "\n",
    "start = time.time()\n",
    "result = expensive_computation(n)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "st.write(f\"Sum of 1 to {n}: {result:,}\")\n",
    "st.write(f\"Time: {elapsed:.3f}s (cached if < 0.1s)\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# @st.cache_resource - Cache resources\n",
    "# Good for: ML models, database connections\n",
    "# ============================================\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    \"\"\"Load ML model (cached across all sessions).\"\"\"\n",
    "    time.sleep(3)  # Simulate model loading\n",
    "    return {\"model\": \"mock_model\", \"loaded_at\": time.time()}\n",
    "\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"@st.cache_resource\")\n",
    "\n",
    "if st.button(\"Load Model\"):\n",
    "    with st.spinner(\"Loading model...\"):\n",
    "        model = load_model()\n",
    "    st.success(f\"Model loaded! (cached: {model})\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Cache clearing\n",
    "# ============================================\n",
    "\n",
    "st.markdown(\"---\")\n",
    "if st.button(\"Clear All Caches\"):\n",
    "    st.cache_data.clear()\n",
    "    st.cache_resource.clear()\n",
    "    st.success(\"Caches cleared!\")\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/caching_demo.py\", \"w\") as f:\n",
    "    f.write(caching_demo)\n",
    "\n",
    "print(\"Saved: ../app-examples/caching_demo.py\")\n",
    "print(\"\\nCACHING DECORATORS:\")\n",
    "print(\"  @st.cache_data    - For data (DataFrame, JSON, calculations)\")\n",
    "print(\"  @st.cache_resource - For resources (models, connections)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Complete Production Dashboard\n",
    "\n",
    "Let's create a complete production-ready dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "part6-dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete dashboard using our utility\n",
    "mock_client = MockLLMClient()\n",
    "dashboard_script = create_streamlit_dashboard(\n",
    "    client=mock_client,\n",
    "    title=\"ML Model Dashboard\",\n",
    ")\n",
    "\n",
    "with open(\"../app-examples/production_dashboard.py\", \"w\") as f:\n",
    "    f.write(dashboard_script)\n",
    "\n",
    "print(\"Saved: ../app-examples/production_dashboard.py\")\n",
    "print(\"\\nThis includes:\")\n",
    "print(\"  - Chat page with history\")\n",
    "print(\"  - Metrics visualization\")\n",
    "print(\"  - Settings configuration\")\n",
    "print(\"\\nRun with: streamlit run ../app-examples/production_dashboard.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself\n",
    "\n",
    "### Exercise 1: Add GPU Monitoring\n",
    "\n",
    "Add a GPU monitoring section to the metrics page.\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "Use pynvml to get GPU stats, or create mock data for demo.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "\n",
    "# Hint: GPU monitoring code\n",
    "gpu_code = '''\n",
    "def get_gpu_metrics():\n",
    "    \"\"\"Get GPU metrics.\"\"\"\n",
    "    try:\n",
    "        import pynvml\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        mem = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        pynvml.nvmlShutdown()\n",
    "        return {\n",
    "            \"memory_used\": mem.used / 1e9,\n",
    "            \"memory_total\": mem.total / 1e9,\n",
    "            \"utilization\": util.gpu,\n",
    "        }\n",
    "    except:\n",
    "        return {\"memory_used\": 45, \"memory_total\": 128, \"utilization\": 42}\n",
    "'''\n",
    "print(gpu_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mistakes-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Forgetting Session State\n",
    "\n",
    "```python\n",
    "# BAD - counter resets on every interaction\n",
    "counter = 0\n",
    "if st.button(\"Click\"):\n",
    "    counter += 1\n",
    "st.write(counter)  # Always shows 1\n",
    "\n",
    "# GOOD - use session state\n",
    "if \"counter\" not in st.session_state:\n",
    "    st.session_state.counter = 0\n",
    "if st.button(\"Click\"):\n",
    "    st.session_state.counter += 1\n",
    "st.write(st.session_state.counter)  # Persists\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 2: Caching Mutable Objects\n",
    "\n",
    "```python\n",
    "# BAD - cached list can be modified\n",
    "@st.cache_data\n",
    "def get_data():\n",
    "    return [1, 2, 3]  # This list can be modified!\n",
    "\n",
    "# GOOD - return immutable or use deepcopy\n",
    "@st.cache_data\n",
    "def get_data():\n",
    "    return tuple([1, 2, 3])  # Immutable\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 3: Slow Operations Without Caching\n",
    "\n",
    "```python\n",
    "# BAD - model loads on every interaction\n",
    "model = load_heavy_model()  # 10 seconds every time!\n",
    "\n",
    "# GOOD - cache the resource\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    return load_heavy_model()\n",
    "\n",
    "model = load_model()  # Loads once, cached forever\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deployment-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Deployment to Streamlit Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deployment files\n",
    "import os\n",
    "os.makedirs(\"../app-examples/.streamlit\", exist_ok=True)\n",
    "\n",
    "# requirements.txt\n",
    "requirements = '''streamlit>=1.30.0\n",
    "pandas>=2.0.0\n",
    "plotly>=5.18.0\n",
    "requests>=2.31.0\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/requirements.txt\", \"w\") as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "# config.toml\n",
    "config = '''[theme]\n",
    "primaryColor = \"#76b900\"\n",
    "backgroundColor = \"#0e1117\"\n",
    "secondaryBackgroundColor = \"#262730\"\n",
    "textColor = \"#fafafa\"\n",
    "\n",
    "[server]\n",
    "maxUploadSize = 50\n",
    "'''\n",
    "\n",
    "with open(\"../app-examples/.streamlit/config.toml\", \"w\") as f:\n",
    "    f.write(config)\n",
    "\n",
    "print(\"Created deployment files!\")\n",
    "print(\"\\nDEPLOYMENT STEPS:\")\n",
    "print(\"  1. Push to GitHub repository\")\n",
    "print(\"  2. Go to share.streamlit.io\")\n",
    "print(\"  3. Connect your GitHub account\")\n",
    "print(\"  4. Select repository and app.py file\")\n",
    "print(\"  5. Click Deploy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- Building Streamlit applications\n",
    "- Managing state with session_state\n",
    "- Creating chat interfaces\n",
    "- Multi-page app structure\n",
    "- Caching for performance\n",
    "- Deploying to Streamlit Cloud\n",
    "\n",
    "---\n",
    "\n",
    "## Challenge (Optional)\n",
    "\n",
    "Build a complete model evaluation dashboard with:\n",
    "1. File upload for test data\n",
    "2. Model selection dropdown\n",
    "3. Real-time evaluation metrics\n",
    "4. Confusion matrix visualization\n",
    "5. Export results to CSV\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Streamlit Documentation](https://docs.streamlit.io/)\n",
    "- [Streamlit Cloud](https://streamlit.io/cloud)\n",
    "- [Streamlit Components](https://streamlit.io/components)\n",
    "- [Session State Guide](https://docs.streamlit.io/library/api-reference/session-state)\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List created files\n",
    "import os\n",
    "\n",
    "print(\"Created files:\")\n",
    "for root, dirs, files in os.walk(\"../app-examples\"):\n",
    "    for f in files:\n",
    "        path = os.path.join(root, f)\n",
    "        print(f\"  {path}\")\n",
    "\n",
    "print(\"\\nTo run any app:\")\n",
    "print(\"  streamlit run ../app-examples/<filename>.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
