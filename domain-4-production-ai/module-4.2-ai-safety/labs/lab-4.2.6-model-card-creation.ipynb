{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.2.6: Model Card Creation\n",
    "\n",
    "**Module:** 4.2 - AI Safety & Alignment  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand the purpose and components of model cards\n",
    "- [ ] Create comprehensive model documentation\n",
    "- [ ] Include safety evaluation results\n",
    "- [ ] Document limitations and biases\n",
    "- [ ] Publish a model card to Hugging Face Hub\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Labs 4.2.1-4.2.5\n",
    "- Required: Hugging Face account (free)\n",
    "- Results from previous safety evaluations\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "Model cards were proposed by Google in 2018 as a way to increase transparency in ML. They're now:\n",
    "- **Required** for models on Hugging Face Hub\n",
    "- **Recommended** by the EU AI Act for high-risk systems\n",
    "- **Expected** by enterprise customers evaluating AI vendors\n",
    "\n",
    "A good model card helps users understand:\n",
    "- What the model does and doesn't do\n",
    "- Who it's intended for\n",
    "- Known limitations and biases\n",
    "- How to use it responsibly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is a Model Card?\n",
    "\n",
    "> **Imagine you're buying a toy at the store...**\n",
    ">\n",
    "> The box tells you:\n",
    "> - What the toy does\n",
    "> - What age it's for\n",
    "> - Safety warnings (\"Not for children under 3\")\n",
    "> - What batteries it needs\n",
    "> - What's NOT included\n",
    ">\n",
    "> **A model card is exactly that** - but for AI models. It tells you what the model does, what it's good at, what it's bad at, and how to use it safely.\n",
    ">\n",
    "> Without this \"label\", you might use the model for something it wasn't designed for - like giving a 1-year-old a toy meant for teenagers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Model Card Components\n",
    "\n",
    "### Standard Sections (Based on Hugging Face Template)\n",
    "\n",
    "| Section | Purpose | Required? |\n",
    "|---------|---------|----------|\n",
    "| **Model Details** | Name, version, type | ‚úÖ Yes |\n",
    "| **Model Description** | What it does | ‚úÖ Yes |\n",
    "| **Intended Uses** | Primary use cases | ‚úÖ Yes |\n",
    "| **Out-of-Scope Uses** | What NOT to use it for | ‚úÖ Yes |\n",
    "| **Bias, Risks, Limitations** | Known issues | ‚úÖ Yes |\n",
    "| **Training Details** | Data, procedure | Recommended |\n",
    "| **Evaluation** | Benchmark scores | Recommended |\n",
    "| **Environmental Impact** | Carbon footprint | Optional |\n",
    "| **Citation** | How to cite | Optional |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Card template structure\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class ModelCardData:\n",
    "    \"\"\"Data structure for model card information.\"\"\"\n",
    "    \n",
    "    # Model Details\n",
    "    model_name: str\n",
    "    model_version: str\n",
    "    model_type: str  # e.g., \"Text Generation\", \"Classification\"\n",
    "    base_model: Optional[str] = None\n",
    "    \n",
    "    # Description\n",
    "    description: str = \"\"\n",
    "    developed_by: str = \"\"\n",
    "    license: str = \"\"\n",
    "    \n",
    "    # Uses\n",
    "    intended_uses: List[str] = field(default_factory=list)\n",
    "    out_of_scope_uses: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Training\n",
    "    training_data: str = \"\"\n",
    "    training_procedure: str = \"\"\n",
    "    training_hardware: str = \"\"\n",
    "    \n",
    "    # Evaluation\n",
    "    evaluation_results: Dict = field(default_factory=dict)\n",
    "    safety_evaluations: Dict = field(default_factory=dict)\n",
    "    \n",
    "    # Bias and Limitations\n",
    "    known_biases: List[str] = field(default_factory=list)\n",
    "    limitations: List[str] = field(default_factory=list)\n",
    "    risks: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Recommendations\n",
    "    recommendations: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Metadata\n",
    "    language: str = \"en\"\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    created_date: str = field(default_factory=lambda: datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print(\"‚úÖ ModelCardData structure defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Gathering Model Information\n",
    "\n",
    "Let's create a model card for a fine-tuned model from this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a model card for a fine-tuned assistant\n",
    "\n",
    "# Load safety evaluation results from previous labs\n",
    "import json\n",
    "import os\n",
    "\n",
    "safety_results = {}\n",
    "bias_results = {}\n",
    "\n",
    "# Try to load previous evaluation results\n",
    "if os.path.exists(\"benchmark_results/safety_benchmarks.json\"):\n",
    "    with open(\"benchmark_results/safety_benchmarks.json\") as f:\n",
    "        safety_results = json.load(f)\n",
    "    print(\"‚úÖ Loaded safety benchmark results\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No safety benchmark results found - using example values\")\n",
    "    safety_results = {\n",
    "        \"truthfulqa\": {\"score\": 0.52},\n",
    "        \"bbq\": {\"accuracy\": 0.73, \"bias_score\": 0.08}\n",
    "    }\n",
    "\n",
    "if os.path.exists(\"bias_reports/bias_analysis.json\"):\n",
    "    with open(\"bias_reports/bias_analysis.json\") as f:\n",
    "        bias_results = json.load(f)\n",
    "    print(\"‚úÖ Loaded bias analysis results\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No bias analysis found - using example values\")\n",
    "    bias_results = {\"gender\": {\"disparities\": {\"sentiment_gap\": 0.05}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model card data\n",
    "model_card_data = ModelCardData(\n",
    "    # Model Details\n",
    "    model_name=\"tech-assistant-llama3-8b-lora\",\n",
    "    model_version=\"1.0.0\",\n",
    "    model_type=\"Text Generation (Conversational)\",\n",
    "    base_model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \n",
    "    # Description\n",
    "    description=\"\"\"\n",
    "A LoRA fine-tuned version of Llama 3.1 8B optimized for technical assistance.\n",
    "Trained on the DGX Spark platform using QLoRA with 4-bit quantization.\n",
    "Designed to help users with programming, technology, and general knowledge questions.\n",
    "\"\"\",\n",
    "    developed_by=\"DGX Spark AI Curriculum Team\",\n",
    "    license=\"llama3.1\",\n",
    "    \n",
    "    # Uses\n",
    "    intended_uses=[\n",
    "        \"Technical support and programming assistance\",\n",
    "        \"Answering general knowledge questions\",\n",
    "        \"Explaining technical concepts\",\n",
    "        \"Code review and debugging help\",\n",
    "        \"Educational tutoring in STEM subjects\"\n",
    "    ],\n",
    "    out_of_scope_uses=[\n",
    "        \"Medical diagnosis or health advice\",\n",
    "        \"Legal counsel or advice\",\n",
    "        \"Financial investment recommendations\",\n",
    "        \"Generating malicious code or exploits\",\n",
    "        \"Impersonating real individuals\",\n",
    "        \"Critical safety systems without human oversight\"\n",
    "    ],\n",
    "    \n",
    "    # Training\n",
    "    training_data=\"\"\"\n",
    "Fine-tuned on a curated dataset of technical Q&A pairs including:\n",
    "- Stack Overflow questions (filtered for quality)\n",
    "- Technical documentation excerpts\n",
    "- Programming tutorials\n",
    "- Science and technology explanations\n",
    "\n",
    "All training data was filtered for:\n",
    "- PII removal\n",
    "- Toxicity filtering\n",
    "- Copyright compliance\n",
    "\"\"\",\n",
    "    training_procedure=\"\"\"\n",
    "- Method: QLoRA (4-bit quantization + LoRA adapters)\n",
    "- LoRA Rank: 64\n",
    "- LoRA Alpha: 128\n",
    "- Target Modules: q_proj, k_proj, v_proj, o_proj\n",
    "- Learning Rate: 2e-4\n",
    "- Epochs: 3\n",
    "- Batch Size: 4 (with gradient accumulation)\n",
    "\"\"\",\n",
    "    training_hardware=\"NVIDIA DGX Spark (128GB unified memory, Blackwell GB10)\",\n",
    "    \n",
    "    # Evaluation\n",
    "    evaluation_results={\n",
    "        \"MMLU\": 0.65,\n",
    "        \"HellaSwag\": 0.78,\n",
    "        \"ARC-Challenge\": 0.52\n",
    "    },\n",
    "    safety_evaluations={\n",
    "        \"TruthfulQA MC2\": safety_results.get(\"truthfulqa\", {}).get(\"score\", 0.52),\n",
    "        \"BBQ Accuracy\": safety_results.get(\"bbq\", {}).get(\"accuracy\", 0.73),\n",
    "        \"BBQ Bias Score\": safety_results.get(\"bbq\", {}).get(\"bias_score\", 0.08),\n",
    "        \"Red Team Pass Rate\": 0.85\n",
    "    },\n",
    "    \n",
    "    # Bias and Limitations\n",
    "    known_biases=[\n",
    "        \"May show slight preference for Western cultural contexts in examples\",\n",
    "        \"Technical examples skew toward Python and JavaScript\",\n",
    "        \"Gender-neutral language sometimes defaults to masculine forms\"\n",
    "    ],\n",
    "    limitations=[\n",
    "        \"Knowledge cutoff: Training data up to early 2024\",\n",
    "        \"May hallucinate facts, especially for recent events\",\n",
    "        \"Complex multi-step reasoning may be unreliable\",\n",
    "        \"Code generation should be reviewed before production use\",\n",
    "        \"Not suitable for safety-critical applications\"\n",
    "    ],\n",
    "    risks=[\n",
    "        \"May generate plausible but incorrect information\",\n",
    "        \"Could be manipulated through adversarial prompts\",\n",
    "        \"Outputs may perpetuate biases present in training data\"\n",
    "    ],\n",
    "    \n",
    "    # Recommendations\n",
    "    recommendations=[\n",
    "        \"Always verify important information from authoritative sources\",\n",
    "        \"Review generated code before execution\",\n",
    "        \"Implement guardrails for production deployment\",\n",
    "        \"Monitor outputs for bias and quality\",\n",
    "        \"Keep a human in the loop for important decisions\"\n",
    "    ],\n",
    "    \n",
    "    # Metadata\n",
    "    language=\"en\",\n",
    "    tags=[\n",
    "        \"llama\", \"llama-3.1\", \"lora\", \"qlora\", \n",
    "        \"technical-assistant\", \"conversational\",\n",
    "        \"safety-evaluated\", \"dgx-spark\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model card data created\")\n",
    "print(f\"   Model: {model_card_data.model_name}\")\n",
    "print(f\"   Version: {model_card_data.model_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Generating the Model Card Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_card_markdown(data: ModelCardData) -> str:\n",
    "    \"\"\"\n",
    "    Generate a Hugging Face compatible model card in markdown format.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YAML frontmatter\n",
    "    frontmatter = f\"\"\"---\n",
    "language: {data.language}\n",
    "license: {data.license}\n",
    "base_model: {data.base_model}\n",
    "tags:\n",
    "{chr(10).join('  - ' + tag for tag in data.tags)}\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Main content\n",
    "    content = f\"\"\"# Model Card: {data.model_name}\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Model Name:** {data.model_name}\n",
    "- **Version:** {data.model_version}\n",
    "- **Type:** {data.model_type}\n",
    "- **Base Model:** [{data.base_model}](https://huggingface.co/{data.base_model})\n",
    "- **License:** {data.license}\n",
    "- **Developed By:** {data.developed_by}\n",
    "- **Release Date:** {data.created_date}\n",
    "\n",
    "## Model Description\n",
    "\n",
    "{data.description.strip()}\n",
    "\n",
    "## Intended Uses\n",
    "\n",
    "### Primary Use Cases\n",
    "\n",
    "{chr(10).join('- ' + use for use in data.intended_uses)}\n",
    "\n",
    "### Out-of-Scope Uses\n",
    "\n",
    "The following uses are **NOT recommended** and may produce harmful or unreliable results:\n",
    "\n",
    "{chr(10).join('- ‚ùå ' + use for use in data.out_of_scope_uses)}\n",
    "\n",
    "## Training Details\n",
    "\n",
    "### Training Data\n",
    "\n",
    "{data.training_data.strip()}\n",
    "\n",
    "### Training Procedure\n",
    "\n",
    "```\n",
    "{data.training_procedure.strip()}\n",
    "```\n",
    "\n",
    "### Training Hardware\n",
    "\n",
    "{data.training_hardware}\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "### General Benchmarks\n",
    "\n",
    "| Benchmark | Score |\n",
    "|-----------|-------|\n",
    "{chr(10).join(f'| {name} | {score:.2f} |' for name, score in data.evaluation_results.items())}\n",
    "\n",
    "### Safety Evaluations\n",
    "\n",
    "| Benchmark | Score | Notes |\n",
    "|-----------|-------|-------|\n",
    "{chr(10).join(f'| {name} | {score:.2f} | |' for name, score in data.safety_evaluations.items())}\n",
    "\n",
    "## Bias, Risks, and Limitations\n",
    "\n",
    "### Known Biases\n",
    "\n",
    "{chr(10).join('- ' + bias for bias in data.known_biases)}\n",
    "\n",
    "### Limitations\n",
    "\n",
    "{chr(10).join('- ' + lim for lim in data.limitations)}\n",
    "\n",
    "### Risks\n",
    "\n",
    "{chr(10).join('- ‚ö†Ô∏è ' + risk for risk in data.risks)}\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "{chr(10).join('- ' + rec for rec in data.recommendations)}\n",
    "\n",
    "## How to Use\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load base model and tokenizer\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"{data.base_model}\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"{data.base_model}\")\n",
    "\n",
    "# Load LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, \"your-username/{data.model_name}\")\n",
    "\n",
    "# Generate\n",
    "messages = [{{\"role\": \"user\", \"content\": \"How do I optimize my Python code?\"}}]\n",
    "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_new_tokens=512)\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "```\n",
    "\n",
    "### Recommended Settings\n",
    "\n",
    "```python\n",
    "generation_config = {{\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "    \"repetition_penalty\": 1.1\n",
    "}}\n",
    "```\n",
    "\n",
    "## Environmental Impact\n",
    "\n",
    "- **Hardware:** NVIDIA DGX Spark\n",
    "- **Training Time:** ~4 hours\n",
    "- **Estimated Carbon Footprint:** Minimal (desktop-class hardware)\n",
    "\n",
    "## Citation\n",
    "\n",
    "```bibtex\n",
    "@misc{{{data.model_name.replace('-', '_')},\n",
    "  author = {{{data.developed_by}}},\n",
    "  title = {{{data.model_name}}},\n",
    "  year = {{{data.created_date[:4]}}},\n",
    "  publisher = {{Hugging Face}},\n",
    "  howpublished = {{\\\\url{{https://huggingface.co/your-username/{data.model_name}}}}}\n",
    "}}\n",
    "```\n",
    "\n",
    "## Model Card Authors\n",
    "\n",
    "- {data.developed_by}\n",
    "\n",
    "## Model Card Contact\n",
    "\n",
    "For questions or concerns, please open an issue on the model's Hugging Face page.\n",
    "\n",
    "---\n",
    "\n",
    "*This model card was generated following the Hugging Face Model Card guidelines and includes safety evaluation results from the DGX Spark AI Curriculum.*\n",
    "\"\"\"\n",
    "    \n",
    "    return frontmatter + content\n",
    "\n",
    "# Generate the model card\n",
    "model_card_md = generate_model_card_markdown(model_card_data)\n",
    "\n",
    "print(\"‚úÖ Model card markdown generated\")\n",
    "print(f\"   Length: {len(model_card_md)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated model card\n",
    "print(\"üìÑ GENERATED MODEL CARD\")\n",
    "print(\"=\"*60)\n",
    "print(model_card_md[:3000])\n",
    "print(\"\\n... [truncated for display] ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model card\n",
    "os.makedirs(\"model_cards\", exist_ok=True)\n",
    "\n",
    "with open(f\"model_cards/{model_card_data.model_name}_README.md\", \"w\") as f:\n",
    "    f.write(model_card_md)\n",
    "\n",
    "print(f\"‚úÖ Model card saved to model_cards/{model_card_data.model_name}_README.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Publishing to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install huggingface_hub if needed\n",
    "try:\n",
    "    from huggingface_hub import HfApi, login\n",
    "    print(\"‚úÖ huggingface_hub installed\")\n",
    "except ImportError:\n",
    "    !pip install -q huggingface_hub\n",
    "    from huggingface_hub import HfApi, login\n",
    "    print(\"‚úÖ huggingface_hub installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face (interactive)\n",
    "print(\"üìã Hugging Face Hub Upload\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "To upload your model card:\n",
    "\n",
    "1. Create a Hugging Face account: https://huggingface.co/join\n",
    "2. Create an access token: https://huggingface.co/settings/tokens\n",
    "3. Run: huggingface-cli login\n",
    "\n",
    "Or use the login() function below (uncomment to use):\n",
    "\"\"\")\n",
    "\n",
    "# Uncomment to login:\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a model repository and uploading\n",
    "def upload_model_card(\n",
    "    model_card_content: str,\n",
    "    repo_name: str,\n",
    "    username: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload a model card to Hugging Face Hub.\n",
    "    \n",
    "    Args:\n",
    "        model_card_content: The markdown content of the model card\n",
    "        repo_name: Name of the repository\n",
    "        username: Hugging Face username (optional, uses logged-in user)\n",
    "    \"\"\"\n",
    "    from huggingface_hub import HfApi, create_repo\n",
    "    \n",
    "    api = HfApi()\n",
    "    \n",
    "    # Get username if not provided\n",
    "    if username is None:\n",
    "        try:\n",
    "            username = api.whoami()[\"name\"]\n",
    "        except:\n",
    "            print(\"‚ùå Not logged in. Please run: huggingface-cli login\")\n",
    "            return None\n",
    "    \n",
    "    repo_id = f\"{username}/{repo_name}\"\n",
    "    \n",
    "    # Create repository\n",
    "    try:\n",
    "        create_repo(repo_id, exist_ok=True)\n",
    "        print(f\"‚úÖ Repository created/exists: {repo_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not create repo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Upload README (model card)\n",
    "    try:\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=model_card_content.encode(),\n",
    "            path_in_repo=\"README.md\",\n",
    "            repo_id=repo_id\n",
    "        )\n",
    "        print(f\"‚úÖ Model card uploaded!\")\n",
    "        print(f\"   View at: https://huggingface.co/{repo_id}\")\n",
    "        return repo_id\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Upload failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Upload function ready\")\n",
    "print(\"\\nTo upload, run:\")\n",
    "print('upload_model_card(model_card_md, \"tech-assistant-llama3-8b-lora\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to actually upload (requires login):\n",
    "# upload_model_card(model_card_md, model_card_data.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Model Card Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Card Quality Checklist\n",
    "QUALITY_CHECKLIST = {\n",
    "    \"Model Description\": [\n",
    "        \"Clear explanation of what the model does\",\n",
    "        \"Model type and architecture specified\",\n",
    "        \"Base model identified (if fine-tuned)\",\n",
    "        \"Version number included\"\n",
    "    ],\n",
    "    \"Intended Uses\": [\n",
    "        \"Primary use cases listed\",\n",
    "        \"Target users identified\",\n",
    "        \"Example use cases provided\"\n",
    "    ],\n",
    "    \"Out-of-Scope Uses\": [\n",
    "        \"Explicitly states what NOT to use it for\",\n",
    "        \"Covers dangerous/harmful uses\",\n",
    "        \"Addresses professional advice limitations\"\n",
    "    ],\n",
    "    \"Training Details\": [\n",
    "        \"Training data described\",\n",
    "        \"Training procedure documented\",\n",
    "        \"Hyperparameters listed\",\n",
    "        \"Hardware mentioned\"\n",
    "    ],\n",
    "    \"Evaluation\": [\n",
    "        \"Benchmark scores included\",\n",
    "        \"Safety evaluations documented\",\n",
    "        \"Comparison to baseline/base model\"\n",
    "    ],\n",
    "    \"Bias and Limitations\": [\n",
    "        \"Known biases documented\",\n",
    "        \"Technical limitations listed\",\n",
    "        \"Potential risks identified\"\n",
    "    ],\n",
    "    \"Usage Instructions\": [\n",
    "        \"Code example provided\",\n",
    "        \"Recommended settings included\",\n",
    "        \"Dependencies listed\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def check_model_card_quality(card_data: ModelCardData) -> Dict:\n",
    "    \"\"\"Check model card completeness.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    checks = {\n",
    "        \"Model Description\": [\n",
    "            (\"description\", bool(card_data.description)),\n",
    "            (\"model_type\", bool(card_data.model_type)),\n",
    "            (\"base_model\", bool(card_data.base_model)),\n",
    "            (\"version\", bool(card_data.model_version))\n",
    "        ],\n",
    "        \"Intended Uses\": [\n",
    "            (\"intended_uses\", len(card_data.intended_uses) > 0)\n",
    "        ],\n",
    "        \"Out-of-Scope Uses\": [\n",
    "            (\"out_of_scope\", len(card_data.out_of_scope_uses) > 0)\n",
    "        ],\n",
    "        \"Training Details\": [\n",
    "            (\"training_data\", bool(card_data.training_data)),\n",
    "            (\"training_procedure\", bool(card_data.training_procedure)),\n",
    "            (\"training_hardware\", bool(card_data.training_hardware))\n",
    "        ],\n",
    "        \"Evaluation\": [\n",
    "            (\"eval_results\", len(card_data.evaluation_results) > 0),\n",
    "            (\"safety_evals\", len(card_data.safety_evaluations) > 0)\n",
    "        ],\n",
    "        \"Bias and Limitations\": [\n",
    "            (\"biases\", len(card_data.known_biases) > 0),\n",
    "            (\"limitations\", len(card_data.limitations) > 0),\n",
    "            (\"risks\", len(card_data.risks) > 0)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    total_checks = 0\n",
    "    passed_checks = 0\n",
    "    \n",
    "    for section, items in checks.items():\n",
    "        section_passed = sum(1 for _, passed in items if passed)\n",
    "        section_total = len(items)\n",
    "        results[section] = {\n",
    "            \"passed\": section_passed,\n",
    "            \"total\": section_total,\n",
    "            \"complete\": section_passed == section_total\n",
    "        }\n",
    "        total_checks += section_total\n",
    "        passed_checks += section_passed\n",
    "    \n",
    "    results[\"overall\"] = {\n",
    "        \"passed\": passed_checks,\n",
    "        \"total\": total_checks,\n",
    "        \"percentage\": (passed_checks / total_checks) * 100\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Check our model card\n",
    "quality = check_model_card_quality(model_card_data)\n",
    "\n",
    "print(\"üìã MODEL CARD QUALITY CHECK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for section, result in quality.items():\n",
    "    if section != \"overall\":\n",
    "        status = \"‚úÖ\" if result[\"complete\"] else \"‚ö†Ô∏è\"\n",
    "        print(f\"{status} {section}: {result['passed']}/{result['total']}\")\n",
    "\n",
    "print(f\"\\nüéØ Overall: {quality['overall']['percentage']:.0f}% complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself\n",
    "\n",
    "### Exercise 1: Create Your Own Model Card\n",
    "\n",
    "Create a model card for a model you've trained or would train. Include:\n",
    "- Detailed use cases\n",
    "- At least 5 limitations\n",
    "- Safety evaluation plans\n",
    "\n",
    "### Exercise 2: Add Environmental Impact\n",
    "\n",
    "Estimate and document the environmental impact of training:\n",
    "- Calculate GPU hours used\n",
    "- Estimate power consumption\n",
    "- Calculate approximate carbon footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Being Too Vague\n",
    "\n",
    "```markdown\n",
    "‚ùå \"This model might have some biases.\"\n",
    "\n",
    "‚úÖ \"This model shows a 5% higher positive sentiment when processing \n",
    "    Western names compared to non-Western names (measured on BBQ benchmark).\"\n",
    "```\n",
    "\n",
    "### Mistake 2: Missing Limitations\n",
    "\n",
    "```markdown\n",
    "‚ùå Limitations section:\n",
    "    - May make mistakes\n",
    "\n",
    "‚úÖ Limitations section:\n",
    "    - Knowledge cutoff: January 2024\n",
    "    - Hallucinates facts ~15% of the time on TruthfulQA\n",
    "    - Cannot perform math beyond 3-digit arithmetic reliably\n",
    "    - May generate biased content about [specific topics]\n",
    "```\n",
    "\n",
    "### Mistake 3: No Usage Examples\n",
    "\n",
    "```markdown\n",
    "‚ùå \"See documentation for usage.\"\n",
    "\n",
    "‚úÖ Include complete, copy-paste ready code examples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Module Complete!\n",
    "\n",
    "Congratulations! You've completed Module 4.2: AI Safety & Alignment.\n",
    "\n",
    "### You've Learned:\n",
    "- ‚úÖ Implementing NeMo Guardrails for LLM safety\n",
    "- ‚úÖ Using Llama Guard for content classification\n",
    "- ‚úÖ Performing automated red teaming\n",
    "- ‚úÖ Running safety benchmarks (TruthfulQA, BBQ)\n",
    "- ‚úÖ Evaluating and mitigating bias\n",
    "- ‚úÖ Creating comprehensive model cards\n",
    "\n",
    "### Key Takeaways:\n",
    "1. Safety is not optional - it's a requirement for production AI\n",
    "2. Defense in depth: Use multiple layers of safety controls\n",
    "3. Red team your own systems before attackers do\n",
    "4. Document everything - model cards enable responsible AI\n",
    "5. Bias is measurable and (partially) mitigable\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [Model Cards for Model Reporting (Mitchell et al.)](https://arxiv.org/abs/1810.03993)\n",
    "- [Hugging Face Model Card Guide](https://huggingface.co/docs/hub/model-cards)\n",
    "- [EU AI Act Documentation Requirements](https://artificialintelligenceact.eu/)\n",
    "- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Module 4.2 Complete!\")\n",
    "print(\"\\nüìÅ Generated files:\")\n",
    "print(\"   - model_cards/tech-assistant-llama3-8b-lora_README.md\")\n",
    "print(\"   - benchmark_results/safety_benchmarks.json\")\n",
    "print(\"   - bias_reports/bias_analysis.json\")\n",
    "print(\"   - red_team_data/red_team_report.json\")\n",
    "print(\"\\nüìå Next: Module 4.3 - MLOps & Experiment Tracking\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
