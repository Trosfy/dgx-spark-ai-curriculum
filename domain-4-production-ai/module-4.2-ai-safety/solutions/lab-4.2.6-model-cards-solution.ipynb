{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Lab 4.2.6: Model Card Creation - SOLUTIONS\n",
    "\n",
    "This notebook contains complete solutions for the exercises in Lab 4.2.6.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise1-header",
   "metadata": {},
   "source": [
    "## Exercise 1: Create Your Own Model Card\n",
    "\n",
    "**Task**: Create a comprehensive model card for a custom fine-tuned model.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class DetailedModelCard:\n",
    "    \"\"\"\n",
    "    A comprehensive model card following best practices.\n",
    "    \n",
    "    This includes:\n",
    "    - Detailed use cases with examples\n",
    "    - Comprehensive limitations (at least 5)\n",
    "    - Safety evaluation plans\n",
    "    - Ethical considerations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identity\n",
    "    model_name: str\n",
    "    model_version: str\n",
    "    model_type: str\n",
    "    base_model: str\n",
    "    \n",
    "    # Authorship\n",
    "    developed_by: str\n",
    "    funded_by: str = \"\"\n",
    "    shared_by: str = \"\"\n",
    "    \n",
    "    # Technical\n",
    "    license: str = \"apache-2.0\"\n",
    "    language: List[str] = field(default_factory=lambda: [\"en\"])\n",
    "    \n",
    "    # Description\n",
    "    summary: str = \"\"\n",
    "    \n",
    "    # Uses\n",
    "    primary_uses: List[Dict[str, str]] = field(default_factory=list)  # {use, example}\n",
    "    secondary_uses: List[str] = field(default_factory=list)\n",
    "    out_of_scope: List[str] = field(default_factory=list)\n",
    "    misuse_risks: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Limitations (minimum 5)\n",
    "    technical_limitations: List[str] = field(default_factory=list)\n",
    "    knowledge_limitations: List[str] = field(default_factory=list)\n",
    "    behavioral_limitations: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Known Biases\n",
    "    biases: List[Dict[str, str]] = field(default_factory=list)  # {type, description, mitigation}\n",
    "    \n",
    "    # Safety\n",
    "    safety_evaluations: Dict[str, float] = field(default_factory=dict)\n",
    "    safety_evaluation_plan: List[str] = field(default_factory=list)\n",
    "    guardrails_implemented: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Training\n",
    "    training_data_summary: str = \"\"\n",
    "    training_procedure: str = \"\"\n",
    "    training_hyperparameters: Dict[str, str] = field(default_factory=dict)\n",
    "    training_hardware: str = \"\"\n",
    "    \n",
    "    # Ethical Considerations\n",
    "    ethical_considerations: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Recommendations\n",
    "    recommendations: List[str] = field(default_factory=list)\n",
    "\n",
    "\n",
    "def create_example_detailed_card() -> DetailedModelCard:\n",
    "    \"\"\"Create an example detailed model card.\"\"\"\n",
    "    \n",
    "    return DetailedModelCard(\n",
    "        # Identity\n",
    "        model_name=\"customer-support-assistant-llama3-8b\",\n",
    "        model_version=\"2.0.0\",\n",
    "        model_type=\"Text Generation (Conversational)\",\n",
    "        base_model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        \n",
    "        # Authorship\n",
    "        developed_by=\"AI Support Team\",\n",
    "        funded_by=\"Internal R&D Budget\",\n",
    "        shared_by=\"Internal Use Only\",\n",
    "        \n",
    "        # Technical\n",
    "        license=\"proprietary\",\n",
    "        language=[\"en\", \"es\"],\n",
    "        \n",
    "        # Description\n",
    "        summary=\"\"\"A fine-tuned customer support assistant specialized for handling \n",
    "        product inquiries, troubleshooting, and account management. Trained on \n",
    "        historical support conversations with a focus on accuracy and helpfulness.\"\"\",\n",
    "        \n",
    "        # Uses\n",
    "        primary_uses=[\n",
    "            {\n",
    "                \"use\": \"Customer support chat\",\n",
    "                \"example\": \"Handling product questions like 'How do I reset my password?'\"\n",
    "            },\n",
    "            {\n",
    "                \"use\": \"Troubleshooting assistance\",\n",
    "                \"example\": \"Guiding users through steps like 'My device won't turn on'\"\n",
    "            },\n",
    "            {\n",
    "                \"use\": \"Order status inquiries\",\n",
    "                \"example\": \"Responding to 'Where is my order?'\"\n",
    "            },\n",
    "        ],\n",
    "        secondary_uses=[\n",
    "            \"Internal documentation search\",\n",
    "            \"FAQ generation from support tickets\",\n",
    "            \"Support agent training simulations\"\n",
    "        ],\n",
    "        out_of_scope=[\n",
    "            \"Making refund decisions (requires human approval)\",\n",
    "            \"Account security changes (password resets, 2FA)\",\n",
    "            \"Pricing negotiations or special discounts\",\n",
    "            \"Legal or compliance advice\",\n",
    "            \"Medical or safety-critical guidance\",\n",
    "            \"Handling complaints about employees\"\n",
    "        ],\n",
    "        misuse_risks=[\n",
    "            \"Using for unsupervised customer communication without human review\",\n",
    "            \"Deploying without proper escalation paths to human agents\",\n",
    "            \"Using for decisions that require legal compliance\"\n",
    "        ],\n",
    "        \n",
    "        # Limitations (5+ required)\n",
    "        technical_limitations=[\n",
    "            \"Maximum context length of 8192 tokens\",\n",
    "            \"Cannot access external databases or APIs in real-time\",\n",
    "            \"Response latency of 200-500ms may impact user experience\",\n",
    "            \"No support for image or voice inputs\"\n",
    "        ],\n",
    "        knowledge_limitations=[\n",
    "            \"Knowledge cutoff: December 2024\",\n",
    "            \"Limited knowledge of competitor products\",\n",
    "            \"May not know about recent product updates or recalls\",\n",
    "            \"No access to customer-specific order or account data\"\n",
    "        ],\n",
    "        behavioral_limitations=[\n",
    "            \"May occasionally generate overly verbose responses\",\n",
    "            \"Can struggle with highly technical edge cases\",\n",
    "            \"May not detect sarcasm or frustration accurately\",\n",
    "            \"Tendency to be overly apologetic in refusals\",\n",
    "            \"May provide generic responses for complex multi-issue queries\"\n",
    "        ],\n",
    "        \n",
    "        # Biases\n",
    "        biases=[\n",
    "            {\n",
    "                \"type\": \"Language formality bias\",\n",
    "                \"description\": \"Slightly more detailed responses to formally-phrased questions\",\n",
    "                \"mitigation\": \"Added informal conversation examples to training data\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"Product category bias\",\n",
    "                \"description\": \"Better performance on electronics than home goods\",\n",
    "                \"mitigation\": \"Rebalanced training data across categories\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"Name-based response variation\",\n",
    "                \"description\": \"Minimal (< 2%) sentiment variation by customer name\",\n",
    "                \"mitigation\": \"Regular bias testing in deployment\"\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # Safety\n",
    "        safety_evaluations={\n",
    "            \"TruthfulQA MC2\": 0.58,\n",
    "            \"BBQ Accuracy\": 0.82,\n",
    "            \"BBQ Bias Score\": 0.04,\n",
    "            \"Red Team Pass Rate\": 0.92,\n",
    "            \"Jailbreak Resistance\": 0.95,\n",
    "            \"PII Detection Accuracy\": 0.97\n",
    "        },\n",
    "        safety_evaluation_plan=[\n",
    "            \"Weekly automated red team testing with 100+ attack prompts\",\n",
    "            \"Monthly bias evaluation across 5 demographic dimensions\",\n",
    "            \"Quarterly third-party safety audit\",\n",
    "            \"Continuous monitoring of blocked/flagged requests\",\n",
    "            \"A/B testing safety interventions before deployment\"\n",
    "        ],\n",
    "        guardrails_implemented=[\n",
    "            \"NeMo Guardrails for input/output validation\",\n",
    "            \"Llama Guard 3 for safety classification\",\n",
    "            \"PII detection and redaction pipeline\",\n",
    "            \"Escalation triggers for sensitive topics\",\n",
    "            \"Rate limiting per customer session\"\n",
    "        ],\n",
    "        \n",
    "        # Training\n",
    "        training_data_summary=\"\"\"Training data consists of:\n",
    "        - 500k historical support conversations (anonymized)\n",
    "        - 50k curated Q&A pairs from product documentation\n",
    "        - 10k edge case examples for difficult scenarios\n",
    "        \n",
    "        Data was filtered for:\n",
    "        - PII removal (names, emails, order numbers)\n",
    "        - Toxicity filtering (< 0.1% toxic content)\n",
    "        - Quality scoring (only top 80% by helpfulness)\"\"\",\n",
    "        training_procedure=\"QLoRA fine-tuning with 4-bit quantization\",\n",
    "        training_hyperparameters={\n",
    "            \"LoRA Rank\": \"64\",\n",
    "            \"LoRA Alpha\": \"128\",\n",
    "            \"Learning Rate\": \"2e-4\",\n",
    "            \"Epochs\": \"3\",\n",
    "            \"Batch Size\": \"8 (effective with gradient accumulation)\",\n",
    "            \"Warmup Ratio\": \"0.05\",\n",
    "            \"Optimizer\": \"AdamW (paged 8-bit)\"\n",
    "        },\n",
    "        training_hardware=\"NVIDIA DGX Spark (128GB unified memory, ~4 hours training)\",\n",
    "        \n",
    "        # Ethics\n",
    "        ethical_considerations=[\n",
    "            \"Customer conversations may contain sensitive personal situations\",\n",
    "            \"Automated responses could frustrate customers needing human empathy\",\n",
    "            \"Risk of over-reliance reducing human support jobs\",\n",
    "            \"Privacy implications of storing/processing customer queries\",\n",
    "            \"Accessibility concerns for customers with disabilities\"\n",
    "        ],\n",
    "        \n",
    "        # Recommendations\n",
    "        recommendations=[\n",
    "            \"Always provide clear escalation path to human agents\",\n",
    "            \"Display disclaimer that users are chatting with AI\",\n",
    "            \"Implement confidence-based escalation for uncertain responses\",\n",
    "            \"Log all conversations for quality review and improvement\",\n",
    "            \"Provide opt-out option for customers preferring human support\",\n",
    "            \"Regular retraining with new product information\",\n",
    "            \"Monitor customer satisfaction scores for AI vs human interactions\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Create example\n",
    "detailed_card = create_example_detailed_card()\n",
    "print(f\"Created detailed model card for: {detailed_card.model_name}\")\n",
    "print(f\"  Limitations defined: {len(detailed_card.technical_limitations) + len(detailed_card.knowledge_limitations) + len(detailed_card.behavioral_limitations)}\")\n",
    "print(f\"  Safety evaluations: {len(detailed_card.safety_evaluations)}\")\n",
    "print(f\"  Ethical considerations: {len(detailed_card.ethical_considerations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise1-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_detailed_model_card(card: DetailedModelCard) -> str:\n",
    "    \"\"\"Render the detailed model card as markdown.\"\"\"\n",
    "    \n",
    "    # Primary uses table\n",
    "    uses_table = \"\\n\".join(\n",
    "        f\"| {u['use']} | {u['example']} |\"\n",
    "        for u in card.primary_uses\n",
    "    )\n",
    "    \n",
    "    # Safety table\n",
    "    safety_table = \"\\n\".join(\n",
    "        f\"| {name} | {score:.2%} |\"\n",
    "        for name, score in card.safety_evaluations.items()\n",
    "    )\n",
    "    \n",
    "    # Biases table\n",
    "    biases_table = \"\\n\".join(\n",
    "        f\"| {b['type']} | {b['description']} | {b['mitigation']} |\"\n",
    "        for b in card.biases\n",
    "    )\n",
    "    \n",
    "    # Hyperparameters\n",
    "    hyperparams = \"\\n\".join(\n",
    "        f\"| {k} | {v} |\"\n",
    "        for k, v in card.training_hyperparameters.items()\n",
    "    )\n",
    "    \n",
    "    return f\"\"\"# Model Card: {card.model_name}\n",
    "\n",
    "## Model Details\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| **Name** | {card.model_name} |\n",
    "| **Version** | {card.model_version} |\n",
    "| **Type** | {card.model_type} |\n",
    "| **Base Model** | {card.base_model} |\n",
    "| **License** | {card.license} |\n",
    "| **Languages** | {', '.join(card.language)} |\n",
    "| **Developed By** | {card.developed_by} |\n",
    "\n",
    "## Model Description\n",
    "\n",
    "{card.summary}\n",
    "\n",
    "## Intended Uses\n",
    "\n",
    "### Primary Use Cases\n",
    "\n",
    "| Use Case | Example |\n",
    "|----------|---------|  \n",
    "{uses_table}\n",
    "\n",
    "### Secondary Uses\n",
    "\n",
    "{chr(10).join('- ' + use for use in card.secondary_uses)}\n",
    "\n",
    "### Out-of-Scope Uses\n",
    "\n",
    "{chr(10).join('- ' + use for use in card.out_of_scope)}\n",
    "\n",
    "### Misuse Risks\n",
    "\n",
    "{chr(10).join('- ' + risk for risk in card.misuse_risks)}\n",
    "\n",
    "## Limitations\n",
    "\n",
    "### Technical Limitations\n",
    "\n",
    "{chr(10).join('- ' + lim for lim in card.technical_limitations)}\n",
    "\n",
    "### Knowledge Limitations\n",
    "\n",
    "{chr(10).join('- ' + lim for lim in card.knowledge_limitations)}\n",
    "\n",
    "### Behavioral Limitations\n",
    "\n",
    "{chr(10).join('- ' + lim for lim in card.behavioral_limitations)}\n",
    "\n",
    "## Bias, Risks, and Mitigations\n",
    "\n",
    "| Bias Type | Description | Mitigation |\n",
    "|-----------|-------------|------------|\n",
    "{biases_table}\n",
    "\n",
    "## Safety Evaluation\n",
    "\n",
    "### Benchmark Results\n",
    "\n",
    "| Metric | Score |\n",
    "|--------|-------|\n",
    "{safety_table}\n",
    "\n",
    "### Safety Evaluation Plan\n",
    "\n",
    "{chr(10).join('- ' + plan for plan in card.safety_evaluation_plan)}\n",
    "\n",
    "### Guardrails Implemented\n",
    "\n",
    "{chr(10).join('- ' + guard for guard in card.guardrails_implemented)}\n",
    "\n",
    "## Training Details\n",
    "\n",
    "### Training Data\n",
    "\n",
    "{card.training_data_summary}\n",
    "\n",
    "### Training Procedure\n",
    "\n",
    "{card.training_procedure}\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "{hyperparams}\n",
    "\n",
    "### Hardware\n",
    "\n",
    "{card.training_hardware}\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "{chr(10).join('- ' + ec for ec in card.ethical_considerations)}\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "{chr(10).join('- ' + rec for rec in card.recommendations)}\n",
    "\n",
    "---\n",
    "\n",
    "*Model card generated on {datetime.now().strftime('%Y-%m-%d')}*\n",
    "\"\"\"\n",
    "\n",
    "# Render and display\n",
    "rendered_card = render_detailed_model_card(detailed_card)\n",
    "print(rendered_card[:2000])\n",
    "print(\"\\n... [truncated] ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise2-header",
   "metadata": {},
   "source": [
    "## Exercise 2: Environmental Impact Calculation\n",
    "\n",
    "**Task**: Calculate and document the environmental impact of training.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EnvironmentalImpact:\n",
    "    \"\"\"Environmental impact calculation for model training.\"\"\"\n",
    "    \n",
    "    # Training metrics\n",
    "    training_hours: float\n",
    "    gpu_count: int\n",
    "    gpu_model: str\n",
    "    gpu_tdp_watts: float  # Thermal Design Power\n",
    "    \n",
    "    # Location-specific\n",
    "    grid_carbon_intensity: float = 400  # gCO2/kWh (US average)\n",
    "    pue: float = 1.1  # Power Usage Effectiveness (datacenter overhead)\n",
    "    \n",
    "    def calculate_energy_kwh(self) -> float:\n",
    "        \"\"\"Calculate total energy consumption in kWh.\"\"\"\n",
    "        gpu_energy = (self.training_hours * self.gpu_count * self.gpu_tdp_watts) / 1000\n",
    "        total_energy = gpu_energy * self.pue  # Add datacenter overhead\n",
    "        return total_energy\n",
    "    \n",
    "    def calculate_carbon_kg(self) -> float:\n",
    "        \"\"\"Calculate carbon emissions in kg CO2.\"\"\"\n",
    "        energy_kwh = self.calculate_energy_kwh()\n",
    "        carbon_kg = (energy_kwh * self.grid_carbon_intensity) / 1000\n",
    "        return carbon_kg\n",
    "    \n",
    "    def calculate_tree_offset(self) -> float:\n",
    "        \"\"\"Calculate equivalent trees needed to offset (trees absorb ~22kg CO2/year).\"\"\"\n",
    "        return self.calculate_carbon_kg() / 22\n",
    "    \n",
    "    def calculate_driving_equivalent(self) -> float:\n",
    "        \"\"\"Calculate equivalent driving distance in km (~120g CO2/km for avg car).\"\"\"\n",
    "        return (self.calculate_carbon_kg() * 1000) / 120\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"Generate environmental impact report.\"\"\"\n",
    "        energy = self.calculate_energy_kwh()\n",
    "        carbon = self.calculate_carbon_kg()\n",
    "        trees = self.calculate_tree_offset()\n",
    "        driving = self.calculate_driving_equivalent()\n",
    "        \n",
    "        return f\"\"\"## Environmental Impact\n",
    "\n",
    "### Training Configuration\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Training Duration | {self.training_hours:.1f} hours |\n",
    "| GPU(s) Used | {self.gpu_count}x {self.gpu_model} |\n",
    "| GPU TDP | {self.gpu_tdp_watts}W |\n",
    "| Data Center PUE | {self.pue} |\n",
    "| Grid Carbon Intensity | {self.grid_carbon_intensity} gCO2/kWh |\n",
    "\n",
    "### Energy Consumption\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Total Energy | {energy:.2f} kWh |\n",
    "| CO2 Emissions | {carbon:.2f} kg |\n",
    "\n",
    "### Equivalents\n",
    "\n",
    "| Comparison | Value |\n",
    "|------------|-------|\n",
    "| Trees to offset (1 year) | {trees:.2f} trees |\n",
    "| Equivalent driving | {driving:.1f} km |\n",
    "| Smartphone charges | {energy * 1000 / 10:.0f} charges |\n",
    "\n",
    "### Carbon Reduction Measures\n",
    "\n",
    "- Used efficient hardware (DGX Spark)\n",
    "- Applied QLoRA for memory efficiency\n",
    "- Trained during off-peak hours when possible\n",
    "- Considered carbon-aware computing\n",
    "\n",
    "### Note\n",
    "\n",
    "This is a significantly lower carbon footprint compared to training from scratch.\n",
    "Fine-tuning an 8B parameter model uses ~1000x less compute than pre-training.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Calculate for DGX Spark training\n",
    "print(\"Environmental Impact Calculation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "impact = EnvironmentalImpact(\n",
    "    training_hours=4.0,  # 4 hours of training\n",
    "    gpu_count=1,         # Single GPU\n",
    "    gpu_model=\"NVIDIA GB10 (DGX Spark)\",\n",
    "    gpu_tdp_watts=100,   # Estimated TDP for edge GPU\n",
    "    grid_carbon_intensity=400,  # US average\n",
    "    pue=1.0  # Desktop, no datacenter overhead\n",
    ")\n",
    "\n",
    "print(f\"\\nEnergy consumed: {impact.calculate_energy_kwh():.2f} kWh\")\n",
    "print(f\"Carbon emitted: {impact.calculate_carbon_kg():.2f} kg CO2\")\n",
    "print(f\"Tree offset needed: {impact.calculate_tree_offset():.2f} trees\")\n",
    "print(f\"Equivalent to driving: {impact.calculate_driving_equivalent():.1f} km\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Full Report:\")\n",
    "print(impact.generate_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise2-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with cloud training\n",
    "print(\"Comparison: DGX Spark vs Cloud Training\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# DGX Spark (local)\n",
    "dgx_spark = EnvironmentalImpact(\n",
    "    training_hours=4.0,\n",
    "    gpu_count=1,\n",
    "    gpu_model=\"GB10 (DGX Spark)\",\n",
    "    gpu_tdp_watts=100,\n",
    "    pue=1.0  # Desktop\n",
    ")\n",
    "\n",
    "# Cloud A100\n",
    "cloud_a100 = EnvironmentalImpact(\n",
    "    training_hours=2.0,  # Faster GPU\n",
    "    gpu_count=1,\n",
    "    gpu_model=\"A100 40GB (Cloud)\",\n",
    "    gpu_tdp_watts=400,\n",
    "    pue=1.2  # Typical cloud datacenter\n",
    ")\n",
    "\n",
    "# Cloud H100\n",
    "cloud_h100 = EnvironmentalImpact(\n",
    "    training_hours=1.0,  # Even faster\n",
    "    gpu_count=1,\n",
    "    gpu_model=\"H100 (Cloud)\",\n",
    "    gpu_tdp_watts=700,\n",
    "    pue=1.2\n",
    ")\n",
    "\n",
    "print(f\"\\n{'Hardware':<30} {'Energy (kWh)':<15} {'CO2 (kg)':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, impact in [(\"DGX Spark (Local)\", dgx_spark), \n",
    "                      (\"Cloud A100\", cloud_a100),\n",
    "                      (\"Cloud H100\", cloud_h100)]:\n",
    "    energy = impact.calculate_energy_kwh()\n",
    "    carbon = impact.calculate_carbon_kg()\n",
    "    print(f\"{name:<30} {energy:<15.2f} {carbon:<15.2f}\")\n",
    "\n",
    "print(\"\\n*Note: Actual impact varies by location and power source.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "print(\"Cleanup complete!\")\n",
    "print(\"\\nModule 4.2: AI Safety & Alignment - COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
