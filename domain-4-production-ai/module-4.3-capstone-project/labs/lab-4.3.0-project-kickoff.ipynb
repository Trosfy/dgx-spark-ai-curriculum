{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Capstone Project Kickoff\n\n**Module:** 4.3 - Capstone Project (Domain 4: Production AI)\n**Time:** 2-3 hours\n**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê\n\n---\n\n## üéâ Congratulations on Reaching the Capstone!\n\nYou've completed an incredible journey through the DGX Spark AI Curriculum. From understanding the fundamentals of neural networks to fine-tuning 70B parameter models, from building RAG systems to deploying production APIs - you've acquired a remarkable set of skills.\n\nNow it's time to put it all together.\n\n---\n\n## üéØ Learning Objectives\n\nBy the end of this notebook, you will:\n- [ ] Understand the four capstone project options\n- [ ] Evaluate which project best matches your interests and goals\n- [ ] Set up your project environment\n- [ ] Complete your project proposal\n- [ ] Create your project timeline\n\n---\n\n## üìö Prerequisites\n\n- Completed: All modules in Domains 1-4\n- Knowledge of: LLM fine-tuning, RAG systems, agents, deployment\n- Access to: DGX Spark with 128GB unified memory\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Real-World Context\n",
    "\n",
    "The capstone project mirrors what AI engineers do in industry every day: identify a problem, design a solution, implement it with production-quality code, and evaluate its effectiveness.\n",
    "\n",
    "Companies like OpenAI, Anthropic, Google, and Meta all follow similar processes when building AI products:\n",
    "\n",
    "1. **Problem Definition** ‚Üí What are we solving?\n",
    "2. **Architecture Design** ‚Üí How will we solve it?\n",
    "3. **Implementation** ‚Üí Build the solution\n",
    "4. **Optimization** ‚Üí Make it fast and efficient\n",
    "5. **Evaluation** ‚Üí Does it actually work?\n",
    "6. **Documentation** ‚Üí Can others use and extend it?\n",
    "\n",
    "Your capstone follows this exact pattern, preparing you for real-world AI engineering roles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is a Capstone Project?\n",
    "\n",
    "> **Imagine you've been learning to cook for months.** You've mastered chopping vegetables, making sauces, baking bread, grilling meat, and plating dishes. Each skill was practiced in isolation.\n",
    ">\n",
    "> **Now, you're going to prepare a complete dinner party.** You need to plan a menu, prep all the ingredients, cook multiple dishes that complement each other, time everything so it's ready together, and present it beautifully.\n",
    ">\n",
    "> **That's a capstone.** It's not about learning one new thing - it's about combining everything you've learned into one impressive, complete creation.\n",
    ">\n",
    "> **In AI terms:** You've learned fine-tuning, RAG, agents, deployment, and more. Your capstone combines these into a complete, working AI system that solves a real problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Environment Verification\n",
    "\n",
    "Before choosing your project, let's verify your DGX Spark environment is properly configured. Your capstone will push the hardware to its limits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Environment Verification\n",
    "# This cell verifies your DGX Spark is ready for capstone development\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ DGX SPARK CAPSTONE ENVIRONMENT CHECK\")\n",
    "print(f\"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Python version\n",
    "print(f\"\\nüêç Python Version: {sys.version}\")\n",
    "\n",
    "# Check critical packages\n",
    "packages_status = []\n",
    "critical_packages = [\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"transformers\", \"Transformers\"),\n",
    "    (\"peft\", \"PEFT (LoRA)\"),\n",
    "    (\"bitsandbytes\", \"BitsAndBytes\"),\n",
    "    (\"sentence_transformers\", \"Sentence Transformers\"),\n",
    "    (\"langchain\", \"LangChain\"),\n",
    "    (\"fastapi\", \"FastAPI\"),\n",
    "    (\"gradio\", \"Gradio\"),\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ Package Status:\")\n",
    "for pkg_name, display_name in critical_packages:\n",
    "    try:\n",
    "        module = __import__(pkg_name)\n",
    "        version = getattr(module, '__version__', 'installed')\n",
    "        print(f\"  ‚úÖ {display_name}: {version}\")\n",
    "        packages_status.append(True)\n",
    "    except ImportError:\n",
    "        print(f\"  ‚ùå {display_name}: NOT INSTALLED\")\n",
    "        packages_status.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU and Memory Check\n",
    "import torch\n",
    "\n",
    "print(\"\\nüéÆ GPU Status:\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"  ‚úÖ GPU: {gpu_name}\")\n",
    "    print(f\"  ‚úÖ GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Check for Blackwell features\n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"  ‚úÖ Compute Capability: {compute_capability[0]}.{compute_capability[1]}\")\n",
    "    \n",
    "    # Memory allocation test\n",
    "    print(\"\\nüíæ Memory Test:\")\n",
    "    print(f\"  Current allocation: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "    print(f\"  Current reserved: {torch.cuda.memory_reserved()/1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"  ‚ùå CUDA not available!\")\n",
    "    print(\"  Make sure you're running in an NGC container with GPU access.\")\n",
    "\n",
    "# System memory\n",
    "import os\n",
    "try:\n",
    "    with open('/proc/meminfo', 'r') as f:\n",
    "        for line in f:\n",
    "            if 'MemTotal' in line:\n",
    "                mem_gb = int(line.split()[1]) / 1e6\n",
    "                print(f\"\\nüñ•Ô∏è System Memory: {mem_gb:.1f} GB\")\n",
    "                if mem_gb > 100:\n",
    "                    print(\"  ‚úÖ Unified memory configuration detected!\")\n",
    "                break\n",
    "except:\n",
    "    print(\"\\nüñ•Ô∏è Could not read system memory info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disk Space Check\n",
    "import shutil\n",
    "\n",
    "print(\"\\nüíø Disk Space:\")\n",
    "paths_to_check = [\n",
    "    (\"/workspace\", \"Workspace\"),\n",
    "    (os.path.expanduser(\"~/.cache/huggingface\"), \"HuggingFace Cache\"),\n",
    "]\n",
    "\n",
    "for path, name in paths_to_check:\n",
    "    if os.path.exists(path):\n",
    "        total, used, free = shutil.disk_usage(path)\n",
    "        print(f\"  {name} ({path}):\")\n",
    "        print(f\"    Total: {total/1e9:.1f} GB\")\n",
    "        print(f\"    Used: {used/1e9:.1f} GB\")\n",
    "        print(f\"    Free: {free/1e9:.1f} GB ({'‚úÖ' if free/1e9 > 100 else '‚ö†Ô∏è'})\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è {name}: Path not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Environment check complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç What Just Happened?\n",
    "\n",
    "We verified:\n",
    "1. **Python Environment** - All required packages are installed\n",
    "2. **GPU Access** - Blackwell GPU is available with sufficient memory\n",
    "3. **System Memory** - 128GB unified memory is configured\n",
    "4. **Disk Space** - Enough space for models and data\n",
    "\n",
    "If any checks failed, resolve them before proceeding. You'll need full access to DGX Spark capabilities for your capstone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Project Options Overview\n",
    "\n",
    "You have four project options, each emphasizing different skills. All are designed to showcase DGX Spark's unique capabilities.\n",
    "\n",
    "### Option A: Domain-Specific AI Assistant\n",
    "\n",
    "**Build a complete AI assistant specialized for a specific domain.**\n",
    "\n",
    "| Component | Technology | DGX Spark Advantage |\n",
    "|-----------|------------|--------------------|\n",
    "| Base Model | Llama 3.3 70B | Fits in 128GB memory |\n",
    "| Fine-tuning | QLoRA | Fast training with unified memory |\n",
    "| RAG | Vector DB + BM25 | Large knowledge base in memory |\n",
    "| Tools | Custom functions | Low-latency tool calls |\n",
    "| API | FastAPI + Streaming | Real-time responses |\n",
    "\n",
    "**Best for:** Students interested in LLM customization, RAG systems, and building practical applications.\n",
    "\n",
    "**Example domains:** DevOps assistant, financial advisor, medical literature search, legal document analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Option B: Multimodal Document Intelligence\n",
    "\n",
    "**Build a system that understands complex documents with text, images, and diagrams.**\n",
    "\n",
    "| Component | Technology | DGX Spark Advantage |\n",
    "|-----------|------------|--------------------|\n",
    "| Vision | LLaVA / Qwen-VL | Large VLM in memory |\n",
    "| OCR | Tesseract + LayoutLM | Batch processing |\n",
    "| Extraction | Schema-based | Complex document handling |\n",
    "| QA | Multimodal RAG | Images + text together |\n",
    "| Export | Structured JSON/CSV | Integration ready |\n",
    "\n",
    "**Best for:** Students interested in computer vision, document processing, and multimodal AI.\n",
    "\n",
    "**Example applications:** Invoice processing, research paper analysis, technical manual QA.\n",
    "\n",
    "---\n",
    "\n",
    "### Option C: AI Agent Swarm\n",
    "\n",
    "**Build a multi-agent system where specialized agents collaborate.**\n",
    "\n",
    "| Component | Technology | DGX Spark Advantage |\n",
    "|-----------|------------|--------------------|\n",
    "| Agents | 4+ specialized agents | Multiple models loaded |\n",
    "| Coordination | LangGraph / custom | Complex workflows |\n",
    "| Tools | Code exec, search, etc. | Parallel tool execution |\n",
    "| Memory | Shared + individual | Large context windows |\n",
    "| Safety | Human-in-the-loop | Real-time approval |\n",
    "\n",
    "**Best for:** Students interested in agentic AI, planning systems, and complex automation.\n",
    "\n",
    "**Example applications:** Research assistant, software development team, data analysis pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### Option D: Custom Training Pipeline\n",
    "\n",
    "**Build infrastructure for continuous model improvement.**\n",
    "\n",
    "| Component | Technology | DGX Spark Advantage |\n",
    "|-----------|------------|--------------------|\n",
    "| Data | Collection + curation | Large dataset processing |\n",
    "| Training | SFT + DPO | 70B training feasible |\n",
    "| Evaluation | Auto benchmarks | Fast model comparison |\n",
    "| Versioning | MLflow / custom | Experiment tracking |\n",
    "| Deployment | A/B testing | Multiple models served |\n",
    "\n",
    "**Best for:** Students interested in MLOps, training infrastructure, and model development.\n",
    "\n",
    "**Example applications:** Domain adaptation pipeline, preference learning system, model improvement loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Project Selection Decision Tree\n",
    "\n",
    "Use this interactive decision helper to find your best project match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Selection Helper\n",
    "# Answer these questions to find your best project match\n",
    "\n",
    "def project_selector():\n",
    "    \"\"\"Interactive project selection based on interests and skills.\"\"\"\n",
    "    \n",
    "    print(\"üéØ CAPSTONE PROJECT SELECTOR\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Answer these questions to find your ideal project.\")\n",
    "    print(\"Rate each from 1 (not interested) to 5 (very interested)\\n\")\n",
    "    \n",
    "    questions = {\n",
    "        \"option_a\": [\n",
    "            \"Building chatbots and conversational AI\",\n",
    "            \"Fine-tuning LLMs for specific domains\",\n",
    "            \"Building RAG systems with knowledge bases\",\n",
    "            \"Creating API-based AI services\",\n",
    "        ],\n",
    "        \"option_b\": [\n",
    "            \"Working with images and visual data\",\n",
    "            \"Processing PDFs and documents\",\n",
    "            \"Extracting structured data from unstructured sources\",\n",
    "            \"Combining vision and language models\",\n",
    "        ],\n",
    "        \"option_c\": [\n",
    "            \"Building autonomous AI agents\",\n",
    "            \"Multi-step planning and reasoning\",\n",
    "            \"Tool use and function calling\",\n",
    "            \"Coordinating multiple AI systems\",\n",
    "        ],\n",
    "        \"option_d\": [\n",
    "            \"Training and fine-tuning workflows\",\n",
    "            \"Building ML infrastructure and pipelines\",\n",
    "            \"Model evaluation and benchmarking\",\n",
    "            \"Experiment tracking and versioning\",\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    scores = {\"option_a\": 0, \"option_b\": 0, \"option_c\": 0, \"option_d\": 0}\n",
    "    \n",
    "    option_names = {\n",
    "        \"option_a\": \"A: Domain-Specific AI Assistant\",\n",
    "        \"option_b\": \"B: Multimodal Document Intelligence\",\n",
    "        \"option_c\": \"C: AI Agent Swarm\",\n",
    "        \"option_d\": \"D: Custom Training Pipeline\",\n",
    "    }\n",
    "    \n",
    "    # Collect all responses\n",
    "    all_questions = []\n",
    "    for option, q_list in questions.items():\n",
    "        for q in q_list:\n",
    "            all_questions.append((option, q))\n",
    "    \n",
    "    # Shuffle to avoid bias\n",
    "    import random\n",
    "    random.seed(42)  # Reproducible shuffle\n",
    "    random.shuffle(all_questions)\n",
    "    \n",
    "    print(\"Rate your interest in each area (1-5):\\n\")\n",
    "    \n",
    "    for i, (option, question) in enumerate(all_questions, 1):\n",
    "        while True:\n",
    "            try:\n",
    "                response = input(f\"{i}. {question}: \")\n",
    "                score = int(response)\n",
    "                if 1 <= score <= 5:\n",
    "                    scores[option] += score\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"   Please enter a number between 1 and 5.\")\n",
    "            except ValueError:\n",
    "                print(\"   Please enter a number between 1 and 5.\")\n",
    "    \n",
    "    # Calculate and display results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä YOUR RESULTS\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    max_possible = len(questions[\"option_a\"]) * 5\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for rank, (option, score) in enumerate(sorted_scores, 1):\n",
    "        percentage = (score / max_possible) * 100\n",
    "        bar = \"‚ñà\" * int(percentage / 5) + \"‚ñë\" * (20 - int(percentage / 5))\n",
    "        medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\" if rank == 3 else \"  \"\n",
    "        print(f\"{medal} {option_names[option]}\")\n",
    "        print(f\"   {bar} {percentage:.0f}% ({score}/{max_possible})\\n\")\n",
    "    \n",
    "    winner = sorted_scores[0][0]\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üéØ RECOMMENDED PROJECT: {option_names[winner]}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return winner\n",
    "\n",
    "# Uncomment to run interactively:\n",
    "# recommended = project_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick selection if you already know your preference\n# Uncomment and modify the line below:\n\n# SELECTED_PROJECT = \"A\"  # Options: \"A\", \"B\", \"C\", or \"D\"\n\nproject_descriptions = {\n    \"A\": {\n        \"name\": \"Domain-Specific AI Assistant\",\n        \"summary\": \"Fine-tuned LLM + RAG + Tools + API\",\n        \"notebook\": \"lab-4.3.2-option-a-ai-assistant.ipynb\",\n    },\n    \"B\": {\n        \"name\": \"Multimodal Document Intelligence\",\n        \"summary\": \"VLM + OCR + Extraction + QA\",\n        \"notebook\": \"lab-4.3.3-option-b-document-intelligence.ipynb\",\n    },\n    \"C\": {\n        \"name\": \"AI Agent Swarm\",\n        \"summary\": \"Multi-agent + Planning + Tools + Safety\",\n        \"notebook\": \"lab-4.3.4-option-c-agent-swarm.ipynb\",\n    },\n    \"D\": {\n        \"name\": \"Custom Training Pipeline\",\n        \"summary\": \"Data + Training + Evaluation + Deployment\",\n        \"notebook\": \"lab-4.3.5-option-d-training-pipeline.ipynb\",\n    },\n}\n\nprint(\"üìã PROJECT OPTIONS SUMMARY\")\nprint(\"=\"*60)\nfor key, info in project_descriptions.items():\n    print(f\"\\nOption {key}: {info['name']}\")\n    print(f\"  Components: {info['summary']}\")\n    print(f\"  Guide: {info['notebook']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Skills Assessment\n",
    "\n",
    "Each project builds on skills from previous modules. Let's verify you have the prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Skills Assessment Matrix\n\nskills_matrix = {\n    \"A\": {\n        \"required\": [\n            (\"Module 3.1: LLM Fine-tuning\", \"QLoRA implementation\"),\n            (\"Module 3.4: AI Agents\", \"RAG pipeline construction\"),\n            (\"Module 3.3: Deployment\", \"FastAPI + streaming\"),\n        ],\n        \"helpful\": [\n            \"Module 3.2: Quantization\",\n            \"Module 2.4: Hugging Face Ecosystem\",\n        ]\n    },\n    \"B\": {\n        \"required\": [\n            (\"Module 2.2: Computer Vision\", \"Image processing\"),\n            (\"Module 4.1: Multimodal\", \"VLM usage\"),\n            (\"Module 3.4: AI Agents\", \"RAG fundamentals\"),\n        ],\n        \"helpful\": [\n            \"Module 2.3: NLP & Transformers\",\n            \"Module 3.3: Deployment\",\n        ]\n    },\n    \"C\": {\n        \"required\": [\n            (\"Module 3.4: AI Agents\", \"Agent frameworks\"),\n            (\"Module 2.3: NLP & Transformers\", \"LLM reasoning\"),\n            (\"Module 3.3: Deployment\", \"Service architecture\"),\n        ],\n        \"helpful\": [\n            \"Module 3.1: LLM Fine-tuning\",\n            \"Module 4.1: Multimodal\",\n        ]\n    },\n    \"D\": {\n        \"required\": [\n            (\"Module 3.1: LLM Fine-tuning\", \"SFT and DPO\"),\n            (\"Module 4.2: MLOps\", \"Evaluation frameworks\"),\n            (\"Module 2.4: Hugging Face Ecosystem\", \"Trainer API\"),\n        ],\n        \"helpful\": [\n            \"Module 3.2: Quantization\",\n            \"Module 3.3: Deployment\",\n        ]\n    },\n}\n\ndef display_skills_for_project(project: str):\n    \"\"\"Display required and helpful skills for a project.\"\"\"\n    print(f\"\\nüìö SKILLS FOR PROJECT {project}\")\n    print(\"=\"*50)\n    \n    info = skills_matrix[project]\n    \n    print(\"\\n‚úÖ Required Skills:\")\n    for module, skill in info[\"required\"]:\n        print(f\"  ‚Ä¢ {module}\")\n        print(f\"    Key skill: {skill}\")\n    \n    print(\"\\nüìò Helpful Background:\")\n    for module in info[\"helpful\"]:\n        print(f\"  ‚Ä¢ {module}\")\n\n# Display for all projects\nfor project in [\"A\", \"B\", \"C\", \"D\"]:\n    display_skills_for_project(project)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Project Timeline Planning\n",
    "\n",
    "Your capstone spans 6 weeks. Here's how to structure your time effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeline Generator\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_timeline(start_date: str = None):\n",
    "    \"\"\"Generate a 6-week capstone timeline.\"\"\"\n",
    "    \n",
    "    if start_date:\n",
    "        start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    else:\n",
    "        start = datetime.now()\n",
    "    \n",
    "    weeks = [\n",
    "        {\n",
    "            \"week\": 1,\n",
    "            \"name\": \"Planning\",\n",
    "            \"hours\": \"6-8\",\n",
    "            \"tasks\": [\n",
    "                \"Complete project proposal\",\n",
    "                \"Design system architecture\",\n",
    "                \"Set up development environment\",\n",
    "                \"Create project repository\",\n",
    "                \"Identify data sources\",\n",
    "            ],\n",
    "            \"deliverable\": \"Approved project proposal + Architecture diagram\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 2,\n",
    "            \"name\": \"Foundation (Part 1)\",\n",
    "            \"hours\": \"8-10\",\n",
    "            \"tasks\": [\n",
    "                \"Implement core component #1\",\n",
    "                \"Set up data pipeline\",\n",
    "                \"Create initial tests\",\n",
    "                \"Document as you build\",\n",
    "            ],\n",
    "            \"deliverable\": \"Working prototype of core component\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 3,\n",
    "            \"name\": \"Foundation (Part 2)\",\n",
    "            \"hours\": \"8-10\",\n",
    "            \"tasks\": [\n",
    "                \"Implement core component #2\",\n",
    "                \"Model training/fine-tuning\",\n",
    "                \"Basic integration tests\",\n",
    "                \"Performance baseline\",\n",
    "            ],\n",
    "            \"deliverable\": \"All core components working independently\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 4,\n",
    "            \"name\": \"Integration\",\n",
    "            \"hours\": \"8-10\",\n",
    "            \"tasks\": [\n",
    "                \"Connect all components\",\n",
    "                \"Build API layer\",\n",
    "                \"End-to-end testing\",\n",
    "                \"Fix integration issues\",\n",
    "            ],\n",
    "            \"deliverable\": \"Complete integrated system\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 5,\n",
    "            \"name\": \"Optimization\",\n",
    "            \"hours\": \"6-8\",\n",
    "            \"tasks\": [\n",
    "                \"Performance profiling\",\n",
    "                \"Memory optimization\",\n",
    "                \"Quantization (if applicable)\",\n",
    "                \"Benchmark suite execution\",\n",
    "            ],\n",
    "            \"deliverable\": \"Optimized system with benchmarks\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 6,\n",
    "            \"name\": \"Documentation\",\n",
    "            \"hours\": \"6-8\",\n",
    "            \"tasks\": [\n",
    "                \"Complete technical report\",\n",
    "                \"Record demo video\",\n",
    "                \"Prepare presentation\",\n",
    "                \"Final code cleanup\",\n",
    "                \"Repository polish\",\n",
    "            ],\n",
    "            \"deliverable\": \"All deliverables complete\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìÖ YOUR CAPSTONE TIMELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for week_info in weeks:\n",
    "        week_start = start + timedelta(weeks=week_info[\"week\"]-1)\n",
    "        week_end = week_start + timedelta(days=6)\n",
    "        \n",
    "        print(f\"\\nüìå Week {week_info['week']}: {week_info['name']}\")\n",
    "        print(f\"   {week_start.strftime('%b %d')} - {week_end.strftime('%b %d')}\")\n",
    "        print(f\"   Estimated hours: {week_info['hours']}\")\n",
    "        print(\"\\n   Tasks:\")\n",
    "        for task in week_info[\"tasks\"]:\n",
    "            print(f\"   [ ] {task}\")\n",
    "        print(f\"\\n   üì¶ Deliverable: {week_info['deliverable']}\")\n",
    "    \n",
    "    final_date = start + timedelta(weeks=6)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üéØ Target completion: {final_date.strftime('%B %d, %Y')}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Generate timeline starting from today\n",
    "generate_timeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Project Setup\n",
    "\n",
    "Let's create your project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Structure Generator\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_project_structure(project_name: str, project_option: str, base_path: str = \"/workspace\"):\n",
    "    \"\"\"\n",
    "    Create a complete project structure for the capstone.\n",
    "    \n",
    "    Args:\n",
    "        project_name: Name of your project (e.g., \"aws-assistant\")\n",
    "        project_option: One of \"A\", \"B\", \"C\", \"D\"\n",
    "        base_path: Where to create the project\n",
    "    \"\"\"\n",
    "    \n",
    "    project_structures = {\n",
    "        \"A\": {  # Domain-Specific AI Assistant\n",
    "            \"dirs\": [\n",
    "                \"src/models\",\n",
    "                \"src/rag\",\n",
    "                \"src/tools\",\n",
    "                \"src/api\",\n",
    "                \"data/raw\",\n",
    "                \"data/processed\",\n",
    "                \"data/knowledge_base\",\n",
    "                \"training/configs\",\n",
    "                \"training/outputs\",\n",
    "                \"evaluation/benchmarks\",\n",
    "                \"evaluation/results\",\n",
    "                \"notebooks\",\n",
    "                \"tests\",\n",
    "                \"docs\",\n",
    "            ],\n",
    "            \"files\": {\n",
    "                \"src/__init__.py\": \"\",\n",
    "                \"src/models/__init__.py\": \"\",\n",
    "                \"src/rag/__init__.py\": \"\",\n",
    "                \"src/tools/__init__.py\": \"\",\n",
    "                \"src/api/__init__.py\": \"\",\n",
    "                \"tests/__init__.py\": \"\",\n",
    "            }\n",
    "        },\n",
    "        \"B\": {  # Multimodal Document Intelligence\n",
    "            \"dirs\": [\n",
    "                \"src/ingestion\",\n",
    "                \"src/vision\",\n",
    "                \"src/extraction\",\n",
    "                \"src/qa\",\n",
    "                \"src/export\",\n",
    "                \"data/documents\",\n",
    "                \"data/processed\",\n",
    "                \"data/outputs\",\n",
    "                \"models\",\n",
    "                \"evaluation/datasets\",\n",
    "                \"evaluation/results\",\n",
    "                \"notebooks\",\n",
    "                \"tests\",\n",
    "                \"docs\",\n",
    "            ],\n",
    "            \"files\": {\n",
    "                \"src/__init__.py\": \"\",\n",
    "                \"src/ingestion/__init__.py\": \"\",\n",
    "                \"src/vision/__init__.py\": \"\",\n",
    "                \"src/extraction/__init__.py\": \"\",\n",
    "                \"src/qa/__init__.py\": \"\",\n",
    "                \"src/export/__init__.py\": \"\",\n",
    "                \"tests/__init__.py\": \"\",\n",
    "            }\n",
    "        },\n",
    "        \"C\": {  # AI Agent Swarm\n",
    "            \"dirs\": [\n",
    "                \"src/agents\",\n",
    "                \"src/coordinator\",\n",
    "                \"src/tools\",\n",
    "                \"src/memory\",\n",
    "                \"src/safety\",\n",
    "                \"workflows\",\n",
    "                \"evaluation/tasks\",\n",
    "                \"evaluation/results\",\n",
    "                \"notebooks\",\n",
    "                \"tests\",\n",
    "                \"docs\",\n",
    "            ],\n",
    "            \"files\": {\n",
    "                \"src/__init__.py\": \"\",\n",
    "                \"src/agents/__init__.py\": \"\",\n",
    "                \"src/coordinator/__init__.py\": \"\",\n",
    "                \"src/tools/__init__.py\": \"\",\n",
    "                \"src/memory/__init__.py\": \"\",\n",
    "                \"src/safety/__init__.py\": \"\",\n",
    "                \"tests/__init__.py\": \"\",\n",
    "            }\n",
    "        },\n",
    "        \"D\": {  # Custom Training Pipeline\n",
    "            \"dirs\": [\n",
    "                \"src/data\",\n",
    "                \"src/training\",\n",
    "                \"src/evaluation\",\n",
    "                \"src/serving\",\n",
    "                \"configs\",\n",
    "                \"data/raw\",\n",
    "                \"data/processed\",\n",
    "                \"data/splits\",\n",
    "                \"experiments\",\n",
    "                \"models/checkpoints\",\n",
    "                \"models/exported\",\n",
    "                \"notebooks\",\n",
    "                \"tests\",\n",
    "                \"docs\",\n",
    "            ],\n",
    "            \"files\": {\n",
    "                \"src/__init__.py\": \"\",\n",
    "                \"src/data/__init__.py\": \"\",\n",
    "                \"src/training/__init__.py\": \"\",\n",
    "                \"src/evaluation/__init__.py\": \"\",\n",
    "                \"src/serving/__init__.py\": \"\",\n",
    "                \"tests/__init__.py\": \"\",\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    structure = project_structures.get(project_option.upper())\n",
    "    if not structure:\n",
    "        print(f\"‚ùå Invalid project option: {project_option}\")\n",
    "        return\n",
    "    \n",
    "    project_path = Path(base_path) / project_name\n",
    "    \n",
    "    print(f\"\\nüèóÔ∏è Creating project structure for: {project_name}\")\n",
    "    print(f\"   Option: {project_option}\")\n",
    "    print(f\"   Location: {project_path}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create directories\n",
    "    for dir_path in structure[\"dirs\"]:\n",
    "        full_path = project_path / dir_path\n",
    "        full_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  üìÅ {dir_path}/\")\n",
    "    \n",
    "    # Create files\n",
    "    for file_path, content in structure[\"files\"].items():\n",
    "        full_path = project_path / file_path\n",
    "        full_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        full_path.write_text(content)\n",
    "        print(f\"  üìÑ {file_path}\")\n",
    "    \n",
    "    # Create common files\n",
    "    common_files = {\n",
    "        \"README.md\": f\"# {project_name}\\n\\nCapstone Project - Option {project_option}\\n\",\n",
    "        \"requirements.txt\": \"# Add your dependencies here\\ntorch>=2.5.0\\ntransformers>=4.46.0\\n\",\n",
    "        \".gitignore\": \"\"\"# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# Data\n",
    "data/raw/*\n",
    "!data/raw/.gitkeep\n",
    "\n",
    "# Models\n",
    "*.bin\n",
    "*.safetensors\n",
    "models/checkpoints/*\n",
    "!models/checkpoints/.gitkeep\n",
    "\n",
    "# Misc\n",
    ".env\n",
    "*.log\n",
    "\"\"\",\n",
    "    }\n",
    "    \n",
    "    for file_name, content in common_files.items():\n",
    "        full_path = project_path / file_name\n",
    "        full_path.write_text(content)\n",
    "        print(f\"  üìÑ {file_name}\")\n",
    "    \n",
    "    # Add .gitkeep to empty directories\n",
    "    for dir_path in structure[\"dirs\"]:\n",
    "        gitkeep = project_path / dir_path / \".gitkeep\"\n",
    "        if not any((project_path / dir_path).iterdir()):\n",
    "            gitkeep.touch()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"‚úÖ Project structure created at: {project_path}\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(f\"  1. cd {project_path}\")\n",
    "    print(\"  2. git init\")\n",
    "    print(\"  3. Start coding!\")\n",
    "    \n",
    "    return project_path\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# project_path = create_project_structure(\"my-ai-assistant\", \"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Project Proposal\n",
    "\n",
    "Now it's time to create your project proposal! \n",
    "\n",
    "1. Choose your project option (A, B, C, or D)\n",
    "2. Copy the proposal template from `templates/project-proposal.md`\n",
    "3. Fill in all sections\n",
    "4. Save as `docs/proposal.md` in your project folder\n",
    "\n",
    "<details>\n",
    "<summary>üí° Tips for a Strong Proposal</summary>\n",
    "\n",
    "- **Be specific about your domain** - \"AWS infrastructure assistant\" is better than \"general assistant\"\n",
    "- **Set measurable success criteria** - \"Answer 80% of test questions correctly\" not \"work well\"\n",
    "- **Identify risks early** - What might go wrong? How will you handle it?\n",
    "- **Leverage DGX Spark** - Explain how you'll use the 128GB memory and Blackwell features\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Scope Creep\n",
    "```python\n",
    "# ‚ùå Wrong: Trying to do everything\n",
    "project_goals = [\n",
    "    \"Fine-tune 70B model\",\n",
    "    \"Build RAG with 1M documents\",\n",
    "    \"Add multimodal support\",\n",
    "    \"Create mobile app\",\n",
    "    \"Deploy to cloud\",\n",
    "    \"Build training pipeline\",\n",
    "]\n",
    "\n",
    "# ‚úÖ Right: Focused scope with clear boundaries\n",
    "project_goals = [\n",
    "    \"Fine-tune 70B model for AWS CLI help\",\n",
    "    \"Build RAG with AWS documentation (1000 pages)\",\n",
    "    \"Create FastAPI endpoint with streaming\",\n",
    "]\n",
    "stretch_goals = [\"Add multimodal diagrams\", \"Gradio UI\"]  # Only if time permits\n",
    "```\n",
    "**Why:** A complete, polished project is better than an ambitious, unfinished one.\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 2: Not Testing Early\n",
    "```python\n",
    "# ‚ùå Wrong: Wait until Week 5 to test\n",
    "week_5_tasks = [\"Integration testing\", \"Fix all bugs\", \"Benchmark\"]  # Too late!\n",
    "\n",
    "# ‚úÖ Right: Test continuously\n",
    "every_week_tasks = [\n",
    "    \"Unit tests for new code\",\n",
    "    \"Manual testing of new features\",\n",
    "    \"Quick performance check\",\n",
    "]\n",
    "```\n",
    "**Why:** Finding bugs early is much cheaper than finding them late.\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 3: Ignoring Documentation\n",
    "```python\n",
    "# ‚ùå Wrong: \"I'll document it later\"\n",
    "def process_query(q, ctx, opts):\n",
    "    # Complex logic with no explanation\n",
    "    ...\n",
    "\n",
    "# ‚úÖ Right: Document as you code\n",
    "def process_query(\n",
    "    query: str,\n",
    "    context: list[Document],\n",
    "    options: ProcessingOptions\n",
    ") -> QueryResult:\n",
    "    \"\"\"\n",
    "    Process a user query using RAG.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's natural language question\n",
    "        context: Retrieved documents for context\n",
    "        options: Processing configuration\n",
    "        \n",
    "    Returns:\n",
    "        QueryResult with answer and sources\n",
    "    \"\"\"\n",
    "    ...\n",
    "```\n",
    "**Why:** You WILL forget why you did things. Future you will thank present you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## üéâ Checkpoint\n\nYou've completed the capstone kickoff! You should now have:\n\n- ‚úÖ Verified your DGX Spark environment\n- ‚úÖ Understood all four project options\n- ‚úÖ Selected your project\n- ‚úÖ Created your project structure\n- ‚úÖ Planned your 6-week timeline\n\n---\n\n## üöÄ Next Steps\n\n1. **Complete your project proposal** using the template\n2. **Open the guide for your chosen project:**\n   - Option A: `lab-4.3.2-option-a-ai-assistant.ipynb`\n   - Option B: `lab-4.3.3-option-b-document-intelligence.ipynb`\n   - Option C: `lab-4.3.4-option-c-agent-swarm.ipynb`\n   - Option D: `lab-4.3.5-option-d-training-pipeline.ipynb`\n3. **Review the planning notebook:** `lab-4.3.1-project-planning.ipynb`\n\n---\n\n## üìñ Further Reading\n\n- [How to Write a Good Project Proposal](https://www.atlassian.com/work-management/project-management/project-proposal)\n- [NVIDIA DGX Spark Documentation](https://docs.nvidia.com/dgx/)\n- [Best Practices for ML Projects](https://neptune.ai/blog/how-to-organize-ml-project)\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ Cleanup (no cleanup needed for this notebook)\n",
    "print(\"‚úÖ No cleanup needed - ready to proceed!\")\n",
    "print(\"\\nüéØ Next: Choose your project and open the corresponding guide notebook.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}