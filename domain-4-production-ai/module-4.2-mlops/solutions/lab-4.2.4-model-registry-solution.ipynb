{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 15.4 Solution: Model Registry & Version Control\n",
    "\n",
    "This notebook provides solutions for the model registry exercise.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solution: Complete Model Lifecycle Workflow\n",
    "\n",
    "**Task:** Create a complete model lifecycle workflow.\n",
    "\n",
    "Requirements:\n",
    "1. Create 3 versions of a model (different architectures)\n",
    "2. Register all versions in MLflow\n",
    "3. Promote the best one to Production\n",
    "4. Add descriptions and tags\n",
    "5. Write a function to load the production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# Setup\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "MLFLOW_DIR = str((NOTEBOOK_DIR / \"../mlflow\").resolve())\n",
    "os.makedirs(MLFLOW_DIR, exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(f\"file://{MLFLOW_DIR}\")\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"MLflow URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define 3 model architectures with different complexities\n",
    "\n",
    "class TextClassifierSmall(nn.Module):\n",
    "    \"\"\"Small model - single hidden layer.\"\"\"\n",
    "    def __init__(self, vocab_size: int = 10000, embedding_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 3)  # 3-class classification\n",
    "        self.version = \"1.0.0-small\"\n",
    "        self.architecture = \"small\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        pooled = embedded.mean(dim=1)  # Average pooling\n",
    "        return self.fc(pooled)\n",
    "\n",
    "class TextClassifierMedium(nn.Module):\n",
    "    \"\"\"Medium model - LSTM with attention.\"\"\"\n",
    "    def __init__(self, vocab_size: int = 10000, embedding_dim: int = 128, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "        self.fc = nn.Linear(hidden_dim, 3)\n",
    "        self.version = \"2.0.0-medium\"\n",
    "        self.architecture = \"medium\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        attn_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)\n",
    "        return self.fc(context)\n",
    "\n",
    "class TextClassifierLarge(nn.Module):\n",
    "    \"\"\"Large model - Bidirectional LSTM with multi-head attention.\"\"\"\n",
    "    def __init__(self, vocab_size: int = 10000, embedding_dim: int = 256, hidden_dim: int = 512, num_heads: int = 4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim * 2, num_heads, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.version = \"3.0.0-large\"\n",
    "        self.architecture = \"large\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        pooled = attn_out.mean(dim=1)\n",
    "        x = self.relu(self.fc1(self.dropout(pooled)))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Create models\n",
    "models = [\n",
    "    (\"small\", TextClassifierSmall()),\n",
    "    (\"medium\", TextClassifierMedium()),\n",
    "    (\"large\", TextClassifierLarge())\n",
    "]\n",
    "\n",
    "print(\"ðŸ“‹ Model Architectures:\")\n",
    "for name, model in models:\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   {name}: {params:,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Register all versions\n",
    "\n",
    "EXPERIMENT_NAME = \"TextClassifier-Comparison\"\n",
    "MODEL_NAME = \"TextClassifier\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Simulated metrics for each architecture\n",
    "simulated_metrics = {\n",
    "    \"small\": {\"accuracy\": 0.82, \"f1\": 0.80, \"latency_ms\": 5, \"memory_mb\": 50},\n",
    "    \"medium\": {\"accuracy\": 0.88, \"f1\": 0.87, \"latency_ms\": 15, \"memory_mb\": 200},\n",
    "    \"large\": {\"accuracy\": 0.91, \"f1\": 0.90, \"latency_ms\": 45, \"memory_mb\": 800}\n",
    "}\n",
    "\n",
    "registered_versions = []\n",
    "\n",
    "for name, model in models:\n",
    "    with mlflow.start_run(run_name=f\"textclassifier-{name}\") as run:\n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "            \"architecture\": name,\n",
    "            \"version\": model.version,\n",
    "            \"parameters\": sum(p.numel() for p in model.parameters())\n",
    "        })\n",
    "        \n",
    "        # Log metrics\n",
    "        metrics = simulated_metrics[name]\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        sample_input = torch.randint(0, 10000, (1, 50))\n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=MODEL_NAME,\n",
    "            input_example=sample_input.numpy()\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Registered {name} model (acc: {metrics['accuracy']:.2%})\")\n",
    "        registered_versions.append((name, run.info.run_id, metrics))\n",
    "\n",
    "print(f\"\\nâœ… Registered {len(registered_versions)} model versions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compare and promote best to Production\n",
    "\n",
    "# Find all versions\n",
    "versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Version Comparison:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Version':<10} {'Architecture':<12} {'Accuracy':<12} {'Latency':<12} {'Stage':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "best_version = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for v in versions:\n",
    "    run = mlflow.get_run(v.run_id)\n",
    "    arch = run.data.params.get('architecture', 'unknown')\n",
    "    acc = run.data.metrics.get('accuracy', 0)\n",
    "    latency = run.data.metrics.get('latency_ms', 0)\n",
    "    \n",
    "    print(f\"{v.version:<10} {arch:<12} {acc:<12.2%} {latency:<12.0f}ms {v.current_stage:<12}\")\n",
    "    \n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_version = v.version\n",
    "\n",
    "print(f\"\\nðŸ† Best version: {best_version} (accuracy: {best_accuracy:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promote best version through stages\n",
    "\n",
    "print(f\"\\nðŸš€ Promoting version {best_version} to Production...\")\n",
    "\n",
    "# First to Staging (testing)\n",
    "client.transition_model_version_stage(\n",
    "    name=MODEL_NAME,\n",
    "    version=best_version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "print(f\"   âœ“ Moved to Staging\")\n",
    "\n",
    "# Then to Production (after \"testing\")\n",
    "client.transition_model_version_stage(\n",
    "    name=MODEL_NAME,\n",
    "    version=best_version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True\n",
    ")\n",
    "print(f\"   âœ“ Promoted to Production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Add descriptions and tags\n",
    "\n",
    "# Update registered model description\n",
    "client.update_registered_model(\n",
    "    name=MODEL_NAME,\n",
    "    description=\"\"\"Text Classification Model\n",
    "\n",
    "Classifies text into 3 categories.\n",
    "Supports multiple architecture variants: small, medium, large.\n",
    "\n",
    "Input: Tokenized text (max 50 tokens)\n",
    "Output: 3-class probability distribution\n",
    "\n",
    "Owner: ML Team\n",
    "Contact: ml-team@company.com\n",
    "\"\"\"\n",
    ")\n",
    "print(\"âœ… Updated model description\")\n",
    "\n",
    "# Add version description for production version\n",
    "client.update_model_version(\n",
    "    name=MODEL_NAME,\n",
    "    version=best_version,\n",
    "    description=f\"\"\"Production Model - Large Architecture\n",
    "\n",
    "Architecture: Bidirectional LSTM with Multi-head Attention\n",
    "Performance:\n",
    "- Accuracy: {best_accuracy:.2%}\n",
    "- F1 Score: 90%\n",
    "- Latency: ~45ms\n",
    "\n",
    "Approved for production deployment.\n",
    "\"\"\"\n",
    ")\n",
    "print(\"âœ… Updated version description\")\n",
    "\n",
    "# Add tags\n",
    "tags_to_add = {\n",
    "    \"approved_by\": \"ml-lead\",\n",
    "    \"approval_date\": \"2024-01-15\",\n",
    "    \"deployment_type\": \"api\",\n",
    "    \"min_latency_requirement\": \"100ms\",\n",
    "    \"data_version\": \"v2.0\"\n",
    "}\n",
    "\n",
    "for key, value in tags_to_add.items():\n",
    "    client.set_model_version_tag(MODEL_NAME, best_version, key, value)\n",
    "\n",
    "print(\"âœ… Added tags to production version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Write a function to load the production model\n",
    "\n",
    "def load_production_model(model_name: str) -> Optional[nn.Module]:\n",
    "    \"\"\"\n",
    "    Load the current production model from MLflow Model Registry.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "    \n",
    "    Returns:\n",
    "        The production model, or None if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}/Production\"\n",
    "        model = mlflow.pytorch.load_model(model_uri)\n",
    "        print(f\"âœ… Loaded production model: {model_name}\")\n",
    "        print(f\"   URI: {model_uri}\")\n",
    "        print(f\"   Type: {type(model).__name__}\")\n",
    "        if hasattr(model, 'version'):\n",
    "            print(f\"   Version: {model.version}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load production model: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_model_by_stage(model_name: str, stage: str = \"Production\") -> Optional[nn.Module]:\n",
    "    \"\"\"\n",
    "    Load a model by stage (Production, Staging, Archived).\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "        stage: Stage to load from\n",
    "    \n",
    "    Returns:\n",
    "        The model, or None if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}/{stage}\"\n",
    "        return mlflow.pytorch.load_model(model_uri)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ No model found at {stage}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_model_info(model_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get detailed information about all model versions.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with model information\n",
    "    \"\"\"\n",
    "    info = {\"name\": model_name, \"versions\": []}\n",
    "    \n",
    "    try:\n",
    "        model_info = client.get_registered_model(model_name)\n",
    "        info[\"description\"] = model_info.description\n",
    "        \n",
    "        for v in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "            info[\"versions\"].append({\n",
    "                \"version\": v.version,\n",
    "                \"stage\": v.current_stage,\n",
    "                \"tags\": v.tags\n",
    "            })\n",
    "    except Exception as e:\n",
    "        info[\"error\"] = str(e)\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the loader functions\n",
    "\n",
    "print(\"\\nðŸ”§ Testing Model Loader Functions:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load production model\n",
    "prod_model = load_production_model(MODEL_NAME)\n",
    "\n",
    "if prod_model:\n",
    "    # Test inference\n",
    "    test_input = torch.randint(0, 10000, (2, 50))\n",
    "    with torch.no_grad():\n",
    "        output = prod_model(test_input)\n",
    "        predictions = torch.softmax(output, dim=1)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Test Inference:\")\n",
    "    print(f\"   Input shape: {test_input.shape}\")\n",
    "    print(f\"   Output shape: {output.shape}\")\n",
    "    print(f\"   Predictions: {predictions[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final model info\n",
    "\n",
    "info = get_model_info(MODEL_NAME)\n",
    "\n",
    "print(f\"\\nðŸ“‹ Final Model Registry State:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nModel: {info['name']}\")\n",
    "print(f\"\\nDescription:\\n{info.get('description', 'N/A')[:200]}...\")\n",
    "\n",
    "print(f\"\\nVersions:\")\n",
    "for v in info['versions']:\n",
    "    print(f\"   v{v['version']} ({v['stage']})\")\n",
    "    if v['tags']:\n",
    "        for k, val in list(v['tags'].items())[:2]:\n",
    "            print(f\"      {k}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Multiple Versions**: Different architectures registered as versions of same model\n",
    "2. **Stage Transitions**: Proper progression through Staging before Production\n",
    "3. **Documentation**: Descriptions and tags provide context for future use\n",
    "4. **Programmatic Access**: Functions to load models make deployment easy\n",
    "\n",
    "---\n",
    "\n",
    "## Production Checklist\n",
    "\n",
    "- [x] Multiple versions registered\n",
    "- [x] Best model identified through metrics comparison\n",
    "- [x] Production model promoted through staging\n",
    "- [x] Descriptions added for discoverability\n",
    "- [x] Tags added for tracking approvals and requirements\n",
    "- [x] Load functions tested and working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâœ… Solution complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
