{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.6.0: Capstone Project Kickoff\n",
    "\n",
    "**Module:** 4.6 - Capstone Project (Domain 4: Production AI)\n",
    "**Time:** 2-3 hours\n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations on Reaching the Capstone!\n",
    "\n",
    "You've completed an incredible journey through the DGX Spark AI Curriculum. From understanding the fundamentals of neural networks to fine-tuning 70B parameter models, from building RAG systems to deploying production APIs with safety guardrails - you've acquired a remarkable set of skills.\n",
    "\n",
    "**Now it's time to put it all together.**\n",
    "\n",
    "This capstone is your chance to build something substantial - a portfolio piece that demonstrates your mastery of modern AI engineering on cutting-edge hardware.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand the four capstone project options\n",
    "- [ ] Evaluate which project best matches your interests and goals\n",
    "- [ ] Verify your DGX Spark environment is ready\n",
    "- [ ] Complete your project selection\n",
    "- [ ] Create your project timeline\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: All modules in Domains 1-4\n",
    "- Knowledge of: LLM fine-tuning, RAG systems, agents, deployment, AI safety\n",
    "- Access to: DGX Spark with 128GB unified memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "The capstone project mirrors what AI engineers do in industry every day: identify a problem, design a solution, implement it with production-quality code, ensure it's safe, and evaluate its effectiveness.\n",
    "\n",
    "Companies like OpenAI, Anthropic, Google, and Meta all follow similar processes when building AI products:\n",
    "\n",
    "1. **Problem Definition** ‚Üí What are we solving?\n",
    "2. **Architecture Design** ‚Üí How will we solve it?\n",
    "3. **Implementation** ‚Üí Build the solution\n",
    "4. **Safety Evaluation** ‚Üí Is it safe to deploy? üõ°Ô∏è\n",
    "5. **Optimization** ‚Üí Make it fast and efficient\n",
    "6. **Documentation** ‚Üí Can others use and extend it?\n",
    "\n",
    "Your capstone follows this exact pattern, preparing you for real-world AI engineering roles.\n",
    "\n",
    "### What Makes This Special: DGX Spark\n",
    "\n",
    "You have access to hardware that enables things impossible on consumer GPUs:\n",
    "\n",
    "| Capability | Consumer GPU (24GB) | DGX Spark (128GB) | Advantage |\n",
    "|------------|--------------------|--------------------|----------|\n",
    "| Max model size (FP16) | ~12B | **~55B** | 4.5x larger |\n",
    "| Max model (INT4) | ~24B | **~120B** | 5x larger |\n",
    "| Fine-tune (QLoRA) | ~13B | **~100B** | 8x larger |\n",
    "| NVFP4 (Blackwell) | ‚ùå | ‚úÖ **~200B** | Exclusive! |\n",
    "\n",
    "Your capstone should showcase what's possible with this unique hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is a Capstone Project?\n",
    "\n",
    "> **Imagine you've been learning to cook for months.** You've mastered chopping vegetables, making sauces, baking bread, grilling meat, and plating dishes. Each skill was practiced in isolation.\n",
    ">\n",
    "> **Now, you're going to prepare a complete dinner party.** You need to:\n",
    "> - Plan a menu that works together\n",
    "> - Prep all the ingredients\n",
    "> - Cook multiple dishes that complement each other\n",
    "> - Time everything so it's ready together\n",
    "> - Present it beautifully\n",
    "> - Make sure nobody gets food poisoning! üõ°Ô∏è\n",
    ">\n",
    "> **That's a capstone.** It's not about learning one new thing - it's about combining everything you've learned into one impressive, complete creation.\n",
    ">\n",
    "> **In AI terms:** You've learned fine-tuning, RAG, agents, deployment, safety, and more. Your capstone combines these into a complete, working AI system that solves a real problem - safely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Environment Verification\n",
    "\n",
    "Before choosing your project, let's verify your DGX Spark environment is properly configured. Your capstone will push the hardware to its limits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Environment Verification\n",
    "# This cell verifies your DGX Spark is ready for capstone development\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ DGX SPARK CAPSTONE ENVIRONMENT CHECK\")\n",
    "print(f\"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Python version\n",
    "print(f\"\\nüêç Python Version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check critical packages\n",
    "packages_status = []\n",
    "critical_packages = [\n",
    "    (\"torch\", \"PyTorch\", True),\n",
    "    (\"transformers\", \"Transformers\", True),\n",
    "    (\"peft\", \"PEFT (LoRA/QLoRA)\", True),\n",
    "    (\"bitsandbytes\", \"BitsAndBytes (Quantization)\", True),\n",
    "    (\"sentence_transformers\", \"Sentence Transformers\", True),\n",
    "    (\"langchain\", \"LangChain\", False),\n",
    "    (\"langgraph\", \"LangGraph\", False),\n",
    "    (\"fastapi\", \"FastAPI\", True),\n",
    "    (\"gradio\", \"Gradio\", True),\n",
    "    (\"faiss\", \"FAISS (Vector Search)\", False),\n",
    "    (\"nemo_guardrails\", \"NeMo Guardrails\", False),\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ Package Status:\")\n",
    "for pkg_name, display_name, critical in critical_packages:\n",
    "    try:\n",
    "        module = __import__(pkg_name.replace('-', '_'))\n",
    "        version = getattr(module, '__version__', 'installed')\n",
    "        print(f\"  ‚úÖ {display_name}: {version}\")\n",
    "        packages_status.append(True)\n",
    "    except ImportError:\n",
    "        icon = \"‚ùå\" if critical else \"‚ö†Ô∏è\"\n",
    "        status = \"REQUIRED\" if critical else \"recommended\"\n",
    "        print(f\"  {icon} {display_name}: NOT INSTALLED ({status})\")\n",
    "        packages_status.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU and Memory Check\n",
    "import torch\n",
    "\n",
    "print(\"\\nüéÆ GPU Status:\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"  ‚úÖ GPU: {gpu_name}\")\n",
    "    print(f\"  ‚úÖ GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Check for Blackwell features\n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    cc_str = f\"{compute_capability[0]}.{compute_capability[1]}\"\n",
    "    print(f\"  ‚úÖ Compute Capability: {cc_str}\")\n",
    "    \n",
    "    # Check if Blackwell (CC 10.x expected)\n",
    "    if compute_capability[0] >= 10:\n",
    "        print(f\"  üåü Blackwell architecture detected! NVFP4 available.\")\n",
    "    \n",
    "    # Memory allocation test\n",
    "    print(\"\\nüíæ Memory Status:\")\n",
    "    print(f\"  Current allocation: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "    print(f\"  Current reserved: {torch.cuda.memory_reserved()/1e9:.2f} GB\")\n",
    "    print(f\"  Available for models: ~{gpu_memory - 5:.1f} GB (with 5GB system reserve)\")\n",
    "else:\n",
    "    print(\"  ‚ùå CUDA not available!\")\n",
    "    print(\"  Make sure you're running in an NGC container with GPU access.\")\n",
    "\n",
    "# System memory (unified memory detection)\n",
    "try:\n",
    "    with open('/proc/meminfo', 'r') as f:\n",
    "        for line in f:\n",
    "            if 'MemTotal' in line:\n",
    "                mem_gb = int(line.split()[1]) / 1e6\n",
    "                print(f\"\\nüñ•Ô∏è System Memory: {mem_gb:.1f} GB\")\n",
    "                if mem_gb > 100:\n",
    "                    print(\"  ‚úÖ 128GB unified memory configuration detected!\")\n",
    "                    print(\"  ‚úÖ No CPU‚ÜîGPU transfers needed - massive advantage!\")\n",
    "                break\n",
    "except:\n",
    "    print(\"\\nüñ•Ô∏è Could not read system memory info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disk Space and Cache Check\n",
    "import shutil\n",
    "\n",
    "print(\"\\nüíø Disk Space:\")\n",
    "paths_to_check = [\n",
    "    (\"/workspace\", \"Workspace\"),\n",
    "    (os.path.expanduser(\"~/.cache/huggingface\"), \"HuggingFace Cache\"),\n",
    "]\n",
    "\n",
    "for path, name in paths_to_check:\n",
    "    if os.path.exists(path):\n",
    "        total, used, free = shutil.disk_usage(path)\n",
    "        status = \"‚úÖ\" if free/1e9 > 100 else \"‚ö†Ô∏è\" if free/1e9 > 50 else \"‚ùå\"\n",
    "        print(f\"  {name} ({path}):\")\n",
    "        print(f\"    Total: {total/1e9:.1f} GB\")\n",
    "        print(f\"    Used: {used/1e9:.1f} GB\")\n",
    "        print(f\"    Free: {free/1e9:.1f} GB {status}\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è {name}: Path not found\")\n",
    "\n",
    "# Capstone-specific capacity estimates\n",
    "print(\"\\nüìä Capstone Model Capacity (with your 128GB):\")\n",
    "print(\"  ‚Ä¢ Llama 3.3 70B (INT4): ~35GB ‚Üí ‚úÖ FITS with 93GB headroom\")\n",
    "print(\"  ‚Ä¢ Llama 3.3 70B (QLoRA training): ~50GB ‚Üí ‚úÖ FITS\")\n",
    "print(\"  ‚Ä¢ Qwen2.5 72B + Embedding model: ~40GB ‚Üí ‚úÖ FITS\")\n",
    "print(\"  ‚Ä¢ Multi-agent: 3√ó 8B models: ~15GB ‚Üí ‚úÖ FITS easily\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Environment check complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç What Just Happened?\n",
    "\n",
    "We verified:\n",
    "1. **Python Environment** - All required packages are installed\n",
    "2. **GPU Access** - Blackwell GPU is available with sufficient memory\n",
    "3. **Unified Memory** - 128GB configuration is active\n",
    "4. **Disk Space** - Enough space for models and data\n",
    "\n",
    "**If any checks failed**, resolve them before proceeding. You'll need full access to DGX Spark capabilities for your capstone.\n",
    "\n",
    "**Common fixes:**\n",
    "- Missing packages: `pip install langchain langgraph faiss-gpu nemo-guardrails`\n",
    "- Low disk space: Clean HuggingFace cache: `huggingface-cli cache clean`\n",
    "- No GPU: Ensure you're in an NGC container with `--gpus all`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Project Options Overview\n",
    "\n",
    "You have four project options, each emphasizing different skills. All are designed to showcase DGX Spark's unique capabilities and include safety considerations.\n",
    "\n",
    "### Quick Comparison\n",
    "\n",
    "| Option | Focus | Model Size | Key Skills | Safety Component |\n",
    "|--------|-------|------------|------------|-----------------|\n",
    "| **A** | AI Assistant | 70B | Fine-tuning, RAG, Tools | NeMo Guardrails |\n",
    "| **B** | Document Intelligence | 34B VLM | Vision, OCR, Extraction | Content filtering |\n",
    "| **C** | Agent Swarm | Multi-model | Agents, Planning, Coordination | Human-in-the-loop |\n",
    "| **D** | Training Pipeline | 70B | SFT, DPO, MLOps | Red teaming eval |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Project Options\n",
    "\n",
    "project_options = {\n",
    "    \"A\": {\n",
    "        \"name\": \"Domain-Specific AI Assistant\",\n",
    "        \"tagline\": \"Build a complete AI assistant specialized for a domain of your choice\",\n",
    "        \"components\": [\n",
    "            \"Fine-tuned LLM (70B with QLoRA)\",\n",
    "            \"RAG with domain knowledge base\",\n",
    "            \"Custom tools and API integrations\",\n",
    "            \"NeMo Guardrails for safety\",\n",
    "            \"FastAPI with streaming\",\n",
    "            \"Gradio demo interface\",\n",
    "        ],\n",
    "        \"dgx_advantage\": \"70B models fit entirely in memory - no offloading needed\",\n",
    "        \"example_domains\": [\"DevOps/AWS\", \"Financial Analysis\", \"Code Review\", \"Medical Literature\", \"Legal Documents\"],\n",
    "        \"best_for\": \"Those interested in conversational AI, LLM customization, and practical applications\",\n",
    "        \"skills_used\": [\"Module 3.1 (Fine-tuning)\", \"Module 3.5 (RAG)\", \"Module 3.6 (Agents)\", \"Module 4.2 (Safety)\"],\n",
    "        \"hours\": \"35-45\",\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"name\": \"Multimodal Document Intelligence\",\n",
    "        \"tagline\": \"Build a system that processes and understands complex documents\",\n",
    "        \"components\": [\n",
    "            \"Document ingestion (PDF, images, diagrams)\",\n",
    "            \"Vision-Language Model (LLaVA/Qwen-VL)\",\n",
    "            \"Structured information extraction\",\n",
    "            \"Multimodal RAG\",\n",
    "            \"Export to JSON/CSV\",\n",
    "            \"Interactive demo\",\n",
    "        ],\n",
    "        \"dgx_advantage\": \"34B VLMs with high-res image processing fit easily\",\n",
    "        \"example_domains\": [\"Invoice Processing\", \"Research Paper Analysis\", \"Technical Manual QA\", \"Contract Review\"],\n",
    "        \"best_for\": \"Those interested in computer vision, document processing, and multimodal AI\",\n",
    "        \"skills_used\": [\"Module 2.2 (Vision)\", \"Module 4.1 (Multimodal)\", \"Module 3.5 (RAG)\"],\n",
    "        \"hours\": \"35-45\",\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"name\": \"AI Agent Swarm with Safety\",\n",
    "        \"tagline\": \"Build a multi-agent system where specialized agents collaborate safely\",\n",
    "        \"components\": [\n",
    "            \"4+ specialized agents\",\n",
    "            \"Central coordinator/orchestrator\",\n",
    "            \"Tool registry and execution\",\n",
    "            \"Shared + individual memory\",\n",
    "            \"Human-in-the-loop approval\",\n",
    "            \"Safety guardrails on actions\",\n",
    "        ],\n",
    "        \"dgx_advantage\": \"Multiple smaller models can run concurrently in memory\",\n",
    "        \"example_domains\": [\"Research Team\", \"Software Dev Team\", \"Data Analysis Pipeline\", \"Content Creation\"],\n",
    "        \"best_for\": \"Those interested in agentic AI, planning systems, and complex automation\",\n",
    "        \"skills_used\": [\"Module 3.6 (Agents)\", \"Module 3.4 (TTC)\", \"Module 4.2 (Safety)\"],\n",
    "        \"hours\": \"35-45\",\n",
    "    },\n",
    "    \"D\": {\n",
    "        \"name\": \"Custom Training Pipeline\",\n",
    "        \"tagline\": \"Build infrastructure for continuous model improvement\",\n",
    "        \"components\": [\n",
    "            \"Data collection and curation\",\n",
    "            \"SFT + DPO/ORPO training\",\n",
    "            \"Automated evaluation\",\n",
    "            \"Model versioning (MLflow)\",\n",
    "            \"A/B testing framework\",\n",
    "            \"Red teaming evaluation\",\n",
    "        ],\n",
    "        \"dgx_advantage\": \"Full fine-tuning of 16B models possible, QLoRA for 100B+\",\n",
    "        \"example_domains\": [\"Domain Adaptation\", \"Preference Learning\", \"Distillation Pipeline\", \"Continual Learning\"],\n",
    "        \"best_for\": \"Those interested in MLOps, training infrastructure, and model development\",\n",
    "        \"skills_used\": [\"Module 3.1 (Fine-tuning)\", \"Module 4.3 (MLOps)\", \"Module 3.2 (Quantization)\"],\n",
    "        \"hours\": \"35-45\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Display options\n",
    "for key, option in project_options.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìå OPTION {key}: {option['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n\\\"{option['tagline']}\\\"\")\n",
    "    print(f\"\\n‚è±Ô∏è Estimated time: {option['hours']} hours\")\n",
    "    print(f\"\\nüèóÔ∏è Components you'll build:\")\n",
    "    for comp in option['components']:\n",
    "        print(f\"   ‚Ä¢ {comp}\")\n",
    "    print(f\"\\nüöÄ DGX Spark Advantage: {option['dgx_advantage']}\")\n",
    "    print(f\"\\nüí° Example domains: {', '.join(option['example_domains'])}\")\n",
    "    print(f\"\\nüë§ Best for: {option['best_for']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Project Selection Decision Helper\n",
    "\n",
    "Use this interactive tool to find your best project match based on your interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Selection Helper\n",
    "\n",
    "def project_selector():\n",
    "    \"\"\"\n",
    "    Interactive project selection based on interests.\n",
    "    Run this cell and answer the prompts!\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ CAPSTONE PROJECT SELECTOR\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Rate your interest in each area (1-5)\")\n",
    "    print(\"1 = Not interested, 5 = Very interested\\n\")\n",
    "    \n",
    "    questions = {\n",
    "        \"A\": [\n",
    "            \"Building chatbots and conversational AI\",\n",
    "            \"Fine-tuning LLMs for specific domains\",\n",
    "            \"Building RAG systems with knowledge bases\",\n",
    "            \"Creating practical, deployable AI services\",\n",
    "        ],\n",
    "        \"B\": [\n",
    "            \"Working with images and visual data\",\n",
    "            \"Processing PDFs and documents\",\n",
    "            \"Extracting structured data from unstructured sources\",\n",
    "            \"Combining vision and language models\",\n",
    "        ],\n",
    "        \"C\": [\n",
    "            \"Building autonomous AI agents\",\n",
    "            \"Multi-step planning and reasoning\",\n",
    "            \"Tool use and function calling\",\n",
    "            \"Coordinating multiple AI systems safely\",\n",
    "        ],\n",
    "        \"D\": [\n",
    "            \"Training and fine-tuning workflows\",\n",
    "            \"Building ML infrastructure and pipelines\",\n",
    "            \"Model evaluation and benchmarking\",\n",
    "            \"Experiment tracking and versioning\",\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    scores = {\"A\": 0, \"B\": 0, \"C\": 0, \"D\": 0}\n",
    "    \n",
    "    # Flatten and shuffle questions\n",
    "    all_questions = []\n",
    "    for option, q_list in questions.items():\n",
    "        for q in q_list:\n",
    "            all_questions.append((option, q))\n",
    "    \n",
    "    import random\n",
    "    random.seed(42)  # Reproducible order\n",
    "    random.shuffle(all_questions)\n",
    "    \n",
    "    for i, (option, question) in enumerate(all_questions, 1):\n",
    "        while True:\n",
    "            try:\n",
    "                response = input(f\"{i}. {question}: \")\n",
    "                score = int(response)\n",
    "                if 1 <= score <= 5:\n",
    "                    scores[option] += score\n",
    "                    break\n",
    "                print(\"   Please enter 1-5\")\n",
    "            except ValueError:\n",
    "                print(\"   Please enter a number 1-5\")\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nSelection cancelled.\")\n",
    "                return\n",
    "    \n",
    "    # Results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä YOUR RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    option_names = {\n",
    "        \"A\": \"Domain-Specific AI Assistant\",\n",
    "        \"B\": \"Multimodal Document Intelligence\",\n",
    "        \"C\": \"AI Agent Swarm\",\n",
    "        \"D\": \"Custom Training Pipeline\",\n",
    "    }\n",
    "    \n",
    "    max_possible = 20  # 4 questions √ó 5 max\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    medals = [\"ü•á\", \"ü•à\", \"ü•â\", \"  \"]\n",
    "    \n",
    "    for rank, (option, score) in enumerate(sorted_scores):\n",
    "        pct = (score / max_possible) * 100\n",
    "        bar = \"‚ñà\" * int(pct / 5) + \"‚ñë\" * (20 - int(pct / 5))\n",
    "        print(f\"\\n{medals[rank]} Option {option}: {option_names[option]}\")\n",
    "        print(f\"   {bar} {pct:.0f}% ({score}/{max_possible})\")\n",
    "    \n",
    "    winner = sorted_scores[0][0]\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üéØ RECOMMENDED: Option {winner} - {option_names[winner]}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return winner\n",
    "\n",
    "# Uncomment to run interactively:\n",
    "# recommended = project_selector()\n",
    "\n",
    "print(\"üí° To use the interactive selector, uncomment the last line and run this cell.\")\n",
    "print(\"   Or choose directly using the quick selection below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Project Selection - Set your choice here!\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# üéØ SELECT YOUR PROJECT OPTION (Uncomment ONE line)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# SELECTED_PROJECT = \"A\"  # Domain-Specific AI Assistant\n",
    "# SELECTED_PROJECT = \"B\"  # Multimodal Document Intelligence  \n",
    "# SELECTED_PROJECT = \"C\"  # AI Agent Swarm\n",
    "# SELECTED_PROJECT = \"D\"  # Custom Training Pipeline\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "try:\n",
    "    project = project_options[SELECTED_PROJECT]\n",
    "    print(f\"\\n‚úÖ You've selected: Option {SELECTED_PROJECT} - {project['name']}\")\n",
    "    print(f\"\\nüìì Next notebook: lab-4.6.2-option-{SELECTED_PROJECT.lower()}-*.ipynb\")\n",
    "except NameError:\n",
    "    print(\"‚ö†Ô∏è No project selected yet!\")\n",
    "    print(\"\\nUncomment one of the SELECTED_PROJECT lines above and run this cell again.\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"  A: Domain-Specific AI Assistant (Fine-tuning + RAG + Tools)\")\n",
    "    print(\"  B: Multimodal Document Intelligence (Vision + OCR + Extraction)\")\n",
    "    print(\"  C: AI Agent Swarm (Multi-agent + Planning + Safety)\")\n",
    "    print(\"  D: Custom Training Pipeline (SFT + DPO + MLOps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Skills Mapping\n",
    "\n",
    "Each project builds on skills from previous modules. Let's see which skills you'll apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skills Matrix\n",
    "\n",
    "skills_matrix = {\n",
    "    \"A\": {\n",
    "        \"required\": [\n",
    "            (\"Module 3.1: LLM Fine-tuning\", \"QLoRA for 70B models\"),\n",
    "            (\"Module 3.5: RAG Systems\", \"Vector databases, retrieval\"),\n",
    "            (\"Module 3.3: Deployment\", \"FastAPI, streaming\"),\n",
    "            (\"Module 4.2: AI Safety\", \"NeMo Guardrails\"),\n",
    "        ],\n",
    "        \"helpful\": [\n",
    "            \"Module 3.2: Quantization\",\n",
    "            \"Module 2.5: HuggingFace\",\n",
    "            \"Module 4.5: Demo Building\",\n",
    "        ]\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"required\": [\n",
    "            (\"Module 2.2: Computer Vision\", \"Image processing\"),\n",
    "            (\"Module 4.1: Multimodal\", \"Vision-Language models\"),\n",
    "            (\"Module 3.5: RAG Systems\", \"Multimodal retrieval\"),\n",
    "        ],\n",
    "        \"helpful\": [\n",
    "            \"Module 2.3: NLP & Transformers\",\n",
    "            \"Module 3.3: Deployment\",\n",
    "            \"Module 4.5: Demo Building\",\n",
    "        ]\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"required\": [\n",
    "            (\"Module 3.6: AI Agents\", \"Agent frameworks, tools\"),\n",
    "            (\"Module 3.4: Test-Time Compute\", \"Reasoning chains\"),\n",
    "            (\"Module 4.2: AI Safety\", \"Human-in-the-loop, guardrails\"),\n",
    "        ],\n",
    "        \"helpful\": [\n",
    "            \"Module 3.1: LLM Fine-tuning\",\n",
    "            \"Module 3.5: RAG Systems\",\n",
    "            \"Module 4.1: Multimodal\",\n",
    "        ]\n",
    "    },\n",
    "    \"D\": {\n",
    "        \"required\": [\n",
    "            (\"Module 3.1: LLM Fine-tuning\", \"SFT, DPO, ORPO\"),\n",
    "            (\"Module 4.3: MLOps\", \"Experiment tracking, versioning\"),\n",
    "            (\"Module 2.5: HuggingFace\", \"Trainer API, datasets\"),\n",
    "        ],\n",
    "        \"helpful\": [\n",
    "            \"Module 3.2: Quantization\",\n",
    "            \"Module 3.3: Deployment\",\n",
    "            \"Module 4.2: AI Safety\",\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "def show_skills(option):\n",
    "    \"\"\"Display required and helpful skills for a project.\"\"\"\n",
    "    skills = skills_matrix[option]\n",
    "    name = project_options[option]['name']\n",
    "    \n",
    "    print(f\"\\nüìö SKILLS FOR OPTION {option}: {name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n‚úÖ Required Skills (must be comfortable with these):\")\n",
    "    for module, skill in skills[\"required\"]:\n",
    "        print(f\"   ‚Ä¢ {module}\")\n",
    "        print(f\"     Key: {skill}\")\n",
    "    \n",
    "    print(\"\\nüìò Helpful Background (nice to have):\")\n",
    "    for module in skills[\"helpful\"]:\n",
    "        print(f\"   ‚Ä¢ {module}\")\n",
    "\n",
    "# Show all options\n",
    "for opt in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    show_skills(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Timeline Planning\n",
    "\n",
    "Your capstone spans 6 weeks. Here's how to structure your time effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeline Generator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_timeline(start_date=None):\n",
    "    \"\"\"Generate a 6-week capstone timeline.\"\"\"\n",
    "    \n",
    "    if start_date:\n",
    "        start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    else:\n",
    "        start = datetime.now()\n",
    "    \n",
    "    weeks = [\n",
    "        {\n",
    "            \"week\": 1,\n",
    "            \"name\": \"Planning & Setup\",\n",
    "            \"hours\": \"6-8\",\n",
    "            \"tasks\": [\n",
    "                \"Complete project proposal (use template)\",\n",
    "                \"Design system architecture\",\n",
    "                \"Set up development environment\",\n",
    "                \"Create git repository with structure\",\n",
    "                \"Identify and download base models\",\n",
    "            ],\n",
    "            \"deliverable\": \"Approved proposal + Architecture diagram\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 2,\n",
    "            \"name\": \"Foundation (Part 1)\",\n",
    "            \"hours\": \"8-10\",\n",
    "            \"tasks\": [\n",
    "                \"Implement core component #1\",\n",
    "                \"Set up data pipeline\",\n",
    "                \"Create initial tests\",\n",
    "                \"Document as you build\",\n",
    "            ],\n",
    "            \"deliverable\": \"Working prototype of primary component\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 3,\n",
    "            \"name\": \"Foundation (Part 2)\",\n",
    "            \"hours\": \"8-10\",\n",
    "            \"tasks\": [\n",
    "                \"Implement core component #2\",\n",
    "                \"Model training/fine-tuning\",\n",
    "                \"Basic integration tests\",\n",
    "                \"Establish performance baseline\",\n",
    "            ],\n",
    "            \"deliverable\": \"All core components working independently\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 4,\n",
    "            \"name\": \"Integration\",\n",
    "            \"hours\": \"8-10\",\n",
    "            \"tasks\": [\n",
    "                \"Connect all components end-to-end\",\n",
    "                \"Build API layer\",\n",
    "                \"Add safety guardrails üõ°Ô∏è\",\n",
    "                \"End-to-end testing\",\n",
    "            ],\n",
    "            \"deliverable\": \"Complete integrated system with safety\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 5,\n",
    "            \"name\": \"Optimization & Evaluation\",\n",
    "            \"hours\": \"6-8\",\n",
    "            \"tasks\": [\n",
    "                \"Performance profiling\",\n",
    "                \"Memory optimization\",\n",
    "                \"Run evaluation suite\",\n",
    "                \"Red teaming / safety testing üõ°Ô∏è\",\n",
    "            ],\n",
    "            \"deliverable\": \"Optimized system with benchmark results\"\n",
    "        },\n",
    "        {\n",
    "            \"week\": 6,\n",
    "            \"name\": \"Documentation & Demo\",\n",
    "            \"hours\": \"6-8\",\n",
    "            \"tasks\": [\n",
    "                \"Complete technical report\",\n",
    "                \"Create model card with safety info\",\n",
    "                \"Build Gradio demo\",\n",
    "                \"Record demo video (5-10 min)\",\n",
    "                \"Final code cleanup\",\n",
    "            ],\n",
    "            \"deliverable\": \"All deliverables complete!\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìÖ YOUR CAPSTONE TIMELINE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_hours = 0\n",
    "    for week_info in weeks:\n",
    "        week_start = start + timedelta(weeks=week_info[\"week\"]-1)\n",
    "        week_end = week_start + timedelta(days=6)\n",
    "        \n",
    "        print(f\"\\nüìå Week {week_info['week']}: {week_info['name']}\")\n",
    "        print(f\"   {week_start.strftime('%b %d')} - {week_end.strftime('%b %d')}\")\n",
    "        print(f\"   ‚è±Ô∏è Estimated: {week_info['hours']} hours\")\n",
    "        \n",
    "        print(\"\\n   Tasks:\")\n",
    "        for task in week_info[\"tasks\"]:\n",
    "            print(f\"   [ ] {task}\")\n",
    "        \n",
    "        print(f\"\\n   üì¶ Deliverable: {week_info['deliverable']}\")\n",
    "        \n",
    "        # Parse hours for total\n",
    "        hours_range = week_info[\"hours\"].split(\"-\")\n",
    "        total_hours += (int(hours_range[0]) + int(hours_range[1])) / 2\n",
    "    \n",
    "    final_date = start + timedelta(weeks=6)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"üéØ Target Completion: {final_date.strftime('%B %d, %Y')}\")\n",
    "    print(f\"‚è±Ô∏è Total Estimated: {total_hours:.0f} hours\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Generate timeline starting today\n",
    "generate_timeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Create Your Project Structure\n",
    "\n",
    "Let's create a well-organized project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Structure Creator\n",
    "from pathlib import Path\n",
    "\n",
    "def create_project(project_name: str, option: str, base_path: str = \"/workspace\"):\n",
    "    \"\"\"\n",
    "    Create a complete project structure for your capstone.\n",
    "    \n",
    "    Args:\n",
    "        project_name: Name of your project (e.g., \"aws-assistant\")\n",
    "        option: Project option (A, B, C, or D)\n",
    "        base_path: Where to create the project\n",
    "    \"\"\"\n",
    "    \n",
    "    structures = {\n",
    "        \"A\": [  # AI Assistant\n",
    "            \"src/models\", \"src/rag\", \"src/tools\", \"src/api\", \"src/safety\",\n",
    "            \"data/raw\", \"data/processed\", \"data/knowledge_base\",\n",
    "            \"training/configs\", \"training/outputs\",\n",
    "            \"evaluation/benchmarks\", \"evaluation/results\",\n",
    "            \"notebooks\", \"tests\", \"docs\", \"demo\",\n",
    "        ],\n",
    "        \"B\": [  # Document Intelligence\n",
    "            \"src/ingestion\", \"src/vision\", \"src/extraction\", \"src/qa\", \"src/export\",\n",
    "            \"data/documents\", \"data/processed\", \"data/outputs\",\n",
    "            \"models\", \"evaluation\", \"notebooks\", \"tests\", \"docs\", \"demo\",\n",
    "        ],\n",
    "        \"C\": [  # Agent Swarm\n",
    "            \"src/agents\", \"src/coordinator\", \"src/tools\", \"src/memory\", \"src/safety\",\n",
    "            \"workflows\", \"evaluation\", \"notebooks\", \"tests\", \"docs\", \"demo\",\n",
    "        ],\n",
    "        \"D\": [  # Training Pipeline\n",
    "            \"src/data\", \"src/training\", \"src/evaluation\", \"src/serving\",\n",
    "            \"configs\", \"data/raw\", \"data/processed\",\n",
    "            \"experiments\", \"models/checkpoints\", \"models/exported\",\n",
    "            \"notebooks\", \"tests\", \"docs\",\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    dirs = structures.get(option.upper())\n",
    "    if not dirs:\n",
    "        print(f\"‚ùå Invalid option: {option}\")\n",
    "        return\n",
    "    \n",
    "    project_path = Path(base_path) / project_name\n",
    "    \n",
    "    print(f\"\\nüèóÔ∏è Creating project: {project_name}\")\n",
    "    print(f\"   Option: {option}\")\n",
    "    print(f\"   Location: {project_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create directories\n",
    "    for dir_path in dirs:\n",
    "        full_path = project_path / dir_path\n",
    "        full_path.mkdir(parents=True, exist_ok=True)\n",
    "        (full_path / \".gitkeep\").touch()\n",
    "        print(f\"  üìÅ {dir_path}/\")\n",
    "    \n",
    "    # Create common files\n",
    "    files = {\n",
    "        \"README.md\": f\"\"\"# {project_name}\n",
    "\n",
    "Capstone Project - Option {option}: {project_options[option]['name']}\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Describe your project here]\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run the demo\n",
    "python demo/app.py\n",
    "```\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```\n",
    "{project_name}/\n",
    "‚îú‚îÄ‚îÄ src/          # Source code\n",
    "‚îú‚îÄ‚îÄ data/         # Data files\n",
    "‚îú‚îÄ‚îÄ notebooks/    # Jupyter notebooks\n",
    "‚îú‚îÄ‚îÄ tests/        # Test files\n",
    "‚îú‚îÄ‚îÄ docs/         # Documentation\n",
    "‚îî‚îÄ‚îÄ demo/         # Demo application\n",
    "```\n",
    "\n",
    "## DGX Spark Optimization\n",
    "\n",
    "This project is optimized for DGX Spark with 128GB unified memory.\n",
    "\n",
    "## License\n",
    "\n",
    "MIT\n",
    "\"\"\",\n",
    "        \"requirements.txt\": \"\"\"# Core\n",
    "torch>=2.5.0\n",
    "transformers>=4.46.0\n",
    "accelerate>=1.0.0\n",
    "\n",
    "# Fine-tuning\n",
    "peft>=0.13.0\n",
    "bitsandbytes>=0.44.0\n",
    "trl>=0.12.0\n",
    "\n",
    "# RAG\n",
    "sentence-transformers>=3.0.0\n",
    "faiss-gpu>=1.7.0\n",
    "chromadb>=0.5.0\n",
    "\n",
    "# API & Demo\n",
    "fastapi>=0.115.0\n",
    "uvicorn>=0.32.0\n",
    "gradio>=5.0.0\n",
    "\n",
    "# Safety\n",
    "nemoguardrails>=0.10.0\n",
    "\n",
    "# Utils\n",
    "python-dotenv>=1.0.0\n",
    "pydantic>=2.0.0\n",
    "tqdm>=4.66.0\n",
    "\"\"\",\n",
    "        \".gitignore\": \"\"\"# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# Environment\n",
    ".env\n",
    "*.env\n",
    "venv/\n",
    "\n",
    "# Data (don't commit large files)\n",
    "data/raw/*\n",
    "!data/raw/.gitkeep\n",
    "*.parquet\n",
    "*.csv\n",
    "\n",
    "# Models (never commit model weights)\n",
    "*.bin\n",
    "*.safetensors\n",
    "*.gguf\n",
    "models/checkpoints/*\n",
    "!models/checkpoints/.gitkeep\n",
    "\n",
    "# Logs\n",
    "*.log\n",
    "logs/\n",
    "wandb/\n",
    "mlruns/\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "*.swp\n",
    "\"\"\",\n",
    "    }\n",
    "    \n",
    "    for filename, content in files.items():\n",
    "        file_path = project_path / filename\n",
    "        file_path.write_text(content)\n",
    "        print(f\"  üìÑ {filename}\")\n",
    "    \n",
    "    # Create __init__.py files\n",
    "    for dir_path in dirs:\n",
    "        if dir_path.startswith(\"src/\"):\n",
    "            init_path = project_path / dir_path / \"__init__.py\"\n",
    "            init_path.touch()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚úÖ Project created at: {project_path}\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(f\"  1. cd {project_path}\")\n",
    "    print(\"  2. git init\")\n",
    "    print(\"  3. Open the project proposal template\")\n",
    "    print(\"  4. Start building!\")\n",
    "    \n",
    "    return project_path\n",
    "\n",
    "# Example - uncomment to create your project:\n",
    "# create_project(\"my-aws-assistant\", \"A\")\n",
    "\n",
    "print(\"üí° Uncomment the create_project() call above to create your project structure!\")\n",
    "print(\"   Example: create_project('my-aws-assistant', 'A')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes to Avoid\n",
    "\n",
    "### Mistake 1: Scope Creep\n",
    "```python\n",
    "# ‚ùå Too ambitious\n",
    "project_goals = [\n",
    "    \"Fine-tune 70B model\",\n",
    "    \"Build RAG with 1M documents\",\n",
    "    \"Add multimodal support\",\n",
    "    \"Create mobile app\",\n",
    "    \"Deploy to Kubernetes\",\n",
    "    \"Build training pipeline\",\n",
    "]\n",
    "\n",
    "# ‚úÖ Focused and achievable\n",
    "project_goals = [\n",
    "    \"Fine-tune 70B model for AWS CLI help\",\n",
    "    \"Build RAG with 1000 AWS doc pages\",\n",
    "    \"Create FastAPI endpoint with streaming\",\n",
    "]\n",
    "stretch_goals = [\"Gradio UI\", \"Guardrails\"]\n",
    "```\n",
    "**Why:** A complete, polished project is better than an ambitious, unfinished one.\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 2: Waiting Until Week 5 to Test\n",
    "```python\n",
    "# ‚ùå Testing at the end\n",
    "week_5_plan = [\"Integration testing\", \"Fix all bugs\", \"Add safety\"]\n",
    "\n",
    "# ‚úÖ Test continuously\n",
    "every_week = [\n",
    "    \"Unit tests for new code\",\n",
    "    \"Integration check\",\n",
    "    \"Quick safety audit\",\n",
    "]\n",
    "```\n",
    "**Why:** Finding bugs early is 10x cheaper than finding them late.\n",
    "\n",
    "---\n",
    "\n",
    "### Mistake 3: \"I'll Document Later\"\n",
    "```python\n",
    "# ‚ùå Undocumented code\n",
    "def proc(q, ctx, opts):\n",
    "    ...\n",
    "\n",
    "# ‚úÖ Documented as you write\n",
    "def process_query(\n",
    "    query: str,\n",
    "    context: list[Document],\n",
    "    options: ProcessingOptions\n",
    ") -> QueryResult:\n",
    "    \"\"\"\n",
    "    Process a user query using RAG.\n",
    "    \n",
    "    Args:\n",
    "        query: User's natural language question\n",
    "        context: Retrieved documents for context\n",
    "        options: Processing configuration\n",
    "        \n",
    "    Returns:\n",
    "        QueryResult with answer and sources\n",
    "    \"\"\"\n",
    "```\n",
    "**Why:** You WILL forget why you did things. Future you will thank present you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've completed the capstone kickoff! You should now have:\n",
    "\n",
    "- ‚úÖ Verified your DGX Spark environment is ready\n",
    "- ‚úÖ Understood all four project options\n",
    "- ‚úÖ Selected your project (or know which one you're leaning toward)\n",
    "- ‚úÖ Understood the 6-week timeline\n",
    "- ‚úÖ (Optional) Created your project structure\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Complete your project proposal** using `templates/project-proposal.md`\n",
    "\n",
    "2. **Open the planning notebook:** `lab-4.6.1-project-planning.ipynb`\n",
    "\n",
    "3. **Then open your project-specific guide:**\n",
    "   - Option A: `lab-4.6.2-option-a-ai-assistant.ipynb`\n",
    "   - Option B: `lab-4.6.3-option-b-document-intelligence.ipynb`\n",
    "   - Option C: `lab-4.6.4-option-c-agent-swarm.ipynb`\n",
    "   - Option D: `lab-4.6.5-option-d-training-pipeline.ipynb`\n",
    "\n",
    "4. **Don't forget the shared notebooks:**\n",
    "   - `lab-4.6.6-evaluation-framework.ipynb` - How to evaluate your project\n",
    "   - `lab-4.6.7-documentation-guide.ipynb` - How to document your work\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Resources\n",
    "\n",
    "- [DGX Spark Playbooks](https://build.nvidia.com/spark) - Official NVIDIA examples\n",
    "- [Hugging Face Hub](https://huggingface.co/) - Models and datasets\n",
    "- [Papers With Code](https://paperswithcode.com/) - Research and benchmarks\n",
    "- [LangChain Documentation](https://python.langchain.com/) - Agent frameworks\n",
    "- [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails) - AI Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ Cleanup\n",
    "print(\"‚úÖ No cleanup needed - ready to proceed!\")\n",
    "print(\"\\nüéØ Next: Open lab-4.6.1-project-planning.ipynb to design your architecture.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
