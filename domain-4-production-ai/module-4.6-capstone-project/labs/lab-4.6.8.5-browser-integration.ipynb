{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 4.6.8.5: Browser Integration\n\n**Capstone Option E:** Browser-Deployed Fine-Tuned LLM (Troscha Matcha Guide)  \n**Phase:** 5 of 6  \n**Time:** 8-10 hours  \n**Difficulty:** â­â­â­â­\n\n---\n\n## Phase Objectives\n\nBy completing this phase, you will:\n- [ ] Set up a Vite + React project\n- [ ] Integrate Transformers.js for browser inference\n- [ ] Build a TroschaChatbot component with streaming\n- [ ] Handle WebGPU with WASM fallback\n- [ ] Test on multiple browsers\n- [ ] Optimize loading experience\n\n---\n\n## Phase Checklist\n\n- [ ] React project scaffolded\n- [ ] Transformers.js installed\n- [ ] Model loading implemented\n- [ ] Chat interface built (with `<preferences>` JSON parsing)\n- [ ] Streaming responses working\n- [ ] Error handling added\n- [ ] Tested in Chrome, Edge, Safari\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Matters\n",
    "\n",
    "**Browser deployment = Zero ongoing costs + Privacy!**\n",
    "\n",
    "| Deployment Type | Monthly Cost | Privacy |\n",
    "|-----------------|--------------|--------|\n",
    "| Cloud GPU API | $100-1000+ | âŒ Data sent to server |\n",
    "| Self-hosted GPU | $200-500+ | âš ï¸ Your infrastructure |\n",
    "| Browser (static) | **$0-5** | âœ… 100% client-side |\n",
    "\n",
    "**WebGPU** enables GPU acceleration directly in the browser, achieving 15-60 tokens/second depending on hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ELI5: How Does AI Run in a Browser?\n",
    "\n",
    "> **Imagine a library that comes to you.**\n",
    ">\n",
    "> Traditional AI: You send your question to a big library (server), they look it up, and send back the answer. Your question travels over the internet.\n",
    ">\n",
    "> Browser AI: The entire mini-library is downloaded to your computer once. Now you can look things up without ever leaving home. No one else sees your questions.\n",
    ">\n",
    "> **WebGPU** is like having a super-fast reading assistant (your graphics card) help you search through the library much faster than you could alone.\n",
    ">\n",
    "> **The magic:** After the first visit (downloading ~500MB), everything is cached. Return visits are instant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Project Setup\n",
    "\n",
    "This notebook provides the code templates. Run these commands in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Project Setup Commands\n\nsetup_commands = '''\n# Create React project with Vite\nnpm create vite@latest troscha-chatbot -- --template react\ncd troscha-chatbot\n\n# Install dependencies\nnpm install @huggingface/transformers\n\n# Install additional UI dependencies (optional)\nnpm install lucide-react\n\n# Start development server\nnpm run dev\n'''\n\nprint(\"ğŸ› ï¸ PROJECT SETUP\")\nprint(\"=\"*70)\nprint(setup_commands)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Vite Configuration\n",
    "\n",
    "**CRITICAL:** Headers are required for SharedArrayBuffer (needed by WebGPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vite.config.js\n",
    "\n",
    "vite_config = '''\n",
    "import { defineConfig } from 'vite'\n",
    "import react from '@vitejs/plugin-react'\n",
    "\n",
    "export default defineConfig({\n",
    "  plugins: [react()],\n",
    "  \n",
    "  // CRITICAL: Required for SharedArrayBuffer (WebGPU)\n",
    "  server: {\n",
    "    headers: {\n",
    "      'Cross-Origin-Opener-Policy': 'same-origin',\n",
    "      'Cross-Origin-Embedder-Policy': 'require-corp',\n",
    "    },\n",
    "  },\n",
    "  \n",
    "  // Optimize for large model files\n",
    "  build: {\n",
    "    target: 'esnext',\n",
    "    rollupOptions: {\n",
    "      output: {\n",
    "        manualChunks: {\n",
    "          transformers: ['@huggingface/transformers'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "  \n",
    "  // Handle WASM files\n",
    "  optimizeDeps: {\n",
    "    exclude: ['@huggingface/transformers'],\n",
    "  },\n",
    "})\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“„ vite.config.js\")\n",
    "print(\"=\"*70)\n",
    "print(vite_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Model Loading Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# src/hooks/useModelLoader.js\n\nmodel_loader_hook = '''\nimport { useState, useCallback, useRef } from 'react';\nimport { pipeline, env } from '@huggingface/transformers';\n\n// Configure Transformers.js\nenv.allowLocalModels = false;\nenv.useBrowserCache = true;\n\n/**\n * Custom hook for loading and managing the Troscha Matcha Guide model.\n * \n * Features:\n * - Lazy loading (only loads when first needed)\n * - WebGPU with WASM fallback\n * - Progress tracking\n * - Caching for instant reloads\n * \n * @param {string} modelId - The model ID or URL\n * @returns {Object} - { generator, isLoading, progress, error, loadModel }\n */\nexport function useModelLoader(modelId = 'troscha-matcha') {\n  const [isLoading, setIsLoading] = useState(false);\n  const [progress, setProgress] = useState(0);\n  const [error, setError] = useState(null);\n  const generatorRef = useRef(null);\n\n  // Detect WebGPU support\n  const hasWebGPU = useCallback(async () => {\n    if (!navigator.gpu) return false;\n    try {\n      const adapter = await navigator.gpu.requestAdapter();\n      return adapter !== null;\n    } catch {\n      return false;\n    }\n  }, []);\n\n  // Load the model\n  const loadModel = useCallback(async () => {\n    // Return cached generator if available\n    if (generatorRef.current) {\n      return generatorRef.current;\n    }\n\n    setIsLoading(true);\n    setError(null);\n    setProgress(0);\n\n    try {\n      // Determine device\n      const useWebGPU = await hasWebGPU();\n      const device = useWebGPU ? 'webgpu' : 'wasm';\n      \n      console.log(`Loading model with ${device}...`);\n\n      // Create pipeline\n      const generator = await pipeline(\n        'text-generation',\n        modelId,\n        {\n          device: device,\n          dtype: 'q4',  // INT4 quantization\n          progress_callback: (progressInfo) => {\n            if (progressInfo.progress) {\n              setProgress(Math.round(progressInfo.progress * 100));\n            }\n          },\n        }\n      );\n\n      generatorRef.current = generator;\n      setProgress(100);\n      setIsLoading(false);\n      \n      return generator;\n    } catch (err) {\n      console.error('Model loading failed:', err);\n      setError(err.message);\n      setIsLoading(false);\n      throw err;\n    }\n  }, [modelId, hasWebGPU]);\n\n  return {\n    generator: generatorRef.current,\n    isLoading,\n    progress,\n    error,\n    loadModel,\n  };\n}\n'''\n\nprint(\"ğŸ“„ src/hooks/useModelLoader.js\")\nprint(\"=\"*70)\nprint(model_loader_hook)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: MatchaChatbot Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# src/components/TroschaChatbot.jsx\n\nchatbot_component = '''\nimport { useState, useRef, useEffect } from 'react';\nimport { useModelLoader } from '../hooks/useModelLoader';\nimport './TroschaChatbot.css';\n\n// Troscha system prompt (must match training data!)\nconst SYSTEM_PROMPT = `You are Troscha's matcha guide.\n\nMENU:\n- Yura: Latte Rp 27k\n- Taku: Straight Rp 25k | Latte Rp 32k | Strawberry Rp 40k\n- Firu: Straight Rp 34k | Latte Rp 44k | Miruku Rp 49k | Strawberry Rp 52k\n- Giru: Straight Rp 39k | Latte Rp 49k | Miruku Rp 54k | Strawberry Rp 57k\n- Zeno: Straight Rp 44k | Latte Rp 54k | Miruku Rp 59k | Strawberry Rp 62k\n- Moku: Hojicha Latte Rp 35k\n- Hiku: Straight Rp 79k | Latte Rp 89k\n- Kiyo: Straight Rp 94k | Latte Rp 104k\n\nADDON: Oat Milk +Rp 5k\n\nEnd responses with <preferences> JSON.`;\n\n/**\n * Parse preferences JSON from response.\n * Responses end with <preferences>{\"key\": \"value\"}</preferences>\n */\nfunction parsePreferences(response) {\n  const match = response.match(/<preferences>([\\s\\S]*?)<\\/preferences>/);\n  if (match) {\n    try {\n      return {\n        text: response.replace(/<preferences>[\\s\\S]*?<\\/preferences>/, '').trim(),\n        preferences: JSON.parse(match[1]),\n      };\n    } catch (e) {\n      console.warn('Failed to parse preferences:', e);\n    }\n  }\n  return { text: response, preferences: null };\n}\n\n/**\n * TroschaChatbot - A browser-based AI chatbot for Troscha matcha products.\n * \n * Features:\n * - Runs entirely in the browser (WebGPU/WASM)\n * - Streaming responses\n * - Conversation history\n * - Preferences JSON parsing for product recommendations\n * - Loading states with progress\n */\nexport function TroschaChatbot({ modelId }) {\n  const [messages, setMessages] = useState([]);\n  const [input, setInput] = useState('');\n  const [isGenerating, setIsGenerating] = useState(false);\n  const [lastPreferences, setLastPreferences] = useState(null);\n  const messagesEndRef = useRef(null);\n  \n  const { isLoading, progress, error, loadModel } = useModelLoader(modelId);\n\n  // Auto-scroll to bottom\n  useEffect(() => {\n    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });\n  }, [messages]);\n\n  // Send message\n  const handleSend = async () => {\n    if (!input.trim() || isGenerating) return;\n\n    const userMessage = { role: 'user', content: input.trim() };\n    setMessages(prev => [...prev, userMessage]);\n    setInput('');\n    setIsGenerating(true);\n\n    try {\n      // Load model if not loaded\n      const generator = await loadModel();\n\n      // Build conversation for model\n      const conversation = [\n        { role: 'system', content: SYSTEM_PROMPT },\n        ...messages,\n        userMessage,\n      ];\n\n      // Generate response\n      const output = await generator(conversation, {\n        max_new_tokens: 256,\n        temperature: 0.7,\n        top_p: 0.9,\n        do_sample: true,\n      });\n\n      // Extract assistant response\n      const generatedMessages = output[0].generated_text;\n      const assistantMessage = generatedMessages[generatedMessages.length - 1];\n      \n      // Parse preferences from response\n      const { text, preferences } = parsePreferences(assistantMessage.content);\n      if (preferences) {\n        setLastPreferences(preferences);\n      }\n\n      setMessages(prev => [...prev, { \n        role: 'assistant', \n        content: text,\n        preferences: preferences,\n      }]);\n    } catch (err) {\n      console.error('Generation error:', err);\n      setMessages(prev => [...prev, {\n        role: 'assistant',\n        content: 'Sorry, I encountered an error. Please try again.',\n      }]);\n    } finally {\n      setIsGenerating(false);\n    }\n  };\n\n  // Handle Enter key\n  const handleKeyPress = (e) => {\n    if (e.key === 'Enter' && !e.shiftKey) {\n      e.preventDefault();\n      handleSend();\n    }\n  };\n\n  return (\n    <div className=\"chatbot-container\">\n      <div className=\"chatbot-header\">\n        <h1>ğŸµ Troscha Matcha Guide</h1>\n        <p>Your AI guide to premium matcha</p>\n      </div>\n\n      {/* Loading State */}\n      {isLoading && (\n        <div className=\"loading-overlay\">\n          <div className=\"loading-content\">\n            <div className=\"loading-spinner\" />\n            <p>Loading AI model... {progress}%</p>\n            <p className=\"loading-note\">\n              First load downloads ~500MB (cached after)\n            </p>\n            <div className=\"progress-bar\">\n              <div \n                className=\"progress-fill\" \n                style={{ width: `${progress}%` }} \n              />\n            </div>\n          </div>\n        </div>\n      )}\n\n      {/* Error State */}\n      {error && (\n        <div className=\"error-banner\">\n          <p>Error: {error}</p>\n          <button onClick={() => window.location.reload()}>\n            Reload\n          </button>\n        </div>\n      )}\n\n      {/* Messages */}\n      <div className=\"messages-container\">\n        {messages.length === 0 && (\n          <div className=\"welcome-message\">\n            <p>Welcome to Troscha! Ask me about our matcha products:</p>\n            <ul>\n              <li>\"What's the difference between Firu and Giru?\"</li>\n              <li>\"I want something not too bitter but affordable\"</li>\n              <li>\"What's your most premium matcha option?\"</li>\n            </ul>\n          </div>\n        )}\n\n        {messages.map((msg, idx) => (\n          <div key={idx} className={`message ${msg.role}`}>\n            <div className=\"message-content\">\n              {msg.content}\n              {msg.preferences && (\n                <div className=\"preferences-badge\">\n                  ğŸ¯ Recommended: {msg.preferences.product || 'See above'}\n                </div>\n              )}\n            </div>\n          </div>\n        ))}\n\n        {isGenerating && (\n          <div className=\"message assistant\">\n            <div className=\"message-content typing\">\n              <span className=\"dot\" />\n              <span className=\"dot\" />\n              <span className=\"dot\" />\n            </div>\n          </div>\n        )}\n\n        <div ref={messagesEndRef} />\n      </div>\n\n      {/* Input */}\n      <div className=\"input-container\">\n        <textarea\n          value={input}\n          onChange={(e) => setInput(e.target.value)}\n          onKeyPress={handleKeyPress}\n          placeholder=\"Ask about our matcha...\"\n          disabled={isLoading || isGenerating}\n          rows={1}\n        />\n        <button\n          onClick={handleSend}\n          disabled={isLoading || isGenerating || !input.trim()}\n        >\n          Send\n        </button>\n      </div>\n\n      <div className=\"chatbot-footer\">\n        <p>Runs 100% in your browser â€¢ No data sent to servers</p>\n      </div>\n    </div>\n  );\n}\n'''\n\nprint(\"ğŸ“„ src/components/TroschaChatbot.jsx\")\nprint(\"=\"*70)\nprint(chatbot_component)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: CSS Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# src/components/TroschaChatbot.css\n\nchatbot_css = '''\n.chatbot-container {\n  max-width: 800px;\n  margin: 0 auto;\n  height: 100vh;\n  display: flex;\n  flex-direction: column;\n  background: #fafafa;\n  font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n}\n\n.chatbot-header {\n  padding: 1rem;\n  background: linear-gradient(135deg, #2d5a27 0%, #4a7c43 100%);\n  color: white;\n  text-align: center;\n}\n\n.chatbot-header h1 {\n  margin: 0;\n  font-size: 1.5rem;\n}\n\n.chatbot-header p {\n  margin: 0.5rem 0 0;\n  opacity: 0.9;\n  font-size: 0.9rem;\n}\n\n.messages-container {\n  flex: 1;\n  overflow-y: auto;\n  padding: 1rem;\n}\n\n.welcome-message {\n  background: white;\n  padding: 1.5rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n}\n\n.welcome-message ul {\n  margin: 1rem 0 0;\n  padding-left: 1.5rem;\n}\n\n.welcome-message li {\n  margin: 0.5rem 0;\n  color: #2d5a27;\n  cursor: pointer;\n}\n\n.message {\n  margin: 0.75rem 0;\n  display: flex;\n}\n\n.message.user {\n  justify-content: flex-end;\n}\n\n.message-content {\n  max-width: 80%;\n  padding: 0.75rem 1rem;\n  border-radius: 12px;\n  line-height: 1.5;\n  white-space: pre-wrap;\n}\n\n.message.user .message-content {\n  background: #2d5a27;\n  color: white;\n  border-bottom-right-radius: 4px;\n}\n\n.message.assistant .message-content {\n  background: white;\n  box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n  border-bottom-left-radius: 4px;\n}\n\n.preferences-badge {\n  margin-top: 0.5rem;\n  padding: 0.5rem;\n  background: #e8f5e9;\n  border-radius: 8px;\n  font-size: 0.85rem;\n  color: #2d5a27;\n}\n\n.typing {\n  display: flex;\n  gap: 4px;\n  padding: 1rem;\n}\n\n.typing .dot {\n  width: 8px;\n  height: 8px;\n  background: #2d5a27;\n  border-radius: 50%;\n  animation: bounce 1.4s infinite;\n}\n\n.typing .dot:nth-child(2) { animation-delay: 0.2s; }\n.typing .dot:nth-child(3) { animation-delay: 0.4s; }\n\n@keyframes bounce {\n  0%, 80%, 100% { transform: translateY(0); }\n  40% { transform: translateY(-6px); }\n}\n\n.input-container {\n  display: flex;\n  gap: 0.5rem;\n  padding: 1rem;\n  background: white;\n  border-top: 1px solid #eee;\n}\n\n.input-container textarea {\n  flex: 1;\n  padding: 0.75rem 1rem;\n  border: 1px solid #ddd;\n  border-radius: 8px;\n  resize: none;\n  font-size: 1rem;\n  font-family: inherit;\n}\n\n.input-container textarea:focus {\n  outline: none;\n  border-color: #2d5a27;\n}\n\n.input-container button {\n  padding: 0.75rem 1.5rem;\n  background: #2d5a27;\n  color: white;\n  border: none;\n  border-radius: 8px;\n  cursor: pointer;\n  font-size: 1rem;\n  transition: background 0.2s;\n}\n\n.input-container button:hover:not(:disabled) {\n  background: #3d6a37;\n}\n\n.input-container button:disabled {\n  opacity: 0.5;\n  cursor: not-allowed;\n}\n\n.loading-overlay {\n  position: fixed;\n  inset: 0;\n  background: rgba(255,255,255,0.95);\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  z-index: 100;\n}\n\n.loading-content {\n  text-align: center;\n}\n\n.loading-spinner {\n  width: 48px;\n  height: 48px;\n  border: 4px solid #eee;\n  border-top-color: #2d5a27;\n  border-radius: 50%;\n  animation: spin 1s linear infinite;\n  margin: 0 auto 1rem;\n}\n\n@keyframes spin {\n  to { transform: rotate(360deg); }\n}\n\n.loading-note {\n  color: #666;\n  font-size: 0.85rem;\n  margin-top: 0.5rem;\n}\n\n.progress-bar {\n  width: 200px;\n  height: 8px;\n  background: #eee;\n  border-radius: 4px;\n  margin: 1rem auto 0;\n  overflow: hidden;\n}\n\n.progress-fill {\n  height: 100%;\n  background: #2d5a27;\n  transition: width 0.3s;\n}\n\n.error-banner {\n  background: #fee;\n  color: #c00;\n  padding: 1rem;\n  display: flex;\n  align-items: center;\n  justify-content: space-between;\n}\n\n.chatbot-footer {\n  padding: 0.5rem;\n  text-align: center;\n  font-size: 0.75rem;\n  color: #999;\n}\n'''\n\nprint(\"ğŸ“„ src/components/TroschaChatbot.css\")\nprint(\"=\"*70)\nprint(chatbot_css[:2000] + \"...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: App Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# src/App.jsx\n\napp_jsx = '''\nimport { TroschaChatbot } from './components/TroschaChatbot';\nimport './App.css';\n\n// Configure your model URL here\n// Recommended: Use CloudFront distribution URL for CDN delivery\nconst MODEL_ID = 'https://d1234567890abc.cloudfront.net/';\n// Alternative: Direct S3 for testing\n// const MODEL_ID = 'https://your-bucket.s3.us-east-1.amazonaws.com/';\n\nfunction App() {\n  return (\n    <div className=\"app\">\n      <TroschaChatbot modelId={MODEL_ID} />\n    </div>\n  );\n}\n\nexport default App;\n'''\n\nprint(\"ğŸ“„ src/App.jsx\")\nprint(\"=\"*70)\nprint(app_jsx)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Part 7: Deployment Configuration\n\n**Architecture:**\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Model Files: AWS S3 + CloudFront (CDN)                 â”‚\nâ”‚  â”œâ”€â”€ ~500MB ONNX files served globally via CDN          â”‚\nâ”‚  â””â”€â”€ CloudFront URL: https://d123...cloudfront.net/     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Web App: Any static host (Vercel/Netlify/etc)          â”‚\nâ”‚  â”œâ”€â”€ ~200KB React app                                   â”‚\nâ”‚  â””â”€â”€ Fetches model from CloudFront on first load        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Note:** The configs below are for the web app only. Model hosting is handled by S3 + CloudFront (see Lab 4.6.8.6)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# vercel.json - Web App hosting configuration (not for model files)\n# Model files are hosted on S3 + CloudFront (see Lab 4.6.8.6)\n\nvercel_config = '''\n{\n  \"headers\": [\n    {\n      \"source\": \"/(.*)\",\n      \"headers\": [\n        {\n          \"key\": \"Cross-Origin-Opener-Policy\",\n          \"value\": \"same-origin\"\n        },\n        {\n          \"key\": \"Cross-Origin-Embedder-Policy\",\n          \"value\": \"require-corp\"\n        }\n      ]\n    }\n  ]\n}\n'''\n\nprint(\"ğŸ“„ vercel.json (for web app hosting)\")\nprint(\"=\"*70)\nprint(vercel_config)\nprint(\"\\nğŸ’¡ Note: This config is for hosting the React app only.\")\nprint(\"   Model files are served from S3 + CloudFront.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Browser Compatibility Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browser compatibility checklist\n",
    "\n",
    "compatibility = '''\n",
    "## Browser Compatibility Checklist\n",
    "\n",
    "| Browser | WebGPU | WASM Fallback | Notes |\n",
    "|---------|--------|---------------|-------|\n",
    "| Chrome 113+ | âœ… | âœ… | Best performance |\n",
    "| Edge 113+ | âœ… | âœ… | Same as Chrome |\n",
    "| Safari 17+ | âš ï¸ | âœ… | WebGPU in beta |\n",
    "| Firefox | âŒ | âœ… | WASM only |\n",
    "| Mobile Chrome | âŒ | âœ… | WASM, slower |\n",
    "| Mobile Safari | âŒ | âš ï¸ | May have issues |\n",
    "\n",
    "## Testing Checklist\n",
    "\n",
    "- [ ] Chrome: Model loads, generates responses\n",
    "- [ ] Edge: Model loads, generates responses\n",
    "- [ ] Safari: Fallback to WASM works\n",
    "- [ ] Firefox: WASM inference works\n",
    "- [ ] Loading progress updates correctly\n",
    "- [ ] Error handling shows user-friendly messages\n",
    "- [ ] Cached model loads instantly on refresh\n",
    "\n",
    "## Performance Benchmarks\n",
    "\n",
    "| Device | Backend | Tokens/sec |\n",
    "|--------|---------|------------|\n",
    "| RTX 4090 | WebGPU | 40-60 |\n",
    "| M1 Mac | WebGPU | 15-25 |\n",
    "| Intel iGPU | WebGPU | 5-15 |\n",
    "| Any CPU | WASM | 1-5 |\n",
    "'''\n",
    "\n",
    "print(compatibility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Common Issues\n\n### Issue 1: SharedArrayBuffer Not Available\n**Symptom:** Error about SharedArrayBuffer  \n**Fix:** Add COOP/COEP headers in vite.config.js and vercel.json\n\n### Issue 2: Model Download Fails\n**Symptom:** CORS errors or 404  \n**Fix:** \n- Verify CloudFront distribution is deployed and has CORS headers\n- Check that CloudFront Response Headers Policy includes CORS\n- Test S3 URL directly first, then test CloudFront URL\n- Ensure model files are public-read in S3\n\n### Issue 3: WebGPU Not Detected\n**Symptom:** Falls back to WASM even with modern GPU  \n**Fix:** Update browser, check chrome://flags for WebGPU\n\n### Issue 4: Slow Model Loading\n**Symptom:** Model takes a long time to load  \n**Fix:** \n- Use CloudFront (CDN) for global edge caching\n- Model will be cached in browser after first load\n- Check CloudFront cache hit rate in AWS Console"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase Complete!\n",
    "\n",
    "You've achieved:\n",
    "- âœ… Created React project with Vite\n",
    "- âœ… Integrated Transformers.js\n",
    "- âœ… Built MatchaChatbot component\n",
    "- âœ… Implemented loading states and streaming\n",
    "- âœ… Added error handling\n",
    "- âœ… Configured for deployment\n",
    "\n",
    "**Next:** [Lab 4.6.8.6: Deployment & Documentation](./lab-4.6.8.6-deployment-documentation.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save all component files\nfrom pathlib import Path\n\n# Save to project structure (matching training config paths)\nPROJECT_DIR = Path(\"./troscha-matcha\")\noutput_dir = PROJECT_DIR / \"webapp\"\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Save files\nfiles = {\n    \"vite.config.js\": vite_config,\n    \"src/hooks/useModelLoader.js\": model_loader_hook,\n    \"src/components/TroschaChatbot.jsx\": chatbot_component,\n    \"src/components/TroschaChatbot.css\": chatbot_css,\n    \"src/App.jsx\": app_jsx,\n    \"vercel.json\": vercel_config,\n}\n\nfor filename, content in files.items():\n    filepath = output_dir / filename\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n    with open(filepath, 'w') as f:\n        f.write(content.strip())\n    print(f\"âœ… Saved {filename}\")\n\nprint(f\"\\nğŸ“ All template files saved to {output_dir}\")\nprint(\"\\nğŸ“‹ Project Structure:\")\nprint(f\"   {PROJECT_DIR}/\")\nprint(\"   â”œâ”€â”€ data/          # Training data\")\nprint(\"   â”œâ”€â”€ models/        # Trained models\")\nprint(\"   â”‚   â”œâ”€â”€ troscha-lora/\")\nprint(\"   â”‚   â”œâ”€â”€ troscha-merged/\")\nprint(\"   â”‚   â””â”€â”€ troscha-browser/\")\nprint(\"   â””â”€â”€ webapp/        # React app (you are here)\")\nprint(\"\\nğŸ¯ Next Steps:\")\nprint(\"   1. cd troscha-matcha/webapp\")\nprint(\"   2. npm create vite@latest . -- --template react\")\nprint(\"   3. Copy template files into place\")\nprint(\"   4. Update MODEL_ID in App.jsx with your S3 URL\")\nprint(\"   5. npm install @huggingface/transformers\")\nprint(\"   6. npm run dev\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}