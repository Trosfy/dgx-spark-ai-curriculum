{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.6.8.5: Browser Integration\n",
    "\n",
    "**Capstone Option E:** Browser-Deployed Fine-Tuned LLM (Matcha Expert)  \n",
    "**Phase:** 5 of 6  \n",
    "**Time:** 8-10 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## Phase Objectives\n",
    "\n",
    "By completing this phase, you will:\n",
    "- [ ] Set up a Vite + React project\n",
    "- [ ] Integrate Transformers.js for browser inference\n",
    "- [ ] Build a MatchaChatbot component with streaming\n",
    "- [ ] Handle WebGPU with WASM fallback\n",
    "- [ ] Test on multiple browsers\n",
    "- [ ] Optimize loading experience\n",
    "\n",
    "---\n",
    "\n",
    "## Phase Checklist\n",
    "\n",
    "- [ ] React project scaffolded\n",
    "- [ ] Transformers.js installed\n",
    "- [ ] Model loading implemented\n",
    "- [ ] Chat interface built\n",
    "- [ ] Streaming responses working\n",
    "- [ ] Error handling added\n",
    "- [ ] Tested in Chrome, Edge, Safari\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Matters\n",
    "\n",
    "**Browser deployment = Zero ongoing costs + Privacy!**\n",
    "\n",
    "| Deployment Type | Monthly Cost | Privacy |\n",
    "|-----------------|--------------|--------|\n",
    "| Cloud GPU API | $100-1000+ | ‚ùå Data sent to server |\n",
    "| Self-hosted GPU | $200-500+ | ‚ö†Ô∏è Your infrastructure |\n",
    "| Browser (static) | **$0-5** | ‚úÖ 100% client-side |\n",
    "\n",
    "**WebGPU** enables GPU acceleration directly in the browser, achieving 15-60 tokens/second depending on hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ELI5: How Does AI Run in a Browser?\n",
    "\n",
    "> **Imagine a library that comes to you.**\n",
    ">\n",
    "> Traditional AI: You send your question to a big library (server), they look it up, and send back the answer. Your question travels over the internet.\n",
    ">\n",
    "> Browser AI: The entire mini-library is downloaded to your computer once. Now you can look things up without ever leaving home. No one else sees your questions.\n",
    ">\n",
    "> **WebGPU** is like having a super-fast reading assistant (your graphics card) help you search through the library much faster than you could alone.\n",
    ">\n",
    "> **The magic:** After the first visit (downloading ~500MB), everything is cached. Return visits are instant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Project Setup\n",
    "\n",
    "This notebook provides the code templates. Run these commands in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Setup Commands\n",
    "\n",
    "setup_commands = '''\n",
    "# Create React project with Vite\n",
    "npm create vite@latest matcha-chatbot -- --template react\n",
    "cd matcha-chatbot\n",
    "\n",
    "# Install dependencies\n",
    "npm install @huggingface/transformers\n",
    "\n",
    "# Install additional UI dependencies (optional)\n",
    "npm install lucide-react\n",
    "\n",
    "# Start development server\n",
    "npm run dev\n",
    "'''\n",
    "\n",
    "print(\"üõ†Ô∏è PROJECT SETUP\")\n",
    "print(\"=\"*70)\n",
    "print(setup_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Vite Configuration\n",
    "\n",
    "**CRITICAL:** Headers are required for SharedArrayBuffer (needed by WebGPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vite.config.js\n",
    "\n",
    "vite_config = '''\n",
    "import { defineConfig } from 'vite'\n",
    "import react from '@vitejs/plugin-react'\n",
    "\n",
    "export default defineConfig({\n",
    "  plugins: [react()],\n",
    "  \n",
    "  // CRITICAL: Required for SharedArrayBuffer (WebGPU)\n",
    "  server: {\n",
    "    headers: {\n",
    "      'Cross-Origin-Opener-Policy': 'same-origin',\n",
    "      'Cross-Origin-Embedder-Policy': 'require-corp',\n",
    "    },\n",
    "  },\n",
    "  \n",
    "  // Optimize for large model files\n",
    "  build: {\n",
    "    target: 'esnext',\n",
    "    rollupOptions: {\n",
    "      output: {\n",
    "        manualChunks: {\n",
    "          transformers: ['@huggingface/transformers'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "  \n",
    "  // Handle WASM files\n",
    "  optimizeDeps: {\n",
    "    exclude: ['@huggingface/transformers'],\n",
    "  },\n",
    "})\n",
    "'''\n",
    "\n",
    "print(\"üìÑ vite.config.js\")\n",
    "print(\"=\"*70)\n",
    "print(vite_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Model Loading Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/hooks/useModelLoader.js\n",
    "\n",
    "model_loader_hook = '''\n",
    "import { useState, useCallback, useRef } from 'react';\n",
    "import { pipeline, env } from '@huggingface/transformers';\n",
    "\n",
    "// Configure Transformers.js\n",
    "env.allowLocalModels = false;\n",
    "env.useBrowserCache = true;\n",
    "\n",
    "/**\n",
    " * Custom hook for loading and managing the Matcha Expert model.\n",
    " * \n",
    " * Features:\n",
    " * - Lazy loading (only loads when first needed)\n",
    " * - WebGPU with WASM fallback\n",
    " * - Progress tracking\n",
    " * - Caching for instant reloads\n",
    " * \n",
    " * @param {string} modelId - The model ID or URL\n",
    " * @returns {Object} - { generator, isLoading, progress, error, loadModel }\n",
    " */\n",
    "export function useModelLoader(modelId = 'matcha-expert') {\n",
    "  const [isLoading, setIsLoading] = useState(false);\n",
    "  const [progress, setProgress] = useState(0);\n",
    "  const [error, setError] = useState(null);\n",
    "  const generatorRef = useRef(null);\n",
    "\n",
    "  // Detect WebGPU support\n",
    "  const hasWebGPU = useCallback(async () => {\n",
    "    if (!navigator.gpu) return false;\n",
    "    try {\n",
    "      const adapter = await navigator.gpu.requestAdapter();\n",
    "      return adapter !== null;\n",
    "    } catch {\n",
    "      return false;\n",
    "    }\n",
    "  }, []);\n",
    "\n",
    "  // Load the model\n",
    "  const loadModel = useCallback(async () => {\n",
    "    // Return cached generator if available\n",
    "    if (generatorRef.current) {\n",
    "      return generatorRef.current;\n",
    "    }\n",
    "\n",
    "    setIsLoading(true);\n",
    "    setError(null);\n",
    "    setProgress(0);\n",
    "\n",
    "    try {\n",
    "      // Determine device\n",
    "      const useWebGPU = await hasWebGPU();\n",
    "      const device = useWebGPU ? 'webgpu' : 'wasm';\n",
    "      \n",
    "      console.log(`Loading model with ${device}...`);\n",
    "\n",
    "      // Create pipeline\n",
    "      const generator = await pipeline(\n",
    "        'text-generation',\n",
    "        modelId,\n",
    "        {\n",
    "          device: device,\n",
    "          dtype: 'q4',  // INT4 quantization\n",
    "          progress_callback: (progressInfo) => {\n",
    "            if (progressInfo.progress) {\n",
    "              setProgress(Math.round(progressInfo.progress * 100));\n",
    "            }\n",
    "          },\n",
    "        }\n",
    "      );\n",
    "\n",
    "      generatorRef.current = generator;\n",
    "      setProgress(100);\n",
    "      setIsLoading(false);\n",
    "      \n",
    "      return generator;\n",
    "    } catch (err) {\n",
    "      console.error('Model loading failed:', err);\n",
    "      setError(err.message);\n",
    "      setIsLoading(false);\n",
    "      throw err;\n",
    "    }\n",
    "  }, [modelId, hasWebGPU]);\n",
    "\n",
    "  return {\n",
    "    generator: generatorRef.current,\n",
    "    isLoading,\n",
    "    progress,\n",
    "    error,\n",
    "    loadModel,\n",
    "  };\n",
    "}\n",
    "'''\n",
    "\n",
    "print(\"üìÑ src/hooks/useModelLoader.js\")\n",
    "print(\"=\"*70)\n",
    "print(model_loader_hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: MatchaChatbot Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/components/MatchaChatbot.jsx\n",
    "\n",
    "chatbot_component = '''\n",
    "import { useState, useRef, useEffect } from 'react';\n",
    "import { useModelLoader } from '../hooks/useModelLoader';\n",
    "import './MatchaChatbot.css';\n",
    "\n",
    "// System prompt for the matcha expert\n",
    "const SYSTEM_PROMPT = `You are a matcha tea expert with deep knowledge of Japanese tea culture, \n",
    "preparation methods, health benefits, and culinary applications. You provide accurate, helpful \n",
    "information about matcha grades, brewing techniques, traditional ceremonies, and modern recipes. \n",
    "You're passionate about quality matcha and help users make informed choices.`;\n",
    "\n",
    "/**\n",
    " * MatchaChatbot - A browser-based AI chatbot for matcha expertise.\n",
    " * \n",
    " * Features:\n",
    " * - Runs entirely in the browser (WebGPU/WASM)\n",
    " * - Streaming responses\n",
    " * - Conversation history\n",
    " * - Loading states with progress\n",
    " */\n",
    "export function MatchaChatbot({ modelId }) {\n",
    "  const [messages, setMessages] = useState([]);\n",
    "  const [input, setInput] = useState('');\n",
    "  const [isGenerating, setIsGenerating] = useState(false);\n",
    "  const messagesEndRef = useRef(null);\n",
    "  \n",
    "  const { isLoading, progress, error, loadModel } = useModelLoader(modelId);\n",
    "\n",
    "  // Auto-scroll to bottom\n",
    "  useEffect(() => {\n",
    "    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });\n",
    "  }, [messages]);\n",
    "\n",
    "  // Send message\n",
    "  const handleSend = async () => {\n",
    "    if (!input.trim() || isGenerating) return;\n",
    "\n",
    "    const userMessage = { role: 'user', content: input.trim() };\n",
    "    setMessages(prev => [...prev, userMessage]);\n",
    "    setInput('');\n",
    "    setIsGenerating(true);\n",
    "\n",
    "    try {\n",
    "      // Load model if not loaded\n",
    "      const generator = await loadModel();\n",
    "\n",
    "      // Build conversation for model\n",
    "      const conversation = [\n",
    "        { role: 'system', content: SYSTEM_PROMPT },\n",
    "        ...messages,\n",
    "        userMessage,\n",
    "      ];\n",
    "\n",
    "      // Generate response\n",
    "      const output = await generator(conversation, {\n",
    "        max_new_tokens: 256,\n",
    "        temperature: 0.7,\n",
    "        top_p: 0.9,\n",
    "        do_sample: true,\n",
    "      });\n",
    "\n",
    "      // Extract assistant response\n",
    "      const generatedMessages = output[0].generated_text;\n",
    "      const assistantMessage = generatedMessages[generatedMessages.length - 1];\n",
    "\n",
    "      setMessages(prev => [...prev, assistantMessage]);\n",
    "    } catch (err) {\n",
    "      console.error('Generation error:', err);\n",
    "      setMessages(prev => [...prev, {\n",
    "        role: 'assistant',\n",
    "        content: 'Sorry, I encountered an error. Please try again.',\n",
    "      }]);\n",
    "    } finally {\n",
    "      setIsGenerating(false);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  // Handle Enter key\n",
    "  const handleKeyPress = (e) => {\n",
    "    if (e.key === 'Enter' && !e.shiftKey) {\n",
    "      e.preventDefault();\n",
    "      handleSend();\n",
    "    }\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <div className=\"chatbot-container\">\n",
    "      <div className=\"chatbot-header\">\n",
    "        <h1>üçµ Matcha Expert</h1>\n",
    "        <p>Your AI guide to Japanese green tea</p>\n",
    "      </div>\n",
    "\n",
    "      {/* Loading State */}\n",
    "      {isLoading && (\n",
    "        <div className=\"loading-overlay\">\n",
    "          <div className=\"loading-content\">\n",
    "            <div className=\"loading-spinner\" />\n",
    "            <p>Loading AI model... {progress}%</p>\n",
    "            <p className=\"loading-note\">\n",
    "              First load downloads ~500MB (cached after)\n",
    "            </p>\n",
    "            <div className=\"progress-bar\">\n",
    "              <div \n",
    "                className=\"progress-fill\" \n",
    "                style={{ width: `${progress}%` }} \n",
    "              />\n",
    "            </div>\n",
    "          </div>\n",
    "        </div>\n",
    "      )}\n",
    "\n",
    "      {/* Error State */}\n",
    "      {error && (\n",
    "        <div className=\"error-banner\">\n",
    "          <p>Error: {error}</p>\n",
    "          <button onClick={() => window.location.reload()}>\n",
    "            Reload\n",
    "          </button>\n",
    "        </div>\n",
    "      )}\n",
    "\n",
    "      {/* Messages */}\n",
    "      <div className=\"messages-container\">\n",
    "        {messages.length === 0 && (\n",
    "          <div className=\"welcome-message\">\n",
    "            <p>Welcome! Ask me anything about matcha tea:</p>\n",
    "            <ul>\n",
    "              <li>\"What\\'s the difference between ceremonial and culinary grade?\"</li>\n",
    "              <li>\"How do I make the perfect matcha latte?\"</li>\n",
    "              <li>\"What are the health benefits of matcha?\"</li>\n",
    "            </ul>\n",
    "          </div>\n",
    "        )}\n",
    "\n",
    "        {messages.map((msg, idx) => (\n",
    "          <div key={idx} className={`message ${msg.role}`}>\n",
    "            <div className=\"message-content\">\n",
    "              {msg.content}\n",
    "            </div>\n",
    "          </div>\n",
    "        ))}\n",
    "\n",
    "        {isGenerating && (\n",
    "          <div className=\"message assistant\">\n",
    "            <div className=\"message-content typing\">\n",
    "              <span className=\"dot\" />\n",
    "              <span className=\"dot\" />\n",
    "              <span className=\"dot\" />\n",
    "            </div>\n",
    "          </div>\n",
    "        )}\n",
    "\n",
    "        <div ref={messagesEndRef} />\n",
    "      </div>\n",
    "\n",
    "      {/* Input */}\n",
    "      <div className=\"input-container\">\n",
    "        <textarea\n",
    "          value={input}\n",
    "          onChange={(e) => setInput(e.target.value)}\n",
    "          onKeyPress={handleKeyPress}\n",
    "          placeholder=\"Ask about matcha...\"\n",
    "          disabled={isLoading || isGenerating}\n",
    "          rows={1}\n",
    "        />\n",
    "        <button\n",
    "          onClick={handleSend}\n",
    "          disabled={isLoading || isGenerating || !input.trim()}\n",
    "        >\n",
    "          Send\n",
    "        </button>\n",
    "      </div>\n",
    "\n",
    "      <div className=\"chatbot-footer\">\n",
    "        <p>Runs 100% in your browser ‚Ä¢ No data sent to servers</p>\n",
    "      </div>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "'''\n",
    "\n",
    "print(\"üìÑ src/components/MatchaChatbot.jsx\")\n",
    "print(\"=\"*70)\n",
    "print(chatbot_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: CSS Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/components/MatchaChatbot.css\n",
    "\n",
    "chatbot_css = '''\n",
    ".chatbot-container {\n",
    "  max-width: 800px;\n",
    "  margin: 0 auto;\n",
    "  height: 100vh;\n",
    "  display: flex;\n",
    "  flex-direction: column;\n",
    "  background: #fafafa;\n",
    "  font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n",
    "}\n",
    "\n",
    ".chatbot-header {\n",
    "  padding: 1rem;\n",
    "  background: linear-gradient(135deg, #2d5a27 0%, #4a7c43 100%);\n",
    "  color: white;\n",
    "  text-align: center;\n",
    "}\n",
    "\n",
    ".chatbot-header h1 {\n",
    "  margin: 0;\n",
    "  font-size: 1.5rem;\n",
    "}\n",
    "\n",
    ".chatbot-header p {\n",
    "  margin: 0.5rem 0 0;\n",
    "  opacity: 0.9;\n",
    "  font-size: 0.9rem;\n",
    "}\n",
    "\n",
    ".messages-container {\n",
    "  flex: 1;\n",
    "  overflow-y: auto;\n",
    "  padding: 1rem;\n",
    "}\n",
    "\n",
    ".welcome-message {\n",
    "  background: white;\n",
    "  padding: 1.5rem;\n",
    "  border-radius: 12px;\n",
    "  box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "}\n",
    "\n",
    ".welcome-message ul {\n",
    "  margin: 1rem 0 0;\n",
    "  padding-left: 1.5rem;\n",
    "}\n",
    "\n",
    ".welcome-message li {\n",
    "  margin: 0.5rem 0;\n",
    "  color: #2d5a27;\n",
    "  cursor: pointer;\n",
    "}\n",
    "\n",
    ".message {\n",
    "  margin: 0.75rem 0;\n",
    "  display: flex;\n",
    "}\n",
    "\n",
    ".message.user {\n",
    "  justify-content: flex-end;\n",
    "}\n",
    "\n",
    ".message-content {\n",
    "  max-width: 80%;\n",
    "  padding: 0.75rem 1rem;\n",
    "  border-radius: 12px;\n",
    "  line-height: 1.5;\n",
    "  white-space: pre-wrap;\n",
    "}\n",
    "\n",
    ".message.user .message-content {\n",
    "  background: #2d5a27;\n",
    "  color: white;\n",
    "  border-bottom-right-radius: 4px;\n",
    "}\n",
    "\n",
    ".message.assistant .message-content {\n",
    "  background: white;\n",
    "  box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "  border-bottom-left-radius: 4px;\n",
    "}\n",
    "\n",
    ".typing {\n",
    "  display: flex;\n",
    "  gap: 4px;\n",
    "  padding: 1rem;\n",
    "}\n",
    "\n",
    ".typing .dot {\n",
    "  width: 8px;\n",
    "  height: 8px;\n",
    "  background: #2d5a27;\n",
    "  border-radius: 50%;\n",
    "  animation: bounce 1.4s infinite;\n",
    "}\n",
    "\n",
    ".typing .dot:nth-child(2) { animation-delay: 0.2s; }\n",
    ".typing .dot:nth-child(3) { animation-delay: 0.4s; }\n",
    "\n",
    "@keyframes bounce {\n",
    "  0%, 80%, 100% { transform: translateY(0); }\n",
    "  40% { transform: translateY(-6px); }\n",
    "}\n",
    "\n",
    ".input-container {\n",
    "  display: flex;\n",
    "  gap: 0.5rem;\n",
    "  padding: 1rem;\n",
    "  background: white;\n",
    "  border-top: 1px solid #eee;\n",
    "}\n",
    "\n",
    ".input-container textarea {\n",
    "  flex: 1;\n",
    "  padding: 0.75rem 1rem;\n",
    "  border: 1px solid #ddd;\n",
    "  border-radius: 8px;\n",
    "  resize: none;\n",
    "  font-size: 1rem;\n",
    "  font-family: inherit;\n",
    "}\n",
    "\n",
    ".input-container textarea:focus {\n",
    "  outline: none;\n",
    "  border-color: #2d5a27;\n",
    "}\n",
    "\n",
    ".input-container button {\n",
    "  padding: 0.75rem 1.5rem;\n",
    "  background: #2d5a27;\n",
    "  color: white;\n",
    "  border: none;\n",
    "  border-radius: 8px;\n",
    "  cursor: pointer;\n",
    "  font-size: 1rem;\n",
    "  transition: background 0.2s;\n",
    "}\n",
    "\n",
    ".input-container button:hover:not(:disabled) {\n",
    "  background: #3d6a37;\n",
    "}\n",
    "\n",
    ".input-container button:disabled {\n",
    "  opacity: 0.5;\n",
    "  cursor: not-allowed;\n",
    "}\n",
    "\n",
    ".loading-overlay {\n",
    "  position: fixed;\n",
    "  inset: 0;\n",
    "  background: rgba(255,255,255,0.95);\n",
    "  display: flex;\n",
    "  align-items: center;\n",
    "  justify-content: center;\n",
    "  z-index: 100;\n",
    "}\n",
    "\n",
    ".loading-content {\n",
    "  text-align: center;\n",
    "}\n",
    "\n",
    ".loading-spinner {\n",
    "  width: 48px;\n",
    "  height: 48px;\n",
    "  border: 4px solid #eee;\n",
    "  border-top-color: #2d5a27;\n",
    "  border-radius: 50%;\n",
    "  animation: spin 1s linear infinite;\n",
    "  margin: 0 auto 1rem;\n",
    "}\n",
    "\n",
    "@keyframes spin {\n",
    "  to { transform: rotate(360deg); }\n",
    "}\n",
    "\n",
    ".loading-note {\n",
    "  color: #666;\n",
    "  font-size: 0.85rem;\n",
    "  margin-top: 0.5rem;\n",
    "}\n",
    "\n",
    ".progress-bar {\n",
    "  width: 200px;\n",
    "  height: 8px;\n",
    "  background: #eee;\n",
    "  border-radius: 4px;\n",
    "  margin: 1rem auto 0;\n",
    "  overflow: hidden;\n",
    "}\n",
    "\n",
    ".progress-fill {\n",
    "  height: 100%;\n",
    "  background: #2d5a27;\n",
    "  transition: width 0.3s;\n",
    "}\n",
    "\n",
    ".error-banner {\n",
    "  background: #fee;\n",
    "  color: #c00;\n",
    "  padding: 1rem;\n",
    "  display: flex;\n",
    "  align-items: center;\n",
    "  justify-content: space-between;\n",
    "}\n",
    "\n",
    ".chatbot-footer {\n",
    "  padding: 0.5rem;\n",
    "  text-align: center;\n",
    "  font-size: 0.75rem;\n",
    "  color: #999;\n",
    "}\n",
    "'''\n",
    "\n",
    "print(\"üìÑ src/components/MatchaChatbot.css\")\n",
    "print(\"=\"*70)\n",
    "print(chatbot_css[:2000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: App Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/App.jsx\n",
    "\n",
    "app_jsx = '''\n",
    "import { MatchaChatbot } from './components/MatchaChatbot';\n",
    "import './App.css';\n",
    "\n",
    "// Configure your model URL here\n",
    "// This should point to your S3 bucket or Hugging Face model\n",
    "const MODEL_ID = 'https://your-bucket.s3.amazonaws.com/matcha-expert-int4';\n",
    "\n",
    "function App() {\n",
    "  return (\n",
    "    <div className=\"app\">\n",
    "      <MatchaChatbot modelId={MODEL_ID} />\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "\n",
    "export default App;\n",
    "'''\n",
    "\n",
    "print(\"üìÑ src/App.jsx\")\n",
    "print(\"=\"*70)\n",
    "print(app_jsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Deployment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vercel.json - Deployment configuration for Vercel\n",
    "\n",
    "vercel_config = '''\n",
    "{\n",
    "  \"headers\": [\n",
    "    {\n",
    "      \"source\": \"/(.*)\",\n",
    "      \"headers\": [\n",
    "        {\n",
    "          \"key\": \"Cross-Origin-Opener-Policy\",\n",
    "          \"value\": \"same-origin\"\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"Cross-Origin-Embedder-Policy\",\n",
    "          \"value\": \"require-corp\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "'''\n",
    "\n",
    "print(\"üìÑ vercel.json\")\n",
    "print(\"=\"*70)\n",
    "print(vercel_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Browser Compatibility Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browser compatibility checklist\n",
    "\n",
    "compatibility = '''\n",
    "## Browser Compatibility Checklist\n",
    "\n",
    "| Browser | WebGPU | WASM Fallback | Notes |\n",
    "|---------|--------|---------------|-------|\n",
    "| Chrome 113+ | ‚úÖ | ‚úÖ | Best performance |\n",
    "| Edge 113+ | ‚úÖ | ‚úÖ | Same as Chrome |\n",
    "| Safari 17+ | ‚ö†Ô∏è | ‚úÖ | WebGPU in beta |\n",
    "| Firefox | ‚ùå | ‚úÖ | WASM only |\n",
    "| Mobile Chrome | ‚ùå | ‚úÖ | WASM, slower |\n",
    "| Mobile Safari | ‚ùå | ‚ö†Ô∏è | May have issues |\n",
    "\n",
    "## Testing Checklist\n",
    "\n",
    "- [ ] Chrome: Model loads, generates responses\n",
    "- [ ] Edge: Model loads, generates responses\n",
    "- [ ] Safari: Fallback to WASM works\n",
    "- [ ] Firefox: WASM inference works\n",
    "- [ ] Loading progress updates correctly\n",
    "- [ ] Error handling shows user-friendly messages\n",
    "- [ ] Cached model loads instantly on refresh\n",
    "\n",
    "## Performance Benchmarks\n",
    "\n",
    "| Device | Backend | Tokens/sec |\n",
    "|--------|---------|------------|\n",
    "| RTX 4090 | WebGPU | 40-60 |\n",
    "| M1 Mac | WebGPU | 15-25 |\n",
    "| Intel iGPU | WebGPU | 5-15 |\n",
    "| Any CPU | WASM | 1-5 |\n",
    "'''\n",
    "\n",
    "print(compatibility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Issues\n",
    "\n",
    "### Issue 1: SharedArrayBuffer Not Available\n",
    "**Symptom:** Error about SharedArrayBuffer  \n",
    "**Fix:** Add COOP/COEP headers in vite.config.js and vercel.json\n",
    "\n",
    "### Issue 2: Model Download Fails\n",
    "**Symptom:** CORS errors or 404  \n",
    "**Fix:** Check S3 CORS configuration, verify model URL\n",
    "\n",
    "### Issue 3: WebGPU Not Detected\n",
    "**Symptom:** Falls back to WASM even with modern GPU  \n",
    "**Fix:** Update browser, check chrome://flags for WebGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase Complete!\n",
    "\n",
    "You've achieved:\n",
    "- ‚úÖ Created React project with Vite\n",
    "- ‚úÖ Integrated Transformers.js\n",
    "- ‚úÖ Built MatchaChatbot component\n",
    "- ‚úÖ Implemented loading states and streaming\n",
    "- ‚úÖ Added error handling\n",
    "- ‚úÖ Configured for deployment\n",
    "\n",
    "**Next:** [Lab 4.6.8.6: Deployment & Documentation](./lab-4.6.8.6-deployment-documentation.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all component files\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"./matcha-chatbot-template\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save files\n",
    "files = {\n",
    "    \"vite.config.js\": vite_config,\n",
    "    \"src/hooks/useModelLoader.js\": model_loader_hook,\n",
    "    \"src/components/MatchaChatbot.jsx\": chatbot_component,\n",
    "    \"src/components/MatchaChatbot.css\": chatbot_css,\n",
    "    \"src/App.jsx\": app_jsx,\n",
    "    \"vercel.json\": vercel_config,\n",
    "}\n",
    "\n",
    "for filename, content in files.items():\n",
    "    filepath = output_dir / filename\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(content.strip())\n",
    "    print(f\"‚úÖ Saved {filename}\")\n",
    "\n",
    "print(f\"\\nüìÅ All template files saved to {output_dir}\")\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"   1. Copy these files to your React project\")\n",
    "print(\"   2. Update MODEL_ID in App.jsx with your S3 URL\")\n",
    "print(\"   3. Test locally with npm run dev\")\n",
    "print(\"   4. Deploy to Vercel/Netlify\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
