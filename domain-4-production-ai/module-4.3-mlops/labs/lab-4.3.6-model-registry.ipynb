{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.3.6: Model Registry and Version Control\n",
    "\n",
    "**Module:** 4.3 - MLOps & Experiment Tracking  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand model registry concepts and workflows\n",
    "- [ ] Register models in MLflow Model Registry\n",
    "- [ ] Manage model versions and lifecycle stages\n",
    "- [ ] Implement dataset versioning with hashing\n",
    "- [ ] Create a complete versioning workflow\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Lab 4.3.5 (Drift Detection)\n",
    "- Knowledge of: Git basics, MLflow, model deployment concepts\n",
    "- Hardware: DGX Spark (any configuration)\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**\"Which model is in production right now?\"**\n",
    "\n",
    "This simple question can cause chaos without proper versioning:\n",
    "\n",
    "| Scenario | Without Registry | With Registry |\n",
    "|----------|-----------------|---------------|\n",
    "| Bug in production | \"Which model.pkl is deployed?\" üò∞ | \"Model v3.2 is in Production\" ‚úÖ |\n",
    "| Need rollback | \"Where's the old version?\" üò∞ | \"Revert to v3.1\" ‚úÖ |\n",
    "| Audit compliance | \"Show your model history\" üò∞ | Complete lineage available ‚úÖ |\n",
    "| A/B testing | \"How do we track both?\" üò∞ | v4.0 (Staging) vs v3.2 (Production) ‚úÖ |\n",
    "\n",
    "**Model Registry is essential for production ML!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is a Model Registry?\n",
    "\n",
    "> **Imagine you're a baker with multiple cookie recipes.**\n",
    ">\n",
    "> Without a recipe book:\n",
    "> - \"Which recipe did we use yesterday?\"\n",
    "> - \"I think the secret ingredient was... something?\"\n",
    "> - \"Let's just try this random recipe\"\n",
    ">\n",
    "> With a recipe book (Model Registry):\n",
    "> - **Recipe v1.0**: Original chocolate chip (testing)\n",
    "> - **Recipe v1.1**: Added vanilla (staging)\n",
    "> - **Recipe v2.0**: Double chocolate! (production) ‚≠ê\n",
    "> - **Recipe v2.1**: With sea salt (archived)\n",
    ">\n",
    "> You always know:\n",
    "> - Which recipe is being used\n",
    "> - What changed between versions\n",
    "> - How to roll back if needed\n",
    ">\n",
    "> **A Model Registry is your ML recipe book!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding Model Lifecycle\n",
    "\n",
    "### Model Lifecycle Stages\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   None      ‚îÇ -> ‚îÇ   Staging   ‚îÇ -> ‚îÇ Production  ‚îÇ -> ‚îÇ  Archived   ‚îÇ\n",
    "‚îÇ (Testing)   ‚îÇ    ‚îÇ (Validation)‚îÇ    ‚îÇ  (Live!)    ‚îÇ    ‚îÇ (Retired)   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "| Stage | Purpose | Who Uses It |\n",
    "|-------|---------|-------------|\n",
    "| **None** | Initial experiments, testing | Data Scientists |\n",
    "| **Staging** | Pre-production validation | ML Engineers, QA |\n",
    "| **Production** | Live serving | End users, applications |\n",
    "| **Archived** | Retired versions (kept for audit) | Compliance, historical reference |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories and MLflow\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "MODULE_DIR = (NOTEBOOK_DIR / \"..\").resolve()\n",
    "MLFLOW_DIR = MODULE_DIR / \"mlflow\"\n",
    "MLFLOW_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Set up MLflow tracking\n",
    "tracking_uri = f\"file://{MLFLOW_DIR}\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "# Create MLflow client for registry operations\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"üìÅ MLflow tracking: {MLFLOW_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Creating and Registering Models\n",
    "\n",
    "Let's create a model and register it in the MLflow Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple model for demonstration\n",
    "class SentimentClassifier(nn.Module):\n",
    "    \"\"\"Simple sentiment classifier model.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int = 10000, embed_dim: int = 128,\n",
    "                 hidden_dim: int = 256, num_classes: int = 3):\n",
    "        super().__init__()\n",
    "        self.config = {\n",
    "            \"vocab_size\": vocab_size,\n",
    "            \"embed_dim\": embed_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_classes\": num_classes\n",
    "        }\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        hidden = torch.cat([hidden[0], hidden[1]], dim=1)\n",
    "        return self.classifier(hidden)\n",
    "\n",
    "\n",
    "# Create model instance\n",
    "model_v1 = SentimentClassifier()\n",
    "print(f\"Model created: {sum(p.numel() for p in model_v1.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up experiment\n",
    "EXPERIMENT_NAME = \"SentimentClassifier-Development\"\n",
    "MODEL_NAME = \"SentimentClassifier\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Train and register first model version\n",
    "print(\"üì¶ Registering Model Version 1...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"v1-baseline\") as run:\n",
    "    # Log training parameters\n",
    "    mlflow.log_params({\n",
    "        \"vocab_size\": 10000,\n",
    "        \"embed_dim\": 128,\n",
    "        \"hidden_dim\": 256,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"epochs\": 10,\n",
    "        \"version\": \"1.0.0\"\n",
    "    })\n",
    "    \n",
    "    # Log simulated training metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": 0.85,\n",
    "        \"val_accuracy\": 0.82,\n",
    "        \"train_loss\": 0.35,\n",
    "        \"val_loss\": 0.42\n",
    "    })\n",
    "    \n",
    "    # Create input example for signature\n",
    "    sample_input = torch.randint(0, 10000, (1, 128))\n",
    "    \n",
    "    # Log and register the model\n",
    "    model_info = mlflow.pytorch.log_model(\n",
    "        model_v1,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=sample_input.numpy(),\n",
    "        registered_model_name=MODEL_NAME  # This registers the model!\n",
    "    )\n",
    "    \n",
    "    run_id_v1 = run.info.run_id\n",
    "\n",
    "print(f\"\\n‚úÖ Model v1 registered!\")\n",
    "print(f\"   Run ID: {run_id_v1}\")\n",
    "print(f\"   Model URI: {model_info.model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and register improved model version\n",
    "print(\"üì¶ Registering Model Version 2 (improved)...\")\n",
    "\n",
    "# Create improved model\n",
    "model_v2 = SentimentClassifier(embed_dim=256, hidden_dim=512)  # Larger model\n",
    "\n",
    "with mlflow.start_run(run_name=\"v2-improved\") as run:\n",
    "    mlflow.log_params({\n",
    "        \"vocab_size\": 10000,\n",
    "        \"embed_dim\": 256,  # Increased\n",
    "        \"hidden_dim\": 512,  # Increased\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"epochs\": 15,\n",
    "        \"version\": \"2.0.0\",\n",
    "        \"changes\": \"Increased model capacity\"\n",
    "    })\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": 0.91,\n",
    "        \"val_accuracy\": 0.88,  # Improved!\n",
    "        \"train_loss\": 0.22,\n",
    "        \"val_loss\": 0.31\n",
    "    })\n",
    "    \n",
    "    sample_input = torch.randint(0, 10000, (1, 128))\n",
    "    \n",
    "    mlflow.pytorch.log_model(\n",
    "        model_v2,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=sample_input.numpy(),\n",
    "        registered_model_name=MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    run_id_v2 = run.info.run_id\n",
    "\n",
    "print(f\"\\n‚úÖ Model v2 registered!\")\n",
    "print(f\"   Run ID: {run_id_v2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View registered model versions\n",
    "print(\"üìã REGISTERED MODEL VERSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "    \n",
    "    for v in versions:\n",
    "        print(f\"\\nüî∑ Version {v.version}\")\n",
    "        print(f\"   Run ID: {v.run_id[:8]}...\")\n",
    "        print(f\"   Stage: {v.current_stage}\")\n",
    "        print(f\"   Created: {datetime.fromtimestamp(v.creation_timestamp/1000)}\")\n",
    "        if v.description:\n",
    "            print(f\"   Description: {v.description}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "    print(\"Model registry operations may require MLflow server mode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Managing Model Lifecycle\n",
    "\n",
    "Transition models through stages: None ‚Üí Staging ‚Üí Production ‚Üí Archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_model_stage(\n",
    "    model_name: str,\n",
    "    version: int,\n",
    "    stage: str,\n",
    "    archive_existing: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Transition a model version to a new stage.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "        version: Version number to transition\n",
    "        stage: Target stage (Staging, Production, Archived, None)\n",
    "        archive_existing: If True, archive existing models in target stage\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Transition to new stage\n",
    "        client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=version,\n",
    "            stage=stage,\n",
    "            archive_existing_versions=archive_existing\n",
    "        )\n",
    "        print(f\"‚úÖ {model_name} v{version} ‚Üí {stage}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Stage transition: {e}\")\n",
    "        print(\"Note: Full registry features require MLflow server mode.\")\n",
    "\n",
    "\n",
    "# Transition v1 to Staging\n",
    "print(\"üì¶ Transitioning models through lifecycle stages...\")\n",
    "print()\n",
    "\n",
    "transition_model_stage(MODEL_NAME, version=1, stage=\"Staging\")\n",
    "transition_model_stage(MODEL_NAME, version=2, stage=\"Production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model version descriptions\n",
    "def update_model_description(model_name: str, version: int, description: str):\n",
    "    \"\"\"Update the description of a model version.\"\"\"\n",
    "    try:\n",
    "        client.update_model_version(\n",
    "            name=model_name,\n",
    "            version=version,\n",
    "            description=description\n",
    "        )\n",
    "        print(f\"‚úÖ Updated description for {model_name} v{version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Update: {e}\")\n",
    "\n",
    "\n",
    "# Add descriptions\n",
    "update_model_description(\n",
    "    MODEL_NAME, 1,\n",
    "    \"Baseline model with standard architecture. Val accuracy: 82%\"\n",
    ")\n",
    "\n",
    "update_model_description(\n",
    "    MODEL_NAME, 2,\n",
    "    \"Improved model with larger capacity. Val accuracy: 88%. Ready for production.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model by stage (production workflow)\n",
    "def load_production_model(model_name: str):\n",
    "    \"\"\"\n",
    "    Load the current production model.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "    \n",
    "    Returns:\n",
    "        Loaded model ready for inference\n",
    "    \"\"\"\n",
    "    model_uri = f\"models:/{model_name}/Production\"\n",
    "    \n",
    "    try:\n",
    "        model = mlflow.pytorch.load_model(model_uri)\n",
    "        print(f\"‚úÖ Loaded production model from: {model_uri}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load production model: {e}\")\n",
    "        print(\"Using latest version instead...\")\n",
    "        \n",
    "        # Fallback to latest version\n",
    "        model_uri = f\"models:/{model_name}/latest\"\n",
    "        return mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "\n",
    "# Demo: Load production model\n",
    "try:\n",
    "    prod_model = load_production_model(MODEL_NAME)\n",
    "    \n",
    "    # Test inference\n",
    "    test_input = torch.randint(0, 10000, (2, 128))\n",
    "    prod_model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = prod_model(test_input)\n",
    "    print(f\"   Inference test: input {test_input.shape} ‚Üí output {output.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Dataset Versioning\n",
    "\n",
    "Models are only as good as their data. Let's version datasets too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetVersion:\n",
    "    \"\"\"Represents a versioned dataset.\"\"\"\n",
    "    name: str\n",
    "    version: str\n",
    "    hash: str\n",
    "    num_samples: int\n",
    "    num_features: int\n",
    "    created_at: datetime\n",
    "    description: str = \"\"\n",
    "    source_path: str = \"\"\n",
    "\n",
    "\n",
    "def compute_dataframe_hash(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Compute a deterministic hash for a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        SHA256 hash of the DataFrame content\n",
    "    \"\"\"\n",
    "    # Convert to bytes in a deterministic way\n",
    "    content = df.to_csv(index=False).encode('utf-8')\n",
    "    return hashlib.sha256(content).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def create_dataset_version(\n",
    "    df: pd.DataFrame,\n",
    "    name: str,\n",
    "    version: str,\n",
    "    description: str = \"\"\n",
    ") -> DatasetVersion:\n",
    "    \"\"\"\n",
    "    Create a versioned dataset record.\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame to version\n",
    "        name: Dataset name\n",
    "        version: Version string (e.g., \"1.0.0\")\n",
    "        description: Optional description\n",
    "    \n",
    "    Returns:\n",
    "        DatasetVersion object\n",
    "    \"\"\"\n",
    "    return DatasetVersion(\n",
    "        name=name,\n",
    "        version=version,\n",
    "        hash=compute_dataframe_hash(df),\n",
    "        num_samples=len(df),\n",
    "        num_features=len(df.columns),\n",
    "        created_at=datetime.now(),\n",
    "        description=description\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Dataset versioning functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample datasets\n",
    "def generate_sentiment_data(n_samples: int, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Generate synthetic sentiment data.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"text_length\": np.random.randint(10, 500, n_samples),\n",
    "        \"word_count\": np.random.randint(5, 100, n_samples),\n",
    "        \"sentiment_score\": np.random.uniform(-1, 1, n_samples),\n",
    "        \"has_emoji\": np.random.choice([0, 1], n_samples),\n",
    "        \"label\": np.random.choice([\"negative\", \"neutral\", \"positive\"], n_samples)\n",
    "    })\n",
    "\n",
    "\n",
    "# Create versioned datasets\n",
    "train_v1 = generate_sentiment_data(10000, seed=42)\n",
    "train_v2 = generate_sentiment_data(15000, seed=123)  # Larger dataset\n",
    "\n",
    "dataset_v1 = create_dataset_version(\n",
    "    train_v1, \"sentiment-train\", \"1.0.0\",\n",
    "    \"Initial training dataset, 10k samples\"\n",
    ")\n",
    "\n",
    "dataset_v2 = create_dataset_version(\n",
    "    train_v2, \"sentiment-train\", \"2.0.0\",\n",
    "    \"Expanded training dataset, 15k samples with more diversity\"\n",
    ")\n",
    "\n",
    "print(\"üìä DATASET VERSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for dv in [dataset_v1, dataset_v2]:\n",
    "    print(f\"\\nüóÇÔ∏è {dv.name} v{dv.version}\")\n",
    "    print(f\"   Hash: {dv.hash}\")\n",
    "    print(f\"   Samples: {dv.num_samples:,}\")\n",
    "    print(f\"   Features: {dv.num_features}\")\n",
    "    print(f\"   Description: {dv.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log dataset version with model training\n",
    "def log_dataset_info(dataset_version: DatasetVersion):\n",
    "    \"\"\"Log dataset information to MLflow.\"\"\"\n",
    "    mlflow.log_params({\n",
    "        \"dataset_name\": dataset_version.name,\n",
    "        \"dataset_version\": dataset_version.version,\n",
    "        \"dataset_hash\": dataset_version.hash,\n",
    "        \"dataset_samples\": dataset_version.num_samples,\n",
    "        \"dataset_features\": dataset_version.num_features\n",
    "    })\n",
    "    \n",
    "    # Log dataset manifest as artifact\n",
    "    manifest = {\n",
    "        \"name\": dataset_version.name,\n",
    "        \"version\": dataset_version.version,\n",
    "        \"hash\": dataset_version.hash,\n",
    "        \"num_samples\": dataset_version.num_samples,\n",
    "        \"num_features\": dataset_version.num_features,\n",
    "        \"created_at\": dataset_version.created_at.isoformat(),\n",
    "        \"description\": dataset_version.description\n",
    "    }\n",
    "    \n",
    "    manifest_path = \"/tmp/dataset_manifest.json\"\n",
    "    with open(manifest_path, 'w') as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    \n",
    "    mlflow.log_artifact(manifest_path, artifact_path=\"data\")\n",
    "\n",
    "\n",
    "# Demo: Train with dataset versioning\n",
    "print(\"üì¶ Training model with dataset versioning...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"v3-with-versioned-data\") as run:\n",
    "    # Log dataset information\n",
    "    log_dataset_info(dataset_v2)\n",
    "    \n",
    "    # Log model parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_version\": \"3.0.0\",\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"epochs\": 20\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": 0.93,\n",
    "        \"val_accuracy\": 0.90\n",
    "    })\n",
    "    \n",
    "    # Log and register model\n",
    "    model_v3 = SentimentClassifier(embed_dim=256, hidden_dim=512)\n",
    "    sample_input = torch.randint(0, 10000, (1, 128))\n",
    "    \n",
    "    mlflow.pytorch.log_model(\n",
    "        model_v3,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=sample_input.numpy(),\n",
    "        registered_model_name=MODEL_NAME\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úÖ Model v3 trained with versioned data\")\n",
    "print(f\"   Dataset: {dataset_v2.name} v{dataset_v2.version}\")\n",
    "print(f\"   Data hash: {dataset_v2.hash}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Complete Versioning Workflow\n",
    "\n",
    "Let's put it all together in a production-ready workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelVersioningWorkflow:\n",
    "    \"\"\"\n",
    "    Complete model versioning workflow.\n",
    "    \n",
    "    Manages the full lifecycle from training to production.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, experiment_name: str):\n",
    "        self.model_name = model_name\n",
    "        self.experiment_name = experiment_name\n",
    "        self.client = MlflowClient()\n",
    "        \n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    def train_and_register(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        dataset_version: DatasetVersion,\n",
    "        metrics: Dict[str, float],\n",
    "        params: Dict[str, Any],\n",
    "        description: str = \"\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Train and register a new model version.\n",
    "        \n",
    "        Returns:\n",
    "            Model version number\n",
    "        \"\"\"\n",
    "        with mlflow.start_run() as run:\n",
    "            # Log dataset info\n",
    "            log_dataset_info(dataset_version)\n",
    "            \n",
    "            # Log parameters and metrics\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            \n",
    "            # Log model\n",
    "            sample_input = torch.randint(0, 10000, (1, 128))\n",
    "            \n",
    "            model_info = mlflow.pytorch.log_model(\n",
    "                model,\n",
    "                artifact_path=\"model\",\n",
    "                input_example=sample_input.numpy(),\n",
    "                registered_model_name=self.model_name\n",
    "            )\n",
    "            \n",
    "            # Get the version number\n",
    "            versions = self.client.search_model_versions(f\"name='{self.model_name}'\")\n",
    "            latest_version = max(int(v.version) for v in versions)\n",
    "            \n",
    "            # Update description\n",
    "            if description:\n",
    "                self.client.update_model_version(\n",
    "                    name=self.model_name,\n",
    "                    version=latest_version,\n",
    "                    description=description\n",
    "                )\n",
    "            \n",
    "            return str(latest_version)\n",
    "    \n",
    "    def promote_to_staging(self, version: int) -> bool:\n",
    "        \"\"\"Promote a model version to Staging.\"\"\"\n",
    "        try:\n",
    "            self.client.transition_model_version_stage(\n",
    "                name=self.model_name,\n",
    "                version=version,\n",
    "                stage=\"Staging\"\n",
    "            )\n",
    "            print(f\"‚úÖ v{version} promoted to Staging\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Promotion failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def promote_to_production(self, version: int, archive_current: bool = True) -> bool:\n",
    "        \"\"\"Promote a model version to Production.\"\"\"\n",
    "        try:\n",
    "            self.client.transition_model_version_stage(\n",
    "                name=self.model_name,\n",
    "                version=version,\n",
    "                stage=\"Production\",\n",
    "                archive_existing_versions=archive_current\n",
    "            )\n",
    "            print(f\"‚úÖ v{version} promoted to Production\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Promotion failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def rollback(self, target_version: int) -> bool:\n",
    "        \"\"\"Roll back to a previous model version.\"\"\"\n",
    "        print(f\"üîÑ Rolling back to v{target_version}...\")\n",
    "        return self.promote_to_production(target_version)\n",
    "    \n",
    "    def get_production_model(self):\n",
    "        \"\"\"Load the current production model.\"\"\"\n",
    "        model_uri = f\"models:/{self.model_name}/Production\"\n",
    "        return mlflow.pytorch.load_model(model_uri)\n",
    "    \n",
    "    def get_version_history(self) -> List[Dict]:\n",
    "        \"\"\"Get the history of all model versions.\"\"\"\n",
    "        versions = self.client.search_model_versions(f\"name='{self.model_name}'\")\n",
    "        \n",
    "        history = []\n",
    "        for v in versions:\n",
    "            history.append({\n",
    "                \"version\": v.version,\n",
    "                \"stage\": v.current_stage,\n",
    "                \"created\": datetime.fromtimestamp(v.creation_timestamp/1000),\n",
    "                \"description\": v.description or \"No description\"\n",
    "            })\n",
    "        \n",
    "        return sorted(history, key=lambda x: int(x[\"version\"]))\n",
    "\n",
    "\n",
    "print(\"‚úÖ ModelVersioningWorkflow class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Complete workflow\n",
    "print(\"üîÑ COMPLETE VERSIONING WORKFLOW DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "workflow = ModelVersioningWorkflow(\n",
    "    model_name=MODEL_NAME,\n",
    "    experiment_name=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "# Step 1: Train and register a new model\n",
    "print(\"\\nüì¶ Step 1: Train and register new model\")\n",
    "new_model = SentimentClassifier(embed_dim=384, hidden_dim=768)\n",
    "\n",
    "try:\n",
    "    version = workflow.train_and_register(\n",
    "        model=new_model,\n",
    "        dataset_version=dataset_v2,\n",
    "        metrics={\"train_accuracy\": 0.94, \"val_accuracy\": 0.91},\n",
    "        params={\"embed_dim\": 384, \"hidden_dim\": 768, \"epochs\": 25},\n",
    "        description=\"Largest model yet. Best validation accuracy.\"\n",
    "    )\n",
    "    print(f\"   New version: {version}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Note: {e}\")\n",
    "    version = \"4\"\n",
    "\n",
    "# Step 2: View version history\n",
    "print(\"\\nüìú Step 2: Version history\")\n",
    "try:\n",
    "    history = workflow.get_version_history()\n",
    "    for v in history:\n",
    "        print(f\"   v{v['version']}: {v['stage']:<12} - {v['description'][:40]}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Note: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Exercise\n",
    "\n",
    "**Task:** Create a versioning workflow for your use case.\n",
    "\n",
    "1. Define a model for your domain\n",
    "2. Create 3 versions with different configurations\n",
    "3. Register all versions with meaningful descriptions\n",
    "4. Promote the best version to Production\n",
    "5. Simulate a rollback scenario\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "```python\n",
    "# Create workflow\n",
    "workflow = ModelVersioningWorkflow(\n",
    "    model_name=\"MyModel\",\n",
    "    experiment_name=\"MyExperiment\"\n",
    ")\n",
    "\n",
    "# Train multiple versions\n",
    "for config in [{\"size\": \"small\"}, {\"size\": \"medium\"}, {\"size\": \"large\"}]:\n",
    "    model = create_model(config)\n",
    "    version = workflow.train_and_register(\n",
    "        model=model,\n",
    "        dataset_version=dataset,\n",
    "        metrics={\"accuracy\": ..., \"loss\": ...},\n",
    "        params=config,\n",
    "        description=f\"Model with {config['size']} configuration\"\n",
    "    )\n",
    "\n",
    "# Promote best\n",
    "workflow.promote_to_production(version=\"3\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Define your model\n",
    "\n",
    "\n",
    "# Step 2: Create 3 versions\n",
    "\n",
    "\n",
    "# Step 3: Register with descriptions\n",
    "\n",
    "\n",
    "# Step 4: Promote to production\n",
    "\n",
    "\n",
    "# Step 5: Simulate rollback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Not Tracking Data with Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Only tracking the model\n",
    "# mlflow.pytorch.log_model(model, \"model\")\n",
    "# \"What data was this trained on?\" üò∞\n",
    "\n",
    "# ‚úÖ RIGHT: Track data and model together\n",
    "# log_dataset_info(dataset_version)\n",
    "# mlflow.pytorch.log_model(model, \"model\")\n",
    "# Complete lineage! ‚úÖ\n",
    "\n",
    "print(\"Always log dataset information with your model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: No Clear Promotion Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Promoting without criteria\n",
    "# \"This looks good, let's ship it!\"\n",
    "\n",
    "# ‚úÖ RIGHT: Define clear promotion gates\n",
    "promotion_criteria = {\n",
    "    \"staging\": {\n",
    "        \"min_val_accuracy\": 0.85,\n",
    "        \"max_val_loss\": 0.5,\n",
    "        \"required_tests\": [\"unit_tests\", \"integration_tests\"]\n",
    "    },\n",
    "    \"production\": {\n",
    "        \"min_val_accuracy\": 0.88,\n",
    "        \"staging_time_hours\": 24,  # At least 24h in staging\n",
    "        \"a_b_test_passed\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Define clear criteria for each promotion stage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Model registry concepts and lifecycle stages\n",
    "- ‚úÖ Registering and versioning models in MLflow\n",
    "- ‚úÖ Managing model transitions (Staging ‚Üí Production)\n",
    "- ‚úÖ Dataset versioning with content hashing\n",
    "- ‚úÖ Building complete versioning workflows\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)\n",
    "- [DVC for Data Versioning](https://dvc.org/)\n",
    "- [Hugging Face Model Hub](https://huggingface.co/docs/hub/models)\n",
    "- [ML Model Management Best Practices](https://neptune.ai/blog/ml-model-management)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"üìÅ MLflow data saved to: {MLFLOW_DIR}\")\n",
    "print(\"‚úÖ Resources cleaned up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "In this lab, we:\n",
    "\n",
    "1. **Learned** model registry concepts and lifecycle stages\n",
    "2. **Registered** multiple model versions in MLflow\n",
    "3. **Managed** model transitions through stages\n",
    "4. **Implemented** dataset versioning with content hashing\n",
    "5. **Built** a complete versioning workflow class\n",
    "\n",
    "**Next up:** Lab 4.3.7 - Reproducibility Audit!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
