{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.3.7: Reproducibility Audit\n",
    "\n",
    "**Module:** 4.3 - MLOps & Experiment Tracking  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand why reproducibility matters in ML\n",
    "- [ ] Implement proper random seed management\n",
    "- [ ] Capture and recreate training environments\n",
    "- [ ] Verify training reproducibility systematically\n",
    "- [ ] Create reproducibility audit reports\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Lab 4.3.6 (Model Registry)\n",
    "- Knowledge of: Python, PyTorch, environment management\n",
    "- Hardware: DGX Spark (128GB unified memory)\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**\"I can't reproduce last week's results!\"**\n",
    "\n",
    "This nightmare scenario happens more often than you'd think:\n",
    "\n",
    "| Issue | Consequence |\n",
    "|-------|-------------|\n",
    "| Different random seeds | Results vary by 2-5% |\n",
    "| Library version mismatch | Model doesn't load |\n",
    "| Missing preprocessing steps | Wrong predictions |\n",
    "| GPU non-determinism | Slight metric differences |\n",
    "| Data leakage in splits | Inflated test scores |\n",
    "\n",
    "**Reproducibility Crisis in ML:**\n",
    "- NeurIPS 2019: Only 50% of papers had reproducible code\n",
    "- Pharmaceutical AI: FDA requires reproducible models\n",
    "- Self-driving cars: Regulatory audits need exact reproduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is Reproducibility?\n",
    "\n",
    "> **Imagine you're a scientist making a volcano for the science fair.**\n",
    ">\n",
    "> **Not reproducible:**\n",
    "> - \"I added some baking soda and... stuff\"\n",
    "> - \"It worked yesterday, I swear!\"\n",
    "> - \"Maybe try more vinegar?\"\n",
    ">\n",
    "> **Reproducible:**\n",
    "> - \"Add exactly 2 tablespoons of baking soda\"\n",
    "> - \"Pour 50ml of white vinegar\"\n",
    "> - \"Wait 3 seconds\"\n",
    "> - \"BOOM! Works every time!\"\n",
    ">\n",
    "> **In ML, reproducibility means:**\n",
    "> - Same code + same data + same settings = same results\n",
    "> - Every time\n",
    "> - On any machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Reproducibility Checklist\n",
    "\n",
    "### What Affects Reproducibility?\n",
    "\n",
    "| Factor | Example | Impact |\n",
    "|--------|---------|--------|\n",
    "| **Random seeds** | numpy, torch, python | High - different initialization |\n",
    "| **Library versions** | torch 2.0 vs 2.1 | Medium - API changes |\n",
    "| **Hardware** | GPU model, CUDA version | Low-Medium - floating point |\n",
    "| **Data ordering** | Shuffle state | High - different batches |\n",
    "| **Environment** | Python version, OS | Low - usually compatible |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "import platform\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "MODULE_DIR = (NOTEBOOK_DIR / \"..\").resolve()\n",
    "AUDIT_DIR = MODULE_DIR / \"evaluation\" / \"reproducibility\"\n",
    "AUDIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Audit reports will be saved to: {AUDIT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Random Seed Management\n",
    "\n",
    "The foundation of reproducibility is proper random seed management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42, deterministic: bool = True):\n",
    "    \"\"\"\n",
    "    Set random seeds for all libraries to ensure reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed: The random seed to use\n",
    "        deterministic: If True, use deterministic algorithms (may be slower)\n",
    "    \n",
    "    Returns:\n",
    "        dict: The seed state for verification\n",
    "    \"\"\"\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # PyTorch CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    \n",
    "    # Deterministic algorithms\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        # PyTorch 2.0+ deterministic mode\n",
    "        if hasattr(torch, 'use_deterministic_algorithms'):\n",
    "            try:\n",
    "                torch.use_deterministic_algorithms(True)\n",
    "            except Exception:\n",
    "                pass  # Some ops don't have deterministic implementations\n",
    "    \n",
    "    # Environment variable for CUDA\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'deterministic': deterministic,\n",
    "        'python_hash_seed': os.environ.get('PYTHONHASHSEED')\n",
    "    }\n",
    "\n",
    "\n",
    "def get_seed_state() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Capture the current random state of all generators.\n",
    "    \n",
    "    Returns:\n",
    "        dict: States that can be used to restore randomness\n",
    "    \"\"\"\n",
    "    state = {\n",
    "        'python_state': random.getstate(),\n",
    "        'numpy_state': np.random.get_state(),\n",
    "        'torch_state': torch.get_rng_state(),\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        state['cuda_state'] = torch.cuda.get_rng_state_all()\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def set_seed_state(state: Dict[str, Any]):\n",
    "    \"\"\"Restore random state from a captured state dict.\"\"\"\n",
    "    random.setstate(state['python_state'])\n",
    "    np.random.set_state(state['numpy_state'])\n",
    "    torch.set_rng_state(state['torch_state'])\n",
    "    \n",
    "    if 'cuda_state' in state and torch.cuda.is_available():\n",
    "        torch.cuda.set_rng_state_all(state['cuda_state'])\n",
    "\n",
    "\n",
    "print(\"‚úÖ Seed management functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Verify seed setting works\n",
    "print(\"üî¨ Testing Seed Reproducibility\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Same seed = same results\n",
    "set_seed(42)\n",
    "result1 = {\n",
    "    'python': random.random(),\n",
    "    'numpy': np.random.rand(),\n",
    "    'torch': torch.rand(1).item()\n",
    "}\n",
    "\n",
    "set_seed(42)  # Reset with same seed\n",
    "result2 = {\n",
    "    'python': random.random(),\n",
    "    'numpy': np.random.rand(),\n",
    "    'torch': torch.rand(1).item()\n",
    "}\n",
    "\n",
    "print(\"\\nWith same seed (42):\")\n",
    "for key in result1:\n",
    "    match = \"‚úÖ\" if result1[key] == result2[key] else \"‚ùå\"\n",
    "    print(f\"   {key}: {result1[key]:.6f} vs {result2[key]:.6f} {match}\")\n",
    "\n",
    "# Test 2: Different seed = different results\n",
    "set_seed(123)\n",
    "result3 = {\n",
    "    'python': random.random(),\n",
    "    'numpy': np.random.rand(),\n",
    "    'torch': torch.rand(1).item()\n",
    "}\n",
    "\n",
    "print(\"\\nWith different seed (123):\")\n",
    "for key in result1:\n",
    "    different = \"‚úÖ (different)\" if result1[key] != result3[key] else \"‚ùå (same!)\"\n",
    "    print(f\"   {key}: {result1[key]:.6f} vs {result3[key]:.6f} {different}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Environment Capture\n",
    "\n",
    "Capture everything about the training environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EnvironmentSnapshot:\n",
    "    \"\"\"Complete snapshot of the training environment.\"\"\"\n",
    "    \n",
    "    # System info\n",
    "    python_version: str\n",
    "    os_name: str\n",
    "    os_version: str\n",
    "    platform: str\n",
    "    \n",
    "    # Hardware\n",
    "    cpu_count: int\n",
    "    gpu_available: bool\n",
    "    gpu_name: str\n",
    "    gpu_count: int\n",
    "    cuda_version: str\n",
    "    \n",
    "    # Library versions\n",
    "    torch_version: str\n",
    "    numpy_version: str\n",
    "    python_packages: Dict[str, str]\n",
    "    \n",
    "    # Timestamp\n",
    "    captured_at: str\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return asdict(self)\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "\n",
    "\n",
    "def capture_environment() -> EnvironmentSnapshot:\n",
    "    \"\"\"\n",
    "    Capture complete environment snapshot.\n",
    "    \n",
    "    Returns:\n",
    "        EnvironmentSnapshot with all environment details\n",
    "    \"\"\"\n",
    "    # Get installed packages\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, '-m', 'pip', 'freeze'],\n",
    "            capture_output=True, text=True, timeout=30\n",
    "        )\n",
    "        packages = {}\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            if '==' in line:\n",
    "                name, version = line.split('==')\n",
    "                packages[name] = version\n",
    "    except Exception:\n",
    "        packages = {}\n",
    "    \n",
    "    # GPU info\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    gpu_name = torch.cuda.get_device_name(0) if gpu_available else \"N/A\"\n",
    "    gpu_count = torch.cuda.device_count() if gpu_available else 0\n",
    "    cuda_version = torch.version.cuda if gpu_available else \"N/A\"\n",
    "    \n",
    "    return EnvironmentSnapshot(\n",
    "        python_version=sys.version.split()[0],\n",
    "        os_name=platform.system(),\n",
    "        os_version=platform.release(),\n",
    "        platform=platform.platform(),\n",
    "        cpu_count=os.cpu_count() or 0,\n",
    "        gpu_available=gpu_available,\n",
    "        gpu_name=gpu_name,\n",
    "        gpu_count=gpu_count,\n",
    "        cuda_version=cuda_version,\n",
    "        torch_version=torch.__version__,\n",
    "        numpy_version=np.__version__,\n",
    "        python_packages=packages,\n",
    "        captured_at=datetime.now().isoformat()\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Environment capture functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture current environment\n",
    "env_snapshot = capture_environment()\n",
    "\n",
    "print(\"üì∏ ENVIRONMENT SNAPSHOT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüñ•Ô∏è System:\")\n",
    "print(f\"   Python: {env_snapshot.python_version}\")\n",
    "print(f\"   OS: {env_snapshot.os_name} {env_snapshot.os_version}\")\n",
    "print(f\"   Platform: {env_snapshot.platform}\")\n",
    "print(f\"   CPU cores: {env_snapshot.cpu_count}\")\n",
    "\n",
    "print(f\"\\nüéÆ GPU:\")\n",
    "print(f\"   Available: {env_snapshot.gpu_available}\")\n",
    "print(f\"   Name: {env_snapshot.gpu_name}\")\n",
    "print(f\"   Count: {env_snapshot.gpu_count}\")\n",
    "print(f\"   CUDA: {env_snapshot.cuda_version}\")\n",
    "\n",
    "print(f\"\\nüì¶ Key Libraries:\")\n",
    "print(f\"   PyTorch: {env_snapshot.torch_version}\")\n",
    "print(f\"   NumPy: {env_snapshot.numpy_version}\")\n",
    "print(f\"   Total packages: {len(env_snapshot.python_packages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save environment snapshot\n",
    "env_file = AUDIT_DIR / \"environment_snapshot.json\"\n",
    "with open(env_file, 'w') as f:\n",
    "    f.write(env_snapshot.to_json())\n",
    "\n",
    "print(f\"üíæ Environment saved to: {env_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Reproducibility Verification\n",
    "\n",
    "Actually verify that training is reproducible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple model for testing\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim: int = 10, hidden_dim: int = 32, output_dim: int = 2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, data, targets, criterion):\n",
    "    \"\"\"Train for one epoch and return loss.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def get_model_hash(model: nn.Module) -> str:\n",
    "    \"\"\"Compute hash of model weights for comparison.\"\"\"\n",
    "    hasher = hashlib.sha256()\n",
    "    for param in model.parameters():\n",
    "        hasher.update(param.data.cpu().numpy().tobytes())\n",
    "    return hasher.hexdigest()[:16]\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReproducibilityResult:\n",
    "    \"\"\"Result of a reproducibility test.\"\"\"\n",
    "    is_reproducible: bool\n",
    "    seed: int\n",
    "    run1_losses: List[float]\n",
    "    run2_losses: List[float]\n",
    "    run1_model_hash: str\n",
    "    run2_model_hash: str\n",
    "    max_loss_difference: float\n",
    "    weights_match: bool\n",
    "    timestamp: str\n",
    "\n",
    "\n",
    "def verify_reproducibility(\n",
    "    seed: int = 42,\n",
    "    epochs: int = 5,\n",
    "    tolerance: float = 1e-6\n",
    ") -> ReproducibilityResult:\n",
    "    \"\"\"\n",
    "    Verify that training is reproducible with the same seed.\n",
    "    \n",
    "    Args:\n",
    "        seed: Random seed to use\n",
    "        epochs: Number of training epochs\n",
    "        tolerance: Maximum allowed difference in losses\n",
    "    \n",
    "    Returns:\n",
    "        ReproducibilityResult with detailed comparison\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # First run\n",
    "    set_seed(seed)\n",
    "    model1 = SimpleModel().to(device)\n",
    "    optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Generate data with seed\n",
    "    data = torch.randn(100, 10).to(device)\n",
    "    targets = torch.randint(0, 2, (100,)).to(device)\n",
    "    \n",
    "    losses1 = []\n",
    "    for _ in range(epochs):\n",
    "        loss = train_epoch(model1, optimizer1, data, targets, criterion)\n",
    "        losses1.append(loss)\n",
    "    \n",
    "    hash1 = get_model_hash(model1)\n",
    "    \n",
    "    # Second run (reset everything)\n",
    "    set_seed(seed)\n",
    "    model2 = SimpleModel().to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "    \n",
    "    # Regenerate data with same seed\n",
    "    data = torch.randn(100, 10).to(device)\n",
    "    targets = torch.randint(0, 2, (100,)).to(device)\n",
    "    \n",
    "    losses2 = []\n",
    "    for _ in range(epochs):\n",
    "        loss = train_epoch(model2, optimizer2, data, targets, criterion)\n",
    "        losses2.append(loss)\n",
    "    \n",
    "    hash2 = get_model_hash(model2)\n",
    "    \n",
    "    # Compare\n",
    "    max_diff = max(abs(l1 - l2) for l1, l2 in zip(losses1, losses2))\n",
    "    weights_match = hash1 == hash2\n",
    "    is_reproducible = max_diff < tolerance and weights_match\n",
    "    \n",
    "    return ReproducibilityResult(\n",
    "        is_reproducible=is_reproducible,\n",
    "        seed=seed,\n",
    "        run1_losses=losses1,\n",
    "        run2_losses=losses2,\n",
    "        run1_model_hash=hash1,\n",
    "        run2_model_hash=hash2,\n",
    "        max_loss_difference=max_diff,\n",
    "        weights_match=weights_match,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Reproducibility verification function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run reproducibility test\n",
    "print(\"üî¨ REPRODUCIBILITY VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = verify_reproducibility(seed=42, epochs=5)\n",
    "\n",
    "status = \"‚úÖ REPRODUCIBLE\" if result.is_reproducible else \"‚ùå NOT REPRODUCIBLE\"\n",
    "print(f\"\\nResult: {status}\")\n",
    "print(f\"\\nDetails:\")\n",
    "print(f\"   Seed: {result.seed}\")\n",
    "print(f\"   Weights match: {result.weights_match}\")\n",
    "print(f\"   Max loss difference: {result.max_loss_difference:.2e}\")\n",
    "\n",
    "print(f\"\\nüìä Loss Comparison:\")\n",
    "print(f\"   {'Epoch':<8} {'Run 1':<12} {'Run 2':<12} {'Diff':<12}\")\n",
    "print(f\"   {'-'*44}\")\n",
    "for i, (l1, l2) in enumerate(zip(result.run1_losses, result.run2_losses)):\n",
    "    diff = abs(l1 - l2)\n",
    "    match = \"‚úì\" if diff < 1e-6 else \"‚úó\"\n",
    "    print(f\"   {i+1:<8} {l1:<12.6f} {l2:<12.6f} {diff:<12.2e} {match}\")\n",
    "\n",
    "print(f\"\\nüîë Model Hashes:\")\n",
    "print(f\"   Run 1: {result.run1_model_hash}\")\n",
    "print(f\"   Run 2: {result.run2_model_hash}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Comprehensive Reproducibility Audit\n",
    "\n",
    "Create a complete audit report for compliance and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AuditResult:\n",
    "    \"\"\"Complete reproducibility audit result.\"\"\"\n",
    "    \n",
    "    # Summary\n",
    "    passed: bool\n",
    "    audit_id: str\n",
    "    timestamp: str\n",
    "    \n",
    "    # Components\n",
    "    environment: EnvironmentSnapshot\n",
    "    reproducibility: ReproducibilityResult\n",
    "    seed_config: Dict[str, Any]\n",
    "    \n",
    "    # Data verification\n",
    "    data_hash: str\n",
    "    \n",
    "    # Checks passed\n",
    "    checks: Dict[str, bool]\n",
    "    \n",
    "    def to_report(self) -> str:\n",
    "        \"\"\"Generate a human-readable audit report.\"\"\"\n",
    "        status = \"PASSED\" if self.passed else \"FAILED\"\n",
    "        \n",
    "        report = f\"\"\"\n",
    "{'='*70}\n",
    "                    REPRODUCIBILITY AUDIT REPORT\n",
    "{'='*70}\n",
    "\n",
    "Audit ID: {self.audit_id}\n",
    "Date: {self.timestamp}\n",
    "Status: {status}\n",
    "\n",
    "{'-'*70}\n",
    "ENVIRONMENT\n",
    "{'-'*70}\n",
    "Python Version: {self.environment.python_version}\n",
    "PyTorch Version: {self.environment.torch_version}\n",
    "CUDA Version: {self.environment.cuda_version}\n",
    "GPU: {self.environment.gpu_name}\n",
    "Platform: {self.environment.platform}\n",
    "\n",
    "{'-'*70}\n",
    "REPRODUCIBILITY VERIFICATION\n",
    "{'-'*70}\n",
    "Seed Used: {self.reproducibility.seed}\n",
    "Weights Match: {self.reproducibility.weights_match}\n",
    "Max Loss Difference: {self.reproducibility.max_loss_difference:.2e}\n",
    "Training Reproducible: {self.reproducibility.is_reproducible}\n",
    "\n",
    "{'-'*70}\n",
    "CHECKS\n",
    "{'-'*70}\n",
    "\"\"\"\n",
    "        for check, passed in self.checks.items():\n",
    "            status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n",
    "            report += f\"{check}: {status}\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "{'-'*70}\n",
    "DATA\n",
    "{'-'*70}\n",
    "Data Hash: {self.data_hash}\n",
    "\n",
    "{'='*70}\n",
    "                           END OF REPORT\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "        return report\n",
    "\n",
    "\n",
    "def run_full_audit(seed: int = 42) -> AuditResult:\n",
    "    \"\"\"\n",
    "    Run a complete reproducibility audit.\n",
    "    \n",
    "    Args:\n",
    "        seed: Random seed to use for testing\n",
    "    \n",
    "    Returns:\n",
    "        AuditResult with complete audit information\n",
    "    \"\"\"\n",
    "    audit_id = f\"AUDIT-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    \n",
    "    # Capture environment\n",
    "    env = capture_environment()\n",
    "    \n",
    "    # Set seed and get config\n",
    "    seed_config = set_seed(seed)\n",
    "    \n",
    "    # Run reproducibility verification\n",
    "    repro_result = verify_reproducibility(seed=seed)\n",
    "    \n",
    "    # Generate sample data hash\n",
    "    set_seed(seed)\n",
    "    sample_data = torch.randn(100, 10)\n",
    "    data_hash = hashlib.sha256(sample_data.numpy().tobytes()).hexdigest()[:16]\n",
    "    \n",
    "    # Run all checks\n",
    "    checks = {\n",
    "        \"Python seed set\": True,\n",
    "        \"NumPy seed set\": True,\n",
    "        \"PyTorch seed set\": True,\n",
    "        \"CUDA deterministic\": torch.backends.cudnn.deterministic if torch.cuda.is_available() else True,\n",
    "        \"Training reproducible\": repro_result.is_reproducible,\n",
    "        \"Weights match\": repro_result.weights_match,\n",
    "        \"Environment captured\": env is not None,\n",
    "        \"Data hash computed\": len(data_hash) == 16\n",
    "    }\n",
    "    \n",
    "    all_passed = all(checks.values())\n",
    "    \n",
    "    return AuditResult(\n",
    "        passed=all_passed,\n",
    "        audit_id=audit_id,\n",
    "        timestamp=datetime.now().isoformat(),\n",
    "        environment=env,\n",
    "        reproducibility=repro_result,\n",
    "        seed_config=seed_config,\n",
    "        data_hash=data_hash,\n",
    "        checks=checks\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Full audit function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full audit\n",
    "print(\"üîç Running Full Reproducibility Audit...\")\n",
    "print()\n",
    "\n",
    "audit = run_full_audit(seed=42)\n",
    "\n",
    "# Print the report\n",
    "print(audit.to_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save audit report\n",
    "report_file = AUDIT_DIR / f\"{audit.audit_id}.txt\"\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(audit.to_report())\n",
    "\n",
    "# Save JSON for programmatic access\n",
    "json_file = AUDIT_DIR / f\"{audit.audit_id}.json\"\n",
    "audit_dict = {\n",
    "    \"passed\": audit.passed,\n",
    "    \"audit_id\": audit.audit_id,\n",
    "    \"timestamp\": audit.timestamp,\n",
    "    \"seed_config\": audit.seed_config,\n",
    "    \"data_hash\": audit.data_hash,\n",
    "    \"checks\": audit.checks,\n",
    "    \"environment\": audit.environment.to_dict(),\n",
    "    \"reproducibility\": {\n",
    "        \"is_reproducible\": audit.reproducibility.is_reproducible,\n",
    "        \"seed\": audit.reproducibility.seed,\n",
    "        \"weights_match\": audit.reproducibility.weights_match,\n",
    "        \"max_loss_difference\": audit.reproducibility.max_loss_difference\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(audit_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Audit saved to:\")\n",
    "print(f\"   Report: {report_file}\")\n",
    "print(f\"   JSON: {json_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: DataLoader Reproducibility\n",
    "\n",
    "DataLoader shuffling needs special handling for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def worker_init_fn(worker_id: int):\n",
    "    \"\"\"\n",
    "    Initialize each DataLoader worker with a unique seed.\n",
    "    \n",
    "    This ensures reproducibility across workers.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def create_reproducible_dataloader(\n",
    "    data: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    batch_size: int = 32,\n",
    "    shuffle: bool = True,\n",
    "    seed: int = 42\n",
    ") -> DataLoader:\n",
    "    \"\"\"\n",
    "    Create a DataLoader with reproducible shuffling.\n",
    "    \n",
    "    Args:\n",
    "        data: Input data tensor\n",
    "        targets: Target tensor\n",
    "        batch_size: Batch size\n",
    "        shuffle: Whether to shuffle\n",
    "        seed: Random seed for shuffling\n",
    "    \n",
    "    Returns:\n",
    "        Reproducible DataLoader\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(data, targets)\n",
    "    \n",
    "    # Create a generator with fixed seed for shuffling\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(seed)\n",
    "    \n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        generator=generator,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "        num_workers=0  # Use 0 for maximum reproducibility\n",
    "    )\n",
    "\n",
    "\n",
    "# Demo: Verify DataLoader reproducibility\n",
    "print(\"üî¨ Testing DataLoader Reproducibility\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create sample data\n",
    "data = torch.arange(100).float().unsqueeze(1)\n",
    "targets = torch.arange(100)\n",
    "\n",
    "# First loader\n",
    "loader1 = create_reproducible_dataloader(data, targets, batch_size=10, seed=42)\n",
    "batches1 = [batch[0][:3, 0].tolist() for batch in loader1]\n",
    "\n",
    "# Second loader (same seed)\n",
    "loader2 = create_reproducible_dataloader(data, targets, batch_size=10, seed=42)\n",
    "batches2 = [batch[0][:3, 0].tolist() for batch in loader2]\n",
    "\n",
    "print(\"\\nFirst 3 elements of each batch:\")\n",
    "print(f\"{'Batch':<8} {'Loader 1':<20} {'Loader 2':<20} {'Match':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, (b1, b2) in enumerate(zip(batches1, batches2)):\n",
    "    match = \"‚úÖ\" if b1 == b2 else \"‚ùå\"\n",
    "    print(f\"{i+1:<8} {str(b1):<20} {str(b2):<20} {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Exercise\n",
    "\n",
    "**Task:** Create your own reproducibility audit.\n",
    "\n",
    "1. Define a model architecture\n",
    "2. Train it twice with the same seed\n",
    "3. Verify the losses match exactly\n",
    "4. Generate an audit report\n",
    "5. Test what happens with a different seed\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "```python\n",
    "# Define your model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your architecture\n",
    "\n",
    "# Run audit\n",
    "def my_reproducibility_test(seed):\n",
    "    set_seed(seed)\n",
    "    model = MyModel()\n",
    "    # Train and capture losses\n",
    "    return losses, model_hash\n",
    "\n",
    "# Compare runs\n",
    "losses1, hash1 = my_reproducibility_test(42)\n",
    "losses2, hash2 = my_reproducibility_test(42)\n",
    "\n",
    "print(f\"Match: {hash1 == hash2}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Define model\n",
    "\n",
    "\n",
    "# Step 2: Train twice with same seed\n",
    "\n",
    "\n",
    "# Step 3: Verify losses match\n",
    "\n",
    "\n",
    "# Step 4: Generate report\n",
    "\n",
    "\n",
    "# Step 5: Test with different seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Setting Seed Once at the Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Seed only at beginning\n",
    "# set_seed(42)\n",
    "# for epoch in range(10):\n",
    "#     train()  # Random state changes unpredictably\n",
    "\n",
    "# ‚úÖ RIGHT: Reset seed when exact reproduction is needed\n",
    "# set_seed(42)\n",
    "# train_first_model()\n",
    "# \n",
    "# set_seed(42)  # Reset before second run\n",
    "# train_second_model()  # Now reproducible!\n",
    "\n",
    "print(\"Reset seeds before each run you want to reproduce!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Using Non-Deterministic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Some ops are non-deterministic by default\n",
    "# output = torch.nn.functional.interpolate(x, scale_factor=2)  # May vary!\n",
    "\n",
    "# ‚úÖ RIGHT: Use deterministic mode\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# Or use deterministic implementations\n",
    "\n",
    "print(\"Enable torch.use_deterministic_algorithms(True) for strict reproducibility.\")\n",
    "print(\"Note: Some operations don't have deterministic implementations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Why reproducibility matters in ML\n",
    "- ‚úÖ Proper random seed management\n",
    "- ‚úÖ Environment capture and recreation\n",
    "- ‚úÖ Reproducibility verification\n",
    "- ‚úÖ Creating comprehensive audit reports\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [PyTorch Reproducibility Guide](https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "- [Reproducibility in ML (Papers With Code)](https://paperswithcode.com/sota)\n",
    "- [ML Reproducibility Checklist](https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf)\n",
    "- [Docker for ML Reproducibility](https://docs.docker.com/)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"üìÅ Audit reports saved to: {AUDIT_DIR}\")\n",
    "print(\"‚úÖ Resources cleaned up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Module Summary\n",
    "\n",
    "Congratulations on completing Module 4.3: MLOps & Experiment Tracking!\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "| Lab | Topic | Key Skills |\n",
    "|-----|-------|------------|\n",
    "| 4.3.1 | MLflow Setup | Experiment tracking, logging, UI |\n",
    "| 4.3.2 | W&B Integration | Dashboards, sweeps, team collaboration |\n",
    "| 4.3.3 | Benchmark Suite | lm-eval, model comparison, metrics |\n",
    "| 4.3.4 | Custom Evaluation | LLM-as-judge, pairwise comparison |\n",
    "| 4.3.5 | Drift Detection | Evidently AI, monitoring, alerts |\n",
    "| 4.3.6 | Model Registry | Versioning, lifecycle, promotion |\n",
    "| 4.3.7 | Reproducibility | Seeds, environments, audits |\n",
    "\n",
    "### Next Steps:\n",
    "- Document your experiment tracking setup\n",
    "- Keep your benchmark results for the capstone\n",
    "- Proceed to Module 4.4: Containerization & Deployment\n",
    "\n",
    "**Well done! You're now equipped with industry-standard MLOps practices!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
