{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.3.2: Weights & Biases Integration\n",
    "\n",
    "**Module:** 4.3 - MLOps & Experiment Tracking  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Set up Weights & Biases for experiment tracking\n",
    "- [ ] Create interactive training dashboards\n",
    "- [ ] Run hyperparameter sweeps with W&B Sweeps\n",
    "- [ ] Log media (images, audio, tables) for rich analysis\n",
    "- [ ] Compare W&B vs MLflow for different use cases\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Lab 4.3.1 (MLflow Setup)\n",
    "- Knowledge of: Python, PyTorch basics, experiment tracking concepts\n",
    "- Account: Free W&B account (we'll create one if needed)\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**Weights & Biases** (W&B) has become the industry standard for ML experiment tracking, especially for:\n",
    "\n",
    "| Company | Use Case |\n",
    "|---------|----------|\n",
    "| **OpenAI** | GPT-4 training monitoring |\n",
    "| **Stability AI** | Stable Diffusion development |\n",
    "| **Toyota** | Autonomous driving ML ops |\n",
    "| **GitHub** | Copilot model experiments |\n",
    "\n",
    "**W&B vs MLflow:**\n",
    "\n",
    "| Feature | W&B | MLflow |\n",
    "|---------|-----|--------|\n",
    "| **Hosting** | Cloud-first (free tier) | Self-hosted first |\n",
    "| **Visualization** | Beautiful dashboards | Basic UI |\n",
    "| **Sweeps** | Built-in, powerful | Manual setup |\n",
    "| **Collaboration** | Teams, reports, sharing | Server setup required |\n",
    "| **Media logging** | Images, audio, video, 3D | Files only |\n",
    "| **Cost** | Free tier, paid for teams | Free, self-hosted |\n",
    "\n",
    "**Best practice:** Use both! MLflow for local dev/model registry, W&B for team collaboration and rich visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is Weights & Biases?\n",
    "\n",
    "> **Imagine you're coaching a soccer team.**\n",
    ">\n",
    "> MLflow is like your **personal notebook** - you write down plays, scores, and notes.\n",
    ">\n",
    "> W&B is like having a **professional sports analytics platform**:\n",
    "> - Real-time dashboards showing player stats\n",
    "> - Video replays of every play\n",
    "> - Automatic comparisons between games\n",
    "> - Share reports with the whole coaching staff\n",
    "> - Scouts can see everything from anywhere\n",
    ">\n",
    "> **For ML:**\n",
    "> - Real-time training curves that update live\n",
    "> - Automatic hyperparameter optimization\n",
    "> - Rich media logging (images, predictions, confusion matrices)\n",
    "> - Team collaboration without server setup\n",
    "> - Reports and presentations built-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setting Up Weights & Biases\n",
    "\n",
    "### Installation and Account Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install W&B if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    print(f\"‚úÖ W&B already installed: v{wandb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Weights & Biases...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"wandb\", \"-q\"])\n",
    "    import wandb\n",
    "    print(f\"‚úÖ W&B installed: v{wandb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(f\"W&B version: {wandb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "You have two options:\n",
    "\n",
    "1. **Online mode** (recommended): Create a free account at https://wandb.ai and get an API key\n",
    "2. **Offline mode**: For air-gapped environments or privacy, logs are saved locally\n",
    "\n",
    "Let's set up authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if already logged in\n",
    "try:\n",
    "    api = wandb.Api()\n",
    "    print(f\"‚úÖ Already logged in as: {api.viewer.username}\")\n",
    "    WANDB_MODE = \"online\"\n",
    "except Exception:\n",
    "    print(\"Not logged in to W&B.\")\n",
    "    print(\"\")\n",
    "    print(\"Options:\")\n",
    "    print(\"1. Run 'wandb login' in terminal with your API key\")\n",
    "    print(\"2. Set WANDB_API_KEY environment variable\")\n",
    "    print(\"3. Continue in offline mode (logs saved locally)\")\n",
    "    print(\"\")\n",
    "    print(\"For this tutorial, we'll use OFFLINE mode.\")\n",
    "    WANDB_MODE = \"offline\"\n",
    "    os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "print(f\"\\nüìä Running in {WANDB_MODE.upper()} mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To login interactively (uncomment if you have an account):\n",
    "# wandb.login()\n",
    "\n",
    "# Or set your API key directly:\n",
    "# wandb.login(key=\"your-api-key-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Your First W&B Run\n",
    "\n",
    "### Basic Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a W&B run\n",
    "# This creates a new experiment run\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"dgx-spark-mlops-demo\",  # Groups related experiments\n",
    "    name=\"my-first-wandb-run\",       # Unique name for this run\n",
    "    config={                          # Hyperparameters\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 10,\n",
    "        \"model\": \"phi-2\",\n",
    "        \"lora_rank\": 16,\n",
    "        \"optimizer\": \"AdamW\"\n",
    "    },\n",
    "    tags=[\"demo\", \"tutorial\", \"dgx-spark\"],  # For filtering\n",
    "    notes=\"First W&B experiment for the MLOps module\"  # Description\n",
    ")\n",
    "\n",
    "print(f\"\\nüöÄ Run initialized!\")\n",
    "print(f\"   Project: {run.project}\")\n",
    "print(f\"   Run name: {run.name}\")\n",
    "print(f\"   Run ID: {run.id}\")\n",
    "if WANDB_MODE == \"online\":\n",
    "    print(f\"   URL: {run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and modify config\n",
    "print(\"üìã Current config:\")\n",
    "for key, value in wandb.config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# You can update config dynamically\n",
    "wandb.config.update({\n",
    "    \"warmup_steps\": 100,\n",
    "    \"weight_decay\": 0.01\n",
    "})\n",
    "\n",
    "print(\"\\n‚úÖ Config updated with warmup_steps and weight_decay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate training and log metrics\n",
    "print(\"üèÉ Simulating training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(wandb.config.epochs):\n",
    "    # Simulate training metrics\n",
    "    train_loss = 1.0 * np.exp(-epoch * 0.3) + 0.1 + np.random.normal(0, 0.02)\n",
    "    val_loss = 1.2 * np.exp(-epoch * 0.25) + 0.15 + np.random.normal(0, 0.03)\n",
    "    accuracy = min(0.95, 0.5 + epoch * 0.05 + np.random.normal(0, 0.01))\n",
    "    learning_rate = wandb.config.learning_rate * (0.95 ** epoch)  # LR decay\n",
    "    \n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train/loss\": train_loss,\n",
    "        \"val/loss\": val_loss,\n",
    "        \"val/accuracy\": accuracy,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"gpu_memory_gb\": 24 + np.random.normal(0, 0.5)  # Simulated\n",
    "    })\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}/{wandb.config.epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Acc: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log summary metrics (best values)\n",
    "wandb.summary[\"best_accuracy\"] = 0.92\n",
    "wandb.summary[\"best_epoch\"] = 8\n",
    "wandb.summary[\"total_training_time\"] = 3600  # seconds\n",
    "\n",
    "print(\"üìä Summary metrics logged:\")\n",
    "print(f\"   best_accuracy: {wandb.summary['best_accuracy']}\")\n",
    "print(f\"   best_epoch: {wandb.summary['best_epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the run\n",
    "wandb.finish()\n",
    "print(\"\\n‚úÖ Run finished and synced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Key Differences from MLflow\n",
    "\n",
    "| Aspect | MLflow | W&B |\n",
    "|--------|--------|-----|\n",
    "| **Logging** | `log_metric(key, value, step)` | `log({key: value, ...})` |\n",
    "| **Config** | `log_param()` | `config` dict |\n",
    "| **Grouping** | Experiments | Projects |\n",
    "| **UI** | Local server required | Cloud dashboard (instant) |\n",
    "| **Namespacing** | Flat | Hierarchical (`train/loss`, `val/loss`) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Rich Media Logging\n",
    "\n",
    "W&B excels at logging rich media - images, tables, plots, and more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new run for media logging\n",
    "run = wandb.init(\n",
    "    project=\"dgx-spark-mlops-demo\",\n",
    "    name=\"media-logging-demo\",\n",
    "    config={\"demo_type\": \"media_logging\"}\n",
    ")\n",
    "\n",
    "print(f\"üñºÔ∏è Media logging demo started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log matplotlib figures\n",
    "def create_loss_figure():\n",
    "    \"\"\"Create a training loss figure.\"\"\"\n",
    "    epochs = np.arange(1, 21)\n",
    "    train_loss = np.exp(-epochs * 0.15) + 0.1 + np.random.normal(0, 0.02, len(epochs))\n",
    "    val_loss = np.exp(-epochs * 0.12) + 0.15 + np.random.normal(0, 0.03, len(epochs))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(epochs, train_loss, 'b-o', label='Training Loss', linewidth=2)\n",
    "    ax.plot(epochs, val_loss, 'r-s', label='Validation Loss', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.set_title('Training Progress', fontsize=14)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return fig\n",
    "\n",
    "# Create and log the figure\n",
    "fig = create_loss_figure()\n",
    "wandb.log({\"training_curves\": wandb.Image(fig)})\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"üìä Logged training curves plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log a confusion matrix\n",
    "def create_confusion_matrix():\n",
    "    \"\"\"Create a sample confusion matrix.\"\"\"\n",
    "    # Simulated confusion matrix for sentiment analysis\n",
    "    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "    cm = np.array([\n",
    "        [85, 10, 5],\n",
    "        [8, 78, 14],\n",
    "        [3, 12, 85]\n",
    "    ])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm, cmap='Blues')\n",
    "    \n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, cm[i, j], ha='center', va='center', \n",
    "                          color='white' if cm[i, j] > 50 else 'black', fontsize=14)\n",
    "    \n",
    "    plt.colorbar(im)\n",
    "    return fig\n",
    "\n",
    "fig = create_confusion_matrix()\n",
    "wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"üìä Logged confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log tables for structured data\n",
    "# Great for predictions, errors, samples, etc.\n",
    "\n",
    "# Sample predictions table\n",
    "predictions_table = wandb.Table(\n",
    "    columns=[\"Input\", \"Prediction\", \"Confidence\", \"Correct\"],\n",
    "    data=[\n",
    "        [\"This product is amazing!\", \"Positive\", 0.95, True],\n",
    "        [\"Worst purchase ever\", \"Negative\", 0.88, True],\n",
    "        [\"It's okay I guess\", \"Neutral\", 0.65, True],\n",
    "        [\"Not bad, not great\", \"Positive\", 0.52, False],  # Error\n",
    "        [\"Absolutely love it!\", \"Positive\", 0.97, True],\n",
    "        [\"Never buying again\", \"Negative\", 0.91, True],\n",
    "        [\"Meh\", \"Neutral\", 0.78, True],\n",
    "        [\"Could be better\", \"Negative\", 0.61, False],  # Error\n",
    "    ]\n",
    ")\n",
    "\n",
    "wandb.log({\"predictions\": predictions_table})\n",
    "print(\"üìã Logged predictions table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log histograms for distributions\n",
    "# Useful for gradients, activations, weights, etc.\n",
    "\n",
    "# Simulated gradient distributions over training\n",
    "for step in range(5):\n",
    "    # Gradients typically get smaller as training progresses\n",
    "    gradient_values = np.random.normal(0, 0.1 * (1 - step * 0.15), 1000)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"gradients\": wandb.Histogram(gradient_values),\n",
    "        \"step\": step\n",
    "    })\n",
    "\n",
    "print(\"üìä Logged gradient histograms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log artifacts (files)\n",
    "# Create a model config artifact\n",
    "\n",
    "config_data = {\n",
    "    \"model\": {\n",
    "        \"name\": \"phi-2-finetuned\",\n",
    "        \"base_model\": \"microsoft/phi-2\",\n",
    "        \"dtype\": \"bfloat16\"\n",
    "    },\n",
    "    \"lora\": {\n",
    "        \"rank\": 16,\n",
    "        \"alpha\": 32,\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 10\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save locally\n",
    "config_path = \"/tmp/model_config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config_data, f, indent=2)\n",
    "\n",
    "# Create and log artifact\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"model-config\",\n",
    "    type=\"config\",\n",
    "    description=\"Model configuration for phi-2 fine-tuning\"\n",
    ")\n",
    "artifact.add_file(config_path)\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "print(\"üì¶ Logged config artifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the media logging run\n",
    "wandb.finish()\n",
    "print(\"\\n‚úÖ Media logging demo complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: W&B Sweeps (Hyperparameter Optimization)\n",
    "\n",
    "### üßí ELI5: What are Sweeps?\n",
    "\n",
    "> **Imagine you're trying to find the perfect pizza recipe.**\n",
    ">\n",
    "> **Manual search:** You pick random combinations and hope for the best.\n",
    ">\n",
    "> **Grid search:** You try EVERY combination (100 pizzas!)\n",
    ">\n",
    "> **W&B Sweep (Bayesian):** An AI chef helps you!\n",
    "> - You try a few pizzas\n",
    "> - The AI learns what makes good pizza\n",
    "> - It suggests the NEXT best recipe to try\n",
    "> - Much faster to find the perfect pizza!\n",
    ">\n",
    "> W&B Sweeps do this for hyperparameters, automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sweep configuration\n",
    "sweep_config = {\n",
    "    \"name\": \"llm-finetuning-sweep\",\n",
    "    \"method\": \"bayes\",  # Options: grid, random, bayes\n",
    "    \"metric\": {\n",
    "        \"name\": \"val/accuracy\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 1e-3\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [8, 16, 32]\n",
    "        },\n",
    "        \"lora_rank\": {\n",
    "            \"values\": [8, 16, 32, 64]\n",
    "        },\n",
    "        \"warmup_ratio\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 0.2\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"distribution\": \"log_uniform_values\",\n",
    "            \"min\": 1e-4,\n",
    "            \"max\": 0.1\n",
    "        }\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 3,\n",
    "        \"eta\": 2\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Sweep Configuration:\")\n",
    "print(json.dumps(sweep_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function for the sweep\n",
    "def train_sweep():\n",
    "    \"\"\"Training function called by W&B sweep agent.\"\"\"\n",
    "    # Initialize run (config is automatically set by sweep)\n",
    "    run = wandb.init()\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Simulate training with the given hyperparameters\n",
    "    # In real code, you'd train your actual model here\n",
    "    \n",
    "    # Hyperparameter effects (simplified simulation)\n",
    "    lr_effect = -np.abs(np.log10(config.learning_rate) + 4)  # Best around 1e-4\n",
    "    bs_effect = -np.abs(np.log2(config.batch_size) - 4) * 0.1  # Best around 16\n",
    "    rank_effect = np.log2(config.lora_rank) * 0.02  # Higher rank = slightly better\n",
    "    \n",
    "    base_accuracy = 0.75 + lr_effect * 0.1 + bs_effect + rank_effect\n",
    "    \n",
    "    # Simulate training epochs\n",
    "    for epoch in range(10):\n",
    "        train_loss = (1 - base_accuracy) * (0.8 ** epoch) + np.random.normal(0, 0.02)\n",
    "        val_loss = train_loss * 1.1 + np.random.normal(0, 0.03)\n",
    "        accuracy = base_accuracy + epoch * 0.02 + np.random.normal(0, 0.01)\n",
    "        accuracy = min(0.98, max(0.5, accuracy))\n",
    "        \n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train/loss\": train_loss,\n",
    "            \"val/loss\": val_loss,\n",
    "            \"val/accuracy\": accuracy\n",
    "        })\n",
    "    \n",
    "    # Log final summary\n",
    "    wandb.summary[\"final_accuracy\"] = accuracy\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "print(\"‚úÖ Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sweep\n",
    "# Note: In offline mode, sweeps have limited functionality\n",
    "\n",
    "if WANDB_MODE == \"online\":\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"dgx-spark-mlops-demo\")\n",
    "    print(f\"üöÄ Sweep created: {sweep_id}\")\n",
    "    print(\"\\nTo run the sweep agent:\")\n",
    "    print(f\"wandb agent {sweep_id}\")\n",
    "else:\n",
    "    print(\"üìù Sweep config created (offline mode - cannot run actual sweep)\")\n",
    "    print(\"\\nTo run sweeps, login to W&B and run:\")\n",
    "    print(\"1. sweep_id = wandb.sweep(sweep_config, project='your-project')\")\n",
    "    print(\"2. wandb.agent(sweep_id, train_sweep, count=20)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Run a few sweep iterations locally\n",
    "print(\"üî¨ Running simulated sweep iterations...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simulate what a sweep would do\n",
    "import random\n",
    "\n",
    "sweep_results = []\n",
    "\n",
    "for i in range(10):\n",
    "    # Sample hyperparameters (simulating Bayesian optimization)\n",
    "    config = {\n",
    "        \"learning_rate\": 10 ** random.uniform(-5, -3),\n",
    "        \"batch_size\": random.choice([8, 16, 32]),\n",
    "        \"lora_rank\": random.choice([8, 16, 32, 64]),\n",
    "        \"warmup_ratio\": random.uniform(0, 0.2),\n",
    "        \"weight_decay\": 10 ** random.uniform(-4, -1)\n",
    "    }\n",
    "    \n",
    "    # Simulate result\n",
    "    lr_effect = -np.abs(np.log10(config[\"learning_rate\"]) + 4)\n",
    "    bs_effect = -np.abs(np.log2(config[\"batch_size\"]) - 4) * 0.1\n",
    "    rank_effect = np.log2(config[\"lora_rank\"]) * 0.02\n",
    "    accuracy = 0.75 + lr_effect * 0.1 + bs_effect + rank_effect + random.gauss(0, 0.02)\n",
    "    accuracy = min(0.98, max(0.5, accuracy))\n",
    "    \n",
    "    sweep_results.append({\n",
    "        \"run\": i + 1,\n",
    "        **config,\n",
    "        \"accuracy\": accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"Run {i+1:2d} | lr={config['learning_rate']:.2e} | \"\n",
    "          f\"bs={config['batch_size']:2d} | rank={config['lora_rank']:2d} | \"\n",
    "          f\"acc={accuracy:.4f}\")\n",
    "\n",
    "# Find best\n",
    "best = max(sweep_results, key=lambda x: x[\"accuracy\"])\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"üèÜ BEST RUN: #{best['run']}\")\n",
    "print(f\"   Learning Rate: {best['learning_rate']:.2e}\")\n",
    "print(f\"   Batch Size: {best['batch_size']}\")\n",
    "print(f\"   LoRA Rank: {best['lora_rank']}\")\n",
    "print(f\"   Accuracy: {best['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: W&B Integration with PyTorch\n",
    "\n",
    "Let's see how to integrate W&B with a real PyTorch training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model for demonstration\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=256, output_dim=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Create synthetic dataset\n",
    "def create_synthetic_data(n_samples=1000, n_features=784, n_classes=10):\n",
    "    X = torch.randn(n_samples, n_features)\n",
    "    y = torch.randint(0, n_classes, (n_samples,))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = create_synthetic_data(5000)\n",
    "X_val, y_val = create_synthetic_data(1000)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb(config=None):\n",
    "    \"\"\"Full training loop with W&B integration.\"\"\"\n",
    "    \n",
    "    # Initialize W&B\n",
    "    run = wandb.init(\n",
    "        project=\"dgx-spark-mlops-demo\",\n",
    "        name=\"pytorch-training-demo\",\n",
    "        config=config or {\n",
    "            \"learning_rate\": 1e-3,\n",
    "            \"batch_size\": 32,\n",
    "            \"epochs\": 10,\n",
    "            \"hidden_dim\": 256,\n",
    "            \"dropout\": 0.2\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    config = wandb.config\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
    "    \n",
    "    # Create model\n",
    "    model = SimpleNet(hidden_dim=config.hidden_dim).to(device)\n",
    "    \n",
    "    # Watch model (logs gradients and parameters)\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)\n",
    "    \n",
    "    # Optimizer and loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            train_correct += pred.eq(target).sum().item()\n",
    "            train_total += target.size(0)\n",
    "            \n",
    "            # Log batch metrics\n",
    "            if batch_idx % 50 == 0:\n",
    "                wandb.log({\n",
    "                    \"batch/loss\": loss.item(),\n",
    "                    \"batch/accuracy\": pred.eq(target).float().mean().item()\n",
    "                })\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1)\n",
    "                val_correct += pred.eq(target).sum().item()\n",
    "                val_total += target.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Log epoch metrics\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train/loss\": train_loss,\n",
    "            \"train/accuracy\": train_acc,\n",
    "            \"val/loss\": val_loss,\n",
    "            \"val/accuracy\": val_acc,\n",
    "            \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d}/{config.epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            # In practice, you'd save the model here\n",
    "            wandb.summary[\"best_val_accuracy\"] = best_val_acc\n",
    "            wandb.summary[\"best_epoch\"] = epoch\n",
    "    \n",
    "    # Log model artifact\n",
    "    model_path = \"/tmp/model.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    artifact = wandb.Artifact(\"trained-model\", type=\"model\")\n",
    "    artifact.add_file(model_path)\n",
    "    wandb.log_artifact(artifact)\n",
    "    \n",
    "    wandb.finish()\n",
    "    return model, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training with W&B\n",
    "print(\"üèÉ Starting training with W&B logging...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model, best_acc = train_with_wandb()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"üéâ Training complete! Best validation accuracy: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: W&B with HuggingFace Transformers\n",
    "\n",
    "W&B integrates seamlessly with HuggingFace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for HuggingFace integration\n",
    "hf_integration_code = '''\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import wandb\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"hf-finetuning\", name=\"llama-lora\")\n",
    "\n",
    "# Configure training with W&B reporting\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=500,\n",
    "    \n",
    "    # W&B integration - just set report_to!\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"llama-lora-experiment\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Train - W&B logs everything automatically!\n",
    "trainer.train()\n",
    "\n",
    "# Finish W&B run\n",
    "wandb.finish()\n",
    "'''\n",
    "\n",
    "print(\"üìù HuggingFace + W&B Integration Example:\")\n",
    "print(\"=\" * 50)\n",
    "print(hf_integration_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Exercise\n",
    "\n",
    "**Task:** Create a complete W&B experiment with rich logging.\n",
    "\n",
    "1. Initialize a new run with a custom config\n",
    "2. Simulate training for 15 epochs\n",
    "3. Log:\n",
    "   - Training and validation metrics\n",
    "   - A confusion matrix (as an image)\n",
    "   - A predictions table\n",
    "   - A training curves plot\n",
    "4. Use `wandb.summary` to store best results\n",
    "5. Finish the run cleanly\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "```python\n",
    "run = wandb.init(\n",
    "    project=\"my-project\",\n",
    "    config={\"epochs\": 15, \"lr\": 1e-4}\n",
    ")\n",
    "\n",
    "for epoch in range(15):\n",
    "    # Log metrics\n",
    "    wandb.log({\"train/loss\": ..., \"val/accuracy\": ...})\n",
    "\n",
    "# Log image\n",
    "fig = create_plot()\n",
    "wandb.log({\"plot\": wandb.Image(fig)})\n",
    "\n",
    "# Log table\n",
    "table = wandb.Table(columns=[...], data=[...])\n",
    "wandb.log({\"predictions\": table})\n",
    "\n",
    "wandb.finish()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Initialize run\n",
    "\n",
    "\n",
    "# Step 2: Simulate training\n",
    "\n",
    "\n",
    "# Step 3: Log rich media\n",
    "\n",
    "\n",
    "# Step 4: Log summary\n",
    "\n",
    "\n",
    "# Step 5: Finish run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Forgetting to Finish Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Run never finished, data may not sync\n",
    "# wandb.init(project=\"test\")\n",
    "# ... training ...\n",
    "# (script ends without wandb.finish())\n",
    "\n",
    "# ‚úÖ RIGHT: Always finish runs\n",
    "# run = wandb.init(project=\"test\")\n",
    "# try:\n",
    "#     ... training ...\n",
    "# finally:\n",
    "#     wandb.finish()\n",
    "\n",
    "print(\"Always call wandb.finish() or use context managers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Logging at Every Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Logging every batch slows down training\n",
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#     wandb.log({\"batch_loss\": loss})  # Every single batch!\n",
    "\n",
    "# ‚úÖ RIGHT: Log at intervals\n",
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#     if batch_idx % 100 == 0:  # Every 100 batches\n",
    "#         wandb.log({\"batch_loss\": loss})\n",
    "\n",
    "print(\"Log at reasonable intervals to avoid slowdowns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 3: Not Using Namespaced Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Flat metric names get messy\n",
    "# wandb.log({\"loss\": ..., \"accuracy\": ..., \"val_loss\": ..., \"val_accuracy\": ...})\n",
    "\n",
    "# ‚úÖ RIGHT: Use namespaced metrics (creates grouped charts)\n",
    "# wandb.log({\n",
    "#     \"train/loss\": ...,\n",
    "#     \"train/accuracy\": ...,\n",
    "#     \"val/loss\": ...,\n",
    "#     \"val/accuracy\": ...\n",
    "# })\n",
    "\n",
    "print(\"Use prefixes like 'train/' and 'val/' for organized dashboards!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Setting up W&B for experiment tracking\n",
    "- ‚úÖ Logging metrics, configs, and rich media\n",
    "- ‚úÖ Running hyperparameter sweeps\n",
    "- ‚úÖ Integrating W&B with PyTorch and HuggingFace\n",
    "- ‚úÖ Best practices for production use\n",
    "\n",
    "---\n",
    "\n",
    "## üÜö MLflow vs W&B: When to Use Which?\n",
    "\n",
    "| Scenario | Recommendation |\n",
    "|----------|---------------|\n",
    "| Local development | MLflow (no account needed) |\n",
    "| Team collaboration | W&B (cloud dashboard) |\n",
    "| Model registry | MLflow (built-in) |\n",
    "| Rich visualizations | W&B |\n",
    "| Air-gapped environment | MLflow (self-hosted) |\n",
    "| Hyperparameter sweeps | W&B (Bayesian) |\n",
    "| Free for individuals | Both! |\n",
    "\n",
    "**Pro tip:** Many teams use both - MLflow for model registry and deployment, W&B for experiment tracking and collaboration.\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [W&B Documentation](https://docs.wandb.ai/)\n",
    "- [W&B Sweeps Guide](https://docs.wandb.ai/guides/sweeps)\n",
    "- [W&B + HuggingFace](https://docs.wandb.ai/guides/integrations/huggingface)\n",
    "- [W&B Reports](https://docs.wandb.ai/guides/reports)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "import gc\n",
    "\n",
    "plt.close('all')\n",
    "gc.collect()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Note about offline data\n",
    "print(\"üìÅ W&B offline data saved to: ./wandb/\")\n",
    "print(\"\")\n",
    "print(\"To sync offline runs later:\")\n",
    "print(\"  wandb sync ./wandb/offline-run-*\")\n",
    "print(\"\")\n",
    "print(\"To view online (requires account):\")\n",
    "print(\"  https://wandb.ai/your-username/dgx-spark-mlops-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "In this lab, we:\n",
    "\n",
    "1. **Set up** Weights & Biases for experiment tracking\n",
    "2. **Logged** metrics, configs, and rich media (images, tables, histograms)\n",
    "3. **Explored** W&B Sweeps for hyperparameter optimization\n",
    "4. **Integrated** W&B with PyTorch training loops\n",
    "5. **Compared** W&B and MLflow for different use cases\n",
    "\n",
    "**Next up:** Lab 4.3.3 - LLM Benchmark Suite with lm-evaluation-harness!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
