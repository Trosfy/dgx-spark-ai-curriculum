{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.3.5: Drift Detection with Evidently AI\n",
    "\n",
    "**Module:** 4.3 - MLOps & Experiment Tracking  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand the types of drift (data, concept, prediction)\n",
    "- [ ] Set up Evidently AI for drift monitoring\n",
    "- [ ] Create data quality and drift reports\n",
    "- [ ] Build a monitoring dashboard for production models\n",
    "- [ ] Implement alerting for detected drift\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Lab 4.3.4 (Custom Evaluation)\n",
    "- Knowledge of: Statistics basics, ML deployment concepts\n",
    "- Hardware: DGX Spark (any configuration)\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**Your model works great today. But will it work next month?**\n",
    "\n",
    "The world changes constantly:\n",
    "- Customer behavior shifts (COVID changed everything!)\n",
    "- New products/categories appear\n",
    "- Seasonal patterns change\n",
    "- Data pipelines break silently\n",
    "\n",
    "**Real Drift Examples:**\n",
    "\n",
    "| Company | What Happened | Impact |\n",
    "|---------|---------------|--------|\n",
    "| Zillow | Housing market shifted | $500M loss, shut down home-buying |\n",
    "| Amazon | COVID changed shopping | Recommendation accuracy dropped |\n",
    "| Banks | New fraud patterns | Missed fraud cases, customer losses |\n",
    "| Healthcare | New COVID variants | Diagnostic models degraded |\n",
    "\n",
    "**Drift monitoring is essential for production ML!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is Model Drift?\n",
    "\n",
    "> **Imagine you trained a dog to fetch tennis balls in your backyard.**\n",
    ">\n",
    "> The dog learned: \"Yellow, round, bouncy = fetch!\"\n",
    ">\n",
    "> Now imagine:\n",
    "> - **Data drift**: You move to a new house with a different backyard\n",
    ">   - The grass is artificial, the lighting is different\n",
    ">   - The dog is confused: \"This doesn't look like my training yard!\"\n",
    ">\n",
    "> - **Concept drift**: You switch to orange baseballs\n",
    ">   - The dog learned \"yellow = fetch\", but now the target is orange\n",
    ">   - Same task, but the rules changed!\n",
    ">\n",
    "> - **Prediction drift**: The dog starts fetching sticks instead\n",
    ">   - Something is wrong with its predictions\n",
    ">\n",
    "> **In ML:**\n",
    "> - Data drift = input data distribution changes\n",
    "> - Concept drift = relationship between inputs and outputs changes\n",
    "> - Prediction drift = model outputs change unexpectedly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding Drift Types\n",
    "\n",
    "### The Three Types of Drift\n",
    "\n",
    "| Type | What Changes | Example | Detection |\n",
    "|------|-------------|---------|----------|\n",
    "| **Data Drift** | Input distribution | Age distribution of users shifts | Compare input statistics |\n",
    "| **Concept Drift** | Input‚ÜíOutput relationship | What \"spam\" means changes | Monitor prediction accuracy |\n",
    "| **Prediction Drift** | Model outputs | More \"Yes\" predictions than usual | Track prediction distribution |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Evidently AI\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import evidently\n",
    "    print(f\"‚úÖ Evidently already installed: v{evidently.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Evidently AI...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"evidently\", \"-q\"])\n",
    "    import evidently\n",
    "    print(f\"‚úÖ Evidently installed: v{evidently.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Evidently imports\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset, DataQualityPreset, TargetDriftPreset\n",
    "from evidently.metrics import (\n",
    "    DatasetDriftMetric,\n",
    "    ColumnDriftMetric,\n",
    "    DatasetMissingValuesMetric,\n",
    "    ColumnQuantileMetric\n",
    ")\n",
    "\n",
    "print(f\"Evidently version: {evidently.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "MODULE_DIR = (NOTEBOOK_DIR / \"..\").resolve()\n",
    "REPORTS_DIR = MODULE_DIR / \"evaluation\" / \"drift_reports\"\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Reports will be saved to: {REPORTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Creating Synthetic Data with Drift\n",
    "\n",
    "Let's create realistic data that simulates drift over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loan_data(n_samples: int, drift_factor: float = 0.0, seed: int = 42):\n",
    "    \"\"\"\n",
    "    Generate synthetic loan application data.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples to generate\n",
    "        drift_factor: 0.0 = no drift, 1.0 = maximum drift\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with loan application features and predictions\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Base distributions\n",
    "    age_mean = 35 + drift_factor * 10  # Ages shift older with drift\n",
    "    income_mean = 50000 + drift_factor * 20000  # Incomes increase\n",
    "    credit_score_mean = 680 - drift_factor * 50  # Credit scores decrease\n",
    "    \n",
    "    data = {\n",
    "        \"age\": np.random.normal(age_mean, 10, n_samples).astype(int),\n",
    "        \"income\": np.random.lognormal(np.log(income_mean), 0.5, n_samples),\n",
    "        \"credit_score\": np.random.normal(credit_score_mean, 50, n_samples).astype(int),\n",
    "        \"debt_to_income\": np.random.beta(2 + drift_factor, 5 - drift_factor, n_samples),\n",
    "        \"employment_years\": np.random.exponential(5 - drift_factor * 2, n_samples),\n",
    "        \"loan_amount\": np.random.lognormal(10 + drift_factor * 0.5, 0.8, n_samples),\n",
    "        \"num_credit_lines\": np.random.poisson(3 + drift_factor * 2, n_samples),\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Clip to reasonable ranges\n",
    "    df[\"age\"] = df[\"age\"].clip(18, 80)\n",
    "    df[\"credit_score\"] = df[\"credit_score\"].clip(300, 850)\n",
    "    df[\"debt_to_income\"] = df[\"debt_to_income\"].clip(0, 1)\n",
    "    df[\"employment_years\"] = df[\"employment_years\"].clip(0, 40)\n",
    "    \n",
    "    # Generate predictions (loan approval probability)\n",
    "    # Model \"learned\" on original distribution\n",
    "    base_prob = (\n",
    "        0.3 + \n",
    "        0.002 * (df[\"credit_score\"] - 600) +\n",
    "        0.00001 * df[\"income\"] -\n",
    "        0.5 * df[\"debt_to_income\"] +\n",
    "        0.01 * df[\"employment_years\"]\n",
    "    )\n",
    "    \n",
    "    df[\"prediction_prob\"] = base_prob.clip(0.05, 0.95)\n",
    "    df[\"prediction\"] = (df[\"prediction_prob\"] > 0.5).astype(int)\n",
    "    \n",
    "    # Add actual outcome (with some noise)\n",
    "    noise = np.random.uniform(-0.1, 0.1, n_samples)\n",
    "    df[\"actual\"] = ((base_prob + noise) > 0.5).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Generate reference (training) data and current (production) data\n",
    "print(\"üìä Generating synthetic loan data...\")\n",
    "\n",
    "# Reference data (what the model was trained on)\n",
    "reference_data = generate_loan_data(n_samples=5000, drift_factor=0.0, seed=42)\n",
    "print(f\"   Reference data: {len(reference_data)} samples\")\n",
    "\n",
    "# Current data with mild drift\n",
    "current_data_mild = generate_loan_data(n_samples=1000, drift_factor=0.3, seed=100)\n",
    "print(f\"   Current data (mild drift): {len(current_data_mild)} samples\")\n",
    "\n",
    "# Current data with severe drift\n",
    "current_data_severe = generate_loan_data(n_samples=1000, drift_factor=0.8, seed=200)\n",
    "print(f\"   Current data (severe drift): {len(current_data_severe)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the drift\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "features = [\"age\", \"income\", \"credit_score\", \"debt_to_income\", \"employment_years\", \"loan_amount\"]\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    ax.hist(reference_data[feature], bins=30, alpha=0.5, label=\"Reference\", density=True)\n",
    "    ax.hist(current_data_mild[feature], bins=30, alpha=0.5, label=\"Current (mild)\", density=True)\n",
    "    ax.hist(current_data_severe[feature], bins=30, alpha=0.5, label=\"Current (severe)\", density=True)\n",
    "    \n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(f\"Distribution: {feature}\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle(\"Feature Distribution Drift Visualization\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / \"drift_visualization.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Visualization saved to: {REPORTS_DIR / 'drift_visualization.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Creating Drift Reports with Evidently\n",
    "\n",
    "Evidently makes it easy to create beautiful, interactive drift reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column mapping\n",
    "# This tells Evidently which columns are features, targets, predictions, etc.\n",
    "\n",
    "column_mapping = ColumnMapping(\n",
    "    target=\"actual\",\n",
    "    prediction=\"prediction\",\n",
    "    numerical_features=[\n",
    "        \"age\", \"income\", \"credit_score\", \"debt_to_income\",\n",
    "        \"employment_years\", \"loan_amount\", \"num_credit_lines\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Column mapping configured\")\n",
    "print(f\"   Target: {column_mapping.target}\")\n",
    "print(f\"   Prediction: {column_mapping.prediction}\")\n",
    "print(f\"   Numerical features: {len(column_mapping.numerical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive data drift report\n",
    "print(\"üìä Creating Data Drift Report (mild drift)...\")\n",
    "\n",
    "drift_report_mild = Report(metrics=[\n",
    "    DataDriftPreset(),\n",
    "])\n",
    "\n",
    "drift_report_mild.run(\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_data_mild,\n",
    "    column_mapping=column_mapping\n",
    ")\n",
    "\n",
    "# Save as HTML\n",
    "mild_report_path = REPORTS_DIR / \"drift_report_mild.html\"\n",
    "drift_report_mild.save_html(str(mild_report_path))\n",
    "print(f\"‚úÖ Report saved to: {mild_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create report for severe drift\n",
    "print(\"üìä Creating Data Drift Report (severe drift)...\")\n",
    "\n",
    "drift_report_severe = Report(metrics=[\n",
    "    DataDriftPreset(),\n",
    "])\n",
    "\n",
    "drift_report_severe.run(\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_data_severe,\n",
    "    column_mapping=column_mapping\n",
    ")\n",
    "\n",
    "severe_report_path = REPORTS_DIR / \"drift_report_severe.html\"\n",
    "drift_report_severe.save_html(str(severe_report_path))\n",
    "print(f\"‚úÖ Report saved to: {severe_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract drift metrics programmatically\n",
    "def extract_drift_summary(report: Report) -> dict:\n",
    "    \"\"\"Extract key drift metrics from an Evidently report.\"\"\"\n",
    "    results = report.as_dict()\n",
    "    \n",
    "    summary = {\n",
    "        \"dataset_drift_detected\": False,\n",
    "        \"drift_share\": 0.0,\n",
    "        \"drifted_columns\": [],\n",
    "        \"column_drift_scores\": {}\n",
    "    }\n",
    "    \n",
    "    # Parse results\n",
    "    for metric in results.get(\"metrics\", []):\n",
    "        result = metric.get(\"result\", {})\n",
    "        \n",
    "        if \"dataset_drift\" in result:\n",
    "            summary[\"dataset_drift_detected\"] = result.get(\"dataset_drift\", False)\n",
    "            summary[\"drift_share\"] = result.get(\"share_of_drifted_columns\", 0)\n",
    "        \n",
    "        if \"drift_by_columns\" in result:\n",
    "            for col, col_result in result[\"drift_by_columns\"].items():\n",
    "                if col_result.get(\"drift_detected\", False):\n",
    "                    summary[\"drifted_columns\"].append(col)\n",
    "                summary[\"column_drift_scores\"][col] = col_result.get(\"drift_score\", 0)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "# Compare drift levels\n",
    "print(\"\\nüìä DRIFT COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "mild_summary = extract_drift_summary(drift_report_mild)\n",
    "severe_summary = extract_drift_summary(drift_report_severe)\n",
    "\n",
    "print(f\"\\nüü° Mild Drift:\")\n",
    "print(f\"   Dataset drift detected: {mild_summary['dataset_drift_detected']}\")\n",
    "print(f\"   Drift share: {mild_summary['drift_share']:.1%}\")\n",
    "print(f\"   Drifted columns: {mild_summary['drifted_columns']}\")\n",
    "\n",
    "print(f\"\\nüî¥ Severe Drift:\")\n",
    "print(f\"   Dataset drift detected: {severe_summary['dataset_drift_detected']}\")\n",
    "print(f\"   Drift share: {severe_summary['drift_share']:.1%}\")\n",
    "print(f\"   Drifted columns: {severe_summary['drifted_columns']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Data Quality Reports\n",
    "\n",
    "Beyond drift, monitoring data quality is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with quality issues\n",
    "def add_quality_issues(df: pd.DataFrame, issue_rate: float = 0.1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add data quality issues to a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        issue_rate: Fraction of values to corrupt\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with quality issues\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    n = len(df_copy)\n",
    "    \n",
    "    # Add missing values\n",
    "    for col in [\"income\", \"employment_years\"]:\n",
    "        mask = np.random.random(n) < issue_rate\n",
    "        df_copy.loc[mask, col] = np.nan\n",
    "    \n",
    "    # Add outliers\n",
    "    mask = np.random.random(n) < issue_rate / 2\n",
    "    df_copy.loc[mask, \"age\"] = np.random.choice([0, -5, 150, 200], mask.sum())\n",
    "    \n",
    "    # Add duplicates\n",
    "    n_duplicates = int(n * issue_rate)\n",
    "    duplicates = df_copy.sample(n=n_duplicates, replace=True)\n",
    "    df_copy = pd.concat([df_copy, duplicates], ignore_index=True)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Create data with quality issues\n",
    "current_with_issues = add_quality_issues(current_data_mild, issue_rate=0.15)\n",
    "print(f\"üìä Created data with quality issues: {len(current_with_issues)} samples\")\n",
    "print(f\"   Missing values: {current_with_issues.isnull().sum().sum()}\")\n",
    "print(f\"   Invalid ages: {(current_with_issues['age'] < 0).sum() + (current_with_issues['age'] > 120).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data quality report\n",
    "print(\"üìä Creating Data Quality Report...\")\n",
    "\n",
    "quality_report = Report(metrics=[\n",
    "    DataQualityPreset(),\n",
    "])\n",
    "\n",
    "quality_report.run(\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_with_issues,\n",
    "    column_mapping=column_mapping\n",
    ")\n",
    "\n",
    "quality_report_path = REPORTS_DIR / \"data_quality_report.html\"\n",
    "quality_report.save_html(str(quality_report_path))\n",
    "print(f\"‚úÖ Report saved to: {quality_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract quality metrics\n",
    "quality_results = quality_report.as_dict()\n",
    "\n",
    "print(\"\\nüìä DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for metric in quality_results.get(\"metrics\", []):\n",
    "    result = metric.get(\"result\", {})\n",
    "    \n",
    "    if \"current\" in result:\n",
    "        current = result[\"current\"]\n",
    "        if \"number_of_missing_values\" in current:\n",
    "            print(f\"\\nüìã Current Data:\")\n",
    "            print(f\"   Total rows: {current.get('number_of_rows', 'N/A')}\")\n",
    "            print(f\"   Missing values: {current.get('number_of_missing_values', 0)}\")\n",
    "            print(f\"   Duplicate rows: {current.get('number_of_duplicated_rows', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Target and Prediction Drift\n",
    "\n",
    "Monitor how predictions and actual outcomes change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target drift report\n",
    "print(\"üìä Creating Target Drift Report...\")\n",
    "\n",
    "target_drift_report = Report(metrics=[\n",
    "    TargetDriftPreset(),\n",
    "])\n",
    "\n",
    "target_drift_report.run(\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_data_severe,\n",
    "    column_mapping=column_mapping\n",
    ")\n",
    "\n",
    "target_report_path = REPORTS_DIR / \"target_drift_report.html\"\n",
    "target_drift_report.save_html(str(target_report_path))\n",
    "print(f\"‚úÖ Report saved to: {target_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction drift\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Prediction distribution\n",
    "axes[0].hist(reference_data[\"prediction\"], bins=3, alpha=0.5, label=\"Reference\", density=True)\n",
    "axes[0].hist(current_data_severe[\"prediction\"], bins=3, alpha=0.5, label=\"Current (severe)\", density=True)\n",
    "axes[0].set_xlabel(\"Prediction\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "axes[0].set_title(\"Prediction Distribution\")\n",
    "axes[0].legend()\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels([\"Rejected\", \"Approved\"])\n",
    "\n",
    "# Prediction probability distribution\n",
    "axes[1].hist(reference_data[\"prediction_prob\"], bins=30, alpha=0.5, label=\"Reference\", density=True)\n",
    "axes[1].hist(current_data_severe[\"prediction_prob\"], bins=30, alpha=0.5, label=\"Current (severe)\", density=True)\n",
    "axes[1].set_xlabel(\"Approval Probability\")\n",
    "axes[1].set_ylabel(\"Density\")\n",
    "axes[1].set_title(\"Prediction Probability Distribution\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle(\"Prediction Drift Analysis\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / \"prediction_drift.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Building a Monitoring System\n",
    "\n",
    "Let's create a reusable monitoring system for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MonitoringConfig:\n",
    "    \"\"\"Configuration for drift monitoring.\"\"\"\n",
    "    drift_threshold: float = 0.5  # Fraction of drifted columns to alert\n",
    "    quality_threshold: float = 0.05  # Max fraction of missing values\n",
    "    alert_email: Optional[str] = None\n",
    "    alert_slack_webhook: Optional[str] = None\n",
    "    save_reports: bool = True\n",
    "    report_dir: str = \"./reports\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MonitoringResult:\n",
    "    \"\"\"Result of a monitoring check.\"\"\"\n",
    "    timestamp: datetime\n",
    "    drift_detected: bool\n",
    "    drift_share: float\n",
    "    drifted_columns: List[str]\n",
    "    quality_issues: Dict[str, Any]\n",
    "    alert_triggered: bool\n",
    "    report_path: Optional[str] = None\n",
    "\n",
    "\n",
    "class ProductionMonitor:\n",
    "    \"\"\"\n",
    "    Production monitoring system for ML models.\n",
    "    \n",
    "    Tracks data drift, prediction drift, and data quality.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, reference_data: pd.DataFrame, column_mapping: ColumnMapping,\n",
    "                 config: MonitoringConfig = None):\n",
    "        self.reference_data = reference_data\n",
    "        self.column_mapping = column_mapping\n",
    "        self.config = config or MonitoringConfig()\n",
    "        self.history: List[MonitoringResult] = []\n",
    "        \n",
    "        # Ensure report directory exists\n",
    "        Path(self.config.report_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def check(self, current_data: pd.DataFrame, batch_id: str = None) -> MonitoringResult:\n",
    "        \"\"\"\n",
    "        Run a monitoring check on current data.\n",
    "        \n",
    "        Args:\n",
    "            current_data: Current production data\n",
    "            batch_id: Optional identifier for this batch\n",
    "        \n",
    "        Returns:\n",
    "            MonitoringResult with drift and quality analysis\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        batch_id = batch_id or timestamp.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Run drift detection\n",
    "        drift_report = Report(metrics=[DataDriftPreset()])\n",
    "        drift_report.run(\n",
    "            reference_data=self.reference_data,\n",
    "            current_data=current_data,\n",
    "            column_mapping=self.column_mapping\n",
    "        )\n",
    "        \n",
    "        drift_summary = extract_drift_summary(drift_report)\n",
    "        \n",
    "        # Check data quality\n",
    "        quality_issues = {\n",
    "            \"missing_rate\": current_data.isnull().mean().mean(),\n",
    "            \"columns_with_missing\": current_data.columns[current_data.isnull().any()].tolist()\n",
    "        }\n",
    "        \n",
    "        # Determine if alert should be triggered\n",
    "        alert_triggered = (\n",
    "            drift_summary[\"drift_share\"] > self.config.drift_threshold or\n",
    "            quality_issues[\"missing_rate\"] > self.config.quality_threshold\n",
    "        )\n",
    "        \n",
    "        # Save report if configured\n",
    "        report_path = None\n",
    "        if self.config.save_reports:\n",
    "            report_path = str(Path(self.config.report_dir) / f\"monitor_{batch_id}.html\")\n",
    "            drift_report.save_html(report_path)\n",
    "        \n",
    "        # Create result\n",
    "        result = MonitoringResult(\n",
    "            timestamp=timestamp,\n",
    "            drift_detected=drift_summary[\"dataset_drift_detected\"],\n",
    "            drift_share=drift_summary[\"drift_share\"],\n",
    "            drifted_columns=drift_summary[\"drifted_columns\"],\n",
    "            quality_issues=quality_issues,\n",
    "            alert_triggered=alert_triggered,\n",
    "            report_path=report_path\n",
    "        )\n",
    "        \n",
    "        # Store in history\n",
    "        self.history.append(result)\n",
    "        \n",
    "        # Send alert if triggered\n",
    "        if alert_triggered:\n",
    "            self._send_alert(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _send_alert(self, result: MonitoringResult):\n",
    "        \"\"\"Send alert notification.\"\"\"\n",
    "        alert_message = f\"\"\"\n",
    "üö® ML MONITORING ALERT\n",
    "=======================\n",
    "Timestamp: {result.timestamp}\n",
    "Drift Detected: {result.drift_detected}\n",
    "Drift Share: {result.drift_share:.1%}\n",
    "Drifted Columns: {result.drifted_columns}\n",
    "Missing Rate: {result.quality_issues['missing_rate']:.1%}\n",
    "Report: {result.report_path}\n",
    "\"\"\"\n",
    "        print(alert_message)\n",
    "        \n",
    "        # In production, you'd send to email/Slack here\n",
    "        # if self.config.alert_email:\n",
    "        #     send_email(self.config.alert_email, alert_message)\n",
    "    \n",
    "    def get_trend(self, metric: str = \"drift_share\", last_n: int = 10) -> List[float]:\n",
    "        \"\"\"Get trend of a metric over time.\"\"\"\n",
    "        return [getattr(r, metric) for r in self.history[-last_n:]]\n",
    "    \n",
    "    def plot_history(self):\n",
    "        \"\"\"Plot monitoring history.\"\"\"\n",
    "        if not self.history:\n",
    "            print(\"No monitoring history available\")\n",
    "            return\n",
    "        \n",
    "        timestamps = [r.timestamp for r in self.history]\n",
    "        drift_shares = [r.drift_share for r in self.history]\n",
    "        missing_rates = [r.quality_issues[\"missing_rate\"] for r in self.history]\n",
    "        alerts = [r.alert_triggered for r in self.history]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "        \n",
    "        # Drift share over time\n",
    "        axes[0].plot(timestamps, drift_shares, 'b-o', label='Drift Share')\n",
    "        axes[0].axhline(y=self.config.drift_threshold, color='r', linestyle='--', label='Threshold')\n",
    "        axes[0].fill_between(timestamps, 0, drift_shares, alpha=0.3)\n",
    "        axes[0].set_ylabel('Drift Share')\n",
    "        axes[0].set_title('Data Drift Over Time')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Mark alerts\n",
    "        for i, (t, alert) in enumerate(zip(timestamps, alerts)):\n",
    "            if alert:\n",
    "                axes[0].axvline(x=t, color='red', alpha=0.3)\n",
    "        \n",
    "        # Missing rate over time\n",
    "        axes[1].plot(timestamps, missing_rates, 'g-o', label='Missing Rate')\n",
    "        axes[1].axhline(y=self.config.quality_threshold, color='r', linestyle='--', label='Threshold')\n",
    "        axes[1].fill_between(timestamps, 0, missing_rates, alpha=0.3, color='green')\n",
    "        axes[1].set_xlabel('Time')\n",
    "        axes[1].set_ylabel('Missing Rate')\n",
    "        axes[1].set_title('Data Quality Over Time')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úÖ ProductionMonitor class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Run the monitoring system\n",
    "print(\"üî¨ Running Production Monitoring Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize monitor\n",
    "config = MonitoringConfig(\n",
    "    drift_threshold=0.3,\n",
    "    quality_threshold=0.05,\n",
    "    report_dir=str(REPORTS_DIR)\n",
    ")\n",
    "\n",
    "monitor = ProductionMonitor(\n",
    "    reference_data=reference_data,\n",
    "    column_mapping=column_mapping,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Simulate multiple monitoring checks over time\n",
    "drift_levels = [0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.4, 0.3]\n",
    "\n",
    "for i, drift in enumerate(drift_levels):\n",
    "    # Generate data with varying drift\n",
    "    current = generate_loan_data(n_samples=500, drift_factor=drift, seed=i*100)\n",
    "    \n",
    "    # Run monitoring check\n",
    "    result = monitor.check(current, batch_id=f\"batch_{i:03d}\")\n",
    "    \n",
    "    status = \"üö®\" if result.alert_triggered else \"‚úÖ\"\n",
    "    print(f\"Batch {i}: drift={drift:.1f} -> {status} share={result.drift_share:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize monitoring history\n",
    "monitor.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Integrating with MLflow\n",
    "\n",
    "Log monitoring results to MLflow for comprehensive tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Setup MLflow\n",
    "MLFLOW_DIR = MODULE_DIR / \"mlflow\"\n",
    "mlflow.set_tracking_uri(f\"file://{MLFLOW_DIR}\")\n",
    "mlflow.set_experiment(\"Model-Monitoring\")\n",
    "\n",
    "print(f\"üìä MLflow tracking: {MLFLOW_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_monitoring_to_mlflow(result: MonitoringResult, model_name: str = \"loan-classifier\"):\n",
    "    \"\"\"\n",
    "    Log monitoring results to MLflow.\n",
    "    \n",
    "    Args:\n",
    "        result: MonitoringResult from a check\n",
    "        model_name: Name of the model being monitored\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=f\"monitor_{result.timestamp.strftime('%Y%m%d_%H%M%S')}\"):\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"check_timestamp\", result.timestamp.isoformat())\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"drift_detected\", int(result.drift_detected))\n",
    "        mlflow.log_metric(\"drift_share\", result.drift_share)\n",
    "        mlflow.log_metric(\"num_drifted_columns\", len(result.drifted_columns))\n",
    "        mlflow.log_metric(\"missing_rate\", result.quality_issues[\"missing_rate\"])\n",
    "        mlflow.log_metric(\"alert_triggered\", int(result.alert_triggered))\n",
    "        \n",
    "        # Log drifted columns as param\n",
    "        if result.drifted_columns:\n",
    "            mlflow.log_param(\"drifted_columns\", \", \".join(result.drifted_columns[:10]))\n",
    "        \n",
    "        # Log report as artifact\n",
    "        if result.report_path:\n",
    "            mlflow.log_artifact(result.report_path, artifact_path=\"drift_reports\")\n",
    "        \n",
    "        # Set tags\n",
    "        mlflow.set_tag(\"type\", \"monitoring\")\n",
    "        mlflow.set_tag(\"alert_status\", \"alert\" if result.alert_triggered else \"ok\")\n",
    "\n",
    "\n",
    "# Log our monitoring history\n",
    "print(\"üìä Logging monitoring history to MLflow...\")\n",
    "for result in monitor.history:\n",
    "    log_monitoring_to_mlflow(result)\n",
    "\n",
    "print(f\"‚úÖ Logged {len(monitor.history)} monitoring checks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Exercise\n",
    "\n",
    "**Task:** Create a monitoring system for your use case.\n",
    "\n",
    "1. Create synthetic data representing your domain\n",
    "2. Simulate drift scenarios relevant to your use case\n",
    "3. Set up monitoring with appropriate thresholds\n",
    "4. Run multiple checks and analyze trends\n",
    "5. Log results to MLflow\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "```python\n",
    "# Example: E-commerce product recommendations\n",
    "def generate_ecommerce_data(n_samples, drift_factor=0.0):\n",
    "    return pd.DataFrame({\n",
    "        \"user_age\": np.random.normal(35 + drift_factor*10, 10, n_samples),\n",
    "        \"session_duration\": np.random.exponential(5 - drift_factor, n_samples),\n",
    "        \"items_viewed\": np.random.poisson(10 + drift_factor*5, n_samples),\n",
    "        \"cart_value\": np.random.lognormal(4 + drift_factor*0.5, 1, n_samples),\n",
    "        \"purchased\": np.random.binomial(1, 0.3 + drift_factor*0.2, n_samples)\n",
    "    })\n",
    "\n",
    "# Create monitor with custom thresholds\n",
    "config = MonitoringConfig(drift_threshold=0.4, quality_threshold=0.02)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Create synthetic data\n",
    "\n",
    "\n",
    "# Step 2: Simulate drift scenarios\n",
    "\n",
    "\n",
    "# Step 3: Set up monitoring\n",
    "\n",
    "\n",
    "# Step 4: Run checks and analyze\n",
    "\n",
    "\n",
    "# Step 5: Log to MLflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Using Wrong Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Using test data as reference\n",
    "# reference = test_set  # This wasn't what the model was trained on!\n",
    "\n",
    "# ‚úÖ RIGHT: Use training data distribution\n",
    "# reference = training_set  # Or a representative sample of it\n",
    "\n",
    "print(\"Reference data should match what the model was trained on!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Ignoring Seasonal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Alerting on expected seasonal changes\n",
    "# December shopping data will always differ from June!\n",
    "\n",
    "# ‚úÖ RIGHT: Use season-appropriate reference data\n",
    "# reference_december = get_last_year_december_data()\n",
    "# Or: Adjust thresholds for known seasonal periods\n",
    "\n",
    "print(\"Consider seasonality when setting drift thresholds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 3: Not Monitoring Prediction Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Only monitoring input features\n",
    "# Features might look fine, but predictions could be all wrong!\n",
    "\n",
    "# ‚úÖ RIGHT: Monitor both inputs AND outputs\n",
    "# - Input feature distributions\n",
    "# - Prediction distributions  \n",
    "# - Prediction confidence distributions\n",
    "# - Actual outcome distributions (when available)\n",
    "\n",
    "print(\"Monitor predictions AND inputs for complete coverage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Understanding data drift, concept drift, and prediction drift\n",
    "- ‚úÖ Creating drift reports with Evidently AI\n",
    "- ‚úÖ Monitoring data quality in production\n",
    "- ‚úÖ Building automated monitoring systems with alerting\n",
    "- ‚úÖ Integrating monitoring with MLflow\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [Evidently AI Documentation](https://docs.evidentlyai.com/)\n",
    "- [Data Drift in ML (Google)](https://developers.google.com/machine-learning/guides/rules-of-ml#rule_37_measure_training_serving_skew)\n",
    "- [Concept Drift Paper](https://arxiv.org/abs/2004.05785)\n",
    "- [WhyLogs for Monitoring](https://whylabs.ai/whylogs)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "plt.close('all')\n",
    "gc.collect()\n",
    "\n",
    "print(f\"üìÅ Reports saved to: {REPORTS_DIR}\")\n",
    "print(f\"üìä MLflow data saved to: {MLFLOW_DIR}\")\n",
    "print(\"\\n‚úÖ Resources cleaned up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "In this lab, we:\n",
    "\n",
    "1. **Learned** about data drift, concept drift, and prediction drift\n",
    "2. **Created** drift and quality reports with Evidently AI\n",
    "3. **Built** a production monitoring system with alerting\n",
    "4. **Integrated** monitoring with MLflow for tracking\n",
    "5. **Practiced** detecting and responding to drift scenarios\n",
    "\n",
    "**Next up:** Lab 4.3.6 - Model Registry and Versioning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
