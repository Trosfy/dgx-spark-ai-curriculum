{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.2.3: FP8 Training and Inference - Solutions\n",
    "\n",
    "This notebook contains solutions for all exercises in Lab 3.2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts import quantize_to_fp8, dequantize_from_fp8, FP8_E4M3, FP8_E5M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 Solution: Custom Delayed Scaling Implementation\n",
    "\n",
    "Implement delayed scaling with history-based scale computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayedScalingFP8:\n",
    "    \"\"\"\n",
    "    Delayed scaling for FP8 training with history tracking.\n",
    "    \n",
    "    Instead of computing scales per-tensor, uses a moving average\n",
    "    of historical max values for stability.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, history_length: int = 16, momentum: float = 0.9):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            history_length: Number of iterations to track\n",
    "            momentum: EMA momentum for scale updates\n",
    "        \"\"\"\n",
    "        self.history_length = history_length\n",
    "        self.momentum = momentum\n",
    "        self.amax_history = []\n",
    "        self.current_scale = 1.0\n",
    "        self.fp8_max = FP8_E4M3.max_val\n",
    "    \n",
    "    def update_amax(self, tensor: np.ndarray):\n",
    "        \"\"\"Update amax history with new tensor.\"\"\"\n",
    "        amax = np.abs(tensor).max()\n",
    "        self.amax_history.append(amax)\n",
    "        \n",
    "        # Keep only recent history\n",
    "        if len(self.amax_history) > self.history_length:\n",
    "            self.amax_history.pop(0)\n",
    "    \n",
    "    def compute_scale(self) -> float:\n",
    "        \"\"\"Compute scale from history using max of history.\"\"\"\n",
    "        if not self.amax_history:\n",
    "            return 1.0\n",
    "        \n",
    "        # Use max of recent history for robustness\n",
    "        historical_max = max(self.amax_history)\n",
    "        \n",
    "        # Scale to fit in FP8 range\n",
    "        new_scale = self.fp8_max / (historical_max + 1e-10)\n",
    "        \n",
    "        # Apply momentum for stability\n",
    "        self.current_scale = self.momentum * self.current_scale + (1 - self.momentum) * new_scale\n",
    "        \n",
    "        return self.current_scale\n",
    "    \n",
    "    def quantize(self, tensor: np.ndarray) -> tuple:\n",
    "        \"\"\"\n",
    "        Quantize tensor using delayed scaling.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (quantized_tensor, scale)\n",
    "        \"\"\"\n",
    "        # Update history\n",
    "        self.update_amax(tensor)\n",
    "        \n",
    "        # Get scale from history (delayed)\n",
    "        scale = self.compute_scale()\n",
    "        \n",
    "        # Scale and quantize\n",
    "        scaled = tensor * scale\n",
    "        quantized = np.clip(scaled, -self.fp8_max, self.fp8_max)\n",
    "        \n",
    "        return quantized, scale\n",
    "    \n",
    "    def dequantize(self, quantized: np.ndarray, scale: float) -> np.ndarray:\n",
    "        \"\"\"Dequantize using stored scale.\"\"\"\n",
    "        return quantized / scale\n",
    "\n",
    "\n",
    "# Simulate training with varying activation magnitudes\n",
    "np.random.seed(42)\n",
    "\n",
    "delayed_scaler = DelayedScalingFP8(history_length=16, momentum=0.9)\n",
    "\n",
    "print(\"Delayed Scaling FP8 Simulation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Simulate 100 iterations with changing activation patterns\n",
    "scales = []\n",
    "amaxs = []\n",
    "\n",
    "for i in range(100):\n",
    "    # Simulate activations with varying magnitude\n",
    "    magnitude = 1.0 + 0.5 * np.sin(i / 10)  # Oscillating magnitude\n",
    "    if i == 50:  # Sudden spike\n",
    "        magnitude = 3.0\n",
    "    \n",
    "    activations = np.random.randn(256, 256).astype(np.float32) * magnitude\n",
    "    \n",
    "    quantized, scale = delayed_scaler.quantize(activations)\n",
    "    \n",
    "    scales.append(scale)\n",
    "    amaxs.append(np.abs(activations).max())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(amaxs, label='Actual Amax', alpha=0.7)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Amax')\n",
    "ax1.set_title('Activation Maximum Over Training')\n",
    "ax1.axvline(50, color='r', linestyle='--', alpha=0.5, label='Spike')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.plot(scales, label='Delayed Scale', color='orange')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Scale')\n",
    "ax2.set_title('Delayed Scaling Response')\n",
    "ax2.axvline(50, color='r', linestyle='--', alpha=0.5, label='Spike')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Delayed scaling smooths out sudden spikes for training stability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 Solution: E4M3 vs E5M2 Decision Framework\n",
    "\n",
    "Build a decision framework for choosing between FP8 formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tensor_for_fp8(tensor: np.ndarray, name: str = \"tensor\") -> dict:\n",
    "    \"\"\"\n",
    "    Analyze a tensor and recommend optimal FP8 format.\n",
    "    \n",
    "    Args:\n",
    "        tensor: Input tensor\n",
    "        name: Tensor name for reporting\n",
    "        \n",
    "    Returns:\n",
    "        Analysis and recommendation\n",
    "    \"\"\"\n",
    "    # Statistics\n",
    "    abs_vals = np.abs(tensor)\n",
    "    max_val = abs_vals.max()\n",
    "    min_nonzero = abs_vals[abs_vals > 0].min() if np.any(abs_vals > 0) else 0\n",
    "    mean_val = abs_vals.mean()\n",
    "    std_val = tensor.std()\n",
    "    \n",
    "    # Dynamic range\n",
    "    dynamic_range = np.log2(max_val / min_nonzero) if min_nonzero > 0 else float('inf')\n",
    "    \n",
    "    # Outlier analysis\n",
    "    outlier_threshold = mean_val + 3 * std_val\n",
    "    outlier_ratio = np.mean(abs_vals > outlier_threshold)\n",
    "    \n",
    "    # Quantize with both formats and compare\n",
    "    quant_e4m3, _ = quantize_to_fp8(tensor, FP8_E4M3)\n",
    "    quant_e5m2, _ = quantize_to_fp8(tensor, FP8_E5M2)\n",
    "    \n",
    "    dequant_e4m3 = dequantize_from_fp8(quant_e4m3, 1.0, FP8_E4M3)\n",
    "    dequant_e5m2 = dequantize_from_fp8(quant_e5m2, 1.0, FP8_E5M2)\n",
    "    \n",
    "    mse_e4m3 = np.mean((tensor - dequant_e4m3) ** 2)\n",
    "    mse_e5m2 = np.mean((tensor - dequant_e5m2) ** 2)\n",
    "    \n",
    "    # Decision logic\n",
    "    if dynamic_range > 10:  # Wide dynamic range\n",
    "        recommendation = \"E5M2\"\n",
    "        reason = \"Wide dynamic range requires more exponent bits\"\n",
    "    elif outlier_ratio > 0.01:  # Many outliers\n",
    "        recommendation = \"E5M2\"\n",
    "        reason = \"High outlier ratio needs larger value range\"\n",
    "    elif mse_e4m3 < mse_e5m2 * 0.8:  # E4M3 significantly better\n",
    "        recommendation = \"E4M3\"\n",
    "        reason = \"Higher precision benefits this tensor\"\n",
    "    else:\n",
    "        recommendation = \"E4M3\"  # Default for inference\n",
    "        reason = \"Standard choice for inference\"\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'max_value': max_val,\n",
    "        'dynamic_range_bits': dynamic_range,\n",
    "        'outlier_ratio': outlier_ratio,\n",
    "        'mse_e4m3': mse_e4m3,\n",
    "        'mse_e5m2': mse_e5m2,\n",
    "        'recommendation': recommendation,\n",
    "        'reason': reason\n",
    "    }\n",
    "\n",
    "\n",
    "# Test with different tensor types\n",
    "np.random.seed(42)\n",
    "\n",
    "tensors = {\n",
    "    'weights': np.random.randn(1000, 1000).astype(np.float32) * 0.02,\n",
    "    'activations': np.random.randn(1000, 1000).astype(np.float32),\n",
    "    'gradients': np.random.standard_t(5, (1000, 1000)).astype(np.float32) * 0.01,\n",
    "    'embeddings': np.random.randn(1000, 1000).astype(np.float32) * 0.5,\n",
    "}\n",
    "\n",
    "print(\"FP8 Format Recommendation Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, tensor in tensors.items():\n",
    "    result = analyze_tensor_for_fp8(tensor, name)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Dynamic range: {result['dynamic_range_bits']:.1f} bits\")\n",
    "    print(f\"  Outlier ratio: {result['outlier_ratio']*100:.2f}%\")\n",
    "    print(f\"  MSE E4M3: {result['mse_e4m3']:.6f}\")\n",
    "    print(f\"  MSE E5M2: {result['mse_e5m2']:.6f}\")\n",
    "    print(f\"  Recommendation: {result['recommendation']}\")\n",
    "    print(f\"  Reason: {result['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 Solution: FP8 Training Loop\n",
    "\n",
    "Implement a complete FP8 training loop with mixed precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FP8TrainingSimulator:\n",
    "    \"\"\"\n",
    "    Simulates FP8 training with proper forward/backward handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Simple 2-layer MLP\n",
    "        self.w1 = np.random.randn(64, 128).astype(np.float32) * 0.01\n",
    "        self.w2 = np.random.randn(10, 64).astype(np.float32) * 0.01\n",
    "        \n",
    "        # FP8 scalers\n",
    "        self.act_scaler = DelayedScalingFP8()\n",
    "        self.grad_scaler = DelayedScalingFP8()\n",
    "        \n",
    "        # Metrics\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def forward_fp8(self, x: np.ndarray) -> tuple:\n",
    "        \"\"\"Forward pass with FP8 activations.\"\"\"\n",
    "        # Layer 1\n",
    "        h1_fp32 = x @ self.w1.T\n",
    "        h1_fp8, scale1 = self.act_scaler.quantize(h1_fp32)\n",
    "        h1 = self.act_scaler.dequantize(h1_fp8, scale1)\n",
    "        a1 = np.maximum(0, h1)  # ReLU\n",
    "        \n",
    "        # Layer 2\n",
    "        h2_fp32 = a1 @ self.w2.T\n",
    "        h2_fp8, scale2 = self.act_scaler.quantize(h2_fp32)\n",
    "        h2 = self.act_scaler.dequantize(h2_fp8, scale2)\n",
    "        \n",
    "        return h2, (x, h1, a1, scale1, scale2)\n",
    "    \n",
    "    def backward_fp8(self, loss_grad: np.ndarray, cache: tuple) -> tuple:\n",
    "        \"\"\"Backward pass with FP8 gradients.\"\"\"\n",
    "        x, h1, a1, scale1, scale2 = cache\n",
    "        \n",
    "        # Gradient through layer 2\n",
    "        dw2 = loss_grad.T @ a1\n",
    "        da1 = loss_grad @ self.w2\n",
    "        \n",
    "        # Quantize gradients to FP8 (E5M2 for training)\n",
    "        da1_fp8, grad_scale = self.grad_scaler.quantize(da1)\n",
    "        da1 = self.grad_scaler.dequantize(da1_fp8, grad_scale)\n",
    "        \n",
    "        # ReLU backward\n",
    "        dh1 = da1 * (h1 > 0)\n",
    "        \n",
    "        # Gradient through layer 1\n",
    "        dw1 = dh1.T @ x\n",
    "        \n",
    "        return dw1, dw2\n",
    "    \n",
    "    def train_step(self, x: np.ndarray, y: np.ndarray, lr: float = 0.01) -> float:\n",
    "        \"\"\"Single training step.\"\"\"\n",
    "        # Forward\n",
    "        pred, cache = self.forward_fp8(x)\n",
    "        \n",
    "        # Loss (MSE)\n",
    "        loss = np.mean((pred - y) ** 2)\n",
    "        loss_grad = 2 * (pred - y) / pred.shape[0]\n",
    "        \n",
    "        # Backward\n",
    "        dw1, dw2 = self.backward_fp8(loss_grad, cache)\n",
    "        \n",
    "        # Update weights\n",
    "        self.w1 -= lr * dw1\n",
    "        self.w2 -= lr * dw2\n",
    "        \n",
    "        self.loss_history.append(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Train simulation\n",
    "np.random.seed(42)\n",
    "\n",
    "simulator = FP8TrainingSimulator()\n",
    "\n",
    "print(\"FP8 Training Simulation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generate synthetic data\n",
    "X = np.random.randn(100, 128).astype(np.float32)\n",
    "Y = np.random.randn(100, 10).astype(np.float32)\n",
    "\n",
    "# Train for 100 steps\n",
    "for step in range(100):\n",
    "    # Mini-batch\n",
    "    idx = np.random.choice(100, 32)\n",
    "    loss = simulator.train_step(X[idx], Y[idx], lr=0.01)\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(f\"Step {step}: Loss = {loss:.4f}\")\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(simulator.loss_history)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('FP8 Training Loss Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal loss: {simulator.loss_history[-1]:.4f}\")\n",
    "print(\"FP8 training converged successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings:\n",
    "\n",
    "1. **Delayed scaling** provides training stability by smoothing scale updates\n",
    "2. **E4M3** is preferred for inference (higher precision)\n",
    "3. **E5M2** is preferred for gradients (larger dynamic range)\n",
    "4. **FP8 training** converges similarly to FP16 with proper scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
