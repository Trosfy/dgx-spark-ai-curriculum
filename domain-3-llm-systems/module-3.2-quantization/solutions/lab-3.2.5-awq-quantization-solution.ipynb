{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.2.5: AWQ Quantization - Solutions\n",
    "\n",
    "This notebook contains solutions for all exercises in Lab 3.2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 Solution: Salient Weight Detection\n",
    "\n",
    "Implement salient weight detection using activation statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_salient_weights(\n",
    "    weights: np.ndarray,\n",
    "    activations: np.ndarray,\n",
    "    percentile: float = 99.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect salient (important) weights based on activation patterns.\n",
    "    \n",
    "    AWQ key insight: Weights that multiply large activations are important.\n",
    "    \n",
    "    Args:\n",
    "        weights: Weight matrix (out_features, in_features)\n",
    "        activations: Calibration activations (batch, in_features)\n",
    "        percentile: Percentile threshold for saliency\n",
    "        \n",
    "    Returns:\n",
    "        Saliency mask (in_features,)\n",
    "    \"\"\"\n",
    "    # Compute activation importance per input channel\n",
    "    # Higher activation magnitude = more important\n",
    "    activation_importance = np.mean(np.abs(activations), axis=0)\n",
    "    \n",
    "    # Compute weight importance\n",
    "    weight_magnitude = np.mean(np.abs(weights), axis=0)\n",
    "    \n",
    "    # Combined importance: channels with large weights AND large activations\n",
    "    combined_importance = activation_importance * weight_magnitude\n",
    "    \n",
    "    # Find threshold\n",
    "    threshold = np.percentile(combined_importance, percentile)\n",
    "    \n",
    "    # Create saliency mask\n",
    "    salient_mask = combined_importance >= threshold\n",
    "    \n",
    "    return salient_mask, combined_importance\n",
    "\n",
    "\n",
    "# Test salient weight detection\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate weights with some important channels\n",
    "weights = np.random.randn(256, 512).astype(np.float32) * 0.02\n",
    "# Make some channels more important\n",
    "weights[:, 100:110] *= 5  # Larger weights\n",
    "\n",
    "# Simulate activations\n",
    "activations = np.random.randn(100, 512).astype(np.float32)\n",
    "# Make corresponding channels have larger activations\n",
    "activations[:, 100:110] *= 3\n",
    "\n",
    "# Detect salient weights\n",
    "salient_mask, importance = detect_salient_weights(weights, activations, percentile=95)\n",
    "\n",
    "print(\"Salient Weight Detection\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total channels: {len(salient_mask)}\")\n",
    "print(f\"Salient channels: {salient_mask.sum()}\")\n",
    "print(f\"Salient ratio: {salient_mask.mean()*100:.1f}%\")\n",
    "\n",
    "# Verify detection\n",
    "detected_important = set(np.where(salient_mask)[0])\n",
    "actual_important = set(range(100, 110))\n",
    "overlap = detected_important & actual_important\n",
    "print(f\"\\nActual important channels: {sorted(actual_important)}\")\n",
    "print(f\"Detected as salient: {len(overlap)}/{len(actual_important)}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(importance)), importance, width=1.0, alpha=0.7)\n",
    "plt.axhline(np.percentile(importance, 95), color='r', linestyle='--', label='95th percentile')\n",
    "plt.xlabel('Channel Index')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Channel Importance (AWQ Saliency)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 Solution: AWQ Scale Search\n",
    "\n",
    "Implement the AWQ scale search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awq_scale_search(\n",
    "    weights: np.ndarray,\n",
    "    activations: np.ndarray,\n",
    "    bits: int = 4,\n",
    "    n_grid: int = 20\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Search for optimal per-channel scales using AWQ algorithm.\n",
    "    \n",
    "    Args:\n",
    "        weights: Weight matrix (out_features, in_features)\n",
    "        activations: Calibration activations (batch, in_features)\n",
    "        bits: Quantization bits\n",
    "        n_grid: Grid search points\n",
    "        \n",
    "    Returns:\n",
    "        Optimal scales per channel (in_features,)\n",
    "    \"\"\"\n",
    "    out_features, in_features = weights.shape\n",
    "    qmax = 2 ** bits - 1\n",
    "    \n",
    "    # Compute activation statistics\n",
    "    act_scales = np.mean(np.abs(activations), axis=0)\n",
    "    \n",
    "    # Search range for scale factors\n",
    "    alphas = np.linspace(0.1, 1.0, n_grid)\n",
    "    \n",
    "    best_scales = np.ones(in_features, dtype=np.float32)\n",
    "    \n",
    "    # Search for each channel\n",
    "    for c in range(in_features):\n",
    "        w_col = weights[:, c]\n",
    "        a_col = activations[:, c]\n",
    "        \n",
    "        # Reference output\n",
    "        ref_out = np.outer(a_col, w_col)  # (batch, out_features)\n",
    "        \n",
    "        best_error = float('inf')\n",
    "        best_scale = 1.0\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            # AWQ scales weights by activation importance\n",
    "            scale = act_scales[c] ** alpha if act_scales[c] > 0 else 1.0\n",
    "            scale = max(scale, 1e-10)  # Avoid zero\n",
    "            \n",
    "            # Scale weights up, then quantize\n",
    "            w_scaled = w_col * scale\n",
    "            \n",
    "            # Quantize\n",
    "            w_min, w_max = w_scaled.min(), w_scaled.max()\n",
    "            q_scale = (w_max - w_min) / qmax\n",
    "            w_quant = np.clip(np.round((w_scaled - w_min) / (q_scale + 1e-10)), 0, qmax)\n",
    "            w_dequant = w_quant * q_scale + w_min\n",
    "            \n",
    "            # Scale back down\n",
    "            w_final = w_dequant / scale\n",
    "            \n",
    "            # Compute output error\n",
    "            test_out = np.outer(a_col, w_final)\n",
    "            error = np.mean((test_out - ref_out) ** 2)\n",
    "            \n",
    "            if error < best_error:\n",
    "                best_error = error\n",
    "                best_scale = scale\n",
    "        \n",
    "        best_scales[c] = best_scale\n",
    "    \n",
    "    return best_scales\n",
    "\n",
    "\n",
    "# Test AWQ scale search\n",
    "np.random.seed(42)\n",
    "\n",
    "weights = np.random.randn(64, 128).astype(np.float32) * 0.02\n",
    "activations = np.random.randn(100, 128).astype(np.float32)\n",
    "\n",
    "print(\"AWQ Scale Search\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "scales = awq_scale_search(weights, activations, bits=4, n_grid=20)\n",
    "\n",
    "print(f\"Scale range: [{scales.min():.4f}, {scales.max():.4f}]\")\n",
    "print(f\"Mean scale: {scales.mean():.4f}\")\n",
    "\n",
    "# Compare with and without AWQ scales\n",
    "def quantize_naive(w, bits=4):\n",
    "    qmax = 2**bits - 1\n",
    "    scale = (w.max() - w.min()) / qmax\n",
    "    q = np.clip(np.round((w - w.min()) / (scale + 1e-10)), 0, qmax)\n",
    "    return q * scale + w.min()\n",
    "\n",
    "def quantize_awq(w, awq_scales, bits=4):\n",
    "    # Scale up\n",
    "    w_scaled = w * awq_scales\n",
    "    # Quantize\n",
    "    w_quant = quantize_naive(w_scaled, bits)\n",
    "    # Scale back\n",
    "    return w_quant / awq_scales\n",
    "\n",
    "w_naive = quantize_naive(weights)\n",
    "w_awq = quantize_awq(weights, scales)\n",
    "\n",
    "# Compute output errors\n",
    "ref_output = activations @ weights.T\n",
    "naive_output = activations @ w_naive.T\n",
    "awq_output = activations @ w_awq.T\n",
    "\n",
    "naive_error = np.mean((naive_output - ref_output) ** 2)\n",
    "awq_error = np.mean((awq_output - ref_output) ** 2)\n",
    "\n",
    "print(f\"\\nOutput Error Comparison:\")\n",
    "print(f\"  Naive quantization: {naive_error:.6f}\")\n",
    "print(f\"  AWQ quantization:   {awq_error:.6f}\")\n",
    "print(f\"  Improvement:        {naive_error/awq_error:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 Solution: AWQ vs GPTQ Comparison\n",
    "\n",
    "Systematically compare AWQ and GPTQ on the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_awq_gptq(\n",
    "    weights: np.ndarray,\n",
    "    activations: np.ndarray,\n",
    "    bits: int = 4\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compare AWQ and GPTQ on the same layer.\n",
    "    \n",
    "    Returns:\n",
    "        Comparison metrics\n",
    "    \"\"\"\n",
    "    in_features = weights.shape[1]\n",
    "    \n",
    "    # Reference output\n",
    "    ref_output = activations @ weights.T\n",
    "    \n",
    "    # Naive quantization\n",
    "    w_naive = quantize_naive(weights, bits)\n",
    "    naive_output = activations @ w_naive.T\n",
    "    naive_mse = np.mean((naive_output - ref_output) ** 2)\n",
    "    \n",
    "    # AWQ quantization\n",
    "    awq_scales = awq_scale_search(weights, activations, bits=bits, n_grid=20)\n",
    "    w_awq = quantize_awq(weights, awq_scales, bits)\n",
    "    awq_output = activations @ w_awq.T\n",
    "    awq_mse = np.mean((awq_output - ref_output) ** 2)\n",
    "    \n",
    "    # Simplified GPTQ (using Hessian approximation)\n",
    "    hessian = (activations.T @ activations) / len(activations)\n",
    "    hessian += 0.01 * np.eye(in_features) * np.mean(np.diag(hessian))\n",
    "    \n",
    "    # Simple GPTQ-style quantization with error compensation\n",
    "    w_gptq = weights.copy()\n",
    "    qmax = 2**bits - 1\n",
    "    \n",
    "    for i in range(in_features):\n",
    "        col = w_gptq[:, i]\n",
    "        scale = (col.max() - col.min()) / qmax\n",
    "        q = np.clip(np.round((col - col.min()) / (scale + 1e-10)), 0, qmax)\n",
    "        w_q = q * scale + col.min()\n",
    "        error = col - w_q\n",
    "        w_gptq[:, i] = w_q\n",
    "        \n",
    "        # Compensate error in remaining columns (simplified)\n",
    "        if i + 1 < in_features:\n",
    "            h_ii = hessian[i, i]\n",
    "            if h_ii > 1e-10:\n",
    "                correction = np.outer(error, hessian[i, i+1:] / h_ii)\n",
    "                w_gptq[:, i+1:] += correction\n",
    "    \n",
    "    gptq_output = activations @ w_gptq.T\n",
    "    gptq_mse = np.mean((gptq_output - ref_output) ** 2)\n",
    "    \n",
    "    return {\n",
    "        'naive_mse': naive_mse,\n",
    "        'awq_mse': awq_mse,\n",
    "        'gptq_mse': gptq_mse,\n",
    "        'awq_improvement': naive_mse / awq_mse,\n",
    "        'gptq_improvement': naive_mse / gptq_mse,\n",
    "        'awq_vs_gptq': gptq_mse / awq_mse\n",
    "    }\n",
    "\n",
    "\n",
    "# Run comparison across multiple layers\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"AWQ vs GPTQ Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "for trial in range(5):\n",
    "    weights = np.random.randn(128, 256).astype(np.float32) * 0.02\n",
    "    activations = np.random.randn(100, 256).astype(np.float32)\n",
    "    \n",
    "    result = compare_awq_gptq(weights, activations, bits=4)\n",
    "    results.append(result)\n",
    "\n",
    "# Average results\n",
    "avg_results = {k: np.mean([r[k] for r in results]) for k in results[0].keys()}\n",
    "\n",
    "print(f\"\\nAverage over 5 trials:\")\n",
    "print(f\"  Naive MSE:       {avg_results['naive_mse']:.6f}\")\n",
    "print(f\"  AWQ MSE:         {avg_results['awq_mse']:.6f}\")\n",
    "print(f\"  GPTQ MSE:        {avg_results['gptq_mse']:.6f}\")\n",
    "print(f\"\")\n",
    "print(f\"  AWQ vs Naive:    {avg_results['awq_improvement']:.2f}x better\")\n",
    "print(f\"  GPTQ vs Naive:   {avg_results['gptq_improvement']:.2f}x better\")\n",
    "print(f\"  AWQ vs GPTQ:     {avg_results['awq_vs_gptq']:.2f}x\")\n",
    "\n",
    "if avg_results['awq_vs_gptq'] > 1:\n",
    "    print(f\"\\nConclusion: AWQ achieves better quality than GPTQ\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: GPTQ achieves better quality than AWQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings:\n",
    "\n",
    "1. **Salient weight detection** correctly identifies important channels\n",
    "2. **AWQ scale search** finds per-channel scales that minimize output error\n",
    "3. **AWQ vs GPTQ**: AWQ is simpler (no Hessian inversion) but both achieve similar quality\n",
    "4. **AWQ is faster** to quantize since it doesn't require sequential column processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
