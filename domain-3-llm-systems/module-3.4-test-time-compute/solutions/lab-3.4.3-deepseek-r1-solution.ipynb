{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.4.3: DeepSeek-R1 Exploration - SOLUTIONS\n",
    "\n",
    "This notebook contains complete solutions to all exercises from Lab 3.4.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Model configuration\n",
    "models = ollama.list()\n",
    "model_names = [m['name'] for m in models.get('models', [])]\n",
    "\n",
    "# Find R1 model or use fallback\n",
    "MODEL = None\n",
    "for name in model_names:\n",
    "    if 'r1' in name.lower():\n",
    "        MODEL = name\n",
    "        break\n",
    "\n",
    "if not MODEL:\n",
    "    MODEL = model_names[0] if model_names else \"llama3.1:8b\"\n",
    "\n",
    "print(f\"Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: ThinkingResult Dataclass and Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ThinkingResult:\n",
    "    \"\"\"Parsed result from R1-style response.\"\"\"\n",
    "    thinking: str\n",
    "    answer: str\n",
    "    thinking_tokens: int\n",
    "    answer_tokens: int\n",
    "    raw_response: str\n",
    "    \n",
    "    @property\n",
    "    def thinking_ratio(self) -> float:\n",
    "        \"\"\"Ratio of thinking tokens to total tokens.\"\"\"\n",
    "        total = self.thinking_tokens + self.answer_tokens\n",
    "        return self.thinking_tokens / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def parse_r1_response(response: str) -> ThinkingResult:\n",
    "    \"\"\"\n",
    "    Parse DeepSeek-R1 style thinking tokens from a response.\n",
    "    \"\"\"\n",
    "    think_pattern = r'<think>(.*?)</think>'\n",
    "    \n",
    "    thinking_matches = re.findall(think_pattern, response, re.DOTALL)\n",
    "    thinking_content = \"\\n\".join(thinking_matches)\n",
    "    \n",
    "    answer_content = re.sub(think_pattern, '', response, flags=re.DOTALL)\n",
    "    answer_content = answer_content.strip()\n",
    "    \n",
    "    thinking_tokens = len(thinking_content) // 4\n",
    "    answer_tokens = len(answer_content) // 4\n",
    "    \n",
    "    return ThinkingResult(\n",
    "        thinking=thinking_content.strip(),\n",
    "        answer=answer_content,\n",
    "        thinking_tokens=thinking_tokens,\n",
    "        answer_tokens=answer_tokens,\n",
    "        raw_response=response,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Enhanced Thinking Visualizer\n",
    "\n",
    "Complete solution for the \"Build a Thinking Visualizer\" challenge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThinkingVisualizer:\n",
    "    \"\"\"\n",
    "    Solution: Advanced visualization of R1's thinking process.\n",
    "    \n",
    "    Features:\n",
    "    - Step detection and numbering\n",
    "    - Pattern recognition (restating, calculating, verifying)\n",
    "    - Color-coded output (for terminals that support it)\n",
    "    - Summary statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Patterns that indicate different types of thinking\n",
    "    PATTERNS = {\n",
    "        'restating': ['let me understand', 'the problem asks', 'so we have', 'given that'],\n",
    "        'planning': ['first', 'then', 'next', 'finally', 'my approach'],\n",
    "        'calculating': ['calculate', 'compute', '=', 'equals', 'multiply', 'divide', 'add', 'subtract'],\n",
    "        'verifying': ['verify', 'check', 'confirm', 'let me make sure', 'double check'],\n",
    "        'correcting': ['wait', 'no', 'actually', 'mistake', 'wrong', 'let me reconsider'],\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.analyses = []\n",
    "    \n",
    "    def analyze_thinking(self, thinking: str) -> Dict:\n",
    "        \"\"\"Analyze the thinking content for patterns.\"\"\"\n",
    "        thinking_lower = thinking.lower()\n",
    "        \n",
    "        pattern_counts = {}\n",
    "        for pattern_type, keywords in self.PATTERNS.items():\n",
    "            count = sum(1 for kw in keywords if kw in thinking_lower)\n",
    "            pattern_counts[pattern_type] = count\n",
    "        \n",
    "        # Count explicit steps\n",
    "        step_patterns = [\n",
    "            r'^\\d+[.)\\s]',\n",
    "            r'^Step\\s+\\d+',\n",
    "            r'^[-*]\\s',\n",
    "        ]\n",
    "        \n",
    "        step_count = 0\n",
    "        for line in thinking.split('\\n'):\n",
    "            for pattern in step_patterns:\n",
    "                if re.match(pattern, line.strip(), re.IGNORECASE):\n",
    "                    step_count += 1\n",
    "                    break\n",
    "        \n",
    "        return {\n",
    "            'pattern_counts': pattern_counts,\n",
    "            'explicit_steps': step_count,\n",
    "            'line_count': len(thinking.split('\\n')),\n",
    "            'word_count': len(thinking.split()),\n",
    "        }\n",
    "    \n",
    "    def visualize(self, result: ThinkingResult, max_lines: int = 30) -> str:\n",
    "        \"\"\"\n",
    "        Create a comprehensive visualization of the thinking process.\n",
    "        \"\"\"\n",
    "        output = []\n",
    "        \n",
    "        # Header\n",
    "        output.append(\"\\n\" + \"#\" * 70)\n",
    "        output.append(\"#  R1 THINKING PROCESS ANALYSIS\")\n",
    "        output.append(\"#\" * 70)\n",
    "        \n",
    "        # Analyze thinking\n",
    "        analysis = self.analyze_thinking(result.thinking)\n",
    "        self.analyses.append(analysis)\n",
    "        \n",
    "        # Token statistics\n",
    "        output.append(\"\\n[TOKEN STATISTICS]\")\n",
    "        output.append(\"-\" * 40)\n",
    "        output.append(f\"  Thinking tokens: ~{result.thinking_tokens}\")\n",
    "        output.append(f\"  Answer tokens:   ~{result.answer_tokens}\")\n",
    "        output.append(f\"  Thinking ratio:  {result.thinking_ratio:.1%}\")\n",
    "        output.append(f\"  Overhead:        {result.thinking_tokens / max(result.answer_tokens, 1):.1f}x\")\n",
    "        \n",
    "        # Pattern analysis\n",
    "        output.append(\"\\n[THINKING PATTERNS DETECTED]\")\n",
    "        output.append(\"-\" * 40)\n",
    "        for pattern_type, count in analysis['pattern_counts'].items():\n",
    "            if count > 0:\n",
    "                bar = \"*\" * min(count, 10)\n",
    "                output.append(f\"  {pattern_type:<15} {bar} ({count})\")\n",
    "        \n",
    "        # Structure analysis\n",
    "        output.append(\"\\n[STRUCTURE]\")\n",
    "        output.append(\"-\" * 40)\n",
    "        output.append(f\"  Explicit steps: {analysis['explicit_steps']}\")\n",
    "        output.append(f\"  Total lines:    {analysis['line_count']}\")\n",
    "        output.append(f\"  Word count:     {analysis['word_count']}\")\n",
    "        \n",
    "        # Thinking content\n",
    "        output.append(\"\\n[THINKING CONTENT]\")\n",
    "        output.append(\"-\" * 40)\n",
    "        \n",
    "        if result.thinking:\n",
    "            lines = result.thinking.split('\\n')\n",
    "            for i, line in enumerate(lines[:max_lines]):\n",
    "                if line.strip():\n",
    "                    # Truncate long lines\n",
    "                    display_line = line.strip()[:75]\n",
    "                    if len(line.strip()) > 75:\n",
    "                        display_line += \"...\"\n",
    "                    output.append(f\"  {display_line}\")\n",
    "            \n",
    "            if len(lines) > max_lines:\n",
    "                output.append(f\"  ... ({len(lines) - max_lines} more lines)\")\n",
    "        else:\n",
    "            output.append(\"  (No thinking tokens detected)\")\n",
    "        \n",
    "        # Final answer\n",
    "        output.append(\"\\n[FINAL ANSWER]\")\n",
    "        output.append(\"-\" * 40)\n",
    "        answer_preview = result.answer[:500]\n",
    "        if len(result.answer) > 500:\n",
    "            answer_preview += \"...\"\n",
    "        output.append(answer_preview)\n",
    "        \n",
    "        output.append(\"\\n\" + \"#\" * 70)\n",
    "        \n",
    "        return \"\\n\".join(output)\n",
    "    \n",
    "    def get_aggregate_stats(self) -> Dict:\n",
    "        \"\"\"Get aggregate statistics from all analyses.\"\"\"\n",
    "        if not self.analyses:\n",
    "            return {}\n",
    "        \n",
    "        avg_steps = sum(a['explicit_steps'] for a in self.analyses) / len(self.analyses)\n",
    "        avg_lines = sum(a['line_count'] for a in self.analyses) / len(self.analyses)\n",
    "        \n",
    "        # Most common patterns\n",
    "        pattern_totals = {}\n",
    "        for a in self.analyses:\n",
    "            for pattern, count in a['pattern_counts'].items():\n",
    "                pattern_totals[pattern] = pattern_totals.get(pattern, 0) + count\n",
    "        \n",
    "        return {\n",
    "            'total_analyses': len(self.analyses),\n",
    "            'avg_explicit_steps': avg_steps,\n",
    "            'avg_line_count': avg_lines,\n",
    "            'pattern_totals': pattern_totals,\n",
    "        }\n",
    "\n",
    "\n",
    "# Test the visualizer\n",
    "visualizer = ThinkingVisualizer()\n",
    "\n",
    "# Sample R1-style response\n",
    "sample_response = '''<think>\n",
    "Let me understand the problem. We need to find when two trains meet.\n",
    "\n",
    "Given:\n",
    "- Train A leaves at 9:00 AM at 60 mph\n",
    "- Train B leaves at 10:00 AM at 80 mph\n",
    "- Distance between stations: 280 miles\n",
    "\n",
    "Step 1: Calculate Train A's head start\n",
    "By 10:00 AM, Train A has traveled for 1 hour at 60 mph = 60 miles\n",
    "Remaining distance: 280 - 60 = 220 miles\n",
    "\n",
    "Step 2: Calculate closing speed\n",
    "After 10:00 AM, both trains are moving toward each other.\n",
    "Combined speed = 60 + 80 = 140 mph\n",
    "\n",
    "Step 3: Calculate time to meet\n",
    "Time = Distance / Speed = 220 / 140 = 1.57 hours = 1 hour 34 minutes\n",
    "\n",
    "Step 4: Calculate meeting time\n",
    "10:00 AM + 1 hour 34 minutes = 11:34 AM\n",
    "\n",
    "Let me verify: \n",
    "- Train A traveled: 2h 34m at 60 mph = 154 miles\n",
    "- Train B traveled: 1h 34m at 80 mph = 126 miles\n",
    "- Total: 154 + 126 = 280 miles. Correct!\n",
    "</think>\n",
    "\n",
    "The trains will meet at **11:34 AM**.\n",
    "\n",
    "Here's how I solved it:\n",
    "1. By 10 AM, Train A has already traveled 60 miles (1 hour × 60 mph)\n",
    "2. Remaining distance: 280 - 60 = 220 miles\n",
    "3. Combined speed: 60 + 80 = 140 mph\n",
    "4. Time to meet: 220 ÷ 140 ≈ 1.57 hours ≈ 1 hour 34 minutes after 10 AM\n",
    "'''\n",
    "\n",
    "parsed = parse_r1_response(sample_response)\n",
    "print(visualizer.visualize(parsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Thinking Overhead Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_thinking_overhead(\n",
    "    results: List[ThinkingResult],\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Solution: Comprehensive analysis of thinking token overhead.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return {}\n",
    "    \n",
    "    thinking_tokens = [r.thinking_tokens for r in results]\n",
    "    answer_tokens = [r.answer_tokens for r in results]\n",
    "    \n",
    "    total_thinking = sum(thinking_tokens)\n",
    "    total_answer = sum(answer_tokens)\n",
    "    total = total_thinking + total_answer\n",
    "    \n",
    "    stats = {\n",
    "        'n_responses': len(results),\n",
    "        'total_thinking_tokens': total_thinking,\n",
    "        'total_answer_tokens': total_answer,\n",
    "        'total_tokens': total,\n",
    "        'thinking_percentage': total_thinking / total * 100 if total > 0 else 0,\n",
    "        'overhead_ratio': total_thinking / total_answer if total_answer > 0 else 0,\n",
    "        'avg_thinking_per_response': total_thinking / len(results),\n",
    "        'avg_answer_per_response': total_answer / len(results),\n",
    "        'min_thinking': min(thinking_tokens),\n",
    "        'max_thinking': max(thinking_tokens),\n",
    "        'min_overhead': min(t/a if a > 0 else 0 for t, a in zip(thinking_tokens, answer_tokens)),\n",
    "        'max_overhead': max(t/a if a > 0 else 0 for t, a in zip(thinking_tokens, answer_tokens)),\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"THINKING OVERHEAD ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nResponses analyzed: {stats['n_responses']}\")\n",
    "        print(f\"\\nToken Distribution:\")\n",
    "        print(f\"  Total thinking tokens: {stats['total_thinking_tokens']:,}\")\n",
    "        print(f\"  Total answer tokens:   {stats['total_answer_tokens']:,}\")\n",
    "        print(f\"  Thinking percentage:   {stats['thinking_percentage']:.1f}%\")\n",
    "        print(f\"\\nOverhead:\")\n",
    "        print(f\"  Average ratio:  {stats['overhead_ratio']:.1f}x\")\n",
    "        print(f\"  Range:          {stats['min_overhead']:.1f}x - {stats['max_overhead']:.1f}x\")\n",
    "        print(f\"\\nPer Response:\")\n",
    "        print(f\"  Avg thinking:   {stats['avg_thinking_per_response']:.0f} tokens\")\n",
    "        print(f\"  Avg answer:     {stats['avg_answer_per_response']:.0f} tokens\")\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Query R1 with Full Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_r1_with_analysis(\n",
    "    question: str,\n",
    "    model: str = MODEL,\n",
    "    max_tokens: int = 2048,\n",
    "    temperature: float = 0.0,\n",
    ") -> Tuple[ThinkingResult, Dict]:\n",
    "    \"\"\"\n",
    "    Query R1 and return parsed result with analysis.\n",
    "    \"\"\"\n",
    "    print(f\"Querying {model}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        options={\"temperature\": temperature, \"num_predict\": max_tokens}\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    response_text = response['message']['content']\n",
    "    \n",
    "    result = parse_r1_response(response_text)\n",
    "    \n",
    "    # Create visualizer and analyze\n",
    "    viz = ThinkingVisualizer()\n",
    "    analysis = viz.analyze_thinking(result.thinking)\n",
    "    \n",
    "    analysis['latency'] = elapsed\n",
    "    analysis['tokens_per_second'] = (result.thinking_tokens + result.answer_tokens) / elapsed if elapsed > 0 else 0\n",
    "    \n",
    "    return result, analysis\n",
    "\n",
    "\n",
    "# Test on multiple problems\n",
    "test_problems = [\n",
    "    \"What is 17 * 23?\",\n",
    "    \"If a = 3 and b = 4, what is a^2 + b^2?\",\n",
    "    \"A store sells apples for $2 each. If I have $15, how many apples can I buy and how much change will I get?\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "print(\"Running test problems...\\n\")\n",
    "\n",
    "for prob in test_problems:\n",
    "    print(f\"Q: {prob}\")\n",
    "    result, analysis = query_r1_with_analysis(prob)\n",
    "    results.append(result)\n",
    "    print(f\"  Latency: {analysis['latency']:.1f}s\")\n",
    "    print(f\"  Thinking: {result.thinking_tokens} tokens\")\n",
    "    print(f\"  Answer: {result.answer[:80]}...\\n\")\n",
    "\n",
    "# Aggregate analysis\n",
    "if results:\n",
    "    analyze_thinking_overhead(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **R1 uses `<think>` tokens** for explicit reasoning before answering\n",
    "2. **Thinking overhead** is typically 2-5x the answer length\n",
    "3. **Parse thinking tokens** to extract clean answers\n",
    "4. **Analyze patterns** to understand reasoning quality\n",
    "5. **Allow sufficient max_tokens** for R1 to think (at least 2048)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
