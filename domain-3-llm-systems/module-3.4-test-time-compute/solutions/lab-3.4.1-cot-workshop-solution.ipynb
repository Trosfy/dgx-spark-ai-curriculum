{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.4.1: Chain-of-Thought Workshop - SOLUTIONS\n",
    "\n",
    "This notebook contains complete solutions to all exercises from Lab 3.4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "MODEL = \"qwen3:8b\"  # Adjust as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Create Your Own Few-Shot Examples\n",
    "\n",
    "Here's a complete set of high-quality few-shot examples for percentage calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Custom few-shot examples for percentage calculations\n",
    "PERCENTAGE_EXAMPLES = [\n",
    "    {\n",
    "        \"question\": \"What is 20% of 150?\",\n",
    "        \"reasoning\": \"\"\"Let me solve this step by step:\n",
    "1. To find a percentage of a number, I convert the percentage to a decimal\n",
    "2. 20% = 20/100 = 0.20\n",
    "3. Now multiply: 150 * 0.20 = 30\n",
    "\n",
    "The answer is 30.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"A shirt costs $80 and is on sale for 25% off. What is the sale price?\",\n",
    "        \"reasoning\": \"\"\"Let me solve this step by step:\n",
    "1. First, find the discount amount: 25% of $80\n",
    "2. 25% = 0.25\n",
    "3. Discount = $80 * 0.25 = $20\n",
    "4. Sale price = Original price - Discount = $80 - $20 = $60\n",
    "\n",
    "The answer is $60.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"If you scored 45 out of 60 on a test, what percentage did you get?\",\n",
    "        \"reasoning\": \"\"\"Let me solve this step by step:\n",
    "1. To find percentage, divide the part by the whole and multiply by 100\n",
    "2. Percentage = (45 / 60) * 100\n",
    "3. First: 45 / 60 = 0.75\n",
    "4. Then: 0.75 * 100 = 75%\n",
    "\n",
    "The answer is 75%.\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def few_shot_percentage(question: str) -> str:\n",
    "    \"\"\"Apply few-shot CoT for percentage problems.\"\"\"\n",
    "    prompt_parts = []\n",
    "    \n",
    "    for ex in PERCENTAGE_EXAMPLES:\n",
    "        prompt_parts.append(f\"Q: {ex['question']}\")\n",
    "        prompt_parts.append(f\"A: {ex['reasoning']}\")\n",
    "        prompt_parts.append(\"\")\n",
    "    \n",
    "    prompt_parts.append(f\"Q: {question}\")\n",
    "    prompt_parts.append(\"A: Let me solve this step by step:\")\n",
    "    \n",
    "    prompt = \"\\n\".join(prompt_parts)\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\"temperature\": 0.0, \"num_predict\": 512}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "# Test the solution\n",
    "test_question = \"A restaurant bill is $85. If you want to leave a 18% tip, how much is the tip?\"\n",
    "print(f\"Question: {test_question}\\n\")\n",
    "print(\"Response:\")\n",
    "print(few_shot_percentage(test_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Complete CoT Prompt Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoTPromptLibrary:\n",
    "    \"\"\"\n",
    "    Complete solution for the CoT Prompt Template Library challenge.\n",
    "    \n",
    "    Includes templates for multiple domains with examples.\n",
    "    \"\"\"\n",
    "    \n",
    "    TEMPLATES = {\n",
    "        \"math\": {\n",
    "            \"system\": \"You are a math tutor. Always show your work step by step.\",\n",
    "            \"trigger\": \"Let me solve this step by step:\",\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"q\": \"What is 25% of 80?\",\n",
    "                    \"a\": \"\"\"Let me solve this step by step:\n",
    "1. 25% means 25 per 100, or 25/100 = 0.25\n",
    "2. To find 25% of 80, multiply: 80 * 0.25\n",
    "3. 80 * 0.25 = 20\n",
    "\n",
    "The answer is 20.\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"code_debug\": {\n",
    "            \"system\": \"You are a debugging expert. Analyze code systematically.\",\n",
    "            \"trigger\": \"Let me analyze this code step by step:\",\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"q\": \"Why does this code fail: print(len(None))?\",\n",
    "                    \"a\": \"\"\"Let me analyze this code step by step:\n",
    "1. The code calls len() on None\n",
    "2. len() expects an object with a __len__ method (like string, list, dict)\n",
    "3. None is a NoneType object and doesn't have __len__\n",
    "4. This will raise TypeError: object of type 'NoneType' has no len()\n",
    "\n",
    "Fix: Check for None before calling len(), e.g., len(x) if x else 0\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"logic\": {\n",
    "            \"system\": \"You are a logic expert. Use formal reasoning.\",\n",
    "            \"trigger\": \"Let me reason through this logically:\",\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"q\": \"All dogs are mammals. All mammals breathe air. Do dogs breathe air?\",\n",
    "                    \"a\": \"\"\"Let me reason through this logically:\n",
    "1. Premise 1: All dogs are mammals\n",
    "2. Premise 2: All mammals breathe air\n",
    "3. By syllogism: If dogs are mammals, and mammals breathe air...\n",
    "4. Conclusion: Dogs breathe air (by transitive property)\n",
    "\n",
    "The answer is yes.\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"word_problem\": {\n",
    "            \"system\": \"You solve word problems by identifying variables and relationships.\",\n",
    "            \"trigger\": \"Let me break down this problem:\",\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"q\": \"Tom is twice as old as Mary. In 5 years, the sum of their ages will be 40. How old is Mary now?\",\n",
    "                    \"a\": \"\"\"Let me break down this problem:\n",
    "1. Let Mary's current age = M\n",
    "2. Tom's current age = 2M (twice Mary's age)\n",
    "3. In 5 years: Mary = M+5, Tom = 2M+5\n",
    "4. Sum in 5 years: (M+5) + (2M+5) = 40\n",
    "5. Simplify: 3M + 10 = 40\n",
    "6. Solve: 3M = 30, M = 10\n",
    "\n",
    "The answer is Mary is 10 years old.\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.templates = self.TEMPLATES.copy()\n",
    "    \n",
    "    def get_prompt(self, domain: str, question: str, use_examples: bool = True) -> str:\n",
    "        \"\"\"Get a CoT prompt for a given domain and question.\"\"\"\n",
    "        if domain not in self.templates:\n",
    "            raise ValueError(f\"Unknown domain: {domain}. Available: {list(self.templates.keys())}\")\n",
    "        \n",
    "        template = self.templates[domain]\n",
    "        \n",
    "        parts = []\n",
    "        \n",
    "        if use_examples and template.get('examples'):\n",
    "            for ex in template['examples']:\n",
    "                parts.append(f\"Q: {ex['q']}\")\n",
    "                parts.append(f\"A: {ex['a']}\")\n",
    "                parts.append(\"\")\n",
    "        \n",
    "        parts.append(f\"Q: {question}\")\n",
    "        parts.append(f\"A: {template['trigger']}\")\n",
    "        \n",
    "        return \"\\n\".join(parts)\n",
    "    \n",
    "    def add_domain(self, domain: str, system: str, trigger: str, examples: List[Dict] = None):\n",
    "        \"\"\"Add a new domain to the library.\"\"\"\n",
    "        self.templates[domain] = {\n",
    "            \"system\": system,\n",
    "            \"trigger\": trigger,\n",
    "            \"examples\": examples or []\n",
    "        }\n",
    "    \n",
    "    def query(self, domain: str, question: str, model: str = MODEL) -> str:\n",
    "        \"\"\"Query the model with domain-specific CoT prompting.\"\"\"\n",
    "        prompt = self.get_prompt(domain, question)\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            options={\"temperature\": 0.0, \"num_predict\": 1024}\n",
    "        )\n",
    "        \n",
    "        return response['message']['content']\n",
    "\n",
    "\n",
    "# Test the complete library\n",
    "library = CoTPromptLibrary()\n",
    "\n",
    "print(\"Testing CoT Library across domains:\\n\")\n",
    "\n",
    "# Math\n",
    "print(\"=\" * 50)\n",
    "print(\"MATH DOMAIN\")\n",
    "print(\"=\" * 50)\n",
    "print(library.query(\"math\", \"What is 15% of 240?\"))\n",
    "\n",
    "# Logic\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"LOGIC DOMAIN\")\n",
    "print(\"=\" * 50)\n",
    "print(library.query(\"logic\", \"Some birds can fly. Penguins are birds. Can penguins fly?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Comprehensive Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_evaluation(\n",
    "    problems: List[Dict],\n",
    "    n_problems: int = 10,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Complete solution for comprehensive evaluation comparing\n",
    "    direct answering, zero-shot CoT, and few-shot CoT.\n",
    "    \"\"\"\n",
    "    from typing import Callable\n",
    "    import time\n",
    "    \n",
    "    def extract_answer(response: str) -> Optional[float]:\n",
    "        \"\"\"Extract numerical answer from response.\"\"\"\n",
    "        patterns = [\n",
    "            r\"[Tt]he (?:final )?answer is[:\\s]+\\$?([\\d,]+(?:\\.\\d+)?)\",\n",
    "            r\"=\\s*\\$?([\\d,]+(?:\\.\\d+)?)\\s*(?:$|\\.|\\n)\",\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, response)\n",
    "            if matches:\n",
    "                try:\n",
    "                    return float(matches[-1].replace(',', ''))\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        numbers = re.findall(r'-?[\\d,]+(?:\\.\\d+)?', response)\n",
    "        if numbers:\n",
    "            try:\n",
    "                return float(numbers[-1].replace(',', ''))\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "    \n",
    "    methods = {\n",
    "        \"direct\": lambda q: f\"{q}\\n\\nGive only the numerical answer:\",\n",
    "        \"zero_shot_cot\": lambda q: f\"{q}\\n\\nLet's think step by step:\",\n",
    "        \"few_shot_cot\": lambda q: f\"\"\"Q: If there are 3 cars and 2 more arrive, how many?\n",
    "A: Let's think step by step. 3 + 2 = 5 cars. The answer is 5.\n",
    "\n",
    "Q: {q}\n",
    "A: Let's think step by step:\"\"\"\n",
    "    }\n",
    "    \n",
    "    results = {method: {\"correct\": 0, \"total\": 0, \"latency\": 0} for method in methods}\n",
    "    \n",
    "    for i, prob in enumerate(problems[:n_problems]):\n",
    "        question = prob['question']\n",
    "        expected = prob.get('numerical_answer', prob.get('answer'))\n",
    "        \n",
    "        print(f\"\\nProblem {i+1}: {question[:50]}...\")\n",
    "        \n",
    "        for method_name, prompt_fn in methods.items():\n",
    "            prompt = prompt_fn(question)\n",
    "            \n",
    "            start = time.time()\n",
    "            response = ollama.chat(\n",
    "                model=MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                options={\"temperature\": 0.0, \"num_predict\": 512}\n",
    "            )\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            predicted = extract_answer(response['message']['content'])\n",
    "            \n",
    "            try:\n",
    "                correct = abs(float(predicted or 0) - float(expected)) < 0.01 * abs(float(expected))\n",
    "            except:\n",
    "                correct = False\n",
    "            \n",
    "            results[method_name][\"total\"] += 1\n",
    "            results[method_name][\"correct\"] += int(correct)\n",
    "            results[method_name][\"latency\"] += elapsed\n",
    "            \n",
    "            status = \"CORRECT\" if correct else \"WRONG\"\n",
    "            print(f\"  {method_name}: {status} (pred={predicted}, exp={expected})\")\n",
    "    \n",
    "    # Calculate summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPREHENSIVE EVALUATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for method, data in results.items():\n",
    "        accuracy = data[\"correct\"] / data[\"total\"] if data[\"total\"] > 0 else 0\n",
    "        avg_latency = data[\"latency\"] / data[\"total\"] if data[\"total\"] > 0 else 0\n",
    "        print(f\"{method:20} Accuracy: {accuracy:.1%}  Avg Latency: {avg_latency:.2f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run if problems are available\n",
    "# comprehensive_evaluation(problems, n_problems=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Zero-shot CoT** (\"Let's think step by step\") is simple and effective\n",
    "2. **Few-shot CoT** with good examples can further improve accuracy\n",
    "3. **Domain-specific templates** help maintain consistency\n",
    "4. **Always extract the final answer** programmatically for evaluation\n",
    "5. **CoT helps most on multi-step reasoning problems**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
