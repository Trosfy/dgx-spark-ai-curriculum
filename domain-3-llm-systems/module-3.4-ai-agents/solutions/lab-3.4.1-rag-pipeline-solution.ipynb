{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 3.4.1: RAG Pipeline - Solutions\n\nThis notebook contains complete solutions for the exercises in the RAG Pipeline notebook.\n\n> **Important:** Run cells in order from top to bottom. Each cell may depend on variables or imports from previous cells.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Experiment with Chunk Sizes\n",
    "\n",
    "**Solution:** Testing different chunk sizes to understand the impact on retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# Load documents\n",
    "DATA_DIR = Path.cwd().parent / \"data\" / \"sample_documents\"\n",
    "loader = DirectoryLoader(str(DATA_DIR), glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# Test different chunk sizes\n",
    "chunk_configs = [\n",
    "    {\"size\": 100, \"overlap\": 10, \"desc\": \"Very small - good for precise retrieval, may lack context\"},\n",
    "    {\"size\": 256, \"overlap\": 25, \"desc\": \"Small - balanced for short queries\"},\n",
    "    {\"size\": 512, \"overlap\": 50, \"desc\": \"Medium - recommended for most use cases\"},\n",
    "    {\"size\": 1024, \"overlap\": 100, \"desc\": \"Large - good for complex topics\"},\n",
    "    {\"size\": 2000, \"overlap\": 200, \"desc\": \"Very large - may dilute relevance\"},\n",
    "]\n",
    "\n",
    "print(\"Chunk Size Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for config in chunk_configs:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=config[\"size\"],\n",
    "        chunk_overlap=config[\"overlap\"]\n",
    "    )\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    avg_size = sum(len(c.page_content) for c in chunks) / len(chunks)\n",
    "    \n",
    "    print(f\"\\nChunk size: {config['size']}, Overlap: {config['overlap']}\")\n",
    "    print(f\"  Chunks created: {len(chunks)}\")\n",
    "    print(f\"  Avg chunk length: {avg_size:.0f} chars\")\n",
    "    print(f\"  Note: {config['desc']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Implement Hybrid Search\n",
    "\n",
    "**Solution:** Combining BM25 (keyword) with vector (semantic) search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# BM25 requires the rank_bm25 package: pip install rank_bm25\n\n# Handle different LangChain versions for BM25Retriever\ntry:\n    from langchain_community.retrievers import BM25Retriever\nexcept ImportError:\n    try:\n        from langchain.retrievers import BM25Retriever\n    except ImportError:\n        raise ImportError(\n            \"BM25Retriever not found. Install with: pip install rank_bm25\\n\"\n            \"Then import from langchain.retrievers or langchain_community.retrievers\"\n        )\n\nfrom langchain.retrievers import EnsembleRetriever\nfrom langchain_community.embeddings import OllamaEmbeddings\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.llms import Ollama\nfrom langchain.chains import RetrievalQA\n\n# Initialize components\nembeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\nllm = Ollama(model=\"llama3.1:8b\", temperature=0.3)\n\n# Create chunks\nsplitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\nchunks = splitter.split_documents(documents)\n\n# Create vector store\nvectorstore = Chroma.from_documents(chunks, embeddings)\n\n# Create BM25 (keyword) retriever\nbm25_retriever = BM25Retriever.from_documents(chunks)\nbm25_retriever.k = 5\n\n# Create vector (semantic) retriever\nvector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n\n# Create ensemble (hybrid) retriever\n# Weights: 30% keyword, 70% semantic\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, vector_retriever],\n    weights=[0.3, 0.7]\n)\n\nprint(\"âœ… Hybrid retriever created!\")\nprint(\"  - BM25 weight: 30% (keyword matching)\")\nprint(\"  - Vector weight: 70% (semantic similarity)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAG chain with hybrid retrieval\n",
    "hybrid_rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ensemble_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Test the hybrid RAG\n",
    "query = \"What are the CUDA cores and Tensor Cores specifications of DGX Spark?\"\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = hybrid_rag.invoke({\"query\": query})\n",
    "\n",
    "print(f\"\\nAnswer: {result['result']}\")\n",
    "print(f\"\\nSources used: {len(result['source_documents'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Chunk Size Selection:**\n",
    "   - Small (100-256): Good for precise factual queries\n",
    "   - Medium (512): Best balance for most use cases\n",
    "   - Large (1024+): Better for complex, contextual queries\n",
    "\n",
    "2. **Hybrid Search Benefits:**\n",
    "   - Catches exact keyword matches (BM25)\n",
    "   - Finds semantically similar content (Vector)\n",
    "   - More robust than either alone\n",
    "\n",
    "3. **Weight Tuning:**\n",
    "   - Technical docs: More weight on BM25 (terms matter)\n",
    "   - Conversational: More weight on vector (meaning matters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}