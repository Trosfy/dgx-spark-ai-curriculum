{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.4.4: LangGraph Workflow with Human-in-the-Loop\n",
    "\n",
    "**Module:** 3.4 - AI Agents & Agentic Systems  \n",
    "**Time:** 3 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê (Advanced)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand graph-based agent orchestration\n",
    "- [ ] Build stateful workflows with LangGraph\n",
    "- [ ] Implement human-in-the-loop approval checkpoints\n",
    "- [ ] Handle complex branching and conditional logic\n",
    "- [ ] Create persistent, resumable agent workflows\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Tasks 13.1-13.3\n",
    "- Knowledge of: State machines, graph concepts\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**Why do we need graph-based workflows?**\n",
    "\n",
    "Simple chains work for linear tasks, but real-world processes are complex:\n",
    "- üîÑ **Loops**: \"Keep refining until the user approves\"\n",
    "- üîÄ **Branches**: \"If high-risk, get manager approval\"\n",
    "- ‚è∏Ô∏è **Pauses**: \"Wait for human review before proceeding\"\n",
    "- üíæ **Memory**: \"Remember what happened across sessions\"\n",
    "\n",
    "**Real examples:**\n",
    "- ‚úçÔ∏è **Content Creation**: Draft ‚Üí Review ‚Üí Revise ‚Üí Approve ‚Üí Publish\n",
    "- üè¶ **Loan Processing**: Application ‚Üí Risk Assessment ‚Üí Human Review ‚Üí Decision\n",
    "- üîß **IT Tickets**: Classify ‚Üí Route ‚Üí Escalate if needed ‚Üí Resolve ‚Üí Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is LangGraph?\n",
    "\n",
    "> **Imagine a board game where the AI is a player...** üé≤\n",
    ">\n",
    "> In most AI applications, it's like playing a game where you can only move forward:\n",
    "> - Start ‚Üí Do thing 1 ‚Üí Do thing 2 ‚Üí Done!\n",
    ">\n",
    "> But real games have more options:\n",
    "> - You might go back (\"Oops, try again!\")\n",
    "> - You might branch (\"If you roll 6, go here\")\n",
    "> - You might wait (\"Player 2's turn first\")\n",
    ">\n",
    "> **LangGraph is like the game board!**\n",
    "> - Each square is a \"node\" (something that happens)\n",
    "> - Lines between squares are \"edges\" (what happens next)\n",
    "> - The game piece remembers where it's been (\"state\")\n",
    ">\n",
    "> ```\n",
    ">        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    ">        ‚îÇ  START   ‚îÇ\n",
    ">        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    ">             ‚îÇ\n",
    ">             ‚ñº\n",
    ">        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    ">        ‚îÇ  DRAFT   ‚îÇ\n",
    ">        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    ">             ‚îÇ\n",
    ">             ‚ñº\n",
    ">        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    ">        ‚îÇ  REVIEW  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  REVISE  ‚îÇ\n",
    ">        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    ">             ‚îÇ                 ‚îÇ\n",
    ">        approved           loops back\n",
    ">             ‚îÇ                 ‚îÇ\n",
    ">             ‚ñº                 ‚îÇ\n",
    ">        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ\n",
    ">        ‚îÇ PUBLISH  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    ">        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    ">   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install LangGraph (run once)\n# Pinned version for reproducibility - update as needed\n# !pip install langgraph>=0.1.0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Standard imports\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import TypedDict, Annotated, List, Optional, Literal\nimport json\nimport time\nfrom datetime import datetime\n\n# LangGraph imports with version compatibility\nfrom langgraph.graph import StateGraph, END\n\n# Handle different LangGraph versions for MemorySaver\ntry:\n    from langgraph.checkpoint.memory import MemorySaver  # langgraph >= 0.1.0\nexcept ImportError:\n    try:\n        from langgraph.checkpoint import MemorySaver  # langgraph < 0.1.0\n    except ImportError:\n        print(\"‚ö†Ô∏è MemorySaver not available. Install langgraph: pip install langgraph>=0.1.0\")\n        MemorySaver = None\n\n# LangChain imports\nfrom langchain_community.llms import Ollama\nfrom langchain.prompts import PromptTemplate\n\nprint(\"‚úÖ Imports successful!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model Configuration - Change this if using a different model\nLLM_MODEL = \"llama3.1:8b\"  # Options: \"llama3.1:8b\", \"llama3.1:70b\", \"mistral:7b\"\n\n# Initialize LLM with timeout for long operations\nllm = Ollama(\n    model=LLM_MODEL,\n    temperature=0.7,\n    request_timeout=120.0,  # 2 minute timeout\n    base_url=\"http://localhost:11434\"\n)\n\nprint(f\"‚úÖ LLM initialized: {LLM_MODEL}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Understanding State\n",
    "\n",
    "In LangGraph, **state** is the data that flows through your graph and gets updated at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state for our content creation workflow\n",
    "class ContentState(TypedDict):\n",
    "    \"\"\"State for the content creation workflow.\"\"\"\n",
    "    # Input\n",
    "    topic: str\n",
    "    content_type: str  # \"blog\", \"tweet\", \"email\"\n",
    "    \n",
    "    # Generated content\n",
    "    draft: str\n",
    "    revised_draft: str\n",
    "    \n",
    "    # Review state\n",
    "    feedback: str\n",
    "    approved: bool\n",
    "    revision_count: int\n",
    "    max_revisions: int\n",
    "    \n",
    "    # Metadata\n",
    "    messages: List[str]  # Log of what happened\n",
    "\n",
    "print(\"ContentState defined!\")\n",
    "print(\"Fields:\", list(ContentState.__annotations__.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Building the Graph Nodes\n",
    "\n",
    "Each node is a function that takes state, does something, and returns updated state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: Generate initial draft\n",
    "def generate_draft(state: ContentState) -> ContentState:\n",
    "    \"\"\"Generate the initial content draft.\"\"\"\n",
    "    print(\"üìù Generating draft...\")\n",
    "    \n",
    "    prompt = f\"\"\"Write a {state['content_type']} about: {state['topic']}\n",
    "    \n",
    "Keep it concise, engaging, and professional.\n",
    "Only output the content itself, no preamble.\"\"\"\n",
    "    \n",
    "    draft = llm.invoke(prompt)\n",
    "    \n",
    "    state['draft'] = draft\n",
    "    state['messages'].append(f\"Draft generated at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"Node 'generate_draft' defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 2: Review the draft (simulated or real human review)\n",
    "def review_draft(state: ContentState) -> ContentState:\n",
    "    \"\"\"Review the draft and provide feedback.\"\"\"\n",
    "    print(\"üîç Reviewing draft...\")\n",
    "    \n",
    "    # In production, this could wait for human input!\n",
    "    # Here we simulate AI review\n",
    "    \n",
    "    current_draft = state.get('revised_draft') or state['draft']\n",
    "    \n",
    "    review_prompt = f\"\"\"Review this {state['content_type']} and provide brief feedback.\n",
    "If it's good, say \"APPROVED: [brief praise]\".\n",
    "If it needs work, say \"REVISE: [specific feedback]\".\n",
    "\n",
    "Content to review:\n",
    "{current_draft}\"\"\"\n",
    "    \n",
    "    feedback = llm.invoke(review_prompt)\n",
    "    \n",
    "    state['feedback'] = feedback\n",
    "    state['approved'] = \"APPROVED\" in feedback.upper()\n",
    "    state['messages'].append(f\"Review complete: {'Approved' if state['approved'] else 'Needs revision'}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"Node 'review_draft' defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3: Revise the draft based on feedback\n",
    "def revise_draft(state: ContentState) -> ContentState:\n",
    "    \"\"\"Revise the draft based on feedback.\"\"\"\n",
    "    print(f\"‚úèÔ∏è Revising draft (attempt {state['revision_count'] + 1})...\")\n",
    "    \n",
    "    current_draft = state.get('revised_draft') or state['draft']\n",
    "    \n",
    "    revise_prompt = f\"\"\"Revise this {state['content_type']} based on the feedback.\n",
    "\n",
    "Original content:\n",
    "{current_draft}\n",
    "\n",
    "Feedback:\n",
    "{state['feedback']}\n",
    "\n",
    "Provide the revised content only, no preamble.\"\"\"\n",
    "    \n",
    "    revised = llm.invoke(revise_prompt)\n",
    "    \n",
    "    state['revised_draft'] = revised\n",
    "    state['revision_count'] += 1\n",
    "    state['messages'].append(f\"Revision {state['revision_count']} complete\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"Node 'revise_draft' defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 4: Publish (finalize)\n",
    "def publish_content(state: ContentState) -> ContentState:\n",
    "    \"\"\"Publish the final approved content.\"\"\"\n",
    "    print(\"üéâ Publishing content!\")\n",
    "    \n",
    "    final_content = state.get('revised_draft') or state['draft']\n",
    "    state['messages'].append(f\"Published at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL PUBLISHED CONTENT\")\n",
    "    print(\"=\"*60)\n",
    "    print(final_content)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"Node 'publish_content' defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Defining Edges (Routing Logic)\n",
    "\n",
    "Edges define how the graph flows from one node to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge: After review, decide what to do next\n",
    "def should_continue(state: ContentState) -> Literal[\"revise\", \"publish\", \"end\"]:\n",
    "    \"\"\"Decide whether to revise, publish, or end.\"\"\"\n",
    "    \n",
    "    if state['approved']:\n",
    "        print(\"  ‚Üí Content approved! Moving to publish...\")\n",
    "        return \"publish\"\n",
    "    \n",
    "    if state['revision_count'] >= state['max_revisions']:\n",
    "        print(f\"  ‚Üí Max revisions ({state['max_revisions']}) reached. Publishing anyway...\")\n",
    "        return \"publish\"\n",
    "    \n",
    "    print(\"  ‚Üí Needs revision...\")\n",
    "    return \"revise\"\n",
    "\n",
    "print(\"Routing function 'should_continue' defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(ContentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate\", generate_draft)\n",
    "workflow.add_node(\"review\", review_draft)\n",
    "workflow.add_node(\"revise\", revise_draft)\n",
    "workflow.add_node(\"publish\", publish_content)\n",
    "\n",
    "# Add edges\n",
    "workflow.set_entry_point(\"generate\")  # Start here\n",
    "workflow.add_edge(\"generate\", \"review\")  # Always review after generating\n",
    "\n",
    "# Conditional edge after review\n",
    "workflow.add_conditional_edges(\n",
    "    \"review\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"revise\": \"revise\",\n",
    "        \"publish\": \"publish\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# After revision, go back to review\n",
    "workflow.add_edge(\"revise\", \"review\")\n",
    "\n",
    "# Publish ends the workflow\n",
    "workflow.add_edge(\"publish\", END)\n",
    "\n",
    "print(\"Graph structure defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the graph (if graphviz/mermaid is available)\ntry:\n    from IPython.display import Image, display\n    display(Image(app.get_graph().draw_mermaid_png()))\n    print(\"‚úÖ Graph visualization rendered!\")\nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è Visualization requires additional packages: {e}\")\n    print(\"   Install with: pip install grandalf\")\n    print(\"\\nGraph structure (text representation):\")\n    print(\"\"\"\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ generate ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ\n         ‚ñº\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ  review  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ\n         ‚îÇ                 ‚îÇ\n    (approved?)        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n     ‚îÇ      ‚îÇ          ‚îÇrevise ‚îÇ\n     ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n     ‚îÇ\n     ‚ñº\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ publish  ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚îÇ\n         ‚ñº\n       [END]\n    \"\"\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Visualization not available: {e}\")\n    print(\"Graph flows: generate ‚Üí review ‚Üí (approve?) ‚Üí publish ‚Üí END\")\n    print(\"                         ‚Üë         ‚Üì\")\n    print(\"                         ‚Üê revise ‚Üê\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Running the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the state\n",
    "initial_state = {\n",
    "    \"topic\": \"The benefits of AI agents in software development\",\n",
    "    \"content_type\": \"tweet\",\n",
    "    \"draft\": \"\",\n",
    "    \"revised_draft\": \"\",\n",
    "    \"feedback\": \"\",\n",
    "    \"approved\": False,\n",
    "    \"revision_count\": 0,\n",
    "    \"max_revisions\": 2,\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "print(\"Initial state created!\")\n",
    "print(f\"Topic: {initial_state['topic']}\")\n",
    "print(f\"Content type: {initial_state['content_type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING CONTENT CREATION WORKFLOW\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Stream the execution to see each step\n",
    "for step in app.stream(initial_state):\n",
    "    # step is a dict with node_name: output_state\n",
    "    for node_name, output in step.items():\n",
    "        print(f\"\\n--- Completed node: {node_name} ---\")\n",
    "        \n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nWorkflow completed in {elapsed:.1f} seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final result\n",
    "final_result = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WORKFLOW SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Revisions made: {final_result['revision_count']}\")\n",
    "print(f\"Final approval: {final_result['approved']}\")\n",
    "print(f\"\\nExecution log:\")\n",
    "for msg in final_result['messages']:\n",
    "    print(f\"  ‚Ä¢ {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Human-in-the-Loop\n",
    "\n",
    "Now let's add the ability for humans to approve or provide feedback!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a version with interrupt points for human review\n",
    "\n",
    "# Modified review node that can accept human input\n",
    "def human_review(state: ContentState) -> ContentState:\n",
    "    \"\"\"Request human review of the draft.\"\"\"\n",
    "    current_draft = state.get('revised_draft') or state['draft']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üßë HUMAN REVIEW REQUESTED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nContent to review ({state['content_type']}):\")\n",
    "    print(\"-\"*40)\n",
    "    print(current_draft)\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # In a real application, this would wait for actual human input\n",
    "    # For demo, we'll simulate it\n",
    "    print(\"\\nSimulating human review...\")\n",
    "    \n",
    "    # Simulate human decision (in production: get real input)\n",
    "    if state['revision_count'] >= 1:  # Approve after 1 revision\n",
    "        feedback = \"APPROVED: Good job!\"\n",
    "    else:\n",
    "        feedback = \"REVISE: Please make it more engaging and add an emoji.\"\n",
    "    \n",
    "    print(f\"Human feedback: {feedback}\")\n",
    "    \n",
    "    state['feedback'] = feedback\n",
    "    state['approved'] = \"APPROVED\" in feedback.upper()\n",
    "    state['messages'].append(f\"Human review: {'Approved' if state['approved'] else 'Needs revision'}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph with human review\n",
    "hitl_workflow = StateGraph(ContentState)\n",
    "\n",
    "# Add nodes\n",
    "hitl_workflow.add_node(\"generate\", generate_draft)\n",
    "hitl_workflow.add_node(\"human_review\", human_review)  # Human in the loop!\n",
    "hitl_workflow.add_node(\"revise\", revise_draft)\n",
    "hitl_workflow.add_node(\"publish\", publish_content)\n",
    "\n",
    "# Add edges\n",
    "hitl_workflow.set_entry_point(\"generate\")\n",
    "hitl_workflow.add_edge(\"generate\", \"human_review\")\n",
    "\n",
    "hitl_workflow.add_conditional_edges(\n",
    "    \"human_review\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"revise\": \"revise\",\n",
    "        \"publish\": \"publish\",\n",
    "    }\n",
    ")\n",
    "\n",
    "hitl_workflow.add_edge(\"revise\", \"human_review\")\n",
    "hitl_workflow.add_edge(\"publish\", END)\n",
    "\n",
    "# Compile with memory for persistence\n",
    "memory = MemorySaver()\n",
    "hitl_app = hitl_workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Human-in-the-loop workflow compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the HITL workflow\n",
    "hitl_state = {\n",
    "    \"topic\": \"Why DGX Spark is perfect for local AI development\",\n",
    "    \"content_type\": \"tweet\",\n",
    "    \"draft\": \"\",\n",
    "    \"revised_draft\": \"\",\n",
    "    \"feedback\": \"\",\n",
    "    \"approved\": False,\n",
    "    \"revision_count\": 0,\n",
    "    \"max_revisions\": 3,\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "# Config for the thread (enables persistence)\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING HUMAN-IN-THE-LOOP WORKFLOW\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = hitl_app.invoke(hitl_state, config)\n",
    "\n",
    "print(f\"\\nFinal revision count: {result['revision_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Interrupt and Resume\n",
    "\n",
    "With checkpointing, we can pause workflows and resume later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workflow that can be interrupted\n",
    "\n",
    "def wait_for_approval(state: ContentState) -> ContentState:\n",
    "    \"\"\"This node represents waiting for human approval.\"\"\"\n",
    "    print(\"\\n‚è≥ WORKFLOW PAUSED - Waiting for human approval...\")\n",
    "    print(f\"Current draft:\\n{state.get('revised_draft') or state['draft']}\")\n",
    "    state['messages'].append(\"Waiting for approval\")\n",
    "    return state\n",
    "\n",
    "# Build interruptible workflow\n",
    "interrupt_workflow = StateGraph(ContentState)\n",
    "\n",
    "interrupt_workflow.add_node(\"generate\", generate_draft)\n",
    "interrupt_workflow.add_node(\"wait_approval\", wait_for_approval)\n",
    "interrupt_workflow.add_node(\"publish\", publish_content)\n",
    "\n",
    "interrupt_workflow.set_entry_point(\"generate\")\n",
    "interrupt_workflow.add_edge(\"generate\", \"wait_approval\")\n",
    "interrupt_workflow.add_edge(\"wait_approval\", \"publish\")\n",
    "interrupt_workflow.add_edge(\"publish\", END)\n",
    "\n",
    "# Compile with interrupt BEFORE wait_approval\n",
    "interrupt_memory = MemorySaver()\n",
    "interrupt_app = interrupt_workflow.compile(\n",
    "    checkpointer=interrupt_memory,\n",
    "    interrupt_before=[\"wait_approval\"]  # Interrupt before this node\n",
    ")\n",
    "\n",
    "print(\"Interruptible workflow compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the workflow (will pause before approval)\n",
    "interrupt_state = {\n",
    "    \"topic\": \"Tips for running 70B models on DGX Spark\",\n",
    "    \"content_type\": \"blog\",\n",
    "    \"draft\": \"\",\n",
    "    \"revised_draft\": \"\",\n",
    "    \"feedback\": \"\",\n",
    "    \"approved\": False,\n",
    "    \"revision_count\": 0,\n",
    "    \"max_revisions\": 2,\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"interrupt-demo\"}}\n",
    "\n",
    "print(\"Starting workflow (will interrupt before approval)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# This will run until the interrupt point\n",
    "partial_result = interrupt_app.invoke(interrupt_state, thread_config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Workflow paused! Draft is ready for review.\")\n",
    "print(f\"Messages so far: {partial_result['messages']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later: Resume the workflow from where it left off\n",
    "print(\"\\nResuming workflow...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Resume by passing None (uses saved state)\n",
    "final_result = interrupt_app.invoke(None, thread_config)\n",
    "\n",
    "print(f\"\\nWorkflow complete! Messages: {final_result['messages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Forgetting to Handle All Conditional Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Wrong: Missing a possible return value\n",
    "# def route_incomplete(state):\n",
    "#     if state['approved']:\n",
    "#         return \"publish\"\n",
    "#     # What if not approved? No return! Will error.\n",
    "\n",
    "# ‚úÖ Right: Handle all cases\n",
    "def route_complete(state: ContentState) -> str:\n",
    "    if state['approved']:\n",
    "        return \"publish\"\n",
    "    else:\n",
    "        return \"revise\"  # Always have a default!\n",
    "\n",
    "print(\"Always handle all conditional branches!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Not Using Type Hints for State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Wrong: Using plain dict (no type checking)\n",
    "# def bad_node(state: dict) -> dict:\n",
    "#     state['misppeled_key'] = \"oops\"  # No warning!\n",
    "#     return state\n",
    "\n",
    "# ‚úÖ Right: Use TypedDict for type safety\n",
    "class SafeState(TypedDict):\n",
    "    correctly_spelled_key: str\n",
    "\n",
    "def good_node(state: SafeState) -> SafeState:\n",
    "    state['correctly_spelled_key'] = \"safe!\"  # IDE warns if wrong\n",
    "    return state\n",
    "\n",
    "print(\"TypedDict provides type safety and IDE support!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 3: Infinite Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Wrong: No exit condition from loop\n",
    "# workflow.add_edge(\"revise\", \"review\")\n",
    "# workflow.add_edge(\"review\", \"revise\")  # Always revises forever!\n",
    "\n",
    "# ‚úÖ Right: Include exit conditions\n",
    "# 1. Track iteration count\n",
    "# 2. Have a max_iterations limit\n",
    "# 3. Include approval state that breaks the loop\n",
    "\n",
    "print(\"\"\"Always ensure loops can exit:\n",
    "- Track revision count\n",
    "- Set max iterations\n",
    "- Have approval conditions\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ How LangGraph enables complex workflow orchestration\n",
    "- ‚úÖ Building stateful graphs with nodes and edges\n",
    "- ‚úÖ Conditional routing based on state\n",
    "- ‚úÖ Human-in-the-loop approval patterns\n",
    "- ‚úÖ Interrupting and resuming workflows\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Challenge (Optional)\n",
    "\n",
    "Build a more complex workflow that includes:\n",
    "1. Multiple content types (choose between blog, tweet, email)\n",
    "2. A \"research\" step before drafting\n",
    "3. Parallel review by multiple reviewers\n",
    "4. Final manager approval\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Human-in-the-Loop Guide](https://langchain-ai.github.io/langgraph/how-tos/human-in-the-loop/)\n",
    "- [Persistence & Memory](https://langchain-ai.github.io/langgraph/how-tos/persistence/)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive cleanup for DGX Spark\nimport gc\n\n# Clear GPU memory if available\ntry:\n    import torch\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\n        torch.cuda.empty_cache()\n        allocated = torch.cuda.memory_allocated() / 1e9\n        print(f\"‚úÖ GPU memory cleared ({allocated:.2f} GB still allocated)\")\nexcept ImportError:\n    pass\n\n# Python garbage collection\ngc.collect()\nprint(\"‚úÖ Cleanup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Summary\n",
    "\n",
    "In this notebook, you mastered LangGraph for building sophisticated agent workflows:\n",
    "\n",
    "1. **State Management**: TypedDict for structured, type-safe state\n",
    "2. **Nodes**: Functions that transform state\n",
    "3. **Edges**: Define workflow flow (linear and conditional)\n",
    "4. **Human-in-the-Loop**: Approval checkpoints\n",
    "5. **Persistence**: Interrupt and resume with memory\n",
    "\n",
    "**When to use LangGraph:**\n",
    "- Complex workflows with branching\n",
    "- Human approval required\n",
    "- Need to persist state across sessions\n",
    "- Multi-step processes with loops\n",
    "\n",
    "**Next up:** Lab 3.4.5 - Multi-Agent System with CrewAI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}