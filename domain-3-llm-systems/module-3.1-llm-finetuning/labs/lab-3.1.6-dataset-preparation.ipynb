{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.1.6: Dataset Preparation for Fine-Tuning\n",
    "\n",
    "**Module:** 3.1 - Large Language Model Fine-Tuning  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ⭐⭐⭐☆☆\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand different dataset formats (Alpaca, ShareGPT, ChatML)\n",
    "- [ ] Convert raw data to fine-tuning formats\n",
    "- [ ] Create preference pairs for DPO/RLHF\n",
    "- [ ] Implement data quality filtering\n",
    "- [ ] Build a complete data preparation pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "### \"Garbage In, Garbage Out\"\n",
    "\n",
    "The quality of your fine-tuned model depends **entirely** on your data:\n",
    "\n",
    "| Data Quality | Result |\n",
    "|-------------|--------|\n",
    "| 100 high-quality examples | Better than... |\n",
    "| 10,000 low-quality examples | Much worse! |\n",
    "\n",
    "This notebook teaches you to create **gold-standard training data**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5: Why Data Format Matters\n",
    "\n",
    "> **Imagine teaching a new employee.** You could:\n",
    ">\n",
    "> 1. **Give them random notes** scattered everywhere → They'll be confused\n",
    "> 2. **Give them a structured manual** with clear sections → They'll learn fast!\n",
    ">\n",
    "> LLMs are the same! They learn best when data is:\n",
    "> - **Consistently formatted** (same structure every time)\n",
    "> - **Clearly labeled** (who's speaking? what's the task?)\n",
    "> - **High quality** (accurate, helpful, well-written)\n",
    ">\n",
    "> This notebook teaches you to create that \"structured manual\" for your AI!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For working with datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "random.seed(42)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding Dataset Formats\n",
    "\n",
    "### The Three Most Common Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ALPACA FORMAT\n",
    "# Used by: Alpaca, Dolly, many instruction datasets\n",
    "# Simple, single-turn instruction format\n",
    "\n",
    "alpaca_example = {\n",
    "    \"instruction\": \"Summarize the following article in 3 bullet points.\",\n",
    "    \"input\": \"\"\"Climate change is causing sea levels to rise at an accelerating rate. \n",
    "    Scientists predict that by 2100, coastal cities may experience significant flooding. \n",
    "    Many governments are now investing in sea walls and other protective measures.\"\"\",\n",
    "    \"output\": \"\"\"• Sea levels are rising faster due to climate change\n",
    "• Coastal cities face major flood risks by 2100\n",
    "• Governments are building sea walls as protection\"\"\"\n",
    "}\n",
    "\n",
    "print(\"ALPACA FORMAT:\")\n",
    "print(json.dumps(alpaca_example, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SHAREGPT FORMAT\n",
    "# Used by: ShareGPT, many chat datasets\n",
    "# Multi-turn conversation format\n",
    "\n",
    "sharegpt_example = {\n",
    "    \"conversations\": [\n",
    "        {\"from\": \"system\", \"value\": \"You are a helpful coding assistant.\"},\n",
    "        {\"from\": \"human\", \"value\": \"How do I reverse a string in Python?\"},\n",
    "        {\"from\": \"gpt\", \"value\": \"You can reverse a string in Python using slicing:\\n\\n```python\\ntext = 'hello'\\nreversed_text = text[::-1]\\nprint(reversed_text)  # Output: 'olleh'\\n```\"},\n",
    "        {\"from\": \"human\", \"value\": \"What about using a loop?\"},\n",
    "        {\"from\": \"gpt\", \"value\": \"Here's how to reverse using a loop:\\n\\n```python\\ntext = 'hello'\\nreversed_text = ''\\nfor char in text:\\n    reversed_text = char + reversed_text\\nprint(reversed_text)  # Output: 'olleh'\\n```\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"SHAREGPT FORMAT:\")\n",
    "print(json.dumps(sharegpt_example, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. OPENAI/CHATML FORMAT\n",
    "# Used by: OpenAI API, many modern models\n",
    "# Standard chat format with roles\n",
    "\n",
    "chatml_example = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I read a JSON file in Python?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"\"Here's how to read a JSON file:\\n\\n```python\\nimport json\\n\\nwith open('data.json', 'r') as f:\\n    data = json.load(f)\\n\\nprint(data)\\n```\"\"\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"CHATML/OPENAI FORMAT:\")\n",
    "print(json.dumps(chatml_example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Format Converters\n",
    "\n",
    "Let's build utilities to convert between formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    \"\"\"A single message in a conversation.\"\"\"\n",
    "    role: str  # 'system', 'user', 'assistant'\n",
    "    content: str\n",
    "\n",
    "@dataclass\n",
    "class Conversation:\n",
    "    \"\"\"A full conversation.\"\"\"\n",
    "    messages: List[Message] = field(default_factory=list)\n",
    "    \n",
    "    def add(self, role: str, content: str):\n",
    "        self.messages.append(Message(role=role, content=content))\n",
    "        return self\n",
    "    \n",
    "    def to_dict(self) -> List[Dict]:\n",
    "        return [{\"role\": m.role, \"content\": m.content} for m in self.messages]\n",
    "\n",
    "\n",
    "class FormatConverter:\n",
    "    \"\"\"\n",
    "    Convert between different dataset formats.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def alpaca_to_conversation(\n",
    "        alpaca: Dict,\n",
    "        system_prompt: str = \"You are a helpful assistant.\"\n",
    "    ) -> Conversation:\n",
    "        \"\"\"Convert Alpaca format to Conversation.\"\"\"\n",
    "        conv = Conversation()\n",
    "        conv.add(\"system\", system_prompt)\n",
    "        \n",
    "        user_msg = alpaca[\"instruction\"]\n",
    "        if alpaca.get(\"input\", \"\").strip():\n",
    "            user_msg += f\"\\n\\n{alpaca['input']}\"\n",
    "        \n",
    "        conv.add(\"user\", user_msg)\n",
    "        conv.add(\"assistant\", alpaca[\"output\"])\n",
    "        \n",
    "        return conv\n",
    "    \n",
    "    @staticmethod\n",
    "    def sharegpt_to_conversation(sharegpt: Dict) -> Conversation:\n",
    "        \"\"\"Convert ShareGPT format to Conversation.\"\"\"\n",
    "        role_map = {\n",
    "            \"system\": \"system\",\n",
    "            \"human\": \"user\",\n",
    "            \"user\": \"user\",\n",
    "            \"gpt\": \"assistant\",\n",
    "            \"assistant\": \"assistant\",\n",
    "        }\n",
    "        \n",
    "        conv = Conversation()\n",
    "        for turn in sharegpt[\"conversations\"]:\n",
    "            role = role_map.get(turn[\"from\"], turn[\"from\"])\n",
    "            conv.add(role, turn[\"value\"])\n",
    "        \n",
    "        return conv\n",
    "    \n",
    "    @staticmethod\n",
    "    def conversation_to_chatml(conv: Conversation) -> str:\n",
    "        \"\"\"Format conversation as ChatML string.\"\"\"\n",
    "        output = \"\"\n",
    "        for msg in conv.messages:\n",
    "            output += f\"<|im_start|>{msg.role}\\n{msg.content}<|im_end|>\\n\"\n",
    "        return output.strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def conversation_to_llama3(conv: Conversation) -> str:\n",
    "        \"\"\"Format conversation for Llama 3.1.\"\"\"\n",
    "        output = \"<|begin_of_text|>\"\n",
    "        for msg in conv.messages:\n",
    "            output += f\"<|start_header_id|>{msg.role}<|end_header_id|>\\n\\n\"\n",
    "            output += f\"{msg.content}<|eot_id|>\"\n",
    "        return output\n",
    "\n",
    "\n",
    "# Test converters\n",
    "conv = FormatConverter.alpaca_to_conversation(alpaca_example)\n",
    "print(\"Alpaca → ChatML:\")\n",
    "print(FormatConverter.conversation_to_chatml(conv)[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Data Quality Filtering\n",
    "\n",
    "Not all data is created equal. Let's build quality filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQualityFilter:\n",
    "    \"\"\"\n",
    "    Filter training examples for quality.\n",
    "    \n",
    "    Quality criteria:\n",
    "    - Appropriate length\n",
    "    - No duplicates\n",
    "    - No placeholder content\n",
    "    - Language detection (optional)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        min_instruction_len: int = 10,\n",
    "        max_instruction_len: int = 2000,\n",
    "        min_output_len: int = 20,\n",
    "        max_output_len: int = 4000,\n",
    "        remove_duplicates: bool = True,\n",
    "    ):\n",
    "        self.min_instruction_len = min_instruction_len\n",
    "        self.max_instruction_len = max_instruction_len\n",
    "        self.min_output_len = min_output_len\n",
    "        self.max_output_len = max_output_len\n",
    "        self.remove_duplicates = remove_duplicates\n",
    "        self.seen_hashes = set()\n",
    "        \n",
    "        # Placeholder patterns to reject\n",
    "        self.placeholder_patterns = [\n",
    "            r'^TODO',\n",
    "            r'^TBD',\n",
    "            r'^\\[.*\\]$',\n",
    "            r'^N/A$',\n",
    "            r'^\\.\\.\\.$',\n",
    "            r'^\\?+$',\n",
    "        ]\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean a text string.\"\"\"\n",
    "        # Normalize whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Normalize newlines\n",
    "        text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "        # Strip\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "    def is_placeholder(self, text: str) -> bool:\n",
    "        \"\"\"Check if text is just a placeholder.\"\"\"\n",
    "        for pattern in self.placeholder_patterns:\n",
    "            if re.match(pattern, text.strip(), re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_duplicate(self, instruction: str, output: str) -> bool:\n",
    "        \"\"\"Check if we've seen this example before.\"\"\"\n",
    "        if not self.remove_duplicates:\n",
    "            return False\n",
    "        \n",
    "        content_hash = hashlib.md5((instruction + output).encode()).hexdigest()\n",
    "        if content_hash in self.seen_hashes:\n",
    "            return True\n",
    "        self.seen_hashes.add(content_hash)\n",
    "        return False\n",
    "    \n",
    "    def check_example(self, example: Dict) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Check if an example passes quality filters.\n",
    "        \n",
    "        Returns: (is_valid, reason_if_invalid)\n",
    "        \"\"\"\n",
    "        instruction = example.get(\"instruction\", \"\")\n",
    "        output = example.get(\"output\", \"\")\n",
    "        \n",
    "        # Length checks\n",
    "        if len(instruction) < self.min_instruction_len:\n",
    "            return False, f\"Instruction too short ({len(instruction)} chars)\"\n",
    "        if len(instruction) > self.max_instruction_len:\n",
    "            return False, f\"Instruction too long ({len(instruction)} chars)\"\n",
    "        if len(output) < self.min_output_len:\n",
    "            return False, f\"Output too short ({len(output)} chars)\"\n",
    "        if len(output) > self.max_output_len:\n",
    "            return False, f\"Output too long ({len(output)} chars)\"\n",
    "        \n",
    "        # Placeholder check\n",
    "        if self.is_placeholder(output):\n",
    "            return False, \"Output is placeholder\"\n",
    "        \n",
    "        # Duplicate check\n",
    "        if self.is_duplicate(instruction, output):\n",
    "            return False, \"Duplicate example\"\n",
    "        \n",
    "        return True, \"\"\n",
    "    \n",
    "    def filter_dataset(\n",
    "        self, \n",
    "        data: List[Dict], \n",
    "        verbose: bool = True\n",
    "    ) -> Tuple[List[Dict], Dict]:\n",
    "        \"\"\"\n",
    "        Filter a dataset and return cleaned data with statistics.\n",
    "        \"\"\"\n",
    "        cleaned = []\n",
    "        stats = {\n",
    "            \"total\": len(data),\n",
    "            \"passed\": 0,\n",
    "            \"failed\": 0,\n",
    "            \"reasons\": {}\n",
    "        }\n",
    "        \n",
    "        for example in data:\n",
    "            # Clean text fields\n",
    "            cleaned_example = {\n",
    "                \"instruction\": self.clean_text(example.get(\"instruction\", \"\")),\n",
    "                \"input\": self.clean_text(example.get(\"input\", \"\")),\n",
    "                \"output\": self.clean_text(example.get(\"output\", \"\")),\n",
    "            }\n",
    "            \n",
    "            is_valid, reason = self.check_example(cleaned_example)\n",
    "            \n",
    "            if is_valid:\n",
    "                cleaned.append(cleaned_example)\n",
    "                stats[\"passed\"] += 1\n",
    "            else:\n",
    "                stats[\"failed\"] += 1\n",
    "                stats[\"reasons\"][reason] = stats[\"reasons\"].get(reason, 0) + 1\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nFiltering Results:\")\n",
    "            print(f\"  Total: {stats['total']}\")\n",
    "            print(f\"  Passed: {stats['passed']} ({100*stats['passed']/max(1,stats['total']):.1f}%)\")\n",
    "            print(f\"  Failed: {stats['failed']}\")\n",
    "            if stats[\"reasons\"]:\n",
    "                print(f\"  Failure reasons:\")\n",
    "                for reason, count in sorted(stats[\"reasons\"].items(), key=lambda x: -x[1]):\n",
    "                    print(f\"    - {reason}: {count}\")\n",
    "        \n",
    "        return cleaned, stats\n",
    "\n",
    "\n",
    "# Test the filter\n",
    "test_data = [\n",
    "    {\"instruction\": \"Write a poem\", \"input\": \"\", \"output\": \"Roses are red...\"},  # Too short\n",
    "    {\"instruction\": \"Hi\", \"input\": \"\", \"output\": \"Hello! How can I help you today?\"},  # Instruction too short\n",
    "    {\"instruction\": \"Explain machine learning\", \"input\": \"\", \"output\": \"TODO\"},  # Placeholder\n",
    "    {\"instruction\": \"What is Python?\", \"input\": \"\", \"output\": \"Python is a high-level programming language known for its readability and versatility.\"},  # Good!\n",
    "    {\"instruction\": \"What is Python?\", \"input\": \"\", \"output\": \"Python is a high-level programming language known for its readability and versatility.\"},  # Duplicate!\n",
    "]\n",
    "\n",
    "quality_filter = DataQualityFilter(min_output_len=30)\n",
    "cleaned_data, stats = quality_filter.filter_dataset(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Creating Preference Pairs for DPO\n",
    "\n",
    "For preference optimization (DPO, SimPO, etc.), we need (prompt, chosen, rejected) triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreferencePairGenerator:\n",
    "    \"\"\"\n",
    "    Generate preference pairs for DPO training.\n",
    "    \n",
    "    Methods:\n",
    "    1. From quality scores (if you have ratings)\n",
    "    2. From multiple responses (pick best vs rest)\n",
    "    3. Synthetic (generate rejected responses)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_scores(\n",
    "        responses: List[Dict],\n",
    "        min_score_diff: float = 0.5\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Create pairs from responses with quality scores.\n",
    "        \n",
    "        Input: [{\"prompt\": str, \"response\": str, \"score\": float}, ...]\n",
    "        Output: [{\"prompt\": str, \"chosen\": str, \"rejected\": str}, ...]\n",
    "        \"\"\"\n",
    "        # Group by prompt\n",
    "        by_prompt = {}\n",
    "        for r in responses:\n",
    "            prompt = r['prompt']\n",
    "            if prompt not in by_prompt:\n",
    "                by_prompt[prompt] = []\n",
    "            by_prompt[prompt].append(r)\n",
    "        \n",
    "        pairs = []\n",
    "        for prompt, prompt_responses in by_prompt.items():\n",
    "            # Sort by score (highest first)\n",
    "            prompt_responses.sort(key=lambda x: x['score'], reverse=True)\n",
    "            \n",
    "            # Create pairs where chosen >> rejected\n",
    "            for i, high in enumerate(prompt_responses):\n",
    "                for low in prompt_responses[i + 1:]:\n",
    "                    if high['score'] - low['score'] >= min_score_diff:\n",
    "                        pairs.append({\n",
    "                            'prompt': prompt,\n",
    "                            'chosen': high['response'],\n",
    "                            'rejected': low['response'],\n",
    "                        })\n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    @staticmethod\n",
    "    def synthetic_rejected(\n",
    "        examples: List[Dict],\n",
    "        rejection_strategies: List[str] = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Create synthetic rejected responses.\n",
    "        \n",
    "        Strategies:\n",
    "        - truncate: Cut response short\n",
    "        - add_errors: Add grammar/logic errors\n",
    "        - generic: Replace with generic response\n",
    "        - refuse: Add refusal\n",
    "        \"\"\"\n",
    "        if rejection_strategies is None:\n",
    "            rejection_strategies = [\"truncate\", \"generic\"]\n",
    "        \n",
    "        pairs = []\n",
    "        \n",
    "        generic_responses = [\n",
    "            \"I cannot help with that.\",\n",
    "            \"Please try again later.\",\n",
    "            \"I don't know.\",\n",
    "            \"That's an interesting question.\",\n",
    "        ]\n",
    "        \n",
    "        for example in examples:\n",
    "            instruction = example.get('instruction', '')\n",
    "            input_text = example.get('input', '')\n",
    "            chosen = example.get('output', '')\n",
    "            \n",
    "            prompt = instruction\n",
    "            if input_text:\n",
    "                prompt += f\"\\n\\nInput: {input_text}\"\n",
    "            \n",
    "            # Pick a random strategy\n",
    "            strategy = random.choice(rejection_strategies)\n",
    "            \n",
    "            if strategy == \"truncate\" and len(chosen) > 50:\n",
    "                # Cut at ~30% of length\n",
    "                cut_point = len(chosen) // 3\n",
    "                rejected = chosen[:cut_point] + \"...\"\n",
    "            elif strategy == \"generic\":\n",
    "                rejected = random.choice(generic_responses)\n",
    "            else:\n",
    "                rejected = random.choice(generic_responses)\n",
    "            \n",
    "            pairs.append({\n",
    "                'prompt': prompt,\n",
    "                'chosen': chosen,\n",
    "                'rejected': rejected,\n",
    "            })\n",
    "        \n",
    "        return pairs\n",
    "\n",
    "\n",
    "# Demo with scored responses\n",
    "scored_responses = [\n",
    "    {\"prompt\": \"What is 2+2?\", \"response\": \"2+2 equals 4.\", \"score\": 0.9},\n",
    "    {\"prompt\": \"What is 2+2?\", \"response\": \"The answer is four.\", \"score\": 0.85},\n",
    "    {\"prompt\": \"What is 2+2?\", \"response\": \"4\", \"score\": 0.5},\n",
    "    {\"prompt\": \"What is 2+2?\", \"response\": \"I think it's 5?\", \"score\": 0.1},\n",
    "]\n",
    "\n",
    "pairs = PreferencePairGenerator.from_scores(scored_responses, min_score_diff=0.3)\n",
    "print(f\"Generated {len(pairs)} preference pairs:\")\n",
    "for p in pairs[:2]:\n",
    "    print(f\"  Chosen: {p['chosen'][:50]}...\")\n",
    "    print(f\"  Rejected: {p['rejected'][:50]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Complete Data Pipeline\n",
    "\n",
    "Let's put it all together into a complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    \"\"\"\n",
    "    Complete data preparation pipeline for LLM fine-tuning.\n",
    "    \n",
    "    Steps:\n",
    "    1. Load raw data\n",
    "    2. Clean and filter\n",
    "    3. Convert to target format\n",
    "    4. Split into train/val/test\n",
    "    5. Save\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        system_prompt: str = \"You are a helpful assistant.\",\n",
    "        output_format: str = \"llama3\",  # 'llama3', 'chatml', 'alpaca'\n",
    "        quality_filter: Optional[DataQualityFilter] = None,\n",
    "    ):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.output_format = output_format\n",
    "        self.quality_filter = quality_filter or DataQualityFilter()\n",
    "    \n",
    "    def load_jsonl(self, filepath: str) -> List[Dict]:\n",
    "        \"\"\"Load data from JSONL file.\"\"\"\n",
    "        data = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    data.append(json.loads(line))\n",
    "        return data\n",
    "    \n",
    "    def load_json(self, filepath: str) -> List[Dict]:\n",
    "        \"\"\"Load data from JSON file.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def format_example(self, example: Dict) -> str:\n",
    "        \"\"\"Format a single example for training.\"\"\"\n",
    "        conv = FormatConverter.alpaca_to_conversation(example, self.system_prompt)\n",
    "        \n",
    "        if self.output_format == \"llama3\":\n",
    "            return FormatConverter.conversation_to_llama3(conv)\n",
    "        elif self.output_format == \"chatml\":\n",
    "            return FormatConverter.conversation_to_chatml(conv)\n",
    "        else:\n",
    "            # Keep as Alpaca dict\n",
    "            return json.dumps(example)\n",
    "    \n",
    "    def split_data(\n",
    "        self,\n",
    "        data: List[Dict],\n",
    "        train_ratio: float = 0.8,\n",
    "        val_ratio: float = 0.1,\n",
    "        test_ratio: float = 0.1,\n",
    "        shuffle: bool = True,\n",
    "    ) -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
    "        \"\"\"Split data into train/val/test sets.\"\"\"\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6\n",
    "        \n",
    "        data = data.copy()\n",
    "        if shuffle:\n",
    "            random.shuffle(data)\n",
    "        \n",
    "        n = len(data)\n",
    "        train_end = int(n * train_ratio)\n",
    "        val_end = train_end + int(n * val_ratio)\n",
    "        \n",
    "        return data[:train_end], data[train_end:val_end], data[val_end:]\n",
    "    \n",
    "    def process(\n",
    "        self,\n",
    "        data: List[Dict],\n",
    "        output_dir: str = \"./processed_data\",\n",
    "    ) -> DatasetDict:\n",
    "        \"\"\"\n",
    "        Run the complete pipeline.\n",
    "        \n",
    "        Returns HuggingFace DatasetDict ready for training.\n",
    "        \"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"DATA PREPARATION PIPELINE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Step 1: Filter\n",
    "        print(\"\\n1. Filtering data...\")\n",
    "        filtered_data, stats = self.quality_filter.filter_dataset(data)\n",
    "        \n",
    "        # Step 2: Format\n",
    "        print(f\"\\n2. Formatting to {self.output_format}...\")\n",
    "        formatted_data = []\n",
    "        for example in filtered_data:\n",
    "            formatted_data.append({\n",
    "                \"text\": self.format_example(example),\n",
    "                **example  # Keep original fields too\n",
    "            })\n",
    "        \n",
    "        # Step 3: Split\n",
    "        print(\"\\n3. Splitting data...\")\n",
    "        train, val, test = self.split_data(formatted_data)\n",
    "        print(f\"   Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n",
    "        \n",
    "        # Step 4: Create HuggingFace dataset\n",
    "        print(\"\\n4. Creating HuggingFace dataset...\")\n",
    "        dataset_dict = DatasetDict({\n",
    "            \"train\": Dataset.from_list(train),\n",
    "            \"validation\": Dataset.from_list(val),\n",
    "            \"test\": Dataset.from_list(test),\n",
    "        })\n",
    "        \n",
    "        # Step 5: Save\n",
    "        print(f\"\\n5. Saving to {output_dir}...\")\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        dataset_dict.save_to_disk(output_dir)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PIPELINE COMPLETE!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        return dataset_dict\n",
    "\n",
    "\n",
    "# Demo the pipeline\n",
    "sample_data = [\n",
    "    {\"instruction\": \"What is Python?\", \"input\": \"\", \"output\": \"Python is a high-level, interpreted programming language known for its clear syntax and readability.\"},\n",
    "    {\"instruction\": \"Explain machine learning in simple terms.\", \"input\": \"\", \"output\": \"Machine learning is a type of AI where computers learn patterns from data instead of being explicitly programmed.\"},\n",
    "    {\"instruction\": \"Write a haiku about coding.\", \"input\": \"\", \"output\": \"Lines of code flow down\\nSilent bugs hide in the dark\\nDebugger reveals\"},\n",
    "    {\"instruction\": \"What is 2+2?\", \"input\": \"\", \"output\": \"2+2 equals 4. This is a basic arithmetic operation.\"},\n",
    "    {\"instruction\": \"Hi\", \"input\": \"\", \"output\": \"Hello!\"},  # Will be filtered\n",
    "]\n",
    "\n",
    "pipeline = DataPipeline(output_format=\"llama3\")\n",
    "dataset = pipeline.process(sample_data, output_dir=\"./demo_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the processed data\n",
    "print(\"\\nProcessed dataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "print(\"\\nSample formatted example:\")\n",
    "print(dataset[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself: Exercises\n",
    "\n",
    "### Exercise 1: Add Language Detection\n",
    "\n",
    "Extend `DataQualityFilter` to detect and filter by language.\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Use the `langdetect` library: `pip install langdetect`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Extend DataQualityFilter with language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Multi-Turn Conversation Pairs\n",
    "\n",
    "Create preference pairs from multi-turn conversations where the last response varies.\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "The \"prompt\" should include all messages up to the last assistant turn.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Create multi-turn preference pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ✅ Different dataset formats (Alpaca, ShareGPT, ChatML)\n",
    "- ✅ How to convert between formats\n",
    "- ✅ Quality filtering for training data\n",
    "- ✅ Creating preference pairs for DPO\n",
    "- ✅ Building a complete data pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Alpaca Dataset](https://github.com/tatsu-lab/stanford_alpaca)\n",
    "- [ShareGPT Vicuna Dataset](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)\n",
    "- [Data Quality for LLMs](https://arxiv.org/abs/2305.10429)\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up demo files\n",
    "import shutil\n",
    "if Path(\"./demo_dataset\").exists():\n",
    "    shutil.rmtree(\"./demo_dataset\")\n",
    "    print(\"Demo dataset cleaned up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to:\n",
    "\n",
    "**[Lab 3.1.7: DPO Training](lab-3.1.7-dpo-training.ipynb)** - Use your preference pairs to train with Direct Preference Optimization!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
