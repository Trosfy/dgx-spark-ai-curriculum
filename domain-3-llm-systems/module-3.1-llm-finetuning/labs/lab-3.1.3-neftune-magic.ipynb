{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.1.3: NEFTune Magic - 5 Lines to 35% Better Performance\n",
    "\n",
    "**Module:** 3.1 - Large Language Model Fine-Tuning  \n",
    "**Time:** 1 hour  \n",
    "**Difficulty:** ⭐⭐☆☆☆\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand why adding noise to embeddings helps fine-tuning\n",
    "- [ ] Implement NEFTune from scratch (just 5 lines!)\n",
    "- [ ] Measure the dramatic improvement (29.8% → 64.7% on AlpacaEval!)\n",
    "- [ ] Know how to tune the noise parameter for your task\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed: Lab 3.1.1 (LoRA Theory)\n",
    "- Knowledge of: PyTorch, embeddings basics\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "### The Problem: Fine-Tuned Models Sound Repetitive\n",
    "\n",
    "You've probably noticed that fine-tuned models sometimes:\n",
    "- Give shorter, more robotic responses\n",
    "- Repeat phrases or patterns\n",
    "- Lose some of the base model's \"personality\"\n",
    "\n",
    "Why? During fine-tuning, the model overfits to the exact patterns in your training data.\n",
    "\n",
    "**NEFTune (Noisy Embedding Fine-Tuning)** fixes this with a brilliantly simple trick: add random noise to the input embeddings during training. This forces the model to be more robust and generates more diverse, natural responses.\n",
    "\n",
    "**The results are staggering:**\n",
    "- AlpacaEval win rate: 29.8% → **64.7%** (Llama-2-7B)\n",
    "- Just 5 lines of code to implement!\n",
    "- Works with any fine-tuning method (LoRA, full FT, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5: What is NEFTune?\n",
    "\n",
    "> **Imagine you're learning to draw by tracing over pictures.** If you trace the exact same picture 1000 times, you'll be really good at drawing *that specific picture*, but not very good at drawing in general.\n",
    ">\n",
    "> **NEFTune is like drawing with slightly shaky hands.** The small wobbles force you to understand the *essence* of the drawing rather than memorizing exact lines. You learn to capture the general shape and style, not just copy pixels.\n",
    ">\n",
    "> **In AI terms:** By adding small random noise to the input embeddings, we prevent the model from memorizing exact token sequences. Instead, it learns more robust, generalizable patterns that transfer better to new conversations.\n",
    ">\n",
    "> **The secret sauce:** The noise is scaled by $1/\\sqrt{L}$ where $L$ is sequence length. Longer sequences get less noise per token, keeping the total \"shakiness\" consistent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The NEFTune Algorithm\n",
    "\n",
    "### The Math (It's Simple!)\n",
    "\n",
    "Given input embeddings $E \\in \\mathbb{R}^{B \\times L \\times D}$ where:\n",
    "- $B$ = batch size\n",
    "- $L$ = sequence length  \n",
    "- $D$ = embedding dimension\n",
    "\n",
    "NEFTune adds noise:\n",
    "\n",
    "$$E' = E + \\frac{\\alpha}{\\sqrt{L \\cdot D}} \\cdot \\epsilon$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha$ is the noise intensity (typically 5-15)\n",
    "- $\\epsilon \\sim \\text{Uniform}(-1, 1)$ is random noise\n",
    "- The $\\sqrt{L \\cdot D}$ scaling keeps noise proportional\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "1. **Regularization effect**: Noise prevents memorizing exact patterns\n",
    "2. **Data augmentation**: Each training example becomes slightly different each time\n",
    "3. **Smoother loss landscape**: Helps optimization avoid sharp local minima\n",
    "4. **Improved generalization**: Model learns robust features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The 5-Line Implementation\n",
    "\n",
    "Here's the entire NEFTune algorithm in just 5 lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neftune_forward(embeddings: torch.Tensor, alpha: float = 5.0, training: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    NEFTune: Noisy Embedding Fine-Tuning\n",
    "    \n",
    "    The complete implementation in 5 lines!\n",
    "    \n",
    "    Args:\n",
    "        embeddings: Input embeddings (batch, seq_len, embed_dim)\n",
    "        alpha: Noise intensity (recommended: 5-15)\n",
    "        training: Whether in training mode\n",
    "    \n",
    "    Returns:\n",
    "        Noisy embeddings (only during training)\n",
    "    \"\"\"\n",
    "    if not training:                                           # Line 1\n",
    "        return embeddings                                      # Line 2\n",
    "    dims = embeddings.shape[-1] * embeddings.shape[-2]         # Line 3: L * D\n",
    "    noise = torch.rand_like(embeddings) * 2 - 1                # Line 4: Uniform(-1, 1)\n",
    "    return embeddings + (alpha / dims**0.5) * noise            # Line 5: Add scaled noise\n",
    "\n",
    "\n",
    "# That's it! Let's verify it works\n",
    "batch, seq_len, embed_dim = 4, 128, 768\n",
    "embeddings = torch.randn(batch, seq_len, embed_dim)\n",
    "\n",
    "# Apply NEFTune\n",
    "noisy_embeddings = neftune_forward(embeddings, alpha=5.0, training=True)\n",
    "\n",
    "# Calculate noise statistics\n",
    "noise_added = noisy_embeddings - embeddings\n",
    "print(f\"Original embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Noise statistics:\")\n",
    "print(f\"  Mean: {noise_added.mean():.6f} (should be ~0)\")\n",
    "print(f\"  Std:  {noise_added.std():.6f}\")\n",
    "print(f\"  Max:  {noise_added.abs().max():.6f}\")\n",
    "print(f\"\\nNoise as % of embedding std: {noise_added.std() / embeddings.std() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Happening?\n",
    "\n",
    "The noise is:\n",
    "1. **Uniform** between -1 and 1 (not Gaussian)\n",
    "2. **Scaled** by $\\alpha / \\sqrt{L \\cdot D}$ to keep it proportional\n",
    "3. **Only during training** - inference is unaffected\n",
    "\n",
    "The scaling means longer sequences get less noise per token, but the same \"total\" noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Visualizing the Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_neftune_effect():\n",
    "    \"\"\"\n",
    "    Visualize what NEFTune does to embeddings.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Sample embedding\n",
    "    seq_len, embed_dim = 64, 256\n",
    "    embedding = torch.randn(1, seq_len, embed_dim)\n",
    "    \n",
    "    # Different alpha values\n",
    "    alphas = [0, 5, 15]\n",
    "    \n",
    "    for i, alpha in enumerate(alphas):\n",
    "        noisy = neftune_forward(embedding, alpha=alpha, training=True)\n",
    "        noise = noisy - embedding\n",
    "        \n",
    "        # Original vs noisy embedding visualization\n",
    "        im = axes[0, i].imshow(\n",
    "            noisy[0, :32, :32].numpy(), \n",
    "            cmap='RdBu', aspect='auto', vmin=-3, vmax=3\n",
    "        )\n",
    "        axes[0, i].set_title(f'Embedding (α={alpha})')\n",
    "        axes[0, i].set_xlabel('Embedding dim')\n",
    "        axes[0, i].set_ylabel('Sequence position')\n",
    "        \n",
    "        # Noise distribution\n",
    "        axes[1, i].hist(noise.flatten().numpy(), bins=50, density=True, alpha=0.7, color='steelblue')\n",
    "        axes[1, i].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[1, i].set_title(f'Noise Distribution (α={alpha})')\n",
    "        axes[1, i].set_xlabel('Noise value')\n",
    "        axes[1, i].set_ylabel('Density')\n",
    "        \n",
    "        noise_std = noise.std().item()\n",
    "        axes[1, i].text(0.95, 0.95, f'std={noise_std:.4f}', \n",
    "                       transform=axes[1, i].transAxes, ha='right', va='top',\n",
    "                       fontsize=10, bbox=dict(boxstyle='round', facecolor='white'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('neftune_visualization.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "visualize_neftune_effect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_noise_scaling():\n",
    "    \"\"\"\n",
    "    Show how noise scales with sequence length.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    embed_dim = 768\n",
    "    alpha = 5.0\n",
    "    seq_lengths = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "    \n",
    "    noise_stds = []\n",
    "    noise_per_token = []\n",
    "    \n",
    "    for seq_len in seq_lengths:\n",
    "        embedding = torch.randn(1, seq_len, embed_dim)\n",
    "        noisy = neftune_forward(embedding, alpha=alpha, training=True)\n",
    "        noise = noisy - embedding\n",
    "        \n",
    "        noise_stds.append(noise.std().item())\n",
    "        # Total noise magnitude\n",
    "        noise_per_token.append(noise.abs().mean().item())\n",
    "    \n",
    "    # Plot noise std vs sequence length\n",
    "    axes[0].plot(seq_lengths, noise_stds, 'bo-', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Sequence Length')\n",
    "    axes[0].set_ylabel('Noise Std')\n",
    "    axes[0].set_title(f'Noise Magnitude vs Sequence Length (α={alpha})')\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Expected: noise_std ∝ 1/sqrt(seq_len)\n",
    "    expected = [noise_stds[0] * (seq_lengths[0] / sl) ** 0.5 for sl in seq_lengths]\n",
    "    axes[0].plot(seq_lengths, expected, 'r--', linewidth=2, label='Expected 1/√L scaling')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Total noise per sample\n",
    "    total_noise = [s * l for s, l in zip(noise_stds, seq_lengths)]\n",
    "    axes[1].bar([str(s) for s in seq_lengths], total_noise, color='coral')\n",
    "    axes[1].set_xlabel('Sequence Length')\n",
    "    axes[1].set_ylabel('Total Noise (std × seq_len)')\n",
    "    axes[1].set_title('Total Noise Roughly Constant')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('neftune_scaling.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"Key Insight: Noise per token decreases with sequence length,\")\n",
    "    print(\"but total noise per sample stays roughly constant!\")\n",
    "\n",
    "visualize_noise_scaling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Part 4: Wrapping a Model with NEFTune\n\nLet's create a proper wrapper that can be applied to any embedding layer.\n\n### PyTorch Transformer Components Used\n\n| Component | Description |\n|-----------|-------------|\n| `nn.TransformerEncoder` | A stack of N encoder layers. Applies self-attention and feedforward networks. |\n| `nn.TransformerEncoderLayer` | Single encoder layer with multi-head self-attention + feedforward. Parameters: `d_model` (dim), `nhead` (attention heads), `dim_feedforward`, `batch_first=True`. |\n| `nn.Embedding` | Lookup table that maps token IDs to dense vectors. |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEFTuneEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper that adds NEFTune noise to any embedding layer.\n",
    "    \n",
    "    Usage:\n",
    "        model.embed_tokens = NEFTuneEmbedding(model.embed_tokens, alpha=5.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_layer: nn.Embedding, alpha: float = 5.0):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        # Get embeddings\n",
    "        embeddings = self.embedding(input_ids)\n",
    "        \n",
    "        # Apply NEFTune during training\n",
    "        if self.training and self.alpha > 0:\n",
    "            dims = embeddings.shape[-1] * embeddings.shape[-2]\n",
    "            noise = torch.rand_like(embeddings) * 2 - 1\n",
    "            embeddings = embeddings + (self.alpha / dims**0.5) * noise\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.embedding.weight\n",
    "    \n",
    "    @property\n",
    "    def num_embeddings(self):\n",
    "        return self.embedding.num_embeddings\n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self.embedding.embedding_dim\n",
    "\n",
    "\n",
    "def apply_neftune_to_model(model: nn.Module, alpha: float = 5.0, embedding_name: str = 'embed_tokens'):\n",
    "    \"\"\"\n",
    "    Apply NEFTune to a model's embedding layer.\n",
    "    \n",
    "    Works with most HuggingFace models.\n",
    "    \"\"\"\n",
    "    # Find the embedding layer\n",
    "    for name, module in model.named_modules():\n",
    "        if embedding_name in name and isinstance(module, nn.Embedding):\n",
    "            # Get parent module\n",
    "            parent_name = '.'.join(name.split('.')[:-1])\n",
    "            child_name = name.split('.')[-1]\n",
    "            \n",
    "            if parent_name:\n",
    "                parent = model\n",
    "                for part in parent_name.split('.'):\n",
    "                    parent = getattr(parent, part)\n",
    "            else:\n",
    "                parent = model\n",
    "            \n",
    "            # Wrap with NEFTune\n",
    "            neftune_embedding = NEFTuneEmbedding(module, alpha=alpha)\n",
    "            setattr(parent, child_name, neftune_embedding)\n",
    "            print(f\"Applied NEFTune (α={alpha}) to {name}\")\n",
    "            return\n",
    "    \n",
    "    print(f\"Warning: Could not find embedding layer '{embedding_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo with a simple model\n",
    "class SimpleLanguageModel(nn.Module):\n",
    "    \"\"\"A tiny language model for demonstration.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int = 1000, embed_dim: int = 256, hidden_dim: int = 512):\n",
    "        super().__init__()\n",
    "        self.embed_tokens = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embed_dim, nhead=8, dim_feedforward=hidden_dim, batch_first=True),\n",
    "            num_layers=2\n",
    "        )\n",
    "        self.lm_head = nn.Linear(embed_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embed_tokens(input_ids)\n",
    "        x = self.transformer(x)\n",
    "        return self.lm_head(x)\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = SimpleLanguageModel(vocab_size=1000, embed_dim=256).to(device)\n",
    "print(\"Original model:\")\n",
    "print(f\"  Embedding type: {type(model.embed_tokens).__name__}\")\n",
    "\n",
    "# Apply NEFTune\n",
    "apply_neftune_to_model(model, alpha=5.0)\n",
    "print(f\"\\nAfter NEFTune:\")\n",
    "print(f\"  Embedding type: {type(model.embed_tokens).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Comparing With and Without NEFTune\n",
    "\n",
    "Let's train a model with and without NEFTune and measure the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_neftune(\n",
    "    use_neftune: bool = True,\n",
    "    alpha: float = 5.0,\n",
    "    n_epochs: int = 50,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Train a model with or without NEFTune.\n",
    "    \"\"\"\n",
    "    # Create fresh model\n",
    "    model = SimpleLanguageModel(vocab_size=500, embed_dim=128).to(device)\n",
    "    \n",
    "    if use_neftune:\n",
    "        apply_neftune_to_model(model, alpha=alpha)\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    # Task: Next token prediction with some pattern\n",
    "    torch.manual_seed(42)\n",
    "    n_samples = 1000\n",
    "    seq_len = 32\n",
    "    \n",
    "    # Create sequences with patterns (not just random)\n",
    "    train_data = torch.randint(0, 500, (n_samples, seq_len), device=device)\n",
    "    # Target: shifted by 1\n",
    "    train_targets = torch.cat([train_data[:, 1:], torch.randint(0, 500, (n_samples, 1), device=device)], dim=1)\n",
    "    \n",
    "    # Test data (different seed)\n",
    "    torch.manual_seed(999)\n",
    "    test_data = torch.randint(0, 500, (200, seq_len), device=device)\n",
    "    test_targets = torch.cat([test_data[:, 1:], torch.randint(0, 500, (200, 1), device=device)], dim=1)\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    batch_size = 32\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        perm = torch.randperm(n_samples)\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            batch_x = train_data[idx]\n",
    "            batch_y = train_targets[idx]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_x)\n",
    "            loss = F.cross_entropy(logits.view(-1, 500), batch_y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "        \n",
    "        avg_train_loss = epoch_loss / n_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_logits = model(test_data)\n",
    "            test_loss = F.cross_entropy(test_logits.view(-1, 500), test_targets.view(-1))\n",
    "            test_losses.append(test_loss.item())\n",
    "        \n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f\"  Epoch {epoch+1}: Train={avg_train_loss:.4f}, Test={test_loss.item():.4f}\")\n",
    "    \n",
    "    # Compute output diversity\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generate by sampling\n",
    "        sample_input = torch.randint(0, 500, (50, seq_len), device=device)\n",
    "        logits = model(sample_input)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        entropy = -(probs * torch.log(probs + 1e-8)).sum(dim=-1).mean().item()\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\n",
    "        'use_neftune': use_neftune,\n",
    "        'alpha': alpha if use_neftune else 0,\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'final_train_loss': np.mean(train_losses[-5:]),\n",
    "        'final_test_loss': np.mean(test_losses[-5:]),\n",
    "        'output_entropy': entropy,  # Higher = more diverse\n",
    "    }\n",
    "\n",
    "\n",
    "# Run comparison\n",
    "print(\"=\"*60)\n",
    "print(\"Training WITHOUT NEFTune...\")\n",
    "print(\"=\"*60)\n",
    "results_no_neftune = train_with_neftune(use_neftune=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training WITH NEFTune (α=5)...\")\n",
    "print(\"=\"*60)\n",
    "results_neftune = train_with_neftune(use_neftune=True, alpha=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Training curves\n",
    "axes[0].plot(results_no_neftune['train_losses'], label='No NEFTune (train)', color='blue', linestyle='--')\n",
    "axes[0].plot(results_no_neftune['test_losses'], label='No NEFTune (test)', color='blue')\n",
    "axes[0].plot(results_neftune['train_losses'], label='NEFTune (train)', color='red', linestyle='--')\n",
    "axes[0].plot(results_neftune['test_losses'], label='NEFTune (test)', color='red')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training vs Test Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Generalization gap\n",
    "methods = ['No NEFTune', 'NEFTune (α=5)']\n",
    "train_final = [results_no_neftune['final_train_loss'], results_neftune['final_train_loss']]\n",
    "test_final = [results_no_neftune['final_test_loss'], results_neftune['final_test_loss']]\n",
    "gaps = [t - tr for t, tr in zip(test_final, train_final)]\n",
    "\n",
    "x_pos = np.arange(len(methods))\n",
    "width = 0.35\n",
    "axes[1].bar(x_pos - width/2, train_final, width, label='Train', color='steelblue')\n",
    "axes[1].bar(x_pos + width/2, test_final, width, label='Test', color='coral')\n",
    "axes[1].set_xlabel('Method')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Final Losses (Lower = Better)')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(methods)\n",
    "axes[1].legend()\n",
    "\n",
    "# Output diversity (entropy)\n",
    "entropies = [results_no_neftune['output_entropy'], results_neftune['output_entropy']]\n",
    "colors = ['blue', 'red']\n",
    "axes[2].bar(methods, entropies, color=colors)\n",
    "axes[2].set_xlabel('Method')\n",
    "axes[2].set_ylabel('Output Entropy')\n",
    "axes[2].set_title('Output Diversity (Higher = More Diverse)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('neftune_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nWithout NEFTune:\")\n",
    "print(f\"  Final train loss: {results_no_neftune['final_train_loss']:.4f}\")\n",
    "print(f\"  Final test loss:  {results_no_neftune['final_test_loss']:.4f}\")\n",
    "print(f\"  Generalization gap: {gaps[0]:.4f}\")\n",
    "print(f\"  Output entropy: {results_no_neftune['output_entropy']:.4f}\")\n",
    "\n",
    "print(f\"\\nWith NEFTune (α=5):\")\n",
    "print(f\"  Final train loss: {results_neftune['final_train_loss']:.4f}\")\n",
    "print(f\"  Final test loss:  {results_neftune['final_test_loss']:.4f}\")\n",
    "print(f\"  Generalization gap: {gaps[1]:.4f}\")\n",
    "print(f\"  Output entropy: {results_neftune['output_entropy']:.4f}\")\n",
    "\n",
    "test_improvement = (results_no_neftune['final_test_loss'] - results_neftune['final_test_loss']) / results_no_neftune['final_test_loss'] * 100\n",
    "diversity_improvement = (results_neftune['output_entropy'] - results_no_neftune['output_entropy']) / results_no_neftune['output_entropy'] * 100\n",
    "\n",
    "print(f\"\\nNEFTune Benefits:\")\n",
    "print(f\"  Test loss improvement: {test_improvement:.1f}%\")\n",
    "print(f\"  Diversity improvement: {diversity_improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Finding the Optimal Alpha\n",
    "\n",
    "The noise intensity (alpha) matters! Let's find the sweet spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different alpha values\n",
    "alphas_to_test = [0, 1, 5, 10, 15, 20]\n",
    "alpha_results = []\n",
    "\n",
    "print(\"Testing different alpha values...\")\n",
    "for alpha in alphas_to_test:\n",
    "    print(f\"\\nAlpha = {alpha}\")\n",
    "    result = train_with_neftune(\n",
    "        use_neftune=(alpha > 0),\n",
    "        alpha=alpha,\n",
    "        n_epochs=30,\n",
    "        verbose=False\n",
    "    )\n",
    "    result['alpha'] = alpha\n",
    "    alpha_results.append(result)\n",
    "    print(f\"  Test loss: {result['final_test_loss']:.4f}, Entropy: {result['output_entropy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize alpha sweep\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "alphas = [r['alpha'] for r in alpha_results]\n",
    "test_losses = [r['final_test_loss'] for r in alpha_results]\n",
    "entropies = [r['output_entropy'] for r in alpha_results]\n",
    "\n",
    "axes[0].plot(alphas, test_losses, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Alpha (noise intensity)')\n",
    "axes[0].set_ylabel('Test Loss')\n",
    "axes[0].set_title('Test Loss vs Alpha (Lower = Better)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mark the best\n",
    "best_idx = np.argmin(test_losses)\n",
    "axes[0].scatter([alphas[best_idx]], [test_losses[best_idx]], color='red', s=200, zorder=5, marker='*')\n",
    "axes[0].annotate(f'Best: α={alphas[best_idx]}', \n",
    "                 (alphas[best_idx], test_losses[best_idx]),\n",
    "                 xytext=(10, 10), textcoords='offset points')\n",
    "\n",
    "axes[1].plot(alphas, entropies, 'ro-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Alpha (noise intensity)')\n",
    "axes[1].set_ylabel('Output Entropy')\n",
    "axes[1].set_title('Output Diversity vs Alpha (Higher = More Diverse)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('neftune_alpha_sweep.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"\\nRecommendation: α = {alphas[best_idx]} gives the best test loss\")\n",
    "print(\"(In practice, α = 5 is a good default for most LLM fine-tuning tasks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Using NEFTune with TRL (Production)\n",
    "\n",
    "In production, TRL (Transformers Reinforcement Learning) has NEFTune built-in. It's just one parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production usage with TRL\n",
    "trl_example = \"\"\"\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Create trainer with NEFTune enabled\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./output\",\n",
    "    max_seq_length=2048,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    \n",
    "    # NEFTune: Just add this one line!\n",
    "    neftune_noise_alpha=5.0,  # Recommended: 5-15\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "# Train with NEFTune automatically applied!\n",
    "trainer.train()\n",
    "\n",
    "# The improvement is dramatic:\n",
    "# - Llama-2-7B on AlpacaEval: 29.8% → 64.7%\n",
    "# - Llama-2-7B on MT-Bench: 5.22 → 6.02\n",
    "\"\"\"\n",
    "\n",
    "print(\"Production NEFTune with TRL:\")\n",
    "print(\"=\" * 50)\n",
    "print(trl_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Alpha Guidelines\n",
    "\n",
    "| Task | Recommended Alpha | Notes |\n",
    "|------|------------------|-------|\n",
    "| Instruction following | 5 | Default, works well |\n",
    "| Chat/Dialogue | 5-10 | Higher for more diverse responses |\n",
    "| Code generation | 3-5 | Lower to preserve precision |\n",
    "| Creative writing | 10-15 | Higher for more creativity |\n",
    "| QA/Factual | 5 | Balanced |\n",
    "\n",
    "**General rule:** Start with α=5, increase if responses feel repetitive, decrease if they become incoherent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself: Exercises\n",
    "\n",
    "### Exercise 1: Gaussian vs Uniform Noise\n",
    "\n",
    "The original NEFTune uses uniform noise. Try Gaussian noise and compare.\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Replace `torch.rand_like(embeddings) * 2 - 1` with `torch.randn_like(embeddings)`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "def neftune_gaussian(embeddings: torch.Tensor, alpha: float = 5.0, training: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    NEFTune variant with Gaussian noise instead of uniform.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Per-Token Noise\n",
    "\n",
    "What if we add different noise intensity per token position? Earlier tokens might need less noise than later ones.\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Create a position-dependent alpha: `alpha_per_pos = alpha * (1 + position / seq_len)`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "def neftune_positional(embeddings: torch.Tensor, alpha: float = 5.0, training: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    NEFTune variant with position-dependent noise.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Applying Noise During Inference\n",
    "\n",
    "```python\n",
    "# Wrong: Noise during inference makes outputs inconsistent\n",
    "def forward(self, x):\n",
    "    embeddings = self.embedding(x)\n",
    "    noise = torch.rand_like(embeddings) * 2 - 1\n",
    "    return embeddings + noise  # WRONG!\n",
    "\n",
    "# Right: Only during training\n",
    "def forward(self, x):\n",
    "    embeddings = self.embedding(x)\n",
    "    if self.training:  # Key check!\n",
    "        noise = torch.rand_like(embeddings) * 2 - 1\n",
    "        embeddings = embeddings + (self.alpha / dims**0.5) * noise\n",
    "    return embeddings\n",
    "```\n",
    "\n",
    "### Mistake 2: Wrong Scaling\n",
    "\n",
    "```python\n",
    "# Wrong: Not scaling by sequence length\n",
    "noise = torch.rand_like(embeddings) * alpha  # WRONG!\n",
    "\n",
    "# Right: Scale by sqrt(L * D)\n",
    "dims = embeddings.shape[-1] * embeddings.shape[-2]\n",
    "noise = torch.rand_like(embeddings) * 2 - 1\n",
    "noise = (alpha / dims**0.5) * noise  # Correct!\n",
    "```\n",
    "\n",
    "### Mistake 3: Alpha Too High\n",
    "\n",
    "```python\n",
    "# Wrong: Very high alpha can destabilize training\n",
    "neftune_noise_alpha=50  # Too high!\n",
    "\n",
    "# Right: Keep in reasonable range\n",
    "neftune_noise_alpha=5  # Start here\n",
    "# Increase to 10-15 only if needed\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ✅ The NEFTune algorithm (just 5 lines!)\n",
    "- ✅ Why adding noise improves generalization (29.8% → 64.7% on AlpacaEval!)\n",
    "- ✅ How to implement NEFTune from scratch\n",
    "- ✅ How to use NEFTune with TRL in production\n",
    "- ✅ How to tune the alpha parameter for your task\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaway\n",
    "\n",
    "**NEFTune is one of the highest ROI techniques in LLM fine-tuning:**\n",
    "- 5 lines of code\n",
    "- No extra compute cost\n",
    "- 35%+ improvement on benchmarks\n",
    "- Works with any fine-tuning method\n",
    "\n",
    "**Always use NEFTune when fine-tuning LLMs!**\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [NEFTune Paper](https://arxiv.org/abs/2310.05914) - Noisy Embeddings Improve Instruction Finetuning\n",
    "- [TRL Documentation](https://huggingface.co/docs/trl) - NEFTune integration\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"Cleanup complete!\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand NEFTune, continue to:\n",
    "\n",
    "**[Lab 3.1.4: 8B Model LoRA Fine-tuning](lab-3.1.4-8b-lora-finetuning.ipynb)** - Put it all together: LoRA + DoRA + NEFTune on a real 8B model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}