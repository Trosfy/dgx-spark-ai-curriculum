{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.1.3: NEFTune Magic - Solutions\n",
    "\n",
    "Complete solutions for the NEFTune exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Implement NEFTune from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class NEFTuneEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete NEFTune implementation with proper scaling.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_layer: nn.Embedding, alpha: float = 5.0):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.alpha = alpha\n",
    "        self.embedding_dim = embedding_layer.embedding_dim\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        # Get base embeddings\n",
    "        embeddings = self.embedding(input_ids)\n",
    "        \n",
    "        # Only add noise during training\n",
    "        if self.training:\n",
    "            # Get sequence length for scaling\n",
    "            seq_len = input_ids.shape[1]\n",
    "            \n",
    "            # Scaling factor: alpha / sqrt(seq_len * embedding_dim)\n",
    "            # This ensures noise magnitude is independent of sequence length\n",
    "            scale = self.alpha / np.sqrt(seq_len * self.embedding_dim)\n",
    "            \n",
    "            # Sample uniform noise in [-1, 1]\n",
    "            noise = torch.zeros_like(embeddings).uniform_(-1, 1)\n",
    "            \n",
    "            # Add scaled noise\n",
    "            embeddings = embeddings + scale * noise\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def set_alpha(self, alpha: float):\n",
    "        \"\"\"Dynamically adjust noise level.\"\"\"\n",
    "        self.alpha = alpha\n",
    "\n",
    "# Test\n",
    "base_embedding = nn.Embedding(1000, 768)\n",
    "neftune = NEFTuneEmbedding(base_embedding, alpha=5.0)\n",
    "\n",
    "input_ids = torch.randint(0, 1000, (4, 128))\n",
    "\n",
    "# Training mode - noise added\n",
    "neftune.train()\n",
    "train_out = neftune(input_ids)\n",
    "\n",
    "# Eval mode - no noise\n",
    "neftune.eval()\n",
    "eval_out = neftune(input_ids)\n",
    "\n",
    "# Compare\n",
    "print(f\"Training output variance: {train_out.var():.6f}\")\n",
    "print(f\"Eval output variance: {eval_out.var():.6f}\")\n",
    "print(f\"Difference (should be non-zero in train): {(train_out - eval_out).abs().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Alpha Tuning Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def alpha_sensitivity_analysis(model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
    "    \"\"\"\n",
    "    Analyze how different alpha values affect embeddings.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Simulate embeddings\n",
    "    torch.manual_seed(42)\n",
    "    base_embed = torch.randn(4, 128, 2048)  # [batch, seq, dim]\n",
    "    \n",
    "    alphas = [0, 1, 5, 10, 15, 20, 30]\n",
    "    results = []\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        if alpha == 0:\n",
    "            noisy = base_embed.clone()\n",
    "        else:\n",
    "            scale = alpha / np.sqrt(128 * 2048)\n",
    "            noise = torch.zeros_like(base_embed).uniform_(-1, 1)\n",
    "            noisy = base_embed + scale * noise\n",
    "        \n",
    "        # Metrics\n",
    "        l2_diff = (noisy - base_embed).norm(dim=-1).mean().item()\n",
    "        cosine_sim = torch.nn.functional.cosine_similarity(\n",
    "            base_embed.view(-1, 2048), \n",
    "            noisy.view(-1, 2048)\n",
    "        ).mean().item()\n",
    "        snr = base_embed.norm().item() / (noisy - base_embed).norm().item() if alpha > 0 else float('inf')\n",
    "        \n",
    "        results.append({\n",
    "            'alpha': alpha,\n",
    "            'l2_diff': l2_diff,\n",
    "            'cosine_sim': cosine_sim,\n",
    "            'snr': snr\n",
    "        })\n",
    "        \n",
    "        print(f\"α={alpha:2d}: L2 diff={l2_diff:.4f}, Cosine={cosine_sim:.4f}, SNR={snr:.2f}\")\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot([r['alpha'] for r in results], [r['l2_diff'] for r in results], 'o-')\n",
    "    axes[0].set_xlabel('Alpha')\n",
    "    axes[0].set_ylabel('L2 Difference')\n",
    "    axes[0].set_title('Noise Magnitude')\n",
    "    axes[0].axvspan(5, 15, alpha=0.2, color='green', label='Recommended')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot([r['alpha'] for r in results], [r['cosine_sim'] for r in results], 'o-', color='orange')\n",
    "    axes[1].set_xlabel('Alpha')\n",
    "    axes[1].set_ylabel('Cosine Similarity')\n",
    "    axes[1].set_title('Direction Preservation')\n",
    "    \n",
    "    axes[2].plot([r['alpha'] for r in results[1:]], [r['snr'] for r in results[1:]], 'o-', color='green')\n",
    "    axes[2].set_xlabel('Alpha')\n",
    "    axes[2].set_ylabel('SNR')\n",
    "    axes[2].set_title('Signal-to-Noise Ratio')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('alpha_analysis.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = alpha_sensitivity_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Integrate NEFTune with HuggingFace Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "def create_neftune_training_config():\n",
    "    \"\"\"\n",
    "    Create training configuration with NEFTune enabled.\n",
    "    \"\"\"\n",
    "    # Using SFTConfig which has native NEFTune support\n",
    "    training_args = SFTConfig(\n",
    "        output_dir=\"./neftune-output\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=2e-5,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"epoch\",\n",
    "        \n",
    "        # NEFTune configuration\n",
    "        neftune_noise_alpha=5.0,  # This enables NEFTune!\n",
    "        \n",
    "        # Other optimizations\n",
    "        bf16=True,\n",
    "        gradient_checkpointing=True,\n",
    "        optim=\"adamw_torch_fused\",\n",
    "    )\n",
    "    \n",
    "    print(\"Training config created with NEFTune alpha =\", training_args.neftune_noise_alpha)\n",
    "    return training_args\n",
    "\n",
    "config = create_neftune_training_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Compare Training With and Without NEFTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neftune_ablation_study():\n",
    "    \"\"\"\n",
    "    Compare training dynamics with and without NEFTune.\n",
    "    \"\"\"\n",
    "    # Simulated training curves based on paper results\n",
    "    epochs = np.arange(1, 11)\n",
    "    \n",
    "    # Without NEFTune - baseline\n",
    "    baseline_loss = 2.5 * np.exp(-0.3 * epochs) + 0.8\n",
    "    baseline_eval = 55 + 8 * (1 - np.exp(-0.4 * epochs))\n",
    "    \n",
    "    # With NEFTune - better generalization\n",
    "    neftune_loss = 2.6 * np.exp(-0.28 * epochs) + 0.75  # Slightly higher train loss\n",
    "    neftune_eval = 55 + 15 * (1 - np.exp(-0.35 * epochs))  # Much better eval\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Training loss\n",
    "    axes[0].plot(epochs, baseline_loss, 'b-o', label='Baseline')\n",
    "    axes[0].plot(epochs, neftune_loss, 'r-o', label='NEFTune')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Training Loss')\n",
    "    axes[0].set_title('Training Loss Comparison')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Eval accuracy\n",
    "    axes[1].plot(epochs, baseline_eval, 'b-o', label='Baseline')\n",
    "    axes[1].plot(epochs, neftune_eval, 'r-o', label='NEFTune')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Eval Score (%)')\n",
    "    axes[1].set_title('Evaluation Performance')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Annotate final improvement\n",
    "    improvement = neftune_eval[-1] - baseline_eval[-1]\n",
    "    axes[1].annotate(\n",
    "        f'+{improvement:.1f}%',\n",
    "        xy=(10, neftune_eval[-1]),\n",
    "        xytext=(8.5, neftune_eval[-1] + 3),\n",
    "        fontsize=12,\n",
    "        color='red',\n",
    "        arrowprops=dict(arrowstyle='->', color='red')\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('neftune_comparison.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nKey insight: NEFTune may have slightly higher training loss\")\n",
    "    print(f\"but achieves +{improvement:.1f}% better evaluation performance!\")\n",
    "    print(f\"This is the regularization effect in action.\")\n",
    "\n",
    "neftune_ablation_study()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Visualize Noise Effect on Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_embedding_perturbation():\n",
    "    \"\"\"\n",
    "    Show how NEFTune noise affects embedding distribution.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Create clustered embeddings (simulating semantic groups)\n",
    "    n_clusters = 5\n",
    "    n_samples = 50\n",
    "    dim = 64  # Reduced for visualization\n",
    "    \n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for i in range(n_clusters):\n",
    "        center = torch.randn(dim) * 3\n",
    "        cluster = center + torch.randn(n_samples, dim) * 0.5\n",
    "        embeddings.append(cluster)\n",
    "        labels.extend([i] * n_samples)\n",
    "    \n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Apply NEFTune noise\n",
    "    alpha = 5.0\n",
    "    scale = alpha / np.sqrt(n_samples * dim)\n",
    "    noise = torch.zeros_like(embeddings).uniform_(-1, 1)\n",
    "    noisy_embeddings = embeddings + scale * noise\n",
    "    \n",
    "    # t-SNE visualization\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    \n",
    "    combined = torch.cat([embeddings, noisy_embeddings]).numpy()\n",
    "    combined_2d = tsne.fit_transform(combined)\n",
    "    \n",
    "    orig_2d = combined_2d[:len(embeddings)]\n",
    "    noisy_2d = combined_2d[len(embeddings):]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original embeddings\n",
    "    scatter1 = axes[0].scatter(orig_2d[:, 0], orig_2d[:, 1], c=labels, cmap='tab10', alpha=0.6)\n",
    "    axes[0].set_title('Original Embeddings')\n",
    "    axes[0].set_xlabel('t-SNE 1')\n",
    "    axes[0].set_ylabel('t-SNE 2')\n",
    "    \n",
    "    # Noisy embeddings\n",
    "    axes[1].scatter(noisy_2d[:, 0], noisy_2d[:, 1], c=labels, cmap='tab10', alpha=0.6)\n",
    "    axes[1].set_title('NEFTune Embeddings (α=5)')\n",
    "    axes[1].set_xlabel('t-SNE 1')\n",
    "    \n",
    "    # Overlay showing perturbation\n",
    "    for i in range(0, len(embeddings), 10):  # Sample every 10th point\n",
    "        axes[2].arrow(\n",
    "            orig_2d[i, 0], orig_2d[i, 1],\n",
    "            noisy_2d[i, 0] - orig_2d[i, 0],\n",
    "            noisy_2d[i, 1] - orig_2d[i, 1],\n",
    "            head_width=0.3, head_length=0.2,\n",
    "            fc=plt.cm.tab10(labels[i]/10), ec=plt.cm.tab10(labels[i]/10),\n",
    "            alpha=0.5\n",
    "        )\n",
    "    axes[2].scatter(orig_2d[:, 0], orig_2d[:, 1], c=labels, cmap='tab10', alpha=0.3, s=20)\n",
    "    axes[2].set_title('Perturbation Vectors')\n",
    "    axes[2].set_xlabel('t-SNE 1')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('neftune_embedding_viz.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nObservation: NEFTune adds small random perturbations\")\n",
    "    print(\"that help the model learn more robust representations.\")\n",
    "\n",
    "visualize_embedding_perturbation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Simple Implementation**: Just 5 lines of code to add noise\n",
    "2. **Scaling Matters**: α / √(seq_len × dim) ensures consistent noise magnitude\n",
    "3. **Training Only**: Noise disabled during evaluation\n",
    "4. **Regularization**: Higher train loss but better generalization\n",
    "5. **Sweet Spot**: α = 5-15 works best for most models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
