{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.6.4: Multi-Agent Systems\n",
    "\n",
    "**Module:** 3.6 - AI Agents & Agentic Systems  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê (Advanced)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand multi-agent communication patterns\n",
    "- [ ] Build a 3-agent content generation team\n",
    "- [ ] Implement message passing between agents\n",
    "- [ ] Design agent handoff protocols\n",
    "- [ ] Handle agent coordination and conflicts\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Lab 3.6.3 (LangGraph Workflow)\n",
    "- Knowledge of: Agent patterns, state management\n",
    "- Running: Ollama with `llama3.1:8b` or larger model\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**The Problem:** Complex tasks often need multiple perspectives:\n",
    "- A single agent can't be expert in everything\n",
    "- Different roles require different prompts/behaviors\n",
    "- Quality improves with specialization and review\n",
    "\n",
    "**Multi-Agent Systems solve this** by having specialized agents collaborate:\n",
    "- **Researcher**: Finds and gathers information\n",
    "- **Writer**: Creates content from research\n",
    "- **Editor**: Reviews and improves the content\n",
    "\n",
    "**Real-World Applications:**\n",
    "- **Content Creation**: Research ‚Üí Write ‚Üí Edit ‚Üí Publish\n",
    "- **Code Review**: Developer ‚Üí Reviewer ‚Üí Merger\n",
    "- **Customer Service**: Triage ‚Üí Specialist ‚Üí Supervisor\n",
    "- **Data Analysis**: Collector ‚Üí Analyst ‚Üí Visualizer ‚Üí Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What are Multi-Agent Systems?\n",
    "\n",
    "> **Imagine a restaurant kitchen...** üë®‚Äçüç≥\n",
    ">\n",
    "> You don't have ONE chef doing everything. Instead:\n",
    "> - **Prep Cook**: Chops vegetables, prepares ingredients\n",
    "> - **Line Cook**: Actually cooks the dishes\n",
    "> - **Head Chef**: Inspects plates before they go out\n",
    "> - **Expeditor**: Coordinates timing and delivery\n",
    ">\n",
    "> Each person is specialized. They pass work to each other.\n",
    "> The result? Better food, faster service!\n",
    ">\n",
    "> **Multi-Agent AI works the same way:**\n",
    "> - Researcher Agent ‚Üí gathers information\n",
    "> - Writer Agent ‚Üí creates the first draft\n",
    "> - Editor Agent ‚Üí polishes and improves\n",
    "> - Each agent is specialized with different prompts and skills\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    Multi-Agent Content Team                     ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   \"Here's what I found\"   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n",
    "‚îÇ   ‚îÇ  üîç RESEARCHER ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ  ‚úçÔ∏è  WRITER   ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ               ‚îÇ                          ‚îÇ               ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ - Searches    ‚îÇ                          ‚îÇ - Drafts      ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ - Summarizes  ‚îÇ                          ‚îÇ - Structures  ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ - Validates   ‚îÇ                          ‚îÇ - Explains    ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n",
    "‚îÇ                                                      ‚îÇ         ‚îÇ\n",
    "‚îÇ                                    \"Here's my draft\" ‚îÇ         ‚îÇ\n",
    "‚îÇ                                                      ‚ñº         ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   \"Final version\"        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n",
    "‚îÇ   ‚îÇ  üì§ OUTPUT    ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ  üìù EDITOR    ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ               ‚îÇ                          ‚îÇ               ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ - Formatted   ‚îÇ                          ‚îÇ - Reviews     ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ - Ready       ‚îÇ                          ‚îÇ - Improves    ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îÇ - Delivered   ‚îÇ                          ‚îÇ - Polishes    ‚îÇ ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "# Add scripts to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'scripts'))\n",
    "\n",
    "print(\"‚úÖ Standard imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain imports\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Initialize LLM\n",
    "llm = Ollama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.7,  # Slightly higher for creative content\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# Quick test\n",
    "test = llm.invoke(\"Say 'Ready for multi-agent work!' in one sentence.\")\n",
    "print(f\"‚úÖ LLM ready: {test[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Defining Agent Roles\n",
    "\n",
    "Each agent has a specific role with its own system prompt and capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentRole(Enum):\n",
    "    \"\"\"Available agent roles.\"\"\"\n",
    "    RESEARCHER = \"researcher\"\n",
    "    WRITER = \"writer\"\n",
    "    EDITOR = \"editor\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentMessage:\n",
    "    \"\"\"\n",
    "    Message passed between agents.\n",
    "    \n",
    "    Attributes:\n",
    "        sender: Role of the sending agent\n",
    "        recipient: Role of the receiving agent\n",
    "        content: The message content\n",
    "        message_type: Type of message (task, result, feedback)\n",
    "        timestamp: When the message was created\n",
    "    \"\"\"\n",
    "    sender: AgentRole\n",
    "    recipient: AgentRole\n",
    "    content: str\n",
    "    message_type: str = \"task\"  # task, result, feedback\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[{self.sender.value} ‚Üí {self.recipient.value}]: {self.content[:100]}...\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ AgentRole and AgentMessage classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    A specialized AI agent with a specific role.\n",
    "    \n",
    "    Each agent has:\n",
    "    - A role (researcher, writer, editor)\n",
    "    - A system prompt defining its behavior\n",
    "    - An LLM for generating responses\n",
    "    \"\"\"\n",
    "    role: AgentRole\n",
    "    name: str\n",
    "    system_prompt: str\n",
    "    llm: Any = None\n",
    "    \n",
    "    def process(self, input_content: str, context: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        Process input and generate output based on the agent's role.\n",
    "        \n",
    "        Args:\n",
    "            input_content: The main content to process\n",
    "            context: Additional context (e.g., previous agent's work)\n",
    "        \n",
    "        Returns:\n",
    "            The agent's response\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"{self.system_prompt}\n",
    "\n",
    "Context from previous work:\n",
    "{context if context else 'None'}\n",
    "\n",
    "Your task:\n",
    "{input_content}\n",
    "\n",
    "Your response:\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response.strip()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Agent({self.name}, role={self.role.value})\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Agent class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompts for each role\n",
    "AGENT_PROMPTS = {\n",
    "    AgentRole.RESEARCHER: \"\"\"You are an expert Research Agent. Your job is to:\n",
    "1. Gather comprehensive information on the given topic\n",
    "2. Find key facts, statistics, and insights\n",
    "3. Identify multiple perspectives\n",
    "4. Organize information logically\n",
    "5. Provide sources and citations when possible\n",
    "\n",
    "Be thorough but concise. Focus on accuracy and relevance.\n",
    "Format your research as bullet points with clear categories.\"\"\",\n",
    "\n",
    "    AgentRole.WRITER: \"\"\"You are an expert Writing Agent. Your job is to:\n",
    "1. Transform research into clear, engaging content\n",
    "2. Write in a conversational but professional tone\n",
    "3. Structure content with clear sections and flow\n",
    "4. Use examples and analogies to explain complex ideas\n",
    "5. Keep paragraphs short and readable\n",
    "\n",
    "Focus on clarity and engagement. Make the content accessible.\n",
    "Always use the research provided - don't make things up.\"\"\",\n",
    "\n",
    "    AgentRole.EDITOR: \"\"\"You are an expert Editing Agent. Your job is to:\n",
    "1. Review content for clarity and coherence\n",
    "2. Fix grammar, spelling, and punctuation errors\n",
    "3. Improve sentence structure and flow\n",
    "4. Ensure consistent tone and style\n",
    "5. Add polish while preserving the author's voice\n",
    "\n",
    "Be constructive and thorough. Return the improved version.\n",
    "Mark any significant changes with [EDITED: reason].\"\"\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Agent prompts defined!\")\n",
    "print(f\"   Roles: {[r.value for r in AgentRole]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent team\n",
    "researcher = Agent(\n",
    "    role=AgentRole.RESEARCHER,\n",
    "    name=\"ResearchBot\",\n",
    "    system_prompt=AGENT_PROMPTS[AgentRole.RESEARCHER],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    role=AgentRole.WRITER,\n",
    "    name=\"WriteBot\",\n",
    "    system_prompt=AGENT_PROMPTS[AgentRole.WRITER],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "editor = Agent(\n",
    "    role=AgentRole.EDITOR,\n",
    "    name=\"EditBot\",\n",
    "    system_prompt=AGENT_PROMPTS[AgentRole.EDITOR],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "team = [researcher, writer, editor]\n",
    "\n",
    "print(\"‚úÖ Agent team created!\")\n",
    "for agent in team:\n",
    "    print(f\"   {agent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Building the Agent Orchestrator\n",
    "\n",
    "The orchestrator manages communication between agents and tracks the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WorkflowResult:\n",
    "    \"\"\"Results from a multi-agent workflow.\"\"\"\n",
    "    topic: str\n",
    "    research: str\n",
    "    draft: str\n",
    "    final: str\n",
    "    messages: List[AgentMessage]\n",
    "    duration_seconds: float\n",
    "\n",
    "\n",
    "class AgentOrchestrator:\n",
    "    \"\"\"\n",
    "    Orchestrates communication between agents in a content creation pipeline.\n",
    "    \n",
    "    Workflow:\n",
    "    1. Researcher gathers information\n",
    "    2. Writer creates content from research\n",
    "    3. Editor polishes the content\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, researcher: Agent, writer: Agent, editor: Agent):\n",
    "        self.researcher = researcher\n",
    "        self.writer = writer\n",
    "        self.editor = editor\n",
    "        self.messages: List[AgentMessage] = []\n",
    "        self.verbose = True\n",
    "    \n",
    "    def _log(self, message: str):\n",
    "        \"\"\"Log a message if verbose mode is on.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "    \n",
    "    def _record_message(self, sender: AgentRole, recipient: AgentRole, \n",
    "                        content: str, msg_type: str = \"task\"):\n",
    "        \"\"\"Record a message in the workflow history.\"\"\"\n",
    "        msg = AgentMessage(\n",
    "            sender=sender,\n",
    "            recipient=recipient,\n",
    "            content=content,\n",
    "            message_type=msg_type\n",
    "        )\n",
    "        self.messages.append(msg)\n",
    "        return msg\n",
    "    \n",
    "    def run_pipeline(self, topic: str) -> WorkflowResult:\n",
    "        \"\"\"\n",
    "        Run the full content creation pipeline.\n",
    "        \n",
    "        Args:\n",
    "            topic: The topic to create content about\n",
    "        \n",
    "        Returns:\n",
    "            WorkflowResult with all outputs and messages\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.messages = []  # Reset message history\n",
    "        \n",
    "        # === Step 1: Research ===\n",
    "        self._log(\"\\n\" + \"=\"*60)\n",
    "        self._log(\"üìö STEP 1: Research Phase\")\n",
    "        self._log(\"=\"*60)\n",
    "        \n",
    "        research_task = f\"Research the following topic thoroughly: {topic}\"\n",
    "        self._record_message(\n",
    "            AgentRole.WRITER,  # Request from (conceptually)\n",
    "            AgentRole.RESEARCHER,\n",
    "            research_task,\n",
    "            \"task\"\n",
    "        )\n",
    "        \n",
    "        self._log(f\"\\nüîç {self.researcher.name} is researching...\")\n",
    "        research_output = self.researcher.process(research_task)\n",
    "        \n",
    "        self._record_message(\n",
    "            AgentRole.RESEARCHER,\n",
    "            AgentRole.WRITER,\n",
    "            research_output,\n",
    "            \"result\"\n",
    "        )\n",
    "        \n",
    "        self._log(f\"\\nüìã Research complete ({len(research_output)} chars)\")\n",
    "        if self.verbose:\n",
    "            print(f\"\\n{research_output[:500]}...\\n\")\n",
    "        \n",
    "        # === Step 2: Writing ===\n",
    "        self._log(\"\\n\" + \"=\"*60)\n",
    "        self._log(\"‚úçÔ∏è  STEP 2: Writing Phase\")\n",
    "        self._log(\"=\"*60)\n",
    "        \n",
    "        writing_task = f\"Write a comprehensive article about: {topic}\"\n",
    "        self._record_message(\n",
    "            AgentRole.RESEARCHER,\n",
    "            AgentRole.WRITER,\n",
    "            writing_task,\n",
    "            \"task\"\n",
    "        )\n",
    "        \n",
    "        self._log(f\"\\nüìù {self.writer.name} is writing...\")\n",
    "        draft_output = self.writer.process(writing_task, context=research_output)\n",
    "        \n",
    "        self._record_message(\n",
    "            AgentRole.WRITER,\n",
    "            AgentRole.EDITOR,\n",
    "            draft_output,\n",
    "            \"result\"\n",
    "        )\n",
    "        \n",
    "        self._log(f\"\\nüìÑ Draft complete ({len(draft_output)} chars)\")\n",
    "        if self.verbose:\n",
    "            print(f\"\\n{draft_output[:500]}...\\n\")\n",
    "        \n",
    "        # === Step 3: Editing ===\n",
    "        self._log(\"\\n\" + \"=\"*60)\n",
    "        self._log(\"üìù STEP 3: Editing Phase\")\n",
    "        self._log(\"=\"*60)\n",
    "        \n",
    "        editing_task = \"Review and polish the following article for publication.\"\n",
    "        self._record_message(\n",
    "            AgentRole.WRITER,\n",
    "            AgentRole.EDITOR,\n",
    "            editing_task,\n",
    "            \"task\"\n",
    "        )\n",
    "        \n",
    "        self._log(f\"\\n‚úèÔ∏è  {self.editor.name} is editing...\")\n",
    "        final_output = self.editor.process(editing_task, context=draft_output)\n",
    "        \n",
    "        self._record_message(\n",
    "            AgentRole.EDITOR,\n",
    "            AgentRole.WRITER,\n",
    "            final_output,\n",
    "            \"result\"\n",
    "        )\n",
    "        \n",
    "        self._log(f\"\\n‚úÖ Final content ready ({len(final_output)} chars)\")\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        return WorkflowResult(\n",
    "            topic=topic,\n",
    "            research=research_output,\n",
    "            draft=draft_output,\n",
    "            final=final_output,\n",
    "            messages=self.messages,\n",
    "            duration_seconds=duration\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"‚úÖ AgentOrchestrator class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the orchestrator\n",
    "orchestrator = AgentOrchestrator(researcher, writer, editor)\n",
    "\n",
    "print(\"‚úÖ Orchestrator ready!\")\n",
    "print(f\"   Pipeline: Researcher ‚Üí Writer ‚Üí Editor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Running the Multi-Agent Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline!\n",
    "print(\"üöÄ Starting Multi-Agent Content Pipeline...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = orchestrator.run_pipeline(\n",
    "    topic=\"The benefits and challenges of running large language models locally on DGX Spark vs using cloud APIs\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ PIPELINE COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚è±Ô∏è  Duration: {result.duration_seconds:.1f} seconds\")\n",
    "print(f\"üí¨ Messages exchanged: {len(result.messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the final output\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì§ FINAL ARTICLE\")\n",
    "print(\"=\"*60)\n",
    "print(result.final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View message history\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí¨ MESSAGE HISTORY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, msg in enumerate(result.messages, 1):\n",
    "    print(f\"\\n{i}. [{msg.message_type.upper()}]\")\n",
    "    print(f\"   From: {msg.sender.value}\")\n",
    "    print(f\"   To: {msg.recipient.value}\")\n",
    "    print(f\"   Content: {msg.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Advanced Pattern - Feedback Loop\n",
    "\n",
    "Let's add a feedback loop where the editor can request revisions from the writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackOrchestrator(AgentOrchestrator):\n",
    "    \"\"\"\n",
    "    Extended orchestrator that supports feedback loops.\n",
    "    \n",
    "    The editor can request revisions, and the writer will revise.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, max_revisions: int = 2, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.max_revisions = max_revisions\n",
    "    \n",
    "    def _editor_review(self, content: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Have the editor review content and decide if revisions are needed.\n",
    "        \n",
    "        Returns:\n",
    "            (needs_revision: bool, feedback: str)\n",
    "        \"\"\"\n",
    "        review_prompt = f\"\"\"Review this content and determine if it needs revision.\n",
    "\n",
    "Content:\n",
    "{content[:2000]}\n",
    "\n",
    "Respond in this format:\n",
    "VERDICT: [APPROVED or NEEDS_REVISION]\n",
    "FEEDBACK: [Your specific feedback for improvement]\n",
    "\n",
    "Your review:\"\"\"\n",
    "        \n",
    "        review = self.editor.llm.invoke(review_prompt)\n",
    "        \n",
    "        needs_revision = \"NEEDS_REVISION\" in review.upper()\n",
    "        \n",
    "        # Extract feedback\n",
    "        feedback = \"\"\n",
    "        if \"FEEDBACK:\" in review:\n",
    "            feedback = review.split(\"FEEDBACK:\")[-1].strip()\n",
    "        \n",
    "        return needs_revision, feedback\n",
    "    \n",
    "    def run_pipeline_with_feedback(self, topic: str) -> WorkflowResult:\n",
    "        \"\"\"\n",
    "        Run the pipeline with potential revision cycles.\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        self.messages = []\n",
    "        \n",
    "        # Step 1: Research (same as before)\n",
    "        self._log(\"\\nüîç Researching...\")\n",
    "        research_task = f\"Research: {topic}\"\n",
    "        research_output = self.researcher.process(research_task)\n",
    "        \n",
    "        # Step 2: Initial Draft\n",
    "        self._log(\"\\n‚úçÔ∏è  Writing initial draft...\")\n",
    "        writing_task = f\"Write an article about: {topic}\"\n",
    "        current_draft = self.writer.process(writing_task, context=research_output)\n",
    "        \n",
    "        # Step 3: Revision Loop\n",
    "        revision_count = 0\n",
    "        while revision_count < self.max_revisions:\n",
    "            self._log(f\"\\nüìã Review cycle {revision_count + 1}...\")\n",
    "            \n",
    "            needs_revision, feedback = self._editor_review(current_draft)\n",
    "            \n",
    "            if not needs_revision:\n",
    "                self._log(\"\\n‚úÖ Editor approved!\")\n",
    "                break\n",
    "            \n",
    "            self._log(f\"\\nüîÑ Revision requested: {feedback[:100]}...\")\n",
    "            \n",
    "            # Record feedback message\n",
    "            self._record_message(\n",
    "                AgentRole.EDITOR,\n",
    "                AgentRole.WRITER,\n",
    "                feedback,\n",
    "                \"feedback\"\n",
    "            )\n",
    "            \n",
    "            # Writer revises\n",
    "            revision_task = f\"\"\"Revise this content based on editor feedback.\n",
    "            \n",
    "Feedback: {feedback}\n",
    "\n",
    "Original content:\n",
    "{current_draft}\n",
    "\n",
    "Revised content:\"\"\"\n",
    "            \n",
    "            current_draft = self.writer.process(revision_task)\n",
    "            revision_count += 1\n",
    "        \n",
    "        # Final polish\n",
    "        self._log(\"\\n‚úèÔ∏è  Final editing...\")\n",
    "        final_output = self.editor.process(\n",
    "            \"Polish this article for publication.\", \n",
    "            context=current_draft\n",
    "        )\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        self._log(f\"\\nüéâ Complete! ({revision_count} revisions)\")\n",
    "        \n",
    "        return WorkflowResult(\n",
    "            topic=topic,\n",
    "            research=research_output,\n",
    "            draft=current_draft,\n",
    "            final=final_output,\n",
    "            messages=self.messages,\n",
    "            duration_seconds=duration\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"‚úÖ FeedbackOrchestrator defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the feedback loop\n",
    "feedback_orchestrator = FeedbackOrchestrator(\n",
    "    researcher, writer, editor,\n",
    "    max_revisions=2\n",
    ")\n",
    "\n",
    "print(\"üîÑ Running pipeline with feedback loop...\\n\")\n",
    "\n",
    "result2 = feedback_orchestrator.run_pipeline_with_feedback(\n",
    "    topic=\"Best practices for prompt engineering\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Duration: {result2.duration_seconds:.1f}s\")\n",
    "print(f\"üí¨ Messages: {len(result2.messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Pattern - Supervisor Agent\n",
    "\n",
    "Sometimes you need a supervisor agent that decides which agent should handle each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisorAgent:\n",
    "    \"\"\"\n",
    "    A supervisor agent that routes tasks to specialized agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, agents: Dict[str, Agent]):\n",
    "        self.llm = llm\n",
    "        self.agents = agents\n",
    "        \n",
    "    def route_task(self, task: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine which agent should handle a task.\n",
    "        \n",
    "        Args:\n",
    "            task: The task description\n",
    "            \n",
    "        Returns:\n",
    "            Name of the agent to handle the task\n",
    "        \"\"\"\n",
    "        agent_list = \"\\n\".join([\n",
    "            f\"- {name}: {agent.system_prompt[:100]}...\"\n",
    "            for name, agent in self.agents.items()\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"You are a supervisor. Route this task to the best agent.\n",
    "\n",
    "Available agents:\n",
    "{agent_list}\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Respond with ONLY the agent name (e.g., \"researcher\" or \"writer\"):\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt).strip().lower()\n",
    "        \n",
    "        # Find matching agent\n",
    "        for name in self.agents.keys():\n",
    "            if name.lower() in response:\n",
    "                return name\n",
    "        \n",
    "        # Default to first agent\n",
    "        return list(self.agents.keys())[0]\n",
    "    \n",
    "    def delegate(self, task: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Route and execute a task.\n",
    "        \n",
    "        Returns:\n",
    "            (agent_name, result)\n",
    "        \"\"\"\n",
    "        agent_name = self.route_task(task)\n",
    "        agent = self.agents[agent_name]\n",
    "        \n",
    "        print(f\"üìã Routing to: {agent_name}\")\n",
    "        result = agent.process(task)\n",
    "        \n",
    "        return agent_name, result\n",
    "\n",
    "\n",
    "# Create supervisor\n",
    "supervisor = SupervisorAgent(\n",
    "    llm=llm,\n",
    "    agents={\n",
    "        \"researcher\": researcher,\n",
    "        \"writer\": writer,\n",
    "        \"editor\": editor\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ SupervisorAgent created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the supervisor\n",
    "print(\"üß™ Testing Supervisor Agent:\")\n",
    "\n",
    "test_tasks = [\n",
    "    \"Find information about the latest GPT-4 capabilities\",\n",
    "    \"Write a blog post about machine learning\",\n",
    "    \"Review this article for grammar and clarity\"\n",
    "]\n",
    "\n",
    "for task in test_tasks:\n",
    "    print(f\"\\nüì• Task: {task[:50]}...\")\n",
    "    agent_name, result = supervisor.delegate(task)\n",
    "    print(f\"   Result preview: {result[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Agents Not Sharing Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ùå WRONG: Each agent works in isolation\n",
    "\n",
    "research = researcher.process(\"Research AI\")\n",
    "draft = writer.process(\"Write about AI\")  # No context from research!\n",
    "\n",
    "‚úÖ RIGHT: Pass context between agents\n",
    "\n",
    "research = researcher.process(\"Research AI\")\n",
    "draft = writer.process(\"Write about AI\", context=research)  # Research informs writing!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Infinite Feedback Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ùå WRONG: No limit on revisions\n",
    "\n",
    "while True:  # Could loop forever!\n",
    "    needs_revision, feedback = editor.review(draft)\n",
    "    if needs_revision:\n",
    "        draft = writer.revise(draft, feedback)\n",
    "\n",
    "‚úÖ RIGHT: Set a maximum revision count\n",
    "\n",
    "max_revisions = 3\n",
    "for i in range(max_revisions):\n",
    "    needs_revision, feedback = editor.review(draft)\n",
    "    if not needs_revision:\n",
    "        break\n",
    "    draft = writer.revise(draft, feedback)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Defining specialized agent roles\n",
    "- ‚úÖ Message passing between agents\n",
    "- ‚úÖ Building a content creation pipeline\n",
    "- ‚úÖ Implementing feedback loops\n",
    "- ‚úÖ Creating a supervisor agent for routing\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úã Try It Yourself\n",
    "\n",
    "1. Add a **Fact-Checker** agent that verifies the writer's claims\n",
    "2. Create a **Parallel Review** where multiple editors review simultaneously\n",
    "3. Implement **Agent Voting** where agents vote on the best version\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Challenge (Optional)\n",
    "\n",
    "Build a **Code Review Team**:\n",
    "- Developer Agent: Writes code based on requirements\n",
    "- Reviewer Agent: Reviews for bugs and best practices\n",
    "- Security Agent: Checks for security vulnerabilities\n",
    "- Documentation Agent: Adds comments and docs\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [AutoGen Multi-Agent Framework](https://microsoft.github.io/autogen/)\n",
    "- [CrewAI for Role-Based Agents](https://docs.crewai.com/)\n",
    "- [LangGraph Multi-Agent Patterns](https://langchain-ai.github.io/langgraph/)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Summary\n",
    "\n",
    "| Pattern | Description | Use Case |\n",
    "|---------|-------------|----------|\n",
    "| **Sequential Pipeline** | A ‚Üí B ‚Üí C | Content creation |\n",
    "| **Feedback Loop** | A ‚Üí B ‚Üí (review) ‚Üí A | Quality improvement |\n",
    "| **Supervisor Routing** | S ‚Üí [A, B, or C] | Dynamic task assignment |\n",
    "| **Parallel Processing** | [A, B, C] ‚Üí Combine | Multi-perspective analysis |\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Each agent has a specialized role and prompt\n",
    "- Context must be passed between agents\n",
    "- Always set limits on loops/iterations\n",
    "- Record messages for debugging/auditing\n",
    "\n",
    "**Next up:** Lab 3.6.5 - CrewAI for Production Multi-Agent Systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
