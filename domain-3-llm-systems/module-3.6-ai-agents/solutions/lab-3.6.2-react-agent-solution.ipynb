{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.6.2: ReAct Agent - SOLUTIONS\n",
    "\n",
    "**Complete solutions with explanations and alternative approaches**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import Dict, Any, List, Optional, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1 Solution: Build a Complete ReAct Agent\n",
    "\n",
    "**Task**: Implement a ReAct agent from scratch that can handle multi-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(Enum):\n",
    "    \"\"\"Agent execution states.\"\"\"\n",
    "    THINKING = \"thinking\"\n",
    "    ACTING = \"acting\"\n",
    "    OBSERVING = \"observing\"\n",
    "    FINISHED = \"finished\"\n",
    "    ERROR = \"error\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReActStep:\n",
    "    \"\"\"A single step in ReAct execution.\"\"\"\n",
    "    step_number: int\n",
    "    thought: str\n",
    "    action: Optional[str] = None\n",
    "    action_input: Optional[str] = None\n",
    "    observation: Optional[str] = None\n",
    "    state: AgentState = AgentState.THINKING\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"Configuration for the ReAct agent.\"\"\"\n",
    "    max_steps: int = 10\n",
    "    verbose: bool = True\n",
    "    retry_on_error: bool = True\n",
    "    max_retries: int = 2\n",
    "\n",
    "\n",
    "class ReActAgent:\n",
    "    \"\"\"\n",
    "    Production-ready ReAct (Reasoning + Acting) agent.\n",
    "    \n",
    "    Features:\n",
    "    - Multi-step reasoning\n",
    "    - Tool execution with error handling\n",
    "    - Execution trace for debugging\n",
    "    - Configurable behavior\n",
    "    \"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"You are a helpful assistant that uses tools to answer questions.\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools_description}\n",
    "\n",
    "Use this format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: reason about what to do step by step\n",
    "Action: the tool name to use (one of: {tool_names})\n",
    "Action Input: the input for the tool\n",
    "Observation: the result from the tool\n",
    "... (repeat Thought/Action/Action Input/Observation as needed)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the question\n",
    "\n",
    "Begin!\n",
    "\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable], config: Optional[AgentConfig] = None):\n",
    "        \"\"\"\n",
    "        Initialize ReAct agent.\n",
    "        \n",
    "        Args:\n",
    "            tools: Dictionary of tool_name -> callable\n",
    "            config: Agent configuration\n",
    "        \"\"\"\n",
    "        self.tools = tools\n",
    "        self.config = config or AgentConfig()\n",
    "        self.execution_trace: List[ReActStep] = []\n",
    "        self.current_state = AgentState.THINKING\n",
    "    \n",
    "    def _get_tools_description(self) -> str:\n",
    "        \"\"\"Generate tools description for prompt.\"\"\"\n",
    "        descriptions = []\n",
    "        for name, func in self.tools.items():\n",
    "            doc = func.__doc__ or \"No description\"\n",
    "            descriptions.append(f\"- {name}: {doc.strip()}\")\n",
    "        return \"\\n\".join(descriptions)\n",
    "    \n",
    "    def _parse_llm_output(self, output: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse LLM output to extract thought, action, and final answer.\n",
    "        \"\"\"\n",
    "        result = {\n",
    "            \"thought\": None,\n",
    "            \"action\": None,\n",
    "            \"action_input\": None,\n",
    "            \"final_answer\": None,\n",
    "        }\n",
    "        \n",
    "        # Extract thought\n",
    "        thought_match = re.search(r'Thought:\\s*(.+?)(?=Action:|Final Answer:|$)', output, re.DOTALL)\n",
    "        if thought_match:\n",
    "            result[\"thought\"] = thought_match.group(1).strip()\n",
    "        \n",
    "        # Extract action\n",
    "        action_match = re.search(r'Action:\\s*(.+?)(?=Action Input:|$)', output, re.DOTALL)\n",
    "        if action_match:\n",
    "            result[\"action\"] = action_match.group(1).strip()\n",
    "        \n",
    "        # Extract action input\n",
    "        input_match = re.search(r'Action Input:\\s*(.+?)(?=Observation:|Thought:|$)', output, re.DOTALL)\n",
    "        if input_match:\n",
    "            result[\"action_input\"] = input_match.group(1).strip()\n",
    "        \n",
    "        # Extract final answer\n",
    "        final_match = re.search(r'Final Answer:\\s*(.+?)$', output, re.DOTALL)\n",
    "        if final_match:\n",
    "            result[\"final_answer\"] = final_match.group(1).strip()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _execute_tool(self, action: str, action_input: str) -> str:\n",
    "        \"\"\"Execute a tool and return observation.\"\"\"\n",
    "        if action not in self.tools:\n",
    "            return f\"Error: Unknown tool '{action}'. Available: {list(self.tools.keys())}\"\n",
    "        \n",
    "        try:\n",
    "            result = self.tools[action](action_input)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Error executing {action}: {str(e)}\"\n",
    "    \n",
    "    def _simulate_llm_response(self, prompt: str, history: str) -> str:\n",
    "        \"\"\"\n",
    "        Simulate LLM response for demonstration.\n",
    "        In production, this would call the actual LLM.\n",
    "        \"\"\"\n",
    "        # Simple rule-based simulation for demo\n",
    "        if \"capital\" in prompt.lower() and \"france\" in prompt.lower():\n",
    "            if \"Observation:\" not in history:\n",
    "                return \"\"\"Thought: I need to search for the capital of France.\n",
    "Action: search\n",
    "Action Input: capital of France\"\"\"\n",
    "            else:\n",
    "                return \"\"\"Thought: I now know the final answer based on my search.\n",
    "Final Answer: The capital of France is Paris.\"\"\"\n",
    "        \n",
    "        if \"weather\" in prompt.lower():\n",
    "            if \"Observation:\" not in history:\n",
    "                return \"\"\"Thought: I need to check the current weather.\n",
    "Action: weather\n",
    "Action Input: current location\"\"\"\n",
    "            else:\n",
    "                return \"\"\"Thought: I have the weather information.\n",
    "Final Answer: Based on the weather data, it's currently sunny and 72F.\"\"\"\n",
    "        \n",
    "        if \"calculate\" in prompt.lower() or any(op in prompt for op in ['+', '-', '*', '/', 'plus', 'minus']):\n",
    "            # Extract numbers for calculation\n",
    "            numbers = re.findall(r'\\d+', prompt)\n",
    "            if len(numbers) >= 2 and \"Observation:\" not in history:\n",
    "                return f\"\"\"Thought: I need to perform a calculation.\n",
    "Action: calculate\n",
    "Action Input: {numbers[0]} + {numbers[1]}\"\"\"\n",
    "            else:\n",
    "                return \"\"\"Thought: I have completed the calculation.\n",
    "Final Answer: The result of the calculation is shown in my observation.\"\"\"\n",
    "        \n",
    "        return \"\"\"Thought: I'll try to answer directly.\n",
    "Final Answer: I don't have enough information to answer this question accurately.\"\"\"\n",
    "    \n",
    "    def run(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Run the ReAct agent on a question.\n",
    "        \n",
    "        Args:\n",
    "            question: The user's question\n",
    "            \n",
    "        Returns:\n",
    "            The final answer\n",
    "        \"\"\"\n",
    "        self.execution_trace = []\n",
    "        self.current_state = AgentState.THINKING\n",
    "        \n",
    "        # Build system prompt\n",
    "        system_prompt = self.SYSTEM_PROMPT.format(\n",
    "            tools_description=self._get_tools_description(),\n",
    "            tool_names=\", \".join(self.tools.keys())\n",
    "        )\n",
    "        \n",
    "        # Initialize conversation\n",
    "        history = f\"Question: {question}\\n\"\n",
    "        \n",
    "        for step_num in range(1, self.config.max_steps + 1):\n",
    "            # Get LLM response\n",
    "            llm_output = self._simulate_llm_response(question, history)\n",
    "            \n",
    "            # Parse output\n",
    "            parsed = self._parse_llm_output(llm_output)\n",
    "            \n",
    "            # Create step record\n",
    "            step = ReActStep(\n",
    "                step_number=step_num,\n",
    "                thought=parsed[\"thought\"],\n",
    "                action=parsed[\"action\"],\n",
    "                action_input=parsed[\"action_input\"],\n",
    "            )\n",
    "            \n",
    "            if self.config.verbose:\n",
    "                print(f\"\\n--- Step {step_num} ---\")\n",
    "                print(f\"Thought: {step.thought}\")\n",
    "            \n",
    "            # Check for final answer\n",
    "            if parsed[\"final_answer\"]:\n",
    "                step.state = AgentState.FINISHED\n",
    "                self.execution_trace.append(step)\n",
    "                self.current_state = AgentState.FINISHED\n",
    "                \n",
    "                if self.config.verbose:\n",
    "                    print(f\"Final Answer: {parsed['final_answer']}\")\n",
    "                \n",
    "                return parsed[\"final_answer\"]\n",
    "            \n",
    "            # Execute action\n",
    "            if parsed[\"action\"]:\n",
    "                step.state = AgentState.ACTING\n",
    "                \n",
    "                if self.config.verbose:\n",
    "                    print(f\"Action: {step.action}\")\n",
    "                    print(f\"Action Input: {step.action_input}\")\n",
    "                \n",
    "                observation = self._execute_tool(parsed[\"action\"], parsed[\"action_input\"])\n",
    "                step.observation = observation\n",
    "                step.state = AgentState.OBSERVING\n",
    "                \n",
    "                if self.config.verbose:\n",
    "                    print(f\"Observation: {observation}\")\n",
    "                \n",
    "                # Update history\n",
    "                history += f\"\"\"Thought: {step.thought}\n",
    "Action: {step.action}\n",
    "Action Input: {step.action_input}\n",
    "Observation: {observation}\n",
    "\"\"\"\n",
    "            \n",
    "            self.execution_trace.append(step)\n",
    "        \n",
    "        # Max steps reached\n",
    "        self.current_state = AgentState.ERROR\n",
    "        return \"I couldn't find an answer within the allowed steps.\"\n",
    "    \n",
    "    def get_trace(self) -> List[Dict]:\n",
    "        \"\"\"Get execution trace as list of dicts.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"step\": s.step_number,\n",
    "                \"thought\": s.thought,\n",
    "                \"action\": s.action,\n",
    "                \"action_input\": s.action_input,\n",
    "                \"observation\": s.observation,\n",
    "                \"state\": s.state.value,\n",
    "            }\n",
    "            for s in self.execution_trace\n",
    "        ]\n",
    "\n",
    "\n",
    "# Define tools\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information on a topic.\"\"\"\n",
    "    # Simulated search results\n",
    "    if \"france\" in query.lower() and \"capital\" in query.lower():\n",
    "        return \"Paris is the capital of France. It is known as the City of Light.\"\n",
    "    return f\"Search results for: {query}\"\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except:\n",
    "        return \"Error in calculation\"\n",
    "\n",
    "def weather(location: str) -> str:\n",
    "    \"\"\"Get weather for a location.\"\"\"\n",
    "    return f\"Weather in {location}: Sunny, 72F, humidity 45%\"\n",
    "\n",
    "\n",
    "# Test the agent\n",
    "print(\"=\" * 60)\n",
    "print(\"REACT AGENT SOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tools = {\n",
    "    \"search\": search,\n",
    "    \"calculate\": calculate,\n",
    "    \"weather\": weather,\n",
    "}\n",
    "\n",
    "agent = ReActAgent(tools, AgentConfig(verbose=True))\n",
    "\n",
    "# Test questions\n",
    "questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is 25 plus 37?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {q}\")\n",
    "    answer = agent.run(q)\n",
    "    print(f\"\\nFinal Result: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2 Solution: Agent with Memory\n",
    "\n",
    "**Task**: Extend the agent to maintain conversation history across multiple interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from typing import Deque, Tuple\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MemoryConfig:\n",
    "    \"\"\"Configuration for agent memory.\"\"\"\n",
    "    max_history: int = 10\n",
    "    include_observations: bool = True\n",
    "    summarize_old: bool = False\n",
    "\n",
    "\n",
    "class ConversationMemory:\n",
    "    \"\"\"\n",
    "    Memory system for ReAct agent.\n",
    "    \n",
    "    Features:\n",
    "    - Fixed-size conversation history\n",
    "    - Entity tracking\n",
    "    - Context summarization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Optional[MemoryConfig] = None):\n",
    "        self.config = config or MemoryConfig()\n",
    "        self.history: Deque[Tuple[str, str]] = deque(maxlen=self.config.max_history)\n",
    "        self.entities: Dict[str, Any] = {}\n",
    "        self.context_summary: str = \"\"\n",
    "    \n",
    "    def add_interaction(self, question: str, answer: str) -> None:\n",
    "        \"\"\"Add a Q&A interaction to memory.\"\"\"\n",
    "        self.history.append((question, answer))\n",
    "        self._extract_entities(question, answer)\n",
    "    \n",
    "    def _extract_entities(self, question: str, answer: str) -> None:\n",
    "        \"\"\"Extract and store named entities from conversation.\"\"\"\n",
    "        # Simple entity extraction (in production, use NER)\n",
    "        text = f\"{question} {answer}\"\n",
    "        \n",
    "        # Extract capitalized words as potential entities\n",
    "        words = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b', text)\n",
    "        for word in words:\n",
    "            if word not in ['The', 'What', 'How', 'When', 'Where', 'Why', 'Is', 'Are']:\n",
    "                self.entities[word] = self.entities.get(word, 0) + 1\n",
    "    \n",
    "    def get_context(self, max_turns: int = 5) -> str:\n",
    "        \"\"\"Get recent conversation context.\"\"\"\n",
    "        recent = list(self.history)[-max_turns:]\n",
    "        \n",
    "        if not recent:\n",
    "            return \"\"\n",
    "        \n",
    "        context_parts = [\"Previous conversation:\"]\n",
    "        for q, a in recent:\n",
    "            context_parts.append(f\"Q: {q}\")\n",
    "            context_parts.append(f\"A: {a}\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def get_relevant_entities(self, query: str) -> List[str]:\n",
    "        \"\"\"Get entities relevant to query.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        return [\n",
    "            entity for entity in self.entities.keys()\n",
    "            if entity.lower() in query_lower or \n",
    "               any(word in entity.lower() for word in query_lower.split())\n",
    "        ]\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear all memory.\"\"\"\n",
    "        self.history.clear()\n",
    "        self.entities.clear()\n",
    "        self.context_summary = \"\"\n",
    "\n",
    "\n",
    "class MemoryReActAgent(ReActAgent):\n",
    "    \"\"\"\n",
    "    ReAct agent with conversation memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable], \n",
    "                 config: Optional[AgentConfig] = None,\n",
    "                 memory_config: Optional[MemoryConfig] = None):\n",
    "        super().__init__(tools, config)\n",
    "        self.memory = ConversationMemory(memory_config)\n",
    "    \n",
    "    def run(self, question: str) -> str:\n",
    "        \"\"\"Run agent with memory context.\"\"\"\n",
    "        # Get context from memory\n",
    "        context = self.memory.get_context()\n",
    "        \n",
    "        # Enhance question with context if relevant\n",
    "        relevant_entities = self.memory.get_relevant_entities(question)\n",
    "        \n",
    "        if self.config.verbose and context:\n",
    "            print(\"\\n--- Memory Context ---\")\n",
    "            print(context)\n",
    "            if relevant_entities:\n",
    "                print(f\"Relevant entities: {relevant_entities}\")\n",
    "        \n",
    "        # Run parent agent\n",
    "        answer = super().run(question)\n",
    "        \n",
    "        # Store in memory\n",
    "        self.memory.add_interaction(question, answer)\n",
    "        \n",
    "        return answer\n",
    "\n",
    "\n",
    "# Test memory agent\n",
    "print(\"=\" * 60)\n",
    "print(\"MEMORY REACT AGENT SOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "memory_agent = MemoryReActAgent(\n",
    "    tools,\n",
    "    AgentConfig(verbose=True),\n",
    "    MemoryConfig(max_history=10)\n",
    ")\n",
    "\n",
    "# Multi-turn conversation\n",
    "conversation = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"What's the weather there?\",  # \"there\" refers to Paris\n",
    "]\n",
    "\n",
    "for q in conversation:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"User: {q}\")\n",
    "    answer = memory_agent.run(q)\n",
    "    print(f\"\\nAgent: {answer}\")\n",
    "\n",
    "# Show memory state\n",
    "print(f\"\\n--- Memory State ---\")\n",
    "print(f\"Entities tracked: {memory_agent.memory.entities}\")\n",
    "print(f\"History length: {len(memory_agent.memory.history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3 Solution: Self-Correcting Agent\n",
    "\n",
    "**Task**: Build an agent that can recognize and recover from errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorType(Enum):\n",
    "    \"\"\"Types of errors the agent can handle.\"\"\"\n",
    "    TOOL_NOT_FOUND = \"tool_not_found\"\n",
    "    TOOL_EXECUTION = \"tool_execution\"\n",
    "    INVALID_INPUT = \"invalid_input\"\n",
    "    TIMEOUT = \"timeout\"\n",
    "    HALLUCINATION = \"hallucination\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ErrorRecord:\n",
    "    \"\"\"Record of an error and recovery attempt.\"\"\"\n",
    "    error_type: ErrorType\n",
    "    error_message: str\n",
    "    recovery_action: str\n",
    "    successful: bool\n",
    "    timestamp: float = field(default_factory=lambda: datetime.now().timestamp())\n",
    "\n",
    "\n",
    "class SelfCorrectingAgent(ReActAgent):\n",
    "    \"\"\"\n",
    "    Agent with self-correction capabilities.\n",
    "    \n",
    "    Features:\n",
    "    - Error detection\n",
    "    - Automatic retry with different strategies\n",
    "    - Learning from errors\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable], config: Optional[AgentConfig] = None):\n",
    "        super().__init__(tools, config)\n",
    "        self.error_log: List[ErrorRecord] = []\n",
    "        self.recovery_strategies: Dict[ErrorType, Callable] = {\n",
    "            ErrorType.TOOL_NOT_FOUND: self._recover_tool_not_found,\n",
    "            ErrorType.TOOL_EXECUTION: self._recover_tool_execution,\n",
    "            ErrorType.INVALID_INPUT: self._recover_invalid_input,\n",
    "        }\n",
    "    \n",
    "    def _detect_error(self, observation: str) -> Optional[ErrorType]:\n",
    "        \"\"\"Detect error type from observation.\"\"\"\n",
    "        observation_lower = observation.lower()\n",
    "        \n",
    "        if \"unknown tool\" in observation_lower:\n",
    "            return ErrorType.TOOL_NOT_FOUND\n",
    "        if \"error executing\" in observation_lower:\n",
    "            return ErrorType.TOOL_EXECUTION\n",
    "        if \"invalid\" in observation_lower or \"could not parse\" in observation_lower:\n",
    "            return ErrorType.INVALID_INPUT\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _recover_tool_not_found(self, action: str, action_input: str) -> Tuple[str, str]:\n",
    "        \"\"\"Recover from tool not found error.\"\"\"\n",
    "        # Try to find similar tool\n",
    "        similar = None\n",
    "        action_lower = action.lower()\n",
    "        \n",
    "        for tool_name in self.tools.keys():\n",
    "            if tool_name.lower() in action_lower or action_lower in tool_name.lower():\n",
    "                similar = tool_name\n",
    "                break\n",
    "        \n",
    "        if similar:\n",
    "            return similar, action_input\n",
    "        \n",
    "        # Fall back to search if available\n",
    "        if \"search\" in self.tools:\n",
    "            return \"search\", action_input\n",
    "        \n",
    "        return action, action_input  # No recovery possible\n",
    "    \n",
    "    def _recover_tool_execution(self, action: str, action_input: str) -> Tuple[str, str]:\n",
    "        \"\"\"Recover from tool execution error.\"\"\"\n",
    "        # Try to simplify input\n",
    "        simplified = action_input.strip()\n",
    "        \n",
    "        # Remove special characters\n",
    "        simplified = re.sub(r'[^\\w\\s\\d+-/*().]', '', simplified)\n",
    "        \n",
    "        return action, simplified\n",
    "    \n",
    "    def _recover_invalid_input(self, action: str, action_input: str) -> Tuple[str, str]:\n",
    "        \"\"\"Recover from invalid input error.\"\"\"\n",
    "        # Try to extract just the core query\n",
    "        words = action_input.split()\n",
    "        if len(words) > 5:\n",
    "            # Take first 5 words\n",
    "            return action, \" \".join(words[:5])\n",
    "        \n",
    "        return action, action_input\n",
    "    \n",
    "    def _execute_tool(self, action: str, action_input: str) -> str:\n",
    "        \"\"\"Execute tool with error recovery.\"\"\"\n",
    "        for attempt in range(self.config.max_retries + 1):\n",
    "            observation = super()._execute_tool(action, action_input)\n",
    "            \n",
    "            error_type = self._detect_error(observation)\n",
    "            \n",
    "            if error_type is None:\n",
    "                # No error, return result\n",
    "                return observation\n",
    "            \n",
    "            if attempt < self.config.max_retries:\n",
    "                # Try recovery\n",
    "                if error_type in self.recovery_strategies:\n",
    "                    recovery_fn = self.recovery_strategies[error_type]\n",
    "                    new_action, new_input = recovery_fn(action, action_input)\n",
    "                    \n",
    "                    if self.config.verbose:\n",
    "                        print(f\"  [Recovery] {error_type.value}: {action} -> {new_action}\")\n",
    "                    \n",
    "                    action, action_input = new_action, new_input\n",
    "                    \n",
    "                    # Log recovery attempt\n",
    "                    self.error_log.append(ErrorRecord(\n",
    "                        error_type=error_type,\n",
    "                        error_message=observation,\n",
    "                        recovery_action=f\"{new_action}({new_input})\",\n",
    "                        successful=False,  # Will update if recovery works\n",
    "                    ))\n",
    "        \n",
    "        return observation\n",
    "    \n",
    "    def get_error_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get error statistics.\"\"\"\n",
    "        if not self.error_log:\n",
    "            return {\"total_errors\": 0}\n",
    "        \n",
    "        by_type = {}\n",
    "        for record in self.error_log:\n",
    "            by_type[record.error_type.value] = by_type.get(record.error_type.value, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_errors\": len(self.error_log),\n",
    "            \"by_type\": by_type,\n",
    "            \"recovery_rate\": sum(1 for r in self.error_log if r.successful) / len(self.error_log),\n",
    "        }\n",
    "\n",
    "\n",
    "# Test self-correcting agent\n",
    "print(\"=\" * 60)\n",
    "print(\"SELF-CORRECTING AGENT SOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "correcting_agent = SelfCorrectingAgent(\n",
    "    tools,\n",
    "    AgentConfig(verbose=True, max_retries=2)\n",
    ")\n",
    "\n",
    "# The agent will handle typos and errors\n",
    "print(\"\\nTesting error recovery...\")\n",
    "result = correcting_agent._execute_tool(\"serach\", \"capital of France\")  # Typo in 'search'\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "print(f\"\\nError stats: {correcting_agent.get_error_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Solution: Agent Orchestrator\n",
    "\n",
    "**Task**: Build a system that can coordinate multiple specialized agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class AgentSpec(NamedTuple):\n",
    "    \"\"\"Specification for a specialized agent.\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    capabilities: List[str]\n",
    "\n",
    "\n",
    "class AgentOrchestrator:\n",
    "    \"\"\"\n",
    "    Orchestrator for coordinating multiple specialized agents.\n",
    "    \n",
    "    Features:\n",
    "    - Agent routing based on query type\n",
    "    - Parallel execution when possible\n",
    "    - Result aggregation\n",
    "    - Fallback handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agents: Dict[str, Tuple[AgentSpec, ReActAgent]] = {}\n",
    "        self.routing_rules: Dict[str, List[str]] = {}  # keyword -> agent_names\n",
    "    \n",
    "    def register_agent(self, spec: AgentSpec, agent: ReActAgent) -> None:\n",
    "        \"\"\"Register a specialized agent.\"\"\"\n",
    "        self.agents[spec.name] = (spec, agent)\n",
    "        \n",
    "        # Auto-create routing rules from capabilities\n",
    "        for capability in spec.capabilities:\n",
    "            if capability not in self.routing_rules:\n",
    "                self.routing_rules[capability] = []\n",
    "            self.routing_rules[capability].append(spec.name)\n",
    "    \n",
    "    def route_query(self, query: str) -> List[str]:\n",
    "        \"\"\"Determine which agents should handle a query.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        matching_agents = set()\n",
    "        \n",
    "        for keyword, agent_names in self.routing_rules.items():\n",
    "            if keyword.lower() in query_lower:\n",
    "                matching_agents.update(agent_names)\n",
    "        \n",
    "        # If no matches, return all agents (let them try)\n",
    "        if not matching_agents:\n",
    "            return list(self.agents.keys())\n",
    "        \n",
    "        return list(matching_agents)\n",
    "    \n",
    "    def run(self, query: str, max_agents: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run query through appropriate agents.\n",
    "        \n",
    "        Args:\n",
    "            query: User query\n",
    "            max_agents: Maximum agents to consult\n",
    "            \n",
    "        Returns:\n",
    "            Aggregated results from agents\n",
    "        \"\"\"\n",
    "        # Route query\n",
    "        agent_names = self.route_query(query)[:max_agents]\n",
    "        \n",
    "        results = {\n",
    "            \"query\": query,\n",
    "            \"agents_consulted\": agent_names,\n",
    "            \"responses\": {},\n",
    "            \"consensus\": None,\n",
    "        }\n",
    "        \n",
    "        # Run each agent\n",
    "        for name in agent_names:\n",
    "            spec, agent = self.agents[name]\n",
    "            try:\n",
    "                answer = agent.run(query)\n",
    "                results[\"responses\"][name] = {\n",
    "                    \"answer\": answer,\n",
    "                    \"success\": True,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                results[\"responses\"][name] = {\n",
    "                    \"answer\": None,\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e),\n",
    "                }\n",
    "        \n",
    "        # Find consensus (simple: most common answer)\n",
    "        answers = [r[\"answer\"] for r in results[\"responses\"].values() if r[\"success\"]]\n",
    "        if answers:\n",
    "            # Take first successful answer as consensus for simplicity\n",
    "            results[\"consensus\"] = answers[0]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def list_agents(self) -> List[Dict]:\n",
    "        \"\"\"List all registered agents.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"name\": spec.name,\n",
    "                \"description\": spec.description,\n",
    "                \"capabilities\": spec.capabilities,\n",
    "            }\n",
    "            for spec, _ in self.agents.values()\n",
    "        ]\n",
    "\n",
    "\n",
    "# Create specialized agents\n",
    "math_tools = {\"calculate\": calculate}\n",
    "search_tools = {\"search\": search}\n",
    "weather_tools = {\"weather\": weather}\n",
    "\n",
    "math_agent = ReActAgent(math_tools, AgentConfig(verbose=False))\n",
    "research_agent = ReActAgent(search_tools, AgentConfig(verbose=False))\n",
    "weather_agent = ReActAgent(weather_tools, AgentConfig(verbose=False))\n",
    "\n",
    "# Create orchestrator\n",
    "orchestrator = AgentOrchestrator()\n",
    "\n",
    "orchestrator.register_agent(\n",
    "    AgentSpec(\"math\", \"Handles mathematical calculations\", [\"calculate\", \"math\", \"number\", \"sum\", \"add\"]),\n",
    "    math_agent\n",
    ")\n",
    "orchestrator.register_agent(\n",
    "    AgentSpec(\"research\", \"Searches for information\", [\"search\", \"find\", \"what is\", \"who\", \"capital\"]),\n",
    "    research_agent\n",
    ")\n",
    "orchestrator.register_agent(\n",
    "    AgentSpec(\"weather\", \"Provides weather information\", [\"weather\", \"temperature\", \"forecast\"]),\n",
    "    weather_agent\n",
    ")\n",
    "\n",
    "# Test orchestrator\n",
    "print(\"=\" * 60)\n",
    "print(\"AGENT ORCHESTRATOR SOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nRegistered agents:\")\n",
    "for agent_info in orchestrator.list_agents():\n",
    "    print(f\"  - {agent_info['name']}: {agent_info['description']}\")\n",
    "\n",
    "test_queries = [\n",
    "    \"What is 25 + 37?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"What's the weather today?\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n--- Query: {query} ---\")\n",
    "    result = orchestrator.run(query)\n",
    "    print(f\"Routed to: {result['agents_consulted']}\")\n",
    "    print(f\"Consensus: {result['consensus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_agent(agent, query, iterations=5):\n",
    "    \"\"\"Benchmark agent performance.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(iterations):\n",
    "        start = time.perf_counter()\n",
    "        agent.run(query)\n",
    "        times.append(time.perf_counter() - start)\n",
    "    return {\n",
    "        \"avg_ms\": sum(times) / len(times) * 1000,\n",
    "        \"min_ms\": min(times) * 1000,\n",
    "        \"max_ms\": max(times) * 1000,\n",
    "    }\n",
    "\n",
    "print(\"Performance Benchmarks (simulated LLM):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Basic agent\n",
    "basic_agent = ReActAgent(tools, AgentConfig(verbose=False))\n",
    "basic_stats = benchmark_agent(basic_agent, \"What is 5 + 5?\")\n",
    "print(f\"Basic ReAct: {basic_stats['avg_ms']:.2f}ms avg\")\n",
    "\n",
    "# Memory agent\n",
    "mem_agent = MemoryReActAgent(tools, AgentConfig(verbose=False))\n",
    "mem_stats = benchmark_agent(mem_agent, \"What is 5 + 5?\")\n",
    "print(f\"Memory ReAct: {mem_stats['avg_ms']:.2f}ms avg\")\n",
    "\n",
    "# Self-correcting agent\n",
    "corr_agent = SelfCorrectingAgent(tools, AgentConfig(verbose=False))\n",
    "corr_stats = benchmark_agent(corr_agent, \"What is 5 + 5?\")\n",
    "print(f\"Self-Correcting: {corr_stats['avg_ms']:.2f}ms avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **ReAct Pattern**: Think -> Act -> Observe provides structured reasoning\n",
    "2. **Memory**: Conversation history improves multi-turn interactions\n",
    "3. **Error Recovery**: Agents should gracefully handle and recover from errors\n",
    "4. **Orchestration**: Complex tasks benefit from specialized agents working together\n",
    "5. **Tracing**: Execution traces are essential for debugging and improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
