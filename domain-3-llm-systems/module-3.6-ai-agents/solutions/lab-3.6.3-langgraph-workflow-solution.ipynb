{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.6.3: LangGraph Workflow - SOLUTIONS\n",
    "\n",
    "**Complete solutions with explanations and alternative approaches**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List, Optional, TypedDict, Annotated, Literal\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import operator\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1 Solution: Document Processing Pipeline\n",
    "\n",
    "**Task**: Build a multi-stage document processing workflow with branching logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentState(TypedDict):\n",
    "    \"\"\"State for document processing workflow.\"\"\"\n",
    "    document: str\n",
    "    document_type: str\n",
    "    extracted_entities: List[str]\n",
    "    summary: str\n",
    "    sentiment: str\n",
    "    keywords: List[str]\n",
    "    metadata: Dict[str, Any]\n",
    "    processing_steps: List[str]\n",
    "    errors: List[str]\n",
    "\n",
    "\n",
    "class DocumentWorkflow:\n",
    "    \"\"\"\n",
    "    Multi-stage document processing workflow.\n",
    "    \n",
    "    Pipeline:\n",
    "    1. Classify document type\n",
    "    2. Extract entities (conditional on type)\n",
    "    3. Generate summary\n",
    "    4. Analyze sentiment\n",
    "    5. Extract keywords\n",
    "    6. Compile results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, verbose: bool = True):\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def _log(self, step: str, message: str):\n",
    "        if self.verbose:\n",
    "            print(f\"  [{step}] {message}\")\n",
    "    \n",
    "    def classify_document(self, state: DocumentState) -> DocumentState:\n",
    "        \"\"\"Classify document type.\"\"\"\n",
    "        doc = state[\"document\"].lower()\n",
    "        \n",
    "        # Simple classification rules\n",
    "        if any(word in doc for word in [\"invoice\", \"total\", \"payment\", \"due\"]):\n",
    "            doc_type = \"invoice\"\n",
    "        elif any(word in doc for word in [\"dear\", \"sincerely\", \"regards\"]):\n",
    "            doc_type = \"letter\"\n",
    "        elif any(word in doc for word in [\"whereas\", \"hereby\", \"agreement\", \"contract\"]):\n",
    "            doc_type = \"legal\"\n",
    "        elif any(word in doc for word in [\"abstract\", \"methodology\", \"results\", \"conclusion\"]):\n",
    "            doc_type = \"research\"\n",
    "        else:\n",
    "            doc_type = \"general\"\n",
    "        \n",
    "        state[\"document_type\"] = doc_type\n",
    "        state[\"processing_steps\"].append(f\"classified as {doc_type}\")\n",
    "        self._log(\"Classify\", f\"Document type: {doc_type}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def extract_entities(self, state: DocumentState) -> DocumentState:\n",
    "        \"\"\"Extract entities based on document type.\"\"\"\n",
    "        doc = state[\"document\"]\n",
    "        entities = []\n",
    "        \n",
    "        # Type-specific extraction\n",
    "        if state[\"document_type\"] == \"invoice\":\n",
    "            # Extract amounts\n",
    "            import re\n",
    "            amounts = re.findall(r'\\$[\\d,]+\\.?\\d*', doc)\n",
    "            entities.extend([f\"amount: {a}\" for a in amounts])\n",
    "            \n",
    "            # Extract dates\n",
    "            dates = re.findall(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', doc)\n",
    "            entities.extend([f\"date: {d}\" for d in dates])\n",
    "        \n",
    "        elif state[\"document_type\"] == \"legal\":\n",
    "            # Extract party names (simplified)\n",
    "            import re\n",
    "            parties = re.findall(r'\"([^\"]+)\"', doc)\n",
    "            entities.extend([f\"party: {p}\" for p in parties])\n",
    "        \n",
    "        else:\n",
    "            # General entity extraction (capitalized words)\n",
    "            import re\n",
    "            names = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+\\b', doc)\n",
    "            entities.extend([f\"name: {n}\" for n in names[:5]])\n",
    "        \n",
    "        state[\"extracted_entities\"] = entities\n",
    "        state[\"processing_steps\"].append(f\"extracted {len(entities)} entities\")\n",
    "        self._log(\"Extract\", f\"Found {len(entities)} entities\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def generate_summary(self, state: DocumentState) -> DocumentState:\n",
    "        \"\"\"Generate document summary.\"\"\"\n",
    "        doc = state[\"document\"]\n",
    "        \n",
    "        # Simple extractive summary (first 2 sentences)\n",
    "        sentences = doc.replace('!', '.').replace('?', '.').split('.')\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        summary = '. '.join(sentences[:2]) + '.' if sentences else \"No summary available.\"\n",
    "        \n",
    "        state[\"summary\"] = summary\n",
    "        state[\"processing_steps\"].append(\"generated summary\")\n",
    "        self._log(\"Summarize\", f\"Summary: {summary[:50]}...\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def analyze_sentiment(self, state: DocumentState) -> DocumentState:\n",
    "        \"\"\"Analyze document sentiment.\"\"\"\n",
    "        doc = state[\"document\"].lower()\n",
    "        \n",
    "        # Simple sentiment analysis\n",
    "        positive_words = ['good', 'great', 'excellent', 'happy', 'pleased', 'thank', 'appreciate']\n",
    "        negative_words = ['bad', 'poor', 'issue', 'problem', 'complaint', 'disappointed', 'sorry']\n",
    "        \n",
    "        pos_count = sum(1 for word in positive_words if word in doc)\n",
    "        neg_count = sum(1 for word in negative_words if word in doc)\n",
    "        \n",
    "        if pos_count > neg_count:\n",
    "            sentiment = \"positive\"\n",
    "        elif neg_count > pos_count:\n",
    "            sentiment = \"negative\"\n",
    "        else:\n",
    "            sentiment = \"neutral\"\n",
    "        \n",
    "        state[\"sentiment\"] = sentiment\n",
    "        state[\"processing_steps\"].append(f\"sentiment: {sentiment}\")\n",
    "        self._log(\"Sentiment\", f\"Detected: {sentiment}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def extract_keywords(self, state: DocumentState) -> DocumentState:\n",
    "        \"\"\"Extract keywords from document.\"\"\"\n",
    "        import re\n",
    "        from collections import Counter\n",
    "        \n",
    "        doc = state[\"document\"].lower()\n",
    "        \n",
    "        # Remove common words\n",
    "        stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', \n",
    "                      'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
    "                      'would', 'could', 'should', 'may', 'might', 'must', 'shall',\n",
    "                      'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',\n",
    "                      'as', 'into', 'through', 'during', 'before', 'after', 'and',\n",
    "                      'but', 'or', 'nor', 'so', 'yet', 'both', 'either', 'neither',\n",
    "                      'not', 'only', 'own', 'same', 'than', 'too', 'very', 'just',\n",
    "                      'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it',\n",
    "                      'we', 'they', 'what', 'which', 'who', 'whom', 'whose', 'where',\n",
    "                      'when', 'why', 'how'}\n",
    "        \n",
    "        # Extract words\n",
    "        words = re.findall(r'\\b[a-z]+\\b', doc)\n",
    "        words = [w for w in words if w not in stop_words and len(w) > 3]\n",
    "        \n",
    "        # Get top keywords\n",
    "        word_counts = Counter(words)\n",
    "        keywords = [word for word, count in word_counts.most_common(10)]\n",
    "        \n",
    "        state[\"keywords\"] = keywords\n",
    "        state[\"processing_steps\"].append(f\"extracted {len(keywords)} keywords\")\n",
    "        self._log(\"Keywords\", f\"Top keywords: {keywords[:5]}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def compile_results(self, state: DocumentState) -> DocumentState:\n",
    "        \"\"\"Compile final results with metadata.\"\"\"\n",
    "        state[\"metadata\"] = {\n",
    "            \"processed_at\": datetime.now().isoformat(),\n",
    "            \"document_length\": len(state[\"document\"]),\n",
    "            \"word_count\": len(state[\"document\"].split()),\n",
    "            \"steps_completed\": len(state[\"processing_steps\"]),\n",
    "        }\n",
    "        \n",
    "        state[\"processing_steps\"].append(\"compilation complete\")\n",
    "        self._log(\"Compile\", \"Results compiled\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def process(self, document: str) -> DocumentState:\n",
    "        \"\"\"Run full processing pipeline.\"\"\"\n",
    "        # Initialize state\n",
    "        state: DocumentState = {\n",
    "            \"document\": document,\n",
    "            \"document_type\": \"\",\n",
    "            \"extracted_entities\": [],\n",
    "            \"summary\": \"\",\n",
    "            \"sentiment\": \"\",\n",
    "            \"keywords\": [],\n",
    "            \"metadata\": {},\n",
    "            \"processing_steps\": [],\n",
    "            \"errors\": [],\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DOCUMENT PROCESSING PIPELINE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Run pipeline\n",
    "        pipeline = [\n",
    "            self.classify_document,\n",
    "            self.extract_entities,\n",
    "            self.generate_summary,\n",
    "            self.analyze_sentiment,\n",
    "            self.extract_keywords,\n",
    "            self.compile_results,\n",
    "        ]\n",
    "        \n",
    "        for step_fn in pipeline:\n",
    "            try:\n",
    "                state = step_fn(state)\n",
    "            except Exception as e:\n",
    "                state[\"errors\"].append(f\"{step_fn.__name__}: {str(e)}\")\n",
    "                self._log(\"ERROR\", str(e))\n",
    "        \n",
    "        return state\n",
    "\n",
    "\n",
    "# Test the workflow\n",
    "workflow = DocumentWorkflow(verbose=True)\n",
    "\n",
    "test_documents = [\n",
    "    \"\"\"Invoice #12345\n",
    "    Date: 01/15/2024\n",
    "    \n",
    "    Services rendered: Consulting\n",
    "    Amount due: $5,000.00\n",
    "    Payment due by: 02/15/2024\n",
    "    \n",
    "    Thank you for your business!\"\"\",\n",
    "    \n",
    "    \"\"\"Dear John Smith,\n",
    "    \n",
    "    I am pleased to inform you that your application has been approved.\n",
    "    We are excited to have you join our team at Acme Corporation.\n",
    "    \n",
    "    Sincerely,\n",
    "    Jane Doe\n",
    "    HR Manager\"\"\",\n",
    "]\n",
    "\n",
    "for doc in test_documents:\n",
    "    result = workflow.process(doc)\n",
    "    print(f\"\\n--- Results ---\")\n",
    "    print(f\"Type: {result['document_type']}\")\n",
    "    print(f\"Sentiment: {result['sentiment']}\")\n",
    "    print(f\"Keywords: {result['keywords'][:5]}\")\n",
    "    print(f\"Entities: {result['extracted_entities']}\")\n",
    "    print(f\"Summary: {result['summary'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2 Solution: Approval Workflow with Human-in-the-Loop\n",
    "\n",
    "**Task**: Build a workflow that pauses for human approval at critical decision points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApprovalStatus(Enum):\n",
    "    PENDING = \"pending\"\n",
    "    APPROVED = \"approved\"\n",
    "    REJECTED = \"rejected\"\n",
    "    AUTO_APPROVED = \"auto_approved\"\n",
    "\n",
    "\n",
    "class ApprovalWorkflowState(TypedDict):\n",
    "    \"\"\"State for approval workflow.\"\"\"\n",
    "    request_id: str\n",
    "    request_type: str\n",
    "    amount: float\n",
    "    requester: str\n",
    "    description: str\n",
    "    risk_score: float\n",
    "    approval_status: str\n",
    "    approver: Optional[str]\n",
    "    approval_notes: str\n",
    "    history: List[str]\n",
    "\n",
    "\n",
    "class ApprovalWorkflow:\n",
    "    \"\"\"\n",
    "    Approval workflow with human-in-the-loop.\n",
    "    \n",
    "    Flow:\n",
    "    1. Validate request\n",
    "    2. Calculate risk score\n",
    "    3. Route based on amount/risk:\n",
    "       - Low: Auto-approve\n",
    "       - Medium: Single approver\n",
    "       - High: Manager approval required\n",
    "    4. Process approval decision\n",
    "    5. Execute action\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, auto_approve_limit: float = 100.0, \n",
    "                 manager_threshold: float = 1000.0):\n",
    "        self.auto_approve_limit = auto_approve_limit\n",
    "        self.manager_threshold = manager_threshold\n",
    "        self.pending_approvals: Dict[str, ApprovalWorkflowState] = {}\n",
    "    \n",
    "    def validate_request(self, state: ApprovalWorkflowState) -> ApprovalWorkflowState:\n",
    "        \"\"\"Validate the request.\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        if state[\"amount\"] <= 0:\n",
    "            errors.append(\"Amount must be positive\")\n",
    "        if not state[\"requester\"]:\n",
    "            errors.append(\"Requester is required\")\n",
    "        if not state[\"description\"]:\n",
    "            errors.append(\"Description is required\")\n",
    "        \n",
    "        if errors:\n",
    "            state[\"approval_status\"] = ApprovalStatus.REJECTED.value\n",
    "            state[\"approval_notes\"] = f\"Validation failed: {', '.join(errors)}\"\n",
    "        \n",
    "        state[\"history\"].append(f\"Validated: {'passed' if not errors else 'failed'}\")\n",
    "        return state\n",
    "    \n",
    "    def calculate_risk(self, state: ApprovalWorkflowState) -> ApprovalWorkflowState:\n",
    "        \"\"\"Calculate risk score for the request.\"\"\"\n",
    "        risk = 0.0\n",
    "        \n",
    "        # Amount-based risk\n",
    "        if state[\"amount\"] > 5000:\n",
    "            risk += 0.4\n",
    "        elif state[\"amount\"] > 1000:\n",
    "            risk += 0.2\n",
    "        elif state[\"amount\"] > 500:\n",
    "            risk += 0.1\n",
    "        \n",
    "        # Type-based risk\n",
    "        high_risk_types = [\"external_payment\", \"new_vendor\", \"emergency\"]\n",
    "        if state[\"request_type\"] in high_risk_types:\n",
    "            risk += 0.3\n",
    "        \n",
    "        # Description keywords\n",
    "        desc_lower = state[\"description\"].lower()\n",
    "        if any(word in desc_lower for word in [\"urgent\", \"immediate\", \"asap\"]):\n",
    "            risk += 0.2\n",
    "        \n",
    "        state[\"risk_score\"] = min(1.0, risk)\n",
    "        state[\"history\"].append(f\"Risk calculated: {state['risk_score']:.2f}\")\n",
    "        return state\n",
    "    \n",
    "    def route_request(self, state: ApprovalWorkflowState) -> str:\n",
    "        \"\"\"Determine routing based on amount and risk.\"\"\"\n",
    "        if state[\"approval_status\"] == ApprovalStatus.REJECTED.value:\n",
    "            return \"rejected\"\n",
    "        \n",
    "        # Auto-approve low-risk, low-amount\n",
    "        if state[\"amount\"] <= self.auto_approve_limit and state[\"risk_score\"] < 0.2:\n",
    "            return \"auto_approve\"\n",
    "        \n",
    "        # Manager approval for high amount or risk\n",
    "        if state[\"amount\"] > self.manager_threshold or state[\"risk_score\"] > 0.5:\n",
    "            return \"manager_approval\"\n",
    "        \n",
    "        return \"standard_approval\"\n",
    "    \n",
    "    def auto_approve(self, state: ApprovalWorkflowState) -> ApprovalWorkflowState:\n",
    "        \"\"\"Auto-approve low-risk requests.\"\"\"\n",
    "        state[\"approval_status\"] = ApprovalStatus.AUTO_APPROVED.value\n",
    "        state[\"approver\"] = \"SYSTEM\"\n",
    "        state[\"approval_notes\"] = \"Auto-approved: Low risk, within limits\"\n",
    "        state[\"history\"].append(\"Auto-approved by system\")\n",
    "        return state\n",
    "    \n",
    "    def request_human_approval(self, state: ApprovalWorkflowState, \n",
    "                               approval_type: str) -> ApprovalWorkflowState:\n",
    "        \"\"\"Mark request as pending human approval.\"\"\"\n",
    "        state[\"approval_status\"] = ApprovalStatus.PENDING.value\n",
    "        state[\"approval_notes\"] = f\"Awaiting {approval_type}\"\n",
    "        state[\"history\"].append(f\"Pending {approval_type}\")\n",
    "        \n",
    "        # Store for later approval\n",
    "        self.pending_approvals[state[\"request_id\"]] = state\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def process_approval(self, request_id: str, approved: bool, \n",
    "                        approver: str, notes: str = \"\") -> ApprovalWorkflowState:\n",
    "        \"\"\"Process human approval decision.\"\"\"\n",
    "        if request_id not in self.pending_approvals:\n",
    "            raise ValueError(f\"No pending approval for {request_id}\")\n",
    "        \n",
    "        state = self.pending_approvals.pop(request_id)\n",
    "        \n",
    "        state[\"approver\"] = approver\n",
    "        state[\"approval_notes\"] = notes\n",
    "        \n",
    "        if approved:\n",
    "            state[\"approval_status\"] = ApprovalStatus.APPROVED.value\n",
    "            state[\"history\"].append(f\"Approved by {approver}\")\n",
    "        else:\n",
    "            state[\"approval_status\"] = ApprovalStatus.REJECTED.value\n",
    "            state[\"history\"].append(f\"Rejected by {approver}: {notes}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def execute(self, state: ApprovalWorkflowState) -> ApprovalWorkflowState:\n",
    "        \"\"\"Execute approved action.\"\"\"\n",
    "        if state[\"approval_status\"] in [ApprovalStatus.APPROVED.value, \n",
    "                                         ApprovalStatus.AUTO_APPROVED.value]:\n",
    "            state[\"history\"].append(\"Action executed successfully\")\n",
    "        else:\n",
    "            state[\"history\"].append(\"No action taken - not approved\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def run(self, request_id: str, request_type: str, amount: float,\n",
    "            requester: str, description: str) -> ApprovalWorkflowState:\n",
    "        \"\"\"Run the approval workflow.\"\"\"\n",
    "        # Initialize state\n",
    "        state: ApprovalWorkflowState = {\n",
    "            \"request_id\": request_id,\n",
    "            \"request_type\": request_type,\n",
    "            \"amount\": amount,\n",
    "            \"requester\": requester,\n",
    "            \"description\": description,\n",
    "            \"risk_score\": 0.0,\n",
    "            \"approval_status\": \"\",\n",
    "            \"approver\": None,\n",
    "            \"approval_notes\": \"\",\n",
    "            \"history\": [],\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n--- Processing Request {request_id} ---\")\n",
    "        print(f\"Type: {request_type}, Amount: ${amount:.2f}, Requester: {requester}\")\n",
    "        \n",
    "        # Run workflow steps\n",
    "        state = self.validate_request(state)\n",
    "        state = self.calculate_risk(state)\n",
    "        \n",
    "        # Route based on risk\n",
    "        route = self.route_request(state)\n",
    "        print(f\"Routing: {route}\")\n",
    "        \n",
    "        if route == \"auto_approve\":\n",
    "            state = self.auto_approve(state)\n",
    "            state = self.execute(state)\n",
    "        elif route == \"standard_approval\":\n",
    "            state = self.request_human_approval(state, \"standard approval\")\n",
    "        elif route == \"manager_approval\":\n",
    "            state = self.request_human_approval(state, \"manager approval\")\n",
    "        \n",
    "        print(f\"Status: {state['approval_status']}\")\n",
    "        \n",
    "        return state\n",
    "\n",
    "\n",
    "# Test the approval workflow\n",
    "print(\"=\" * 60)\n",
    "print(\"APPROVAL WORKFLOW SOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "workflow = ApprovalWorkflow(auto_approve_limit=100, manager_threshold=1000)\n",
    "\n",
    "# Test cases\n",
    "requests = [\n",
    "    (\"REQ001\", \"expense\", 50.0, \"alice\", \"Office supplies\"),\n",
    "    (\"REQ002\", \"expense\", 500.0, \"bob\", \"Team dinner\"),\n",
    "    (\"REQ003\", \"external_payment\", 2000.0, \"charlie\", \"URGENT vendor payment\"),\n",
    "]\n",
    "\n",
    "for req in requests:\n",
    "    result = workflow.run(*req)\n",
    "    print(f\"History: {result['history']}\\n\")\n",
    "\n",
    "# Simulate human approval\n",
    "print(\"\\n--- Simulating Human Approval ---\")\n",
    "if workflow.pending_approvals:\n",
    "    for req_id in list(workflow.pending_approvals.keys()):\n",
    "        state = workflow.process_approval(\n",
    "            req_id, \n",
    "            approved=True, \n",
    "            approver=\"manager_jane\",\n",
    "            notes=\"Approved after review\"\n",
    "        )\n",
    "        state = workflow.execute(state)\n",
    "        print(f\"{req_id}: {state['approval_status']} by {state['approver']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3 Solution: Parallel Research Workflow\n",
    "\n",
    "**Task**: Build a workflow that executes multiple research tasks in parallel and aggregates results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "class ResearchState(TypedDict):\n",
    "    \"\"\"State for research workflow.\"\"\"\n",
    "    query: str\n",
    "    sources: List[str]\n",
    "    results: Dict[str, Any]\n",
    "    aggregated: str\n",
    "    confidence: float\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "\n",
    "class ParallelResearchWorkflow:\n",
    "    \"\"\"\n",
    "    Parallel research workflow that queries multiple sources.\n",
    "    \n",
    "    Flow:\n",
    "    1. Parse query and identify sources\n",
    "    2. Execute parallel queries\n",
    "    3. Aggregate results\n",
    "    4. Generate final answer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_workers: int = 4):\n",
    "        self.max_workers = max_workers\n",
    "        self.sources = {\n",
    "            \"wikipedia\": self._search_wikipedia,\n",
    "            \"news\": self._search_news,\n",
    "            \"academic\": self._search_academic,\n",
    "            \"web\": self._search_web,\n",
    "        }\n",
    "    \n",
    "    def _search_wikipedia(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simulated Wikipedia search.\"\"\"\n",
    "        time.sleep(random.uniform(0.1, 0.3))  # Simulate network delay\n",
    "        return {\n",
    "            \"source\": \"wikipedia\",\n",
    "            \"content\": f\"Wikipedia article about {query}. Contains factual information.\",\n",
    "            \"reliability\": 0.85,\n",
    "            \"citations\": 15,\n",
    "        }\n",
    "    \n",
    "    def _search_news(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simulated news search.\"\"\"\n",
    "        time.sleep(random.uniform(0.1, 0.3))\n",
    "        return {\n",
    "            \"source\": \"news\",\n",
    "            \"content\": f\"Recent news articles about {query}. Current events coverage.\",\n",
    "            \"reliability\": 0.7,\n",
    "            \"articles\": 8,\n",
    "        }\n",
    "    \n",
    "    def _search_academic(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simulated academic search.\"\"\"\n",
    "        time.sleep(random.uniform(0.2, 0.4))\n",
    "        return {\n",
    "            \"source\": \"academic\",\n",
    "            \"content\": f\"Academic papers on {query}. Peer-reviewed research.\",\n",
    "            \"reliability\": 0.95,\n",
    "            \"papers\": 5,\n",
    "        }\n",
    "    \n",
    "    def _search_web(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simulated web search.\"\"\"\n",
    "        time.sleep(random.uniform(0.1, 0.2))\n",
    "        return {\n",
    "            \"source\": \"web\",\n",
    "            \"content\": f\"General web results for {query}. Mixed quality.\",\n",
    "            \"reliability\": 0.5,\n",
    "            \"results\": 100,\n",
    "        }\n",
    "    \n",
    "    def parallel_search(self, query: str, sources: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute searches in parallel.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_source = {\n",
    "                executor.submit(self.sources[src], query): src\n",
    "                for src in sources if src in self.sources\n",
    "            }\n",
    "            \n",
    "            # Collect results as they complete\n",
    "            for future in as_completed(future_to_source):\n",
    "                source = future_to_source[future]\n",
    "                try:\n",
    "                    results[source] = future.result()\n",
    "                except Exception as e:\n",
    "                    results[source] = {\"error\": str(e)}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def aggregate_results(self, results: Dict[str, Any]) -> tuple:\n",
    "        \"\"\"Aggregate results from multiple sources.\"\"\"\n",
    "        # Collect content weighted by reliability\n",
    "        weighted_content = []\n",
    "        total_reliability = 0\n",
    "        \n",
    "        for source, data in results.items():\n",
    "            if \"error\" not in data:\n",
    "                reliability = data.get(\"reliability\", 0.5)\n",
    "                weighted_content.append((data[\"content\"], reliability))\n",
    "                total_reliability += reliability\n",
    "        \n",
    "        # Create aggregated summary\n",
    "        if not weighted_content:\n",
    "            return \"No results found\", 0.0\n",
    "        \n",
    "        # Sort by reliability\n",
    "        weighted_content.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Combine top sources\n",
    "        aggregated = \"\\n\".join([c[0] for c in weighted_content[:3]])\n",
    "        confidence = total_reliability / len(results) if results else 0\n",
    "        \n",
    "        return aggregated, confidence\n",
    "    \n",
    "    def run(self, query: str, sources: Optional[List[str]] = None) -> ResearchState:\n",
    "        \"\"\"Run the research workflow.\"\"\"\n",
    "        if sources is None:\n",
    "            sources = list(self.sources.keys())\n",
    "        \n",
    "        print(f\"\\n--- Research Query: {query} ---\")\n",
    "        print(f\"Sources: {sources}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Parallel search\n",
    "        results = self.parallel_search(query, sources)\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        # Aggregate\n",
    "        aggregated, confidence = self.aggregate_results(results)\n",
    "        \n",
    "        state: ResearchState = {\n",
    "            \"query\": query,\n",
    "            \"sources\": sources,\n",
    "            \"results\": results,\n",
    "            \"aggregated\": aggregated,\n",
    "            \"confidence\": confidence,\n",
    "            \"metadata\": {\n",
    "                \"search_time_ms\": search_time * 1000,\n",
    "                \"sources_queried\": len(sources),\n",
    "                \"successful_sources\": len([r for r in results.values() if \"error\" not in r]),\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        print(f\"Completed in {search_time*1000:.1f}ms\")\n",
    "        print(f\"Confidence: {confidence:.2f}\")\n",
    "        \n",
    "        return state\n",
    "\n",
    "\n",
    "# Test parallel research\n",
    "print(\"=\" * 60)\n",
    "print(\"PARALLEL RESEARCH WORKFLOW SOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "research = ParallelResearchWorkflow(max_workers=4)\n",
    "\n",
    "queries = [\n",
    "    \"artificial intelligence in healthcare\",\n",
    "    \"climate change solutions\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    result = research.run(query)\n",
    "    print(f\"\\nAggregated Answer:\")\n",
    "    print(result[\"aggregated\"][:200] + \"...\")\n",
    "    print(f\"\\nMetadata: {result['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Solution: Conditional Workflow Builder\n",
    "\n",
    "**Task**: Create a DSL (Domain Specific Language) for building workflows declaratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Union\n",
    "\n",
    "\n",
    "class WorkflowNode:\n",
    "    \"\"\"A node in the workflow graph.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, handler: Callable):\n",
    "        self.name = name\n",
    "        self.handler = handler\n",
    "        self.next_nodes: List[tuple] = []  # (condition, node_name)\n",
    "    \n",
    "    def then(self, next_node: Union[str, 'WorkflowNode']) -> 'WorkflowNode':\n",
    "        \"\"\"Add unconditional transition.\"\"\"\n",
    "        node_name = next_node if isinstance(next_node, str) else next_node.name\n",
    "        self.next_nodes.append((None, node_name))\n",
    "        return self\n",
    "    \n",
    "    def when(self, condition: Callable, next_node: Union[str, 'WorkflowNode']) -> 'WorkflowNode':\n",
    "        \"\"\"Add conditional transition.\"\"\"\n",
    "        node_name = next_node if isinstance(next_node, str) else next_node.name\n",
    "        self.next_nodes.append((condition, node_name))\n",
    "        return self\n",
    "\n",
    "\n",
    "class WorkflowBuilder:\n",
    "    \"\"\"\n",
    "    Declarative workflow builder.\n",
    "    \n",
    "    Usage:\n",
    "        builder = WorkflowBuilder()\n",
    "        builder.add_node(\"start\", start_handler)\n",
    "        builder.add_node(\"process\", process_handler)\n",
    "        builder.add_node(\"end\", end_handler)\n",
    "        \n",
    "        builder.connect(\"start\", \"process\")\n",
    "        builder.connect(\"process\", \"end\", condition=lambda s: s[\"status\"] == \"ok\")\n",
    "        \n",
    "        workflow = builder.build()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nodes: Dict[str, WorkflowNode] = {}\n",
    "        self.start_node: Optional[str] = None\n",
    "        self.end_nodes: List[str] = []\n",
    "    \n",
    "    def add_node(self, name: str, handler: Callable) -> WorkflowNode:\n",
    "        \"\"\"Add a node to the workflow.\"\"\"\n",
    "        node = WorkflowNode(name, handler)\n",
    "        self.nodes[name] = node\n",
    "        return node\n",
    "    \n",
    "    def set_start(self, name: str) -> 'WorkflowBuilder':\n",
    "        \"\"\"Set the starting node.\"\"\"\n",
    "        self.start_node = name\n",
    "        return self\n",
    "    \n",
    "    def set_end(self, *names: str) -> 'WorkflowBuilder':\n",
    "        \"\"\"Set end node(s).\"\"\"\n",
    "        self.end_nodes.extend(names)\n",
    "        return self\n",
    "    \n",
    "    def connect(self, from_node: str, to_node: str, \n",
    "                condition: Optional[Callable] = None) -> 'WorkflowBuilder':\n",
    "        \"\"\"Connect two nodes.\"\"\"\n",
    "        if from_node not in self.nodes:\n",
    "            raise ValueError(f\"Node not found: {from_node}\")\n",
    "        \n",
    "        self.nodes[from_node].next_nodes.append((condition, to_node))\n",
    "        return self\n",
    "    \n",
    "    def build(self) -> 'Workflow':\n",
    "        \"\"\"Build the workflow.\"\"\"\n",
    "        if not self.start_node:\n",
    "            raise ValueError(\"Start node not set\")\n",
    "        \n",
    "        return Workflow(self.nodes, self.start_node, self.end_nodes)\n",
    "\n",
    "\n",
    "class Workflow:\n",
    "    \"\"\"Executable workflow.\"\"\"\n",
    "    \n",
    "    def __init__(self, nodes: Dict[str, WorkflowNode], \n",
    "                 start_node: str, end_nodes: List[str]):\n",
    "        self.nodes = nodes\n",
    "        self.start_node = start_node\n",
    "        self.end_nodes = end_nodes\n",
    "    \n",
    "    def run(self, initial_state: Dict[str, Any], verbose: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the workflow.\"\"\"\n",
    "        state = initial_state.copy()\n",
    "        current = self.start_node\n",
    "        visited = []\n",
    "        max_steps = 100  # Prevent infinite loops\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            if current not in self.nodes:\n",
    "                break\n",
    "            \n",
    "            node = self.nodes[current]\n",
    "            visited.append(current)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Step {step + 1}: {current}\")\n",
    "            \n",
    "            # Execute handler\n",
    "            state = node.handler(state)\n",
    "            \n",
    "            # Check if end node\n",
    "            if current in self.end_nodes:\n",
    "                break\n",
    "            \n",
    "            # Find next node\n",
    "            next_node = None\n",
    "            for condition, target in node.next_nodes:\n",
    "                if condition is None or condition(state):\n",
    "                    next_node = target\n",
    "                    break\n",
    "            \n",
    "            if next_node is None:\n",
    "                break\n",
    "            \n",
    "            current = next_node\n",
    "        \n",
    "        state[\"_workflow_trace\"] = visited\n",
    "        return state\n",
    "    \n",
    "    def visualize(self) -> str:\n",
    "        \"\"\"Generate text visualization of workflow.\"\"\"\n",
    "        lines = [\"Workflow Graph:\"]\n",
    "        lines.append(f\"  Start: {self.start_node}\")\n",
    "        lines.append(f\"  End: {self.end_nodes}\")\n",
    "        lines.append(\"  Connections:\")\n",
    "        \n",
    "        for name, node in self.nodes.items():\n",
    "            for condition, target in node.next_nodes:\n",
    "                cond_str = \"(conditional)\" if condition else \"\"\n",
    "                lines.append(f\"    {name} -> {target} {cond_str}\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Example: Build an order processing workflow\n",
    "print(\"=\" * 60)\n",
    "print(\"WORKFLOW BUILDER SOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define handlers\n",
    "def validate_order(state):\n",
    "    state[\"validated\"] = state.get(\"amount\", 0) > 0\n",
    "    return state\n",
    "\n",
    "def check_inventory(state):\n",
    "    state[\"in_stock\"] = state.get(\"quantity\", 0) <= 100\n",
    "    return state\n",
    "\n",
    "def process_payment(state):\n",
    "    state[\"payment_status\"] = \"completed\"\n",
    "    return state\n",
    "\n",
    "def ship_order(state):\n",
    "    state[\"shipped\"] = True\n",
    "    state[\"tracking\"] = \"TRK123456\"\n",
    "    return state\n",
    "\n",
    "def reject_order(state):\n",
    "    state[\"status\"] = \"rejected\"\n",
    "    return state\n",
    "\n",
    "def complete_order(state):\n",
    "    state[\"status\"] = \"completed\"\n",
    "    return state\n",
    "\n",
    "# Build workflow\n",
    "builder = WorkflowBuilder()\n",
    "\n",
    "builder.add_node(\"validate\", validate_order)\n",
    "builder.add_node(\"check_inventory\", check_inventory)\n",
    "builder.add_node(\"payment\", process_payment)\n",
    "builder.add_node(\"ship\", ship_order)\n",
    "builder.add_node(\"reject\", reject_order)\n",
    "builder.add_node(\"complete\", complete_order)\n",
    "\n",
    "builder.set_start(\"validate\")\n",
    "builder.set_end(\"reject\", \"complete\")\n",
    "\n",
    "# Connect nodes with conditions\n",
    "builder.connect(\"validate\", \"check_inventory\", lambda s: s.get(\"validated\"))\n",
    "builder.connect(\"validate\", \"reject\", lambda s: not s.get(\"validated\"))\n",
    "builder.connect(\"check_inventory\", \"payment\", lambda s: s.get(\"in_stock\"))\n",
    "builder.connect(\"check_inventory\", \"reject\", lambda s: not s.get(\"in_stock\"))\n",
    "builder.connect(\"payment\", \"ship\")\n",
    "builder.connect(\"ship\", \"complete\")\n",
    "\n",
    "workflow = builder.build()\n",
    "\n",
    "# Visualize\n",
    "print(workflow.visualize())\n",
    "\n",
    "# Test cases\n",
    "print(\"\\n--- Test: Valid Order ---\")\n",
    "result = workflow.run({\"amount\": 100, \"quantity\": 5})\n",
    "print(f\"Final status: {result.get('status')}\")\n",
    "print(f\"Trace: {result['_workflow_trace']}\")\n",
    "\n",
    "print(\"\\n--- Test: Invalid Order ---\")\n",
    "result = workflow.run({\"amount\": 0, \"quantity\": 5})\n",
    "print(f\"Final status: {result.get('status')}\")\n",
    "print(f\"Trace: {result['_workflow_trace']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Typed State**: TypedDict ensures type safety in workflow state\n",
    "2. **Conditional Routing**: Branch workflows based on state conditions\n",
    "3. **Human-in-the-Loop**: Pause for approval at critical points\n",
    "4. **Parallel Execution**: Use ThreadPoolExecutor for concurrent tasks\n",
    "5. **Declarative Building**: DSLs make workflows easier to understand and maintain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
