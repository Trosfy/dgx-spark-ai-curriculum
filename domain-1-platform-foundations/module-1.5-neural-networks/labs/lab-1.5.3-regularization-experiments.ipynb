{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.5.3: Regularization Experiments\n",
    "\n",
    "**Module:** 1.5 - Neural Network Fundamentals  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê (Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand overfitting and how to detect it\n",
    "- [ ] Implement L2 (weight decay) regularization\n",
    "- [ ] Implement Dropout regularization\n",
    "- [ ] Visualize the underfitting ‚Üî overfitting spectrum\n",
    "- [ ] Find optimal regularization strength experimentally\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Notebooks 01-02\n",
    "- Knowledge of: Neural network training basics\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**Why regularization matters:**\n",
    "\n",
    "In 2012, the ImageNet competition was won by AlexNet, which used **Dropout** - a regularization technique that was considered radical at the time. Now it's standard practice!\n",
    "\n",
    "Modern LLMs use various regularization techniques:\n",
    "- **Weight decay** in AdamW optimizer\n",
    "- **Dropout** in attention layers\n",
    "- **Early stopping** during training\n",
    "\n",
    "Understanding regularization is crucial for training models that generalize well to new data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßí ELI5: What is Overfitting?\n",
    "\n",
    "> **Imagine you're studying for a test by memorizing the practice problems.**\n",
    ">\n",
    "> If you just memorize the exact answers, you'll do great on practice problems, but terrible on the real test with new questions. That's **overfitting**!\n",
    ">\n",
    "> The goal is to **understand the concepts** so you can answer any question, not just memorize specific answers.\n",
    ">\n",
    "> **Regularization is like a teacher saying:**\n",
    "> - \"Don't just memorize - explain the concept!\" (L2 regularization)\n",
    "> - \"Can you still solve this if I cover part of your notes?\" (Dropout)\n",
    "> - \"Stop studying when you're not improving anymore\" (Early stopping)\n",
    ">\n",
    "> These techniques force the model to learn general patterns, not specific examples.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom typing import Tuple, List, Dict\nimport time\nimport sys\nimport os\nfrom pathlib import Path\n\n# Add scripts directory to path (robust approach)\nnotebook_dir = Path().resolve()\nif notebook_dir.name == 'notebooks':\n    scripts_dir = notebook_dir.parent / 'scripts'\nelse:\n    scripts_dir = notebook_dir / 'scripts'\n    if not scripts_dir.exists():\n        scripts_dir = notebook_dir.parent / 'scripts'\n\nif scripts_dir.exists():\n    sys.path.insert(0, str(scripts_dir))\n\nnp.random.seed(42)\nplt.style.use('default')\n%matplotlib inline\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Creating an Overfitting-Prone Dataset\n",
    "\n",
    "To study overfitting, we need a scenario where it's likely to happen:\n",
    "- Small training set\n",
    "- Large model capacity\n",
    "- No regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "import gzip\n",
    "import urllib.request\n",
    "\n",
    "def load_mnist(path='../data'):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    base_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = {\n",
    "        'train_images': 'train-images-idx3-ubyte.gz',\n",
    "        'train_labels': 'train-labels-idx1-ubyte.gz',\n",
    "        'test_images': 't10k-images-idx3-ubyte.gz',\n",
    "        'test_labels': 't10k-labels-idx1-ubyte.gz'\n",
    "    }\n",
    "    \n",
    "    def download(filename):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "        return filepath\n",
    "    \n",
    "    def load_images(fp):\n",
    "        with gzip.open(fp, 'rb') as f:\n",
    "            f.read(16)\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8).reshape(-1, 784).astype(np.float32) / 255.0\n",
    "    \n",
    "    def load_labels(fp):\n",
    "        with gzip.open(fp, 'rb') as f:\n",
    "            f.read(8)\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    \n",
    "    X_train = load_images(download(files['train_images']))\n",
    "    y_train = load_labels(download(files['train_labels']))\n",
    "    X_test = load_images(download(files['test_images']))\n",
    "    y_test = load_labels(download(files['test_labels']))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading MNIST...\")\n",
    "X_train_full, y_train_full, X_test, y_test = load_mnist()\n",
    "\n",
    "# Create small training set (overfitting-prone)\n",
    "TRAIN_SIZE = 1000  # Very small!\n",
    "X_train = X_train_full[:TRAIN_SIZE]\n",
    "y_train = y_train_full[:TRAIN_SIZE]\n",
    "\n",
    "print(f\"\\nüìä Dataset sizes:\")\n",
    "print(f\"   Training: {len(X_train):,} samples (small, overfitting-prone!)\")\n",
    "print(f\"   Test: {len(X_test):,} samples\")\n",
    "print(f\"   Ratio: 1:{len(X_test)//len(X_train)} (test is {len(X_test)//len(X_train)}x larger!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building the Model with Regularization Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedMLP:\n",
    "    \"\"\"\n",
    "    MLP with L2 regularization and Dropout support.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        layer_sizes: List[int],\n",
    "        l2_lambda: float = 0.0,\n",
    "        dropout_rate: float = 0.0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            layer_sizes: e.g., [784, 512, 256, 10]\n",
    "            l2_lambda: L2 regularization strength (0 = no regularization)\n",
    "            dropout_rate: Probability of dropping neurons (0 = no dropout)\n",
    "        \"\"\"\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.training = True\n",
    "        \n",
    "        self.layers = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            # He initialization\n",
    "            W = np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * np.sqrt(2.0 / layer_sizes[i])\n",
    "            b = np.zeros(layer_sizes[i + 1])\n",
    "            self.layers.append({\n",
    "                'W': W, 'b': b, \n",
    "                'cache': {}, \n",
    "                'dW': None, 'db': None,\n",
    "                'dropout_mask': None\n",
    "            })\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        out = X\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            layer['cache']['X'] = out\n",
    "            \n",
    "            # Linear\n",
    "            out = out @ layer['W'] + layer['b']\n",
    "            \n",
    "            # ReLU\n",
    "            layer['cache']['Z'] = out\n",
    "            out = np.maximum(0, out)\n",
    "            \n",
    "            # Dropout (only during training)\n",
    "            if self.training and self.dropout_rate > 0:\n",
    "                mask = (np.random.rand(*out.shape) > self.dropout_rate).astype(float)\n",
    "                out = out * mask / (1 - self.dropout_rate)  # Inverted dropout\n",
    "                layer['dropout_mask'] = mask\n",
    "            else:\n",
    "                layer['dropout_mask'] = None\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers[-1]['cache']['X'] = out\n",
    "        out = out @ self.layers[-1]['W'] + self.layers[-1]['b']\n",
    "        \n",
    "        # Softmax\n",
    "        out_shifted = out - np.max(out, axis=1, keepdims=True)\n",
    "        exp_out = np.exp(out_shifted)\n",
    "        self.probs = exp_out / np.sum(exp_out, axis=1, keepdims=True)\n",
    "        \n",
    "        return self.probs\n",
    "    \n",
    "    def compute_loss(self, targets: np.ndarray) -> float:\n",
    "        \"\"\"Compute cross-entropy loss + L2 regularization.\"\"\"\n",
    "        batch_size = len(targets)\n",
    "        \n",
    "        # Cross-entropy loss\n",
    "        ce_loss = -np.mean(np.log(self.probs[np.arange(batch_size), targets] + 1e-10))\n",
    "        \n",
    "        # L2 regularization loss\n",
    "        l2_loss = 0.0\n",
    "        if self.l2_lambda > 0:\n",
    "            for layer in self.layers:\n",
    "                l2_loss += np.sum(layer['W'] ** 2)\n",
    "            l2_loss = 0.5 * self.l2_lambda * l2_loss\n",
    "        \n",
    "        return ce_loss + l2_loss\n",
    "    \n",
    "    def backward(self, targets: np.ndarray, learning_rate: float):\n",
    "        \"\"\"Backward pass with L2 regularization.\"\"\"\n",
    "        batch_size = len(targets)\n",
    "        \n",
    "        # Gradient from softmax + cross-entropy\n",
    "        grad = self.probs.copy()\n",
    "        grad[np.arange(batch_size), targets] -= 1\n",
    "        \n",
    "        # Backward through layers\n",
    "        for i in range(len(self.layers) - 1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            X = layer['cache']['X']\n",
    "            \n",
    "            # Compute gradients\n",
    "            layer['dW'] = X.T @ grad / batch_size\n",
    "            layer['db'] = np.mean(grad, axis=0)\n",
    "            \n",
    "            # Add L2 regularization gradient\n",
    "            if self.l2_lambda > 0:\n",
    "                layer['dW'] += self.l2_lambda * layer['W']\n",
    "            \n",
    "            # Gradient for next layer\n",
    "            grad = grad @ layer['W'].T\n",
    "            \n",
    "            # Apply ReLU and dropout gradients (except for last layer)\n",
    "            if i > 0:\n",
    "                Z = self.layers[i - 1]['cache']['Z']\n",
    "                grad = grad * (Z > 0).astype(float)  # ReLU backward\n",
    "                \n",
    "                # Dropout backward\n",
    "                if self.layers[i - 1]['dropout_mask'] is not None:\n",
    "                    grad = grad * self.layers[i - 1]['dropout_mask'] / (1 - self.dropout_rate)\n",
    "            \n",
    "            # Update weights\n",
    "            layer['W'] -= learning_rate * layer['dW']\n",
    "            layer['b'] -= learning_rate * layer['db']\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.training = False\n",
    "        probs = self.forward(X)\n",
    "        self.training = True\n",
    "        return np.argmax(probs, axis=1)\n",
    "    \n",
    "    def get_l2_norm(self) -> float:\n",
    "        \"\"\"Get total L2 norm of weights (useful for visualization).\"\"\"\n",
    "        total = 0.0\n",
    "        for layer in self.layers:\n",
    "            total += np.sum(layer['W'] ** 2)\n",
    "        return np.sqrt(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Training Without Regularization (Observe Overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: RegularizedMLP,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    epochs: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    lr: float = 0.01,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Train model and return history.\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [], 'test_loss': [],\n",
    "        'train_acc': [], 'test_acc': [],\n",
    "        'weight_norm': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.training = True\n",
    "        indices = np.random.permutation(len(X_train))\n",
    "        epoch_loss = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for start in range(0, len(X_train), batch_size):\n",
    "            batch_idx = indices[start:start + batch_size]\n",
    "            X_batch = X_train[batch_idx]\n",
    "            y_batch = y_train[batch_idx]\n",
    "            \n",
    "            model.forward(X_batch)\n",
    "            loss = model.compute_loss(y_batch)\n",
    "            model.backward(y_batch, lr)\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            n_batches += 1\n",
    "        \n",
    "        # Evaluate\n",
    "        train_preds = model.predict(X_train)\n",
    "        test_preds = model.predict(X_test[:2000])  # Subset for speed\n",
    "        \n",
    "        model.training = False\n",
    "        model.forward(X_train)\n",
    "        train_loss = model.compute_loss(y_train)\n",
    "        model.forward(X_test[:2000])\n",
    "        test_loss = model.compute_loss(y_test[:2000])\n",
    "        model.training = True\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(np.mean(train_preds == y_train))\n",
    "        history['test_acc'].append(np.mean(test_preds == y_test[:2000]))\n",
    "        history['weight_norm'].append(model.get_l2_norm())\n",
    "        \n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1:3d} | \"\n",
    "                  f\"Train Acc: {history['train_acc'][-1]:.2%} | \"\n",
    "                  f\"Test Acc: {history['test_acc'][-1]:.2%} | \"\n",
    "                  f\"Gap: {history['train_acc'][-1] - history['test_acc'][-1]:.2%}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train without regularization\n",
    "print(\"üèãÔ∏è Training WITHOUT regularization (expect overfitting!)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(42)\n",
    "model_no_reg = RegularizedMLP([784, 512, 256, 10], l2_lambda=0.0, dropout_rate=0.0)\n",
    "history_no_reg = train_model(model_no_reg, X_train, y_train, X_test, y_test, epochs=50, lr=0.1)\n",
    "\n",
    "print(\"\\nüìä Final Results:\")\n",
    "print(f\"   Train Accuracy: {history_no_reg['train_acc'][-1]:.2%}\")\n",
    "print(f\"   Test Accuracy:  {history_no_reg['test_acc'][-1]:.2%}\")\n",
    "print(f\"   Generalization Gap: {history_no_reg['train_acc'][-1] - history_no_reg['test_acc'][-1]:.2%}\")\n",
    "print(\"\\n‚ö†Ô∏è Notice the large gap between train and test accuracy - that's overfitting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize overfitting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history_no_reg['train_loss'], 'b-', linewidth=2, label='Train Loss')\n",
    "axes[0].plot(history_no_reg['test_loss'], 'r-', linewidth=2, label='Test Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss Curves (No Regularization)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "axes[1].plot(history_no_reg['train_acc'], 'b-', linewidth=2, label='Train Acc')\n",
    "axes[1].plot(history_no_reg['test_acc'], 'r-', linewidth=2, label='Test Acc')\n",
    "axes[1].axhline(y=1.0, color='g', linestyle=':', alpha=0.5)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy Curves (No Regularization)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Weight norm growth\n",
    "axes[2].plot(history_no_reg['weight_norm'], 'purple', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Weight Norm (L2)')\n",
    "axes[2].set_title('Weight Magnitude Growth')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key observations:\")\n",
    "print(\"   1. Train loss keeps decreasing ‚Üí model is memorizing\")\n",
    "print(\"   2. Test loss starts increasing ‚Üí model is overfitting\")\n",
    "print(\"   3. Weights keep growing ‚Üí no constraint on complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: L2 Regularization (Weight Decay)\n",
    "\n",
    "### The Idea\n",
    "\n",
    "L2 regularization adds a penalty for large weights:\n",
    "\n",
    "$$\\mathcal{L}_{total} = \\mathcal{L}_{CE} + \\frac{\\lambda}{2} \\sum_i w_i^2$$\n",
    "\n",
    "This encourages smaller weights, which leads to simpler models that generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different L2 regularization strengths\n",
    "print(\"üî¨ Experimenting with L2 Regularization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "l2_values = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "l2_results = {}\n",
    "\n",
    "for l2_lambda in l2_values:\n",
    "    np.random.seed(42)\n",
    "    model = RegularizedMLP([784, 512, 256, 10], l2_lambda=l2_lambda)\n",
    "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=50, lr=0.1, verbose=False)\n",
    "    l2_results[l2_lambda] = history\n",
    "    \n",
    "    gap = history['train_acc'][-1] - history['test_acc'][-1]\n",
    "    print(f\"Œª = {l2_lambda:6.4f} | Train: {history['train_acc'][-1]:.2%} | \"\n",
    "          f\"Test: {history['test_acc'][-1]:.2%} | Gap: {gap:.2%}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize L2 regularization effects\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.9, len(l2_values)))\n",
    "\n",
    "for (l2, history), color in zip(l2_results.items(), colors):\n",
    "    label = f'Œª={l2}'\n",
    "    \n",
    "    # Accuracy gap\n",
    "    gap = [t - v for t, v in zip(history['train_acc'], history['test_acc'])]\n",
    "    axes[0].plot(gap, color=color, linewidth=2, label=label)\n",
    "    \n",
    "    # Test accuracy\n",
    "    axes[1].plot(history['test_acc'], color=color, linewidth=2, label=label)\n",
    "    \n",
    "    # Weight norm\n",
    "    axes[2].plot(history['weight_norm'], color=color, linewidth=2, label=label)\n",
    "\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Train - Test Accuracy')\n",
    "axes[0].set_title('Generalization Gap')\n",
    "axes[0].legend(fontsize=8)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Test Accuracy')\n",
    "axes[1].set_title('Test Accuracy')\n",
    "axes[1].legend(fontsize=8)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Weight Norm')\n",
    "axes[2].set_title('Weight Magnitude')\n",
    "axes[2].legend(fontsize=8)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Dropout Regularization\n",
    "\n",
    "### The Idea\n",
    "\n",
    "Dropout randomly \"drops\" neurons during training:\n",
    "\n",
    "$$\\tilde{h} = h \\odot m$$\n",
    "\n",
    "where $m \\sim \\text{Bernoulli}(1 - p)$ is a random mask.\n",
    "\n",
    "**Why it works:**\n",
    "1. Prevents neurons from co-adapting\n",
    "2. Acts like training many different networks\n",
    "3. At test time, all neurons contribute (with scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different dropout rates\n",
    "print(\"üî¨ Experimenting with Dropout\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dropout_values = [0.0, 0.1, 0.2, 0.3, 0.5]\n",
    "dropout_results = {}\n",
    "\n",
    "for dropout_rate in dropout_values:\n",
    "    np.random.seed(42)\n",
    "    model = RegularizedMLP([784, 512, 256, 10], dropout_rate=dropout_rate)\n",
    "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=50, lr=0.1, verbose=False)\n",
    "    dropout_results[dropout_rate] = history\n",
    "    \n",
    "    gap = history['train_acc'][-1] - history['test_acc'][-1]\n",
    "    print(f\"Dropout = {dropout_rate:.1f} | Train: {history['train_acc'][-1]:.2%} | \"\n",
    "          f\"Test: {history['test_acc'][-1]:.2%} | Gap: {gap:.2%}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dropout effects\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "colors = plt.cm.plasma(np.linspace(0, 0.9, len(dropout_values)))\n",
    "\n",
    "for (drop, history), color in zip(dropout_results.items(), colors):\n",
    "    label = f'Dropout={drop}'\n",
    "    \n",
    "    # Accuracy gap\n",
    "    gap = [t - v for t, v in zip(history['train_acc'], history['test_acc'])]\n",
    "    axes[0].plot(gap, color=color, linewidth=2, label=label)\n",
    "    \n",
    "    # Test accuracy\n",
    "    axes[1].plot(history['test_acc'], color=color, linewidth=2, label=label)\n",
    "\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Train - Test Accuracy')\n",
    "axes[0].set_title('Generalization Gap with Dropout')\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Test Accuracy')\n",
    "axes[1].set_title('Test Accuracy with Dropout')\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: The Underfitting ‚Üî Overfitting Spectrum\n",
    "\n",
    "Let's visualize how regularization affects the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "print(\"üéØ Finding the Sweet Spot\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine L2 and Dropout\n",
    "configs = [\n",
    "    ('No Regularization', 0.0, 0.0),\n",
    "    ('L2 only (Œª=0.001)', 0.001, 0.0),\n",
    "    ('Dropout only (0.2)', 0.0, 0.2),\n",
    "    ('L2 + Dropout', 0.001, 0.2),\n",
    "    ('Strong Regularization', 0.01, 0.5),\n",
    "]\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "for name, l2, drop in configs:\n",
    "    np.random.seed(42)\n",
    "    model = RegularizedMLP([784, 512, 256, 10], l2_lambda=l2, dropout_rate=drop)\n",
    "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=50, lr=0.1, verbose=False)\n",
    "    comparison_results[name] = history\n",
    "    \n",
    "    gap = history['train_acc'][-1] - history['test_acc'][-1]\n",
    "    print(f\"{name:25s} | Train: {history['train_acc'][-1]:.2%} | \"\n",
    "          f\"Test: {history['test_acc'][-1]:.2%} | Gap: {gap:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spectrum visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Prepare data\n",
    "names = list(comparison_results.keys())\n",
    "train_accs = [comparison_results[n]['train_acc'][-1] for n in names]\n",
    "test_accs = [comparison_results[n]['test_acc'][-1] for n in names]\n",
    "gaps = [t - v for t, v in zip(train_accs, test_accs)]\n",
    "\n",
    "x = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, train_accs, width, label='Train Accuracy', color='#2196F3', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, test_accs, width, label='Test Accuracy', color='#4CAF50', alpha=0.8)\n",
    "\n",
    "# Add gap annotations\n",
    "for i, (train, test, gap) in enumerate(zip(train_accs, test_accs, gaps)):\n",
    "    mid = (train + test) / 2\n",
    "    ax.annotate(f'Gap: {gap:.1%}', (i, mid), ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Underfitting ‚Üî Good Fit ‚Üî Overfitting Spectrum', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, rotation=15, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0.7, 1.05)\n",
    "\n",
    "# Add regions\n",
    "ax.axvspan(-0.5, 0.5, alpha=0.1, color='red', label='Overfitting')\n",
    "ax.axvspan(2.5, 3.5, alpha=0.1, color='green', label='Sweet Spot')\n",
    "ax.axvspan(3.5, 4.5, alpha=0.1, color='blue', label='Underfitting')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"                    REGULARIZATION RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Technique       ‚îÇ When to Use                                                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ L2 (Weight      ‚îÇ ‚Ä¢ Default choice, always a good starting point             ‚îÇ\n",
    "‚îÇ Decay)          ‚îÇ ‚Ä¢ Built into AdamW optimizer (modern standard)             ‚îÇ\n",
    "‚îÇ                 ‚îÇ ‚Ä¢ Typical values: 0.0001 to 0.01                           ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Dropout         ‚îÇ ‚Ä¢ Large models with many parameters                        ‚îÇ\n",
    "‚îÇ                 ‚îÇ ‚Ä¢ Fully-connected layers (less common in CNNs now)         ‚îÇ\n",
    "‚îÇ                 ‚îÇ ‚Ä¢ Typical values: 0.1 to 0.5                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Early Stopping  ‚îÇ ‚Ä¢ When you see test loss increasing                        ‚îÇ\n",
    "‚îÇ                 ‚îÇ ‚Ä¢ Save model at best validation performance                ‚îÇ\n",
    "‚îÇ                 ‚îÇ ‚Ä¢ Patience: typically 5-10 epochs                          ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Data            ‚îÇ ‚Ä¢ Limited training data                                    ‚îÇ\n",
    "‚îÇ Augmentation    ‚îÇ ‚Ä¢ Computer vision tasks                                    ‚îÇ\n",
    "‚îÇ                 ‚îÇ ‚Ä¢ Creates \"virtual\" training examples                      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Key Signs:\n",
    "‚Ä¢ Overfitting: Train acc >> Test acc, Test loss increasing\n",
    "‚Ä¢ Underfitting: Both train and test acc are low\n",
    "‚Ä¢ Good fit: Small gap between train and test, test acc high\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Applying dropout during inference\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - dropout still active during testing\n",
    "predictions = model(test_data)  # Some values randomly zeroed!\n",
    "\n",
    "# ‚úÖ Right - disable dropout during testing\n",
    "model.training = False\n",
    "predictions = model(test_data)\n",
    "```\n",
    "\n",
    "### Mistake 2: Too much regularization\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - model can't learn anything\n",
    "model = MLP(l2_lambda=1.0, dropout=0.9)\n",
    "\n",
    "# ‚úÖ Right - start small and increase if needed\n",
    "model = MLP(l2_lambda=0.001, dropout=0.2)\n",
    "```\n",
    "\n",
    "### Mistake 3: Not monitoring both train and test metrics\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - only looking at training loss\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "\n",
    "# ‚úÖ Right - always compare train vs test\n",
    "print(f\"Train loss: {train_loss}, Test loss: {test_loss}\")\n",
    "print(f\"Gap: {train_acc - test_acc}\")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úã Try It Yourself\n",
    "\n",
    "### Exercise 1: Find the Optimal Regularization\n",
    "\n",
    "Use grid search to find the best combination of L2 and Dropout for this dataset.\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "Try L2 in [0.0001, 0.001, 0.01] and Dropout in [0.0, 0.1, 0.2, 0.3].\n",
    "Track test accuracy for each combination.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Grid search for optimal regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Early Stopping\n",
    "\n",
    "Add early stopping to the training loop:\n",
    "- Monitor validation loss\n",
    "- Stop if it doesn't improve for N epochs\n",
    "- Return the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Implement early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "\n",
    "- ‚úÖ How to detect overfitting (train >> test)\n",
    "- ‚úÖ L2 regularization constrains weight magnitudes\n",
    "- ‚úÖ Dropout prevents co-adaptation of neurons\n",
    "- ‚úÖ The underfitting ‚Üî overfitting spectrum\n",
    "- ‚úÖ How to find optimal regularization experimentally\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [Dropout Paper (Srivastava et al.)](https://jmlr.org/papers/v15/srivastava14a.html)\n",
    "- [Regularization for Deep Learning (Goodfellow)](https://www.deeplearningbook.org/contents/regularization.html)\n",
    "- [L2 Regularization and Batch Norm](https://arxiv.org/abs/1706.05350)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Cleanup complete!\")\n",
    "print(\"\\nüéØ Next: Proceed to notebook 04-normalization-comparison.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}