{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 1.4.2: Optimizer Implementation\n\n**Module:** 1.4 - Mathematics for Deep Learning  \n**Time:** 2 hours  \n**Difficulty:** ‚≠ê‚≠ê‚≠ê\n\n---\n\n## üéØ Learning Objectives\n\nBy the end of this notebook, you will:\n- [ ] Implement vanilla SGD from scratch\n- [ ] Implement SGD with momentum\n- [ ] Implement the Adam optimizer\n- [ ] Understand why adaptive learning rates help\n- [ ] Compare convergence behavior of different optimizers\n\n---\n\n## üìö Prerequisites\n\n- Completed: Lab 1.4.1 (Manual Backpropagation)\n- Knowledge of: Gradients, basic calculus\n\n---\n\n## üåç Real-World Context\n\n**Why do optimizers matter?**\n\nChoosing the right optimizer can mean the difference between:\n- A model that trains in 1 hour vs 100 hours\n- A model that converges vs one that diverges\n- Finding a good solution vs getting stuck in a bad one\n\n**Real examples:**\n- GPT models use AdamW (Adam with weight decay)\n- Vision Transformers often use AdamW with specific Œ≤ values\n- BERT was trained with Adam (Œ≤1=0.9, Œ≤2=0.999)\n\nUnderstanding these algorithms helps you debug training and choose the right tool!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is an Optimizer?\n",
    "\n",
    "> **Imagine you're blindfolded on a mountain, trying to find the lowest valley...**\n",
    ">\n",
    "> **Vanilla SGD (the basic approach):**\n",
    "> - Feel which way is downhill with your foot\n",
    "> - Take one step in that direction\n",
    "> - Repeat\n",
    "> - Problem: You might zigzag a lot and waste energy!\n",
    ">\n",
    "> **SGD with Momentum (like a ball rolling downhill):**\n",
    "> - You're a ball now! You build up speed as you roll\n",
    "> - When going downhill consistently, you go faster\n",
    "> - Small bumps don't stop you (you have momentum!)\n",
    "> - Problem: Sometimes you overshoot the valley\n",
    ">\n",
    "> **Adam (the smart explorer):**\n",
    "> - You have momentum (like the ball)\n",
    "> - BUT you also adapt your step size!\n",
    "> - Steep areas? Take smaller steps to not overshoot\n",
    "> - Flat areas? Take bigger steps to make progress\n",
    "> - This is like having a smart GPS that adjusts your walking speed!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üöÄ Optimizer Implementation Lab\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Test Function\n",
    "\n",
    "We'll optimize the **Rosenbrock function** - a classic optimization test:\n",
    "\n",
    "$$f(x, y) = (a - x)^2 + b(y - x^2)^2$$\n",
    "\n",
    "Where typically $a=1$, $b=100$.\n",
    "\n",
    "**Why this function?**\n",
    "- Has a global minimum at $(a, a^2) = (1, 1)$\n",
    "- Has a curved valley that's hard to navigate\n",
    "- Exposes weaknesses in different optimizers\n",
    "\n",
    "It looks like a banana-shaped valley - easy to find the valley, hard to find the bottom!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, y, a=1, b=100):\n",
    "    \"\"\"\n",
    "    Rosenbrock function - a classic optimization test case.\n",
    "    \n",
    "    Global minimum: f(a, a¬≤) = 0 ‚Üí at (1, 1) with default params\n",
    "    \"\"\"\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "def rosenbrock_gradient(x, y, a=1, b=100):\n",
    "    \"\"\"\n",
    "    Gradient of Rosenbrock function.\n",
    "    \n",
    "    ‚àÇf/‚àÇx = -2(a-x) - 4bx(y-x¬≤)\n",
    "    ‚àÇf/‚àÇy = 2b(y-x¬≤)\n",
    "    \"\"\"\n",
    "    df_dx = -2*(a - x) - 4*b*x*(y - x**2)\n",
    "    df_dy = 2*b*(y - x**2)\n",
    "    return np.array([df_dx, df_dy])\n",
    "\n",
    "# Visualize the function\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Create mesh\n",
    "x_range = np.linspace(-2, 2, 200)\n",
    "y_range = np.linspace(-1, 3, 200)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "Z = rosenbrock(X, Y)\n",
    "\n",
    "# Contour plot\n",
    "ax1 = fig.add_subplot(121)\n",
    "levels = np.logspace(0, 3, 20)  # Log-spaced levels\n",
    "contour = ax1.contour(X, Y, Z, levels=levels, cmap='viridis')\n",
    "ax1.scatter([1], [1], color='red', s=100, marker='*', \n",
    "           label='Global minimum (1, 1)', zorder=5)\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Rosenbrock Function (Contour)')\n",
    "ax1.legend()\n",
    "plt.colorbar(contour, ax=ax1, label='f(x,y)')\n",
    "\n",
    "# 3D surface\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "# Use log scale for better visualization\n",
    "Z_log = np.log10(Z + 1)\n",
    "surf = ax2.plot_surface(X, Y, Z_log, cmap='viridis', alpha=0.8)\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('log‚ÇÅ‚ÇÄ(f + 1)')\n",
    "ax2.set_title('Rosenbrock Function (3D)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä The Rosenbrock function:\")\n",
    "print(\"  - Has a curved 'banana' valley\")\n",
    "print(\"  - Global minimum at (1, 1) with value 0\")\n",
    "print(\"  - Difficult because the valley is flat but curved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Vanilla SGD\n",
    "\n",
    "The simplest optimizer:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\cdot \\nabla L(\\theta_t)$$\n",
    "\n",
    "Where:\n",
    "- $\\theta$ = parameters\n",
    "- $\\eta$ = learning rate\n",
    "- $\\nabla L$ = gradient of loss\n",
    "\n",
    "**That's it!** Just move opposite to the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    Vanilla Stochastic Gradient Descent optimizer.\n",
    "    \n",
    "    The simplest optimizer: just follow the negative gradient.\n",
    "    \n",
    "    Update rule:\n",
    "        Œ∏ = Œ∏ - lr * gradient\n",
    "    \n",
    "    Args:\n",
    "        lr: Learning rate (step size)\n",
    "    \n",
    "    Example:\n",
    "        >>> optimizer = SGD(lr=0.01)\n",
    "        >>> params = np.array([0.0, 0.0])\n",
    "        >>> for _ in range(100):\n",
    "        ...     grad = compute_gradient(params)\n",
    "        ...     params = optimizer.step(params, grad)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.name = f\"SGD (lr={lr})\"\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        \"\"\"\n",
    "        Perform one optimization step.\n",
    "        \n",
    "        Args:\n",
    "            params: Current parameters (numpy array)\n",
    "            grads: Gradients at current parameters\n",
    "            \n",
    "        Returns:\n",
    "            Updated parameters\n",
    "        \"\"\"\n",
    "        return params - self.lr * grads\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset optimizer state (nothing to reset for vanilla SGD)\"\"\"\n",
    "        pass\n",
    "\n",
    "print(\"SGD Implementation:\")\n",
    "print(\"  Œ∏_new = Œ∏ - lr √ó gradient\")\n",
    "print(\"\\nSimple, but can be slow in curved valleys!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: SGD with Momentum\n",
    "\n",
    "Momentum helps overcome oscillations by accumulating past gradients:\n",
    "\n",
    "$$v_t = \\beta \\cdot v_{t-1} + \\nabla L(\\theta_t)$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\cdot v_t$$\n",
    "\n",
    "Where:\n",
    "- $v$ = velocity (accumulated gradient)\n",
    "- $\\beta$ = momentum coefficient (typically 0.9)\n",
    "\n",
    "### üßí ELI5: Why Momentum?\n",
    "\n",
    "> Imagine pushing a shopping cart down a bumpy path:\n",
    "> - Without momentum: Every bump makes you change direction\n",
    "> - With momentum: The cart's weight carries it through small bumps\n",
    ">\n",
    "> The cart naturally smooths out the path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum:\n",
    "    \"\"\"\n",
    "    SGD with Momentum optimizer.\n",
    "    \n",
    "    Accumulates past gradients to build \"velocity\" and smooth out oscillations.\n",
    "    \n",
    "    Update rules:\n",
    "        v = Œ≤ √ó v + gradient           (accumulate velocity)\n",
    "        Œ∏ = Œ∏ - lr √ó v                 (update parameters)\n",
    "    \n",
    "    Args:\n",
    "        lr: Learning rate\n",
    "        momentum: Momentum coefficient Œ≤ (typically 0.9)\n",
    "    \n",
    "    Example:\n",
    "        >>> optimizer = SGDMomentum(lr=0.01, momentum=0.9)\n",
    "        >>> optimizer.reset()  # Initialize velocity\n",
    "        >>> params = np.array([0.0, 0.0])\n",
    "        >>> for _ in range(100):\n",
    "        ...     grad = compute_gradient(params)\n",
    "        ...     params = optimizer.step(params, grad)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.velocity = None\n",
    "        self.name = f\"SGD+Momentum (lr={lr}, Œ≤={momentum})\"\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        \"\"\"\n",
    "        Perform one optimization step with momentum.\n",
    "        \n",
    "        Args:\n",
    "            params: Current parameters\n",
    "            grads: Gradients at current parameters\n",
    "            \n",
    "        Returns:\n",
    "            Updated parameters\n",
    "        \"\"\"\n",
    "        # Initialize velocity on first call\n",
    "        if self.velocity is None:\n",
    "            self.velocity = np.zeros_like(params)\n",
    "        \n",
    "        # Update velocity: v = Œ≤*v + grad\n",
    "        self.velocity = self.momentum * self.velocity + grads\n",
    "        \n",
    "        # Update parameters: Œ∏ = Œ∏ - lr*v\n",
    "        return params - self.lr * self.velocity\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset velocity to zero\"\"\"\n",
    "        self.velocity = None\n",
    "\n",
    "print(\"SGD+Momentum Implementation:\")\n",
    "print(\"  v = Œ≤ √ó v + gradient\")\n",
    "print(\"  Œ∏_new = Œ∏ - lr √ó v\")\n",
    "print(\"\\nThe velocity builds up in consistent directions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Adam Optimizer\n",
    "\n",
    "**Adam** = **Ada**ptive **M**oment estimation\n",
    "\n",
    "Adam combines:\n",
    "1. **Momentum** (first moment = mean of gradients)\n",
    "2. **RMSprop** (second moment = variance of gradients)\n",
    "\n",
    "### The Algorithm:\n",
    "\n",
    "$$m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t$$\n",
    "$$v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2$$\n",
    "$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$$\n",
    "$$\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
    "\n",
    "### üßí ELI5: Why Adam Works\n",
    "\n",
    "> Imagine you're navigating a fog-covered valley:\n",
    ">\n",
    "> **First moment (m):** \"On average, I've been going LEFT, so I should keep going left\"\n",
    "> (This is momentum!)\n",
    ">\n",
    "> **Second moment (v):** \"The ground has been VERY bumpy in the left-right direction\"\n",
    "> (This tells you how much the gradient varies)\n",
    ">\n",
    "> **Combining them:** \"I should go left (m says so), but take SMALL steps because it's bumpy there (v says so)\"\n",
    ">\n",
    "> Adam automatically takes smaller steps in bumpy directions and bigger steps in smooth directions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    \"\"\"\n",
    "    Adam (Adaptive Moment Estimation) optimizer.\n",
    "    \n",
    "    Combines momentum with adaptive learning rates per parameter.\n",
    "    \n",
    "    Update rules:\n",
    "        m = Œ≤1 √ó m + (1-Œ≤1) √ó g         (first moment / momentum)\n",
    "        v = Œ≤2 √ó v + (1-Œ≤2) √ó g¬≤        (second moment / variance)\n",
    "        m_hat = m / (1 - Œ≤1^t)          (bias correction)\n",
    "        v_hat = v / (1 - Œ≤2^t)          (bias correction)\n",
    "        Œ∏ = Œ∏ - lr √ó m_hat / (‚àöv_hat + Œµ)\n",
    "    \n",
    "    Args:\n",
    "        lr: Learning rate (default 0.001)\n",
    "        beta1: Momentum coefficient (default 0.9)\n",
    "        beta2: Variance coefficient (default 0.999)\n",
    "        epsilon: Numerical stability term (default 1e-8)\n",
    "    \n",
    "    Example:\n",
    "        >>> optimizer = Adam(lr=0.001)\n",
    "        >>> optimizer.reset()\n",
    "        >>> params = np.array([0.0, 0.0])\n",
    "        >>> for _ in range(100):\n",
    "        ...     grad = compute_gradient(params)\n",
    "        ...     params = optimizer.step(params, grad)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Moving averages (will be initialized on first step)\n",
    "        self.m = None  # First moment (mean of gradients)\n",
    "        self.v = None  # Second moment (variance of gradients)\n",
    "        self.t = 0     # Timestep (for bias correction)\n",
    "        \n",
    "        self.name = f\"Adam (lr={lr})\"\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        \"\"\"\n",
    "        Perform one Adam optimization step.\n",
    "        \n",
    "        Args:\n",
    "            params: Current parameters\n",
    "            grads: Gradients at current parameters\n",
    "            \n",
    "        Returns:\n",
    "            Updated parameters\n",
    "        \"\"\"\n",
    "        # Initialize on first call\n",
    "        if self.m is None:\n",
    "            self.m = np.zeros_like(params)\n",
    "            self.v = np.zeros_like(params)\n",
    "        \n",
    "        # Increment timestep\n",
    "        self.t += 1\n",
    "        \n",
    "        # Update biased first moment estimate (momentum)\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * grads\n",
    "        \n",
    "        # Update biased second moment estimate (variance)\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (grads ** 2)\n",
    "        \n",
    "        # Compute bias-corrected estimates\n",
    "        # (Important early in training when m and v are biased toward 0)\n",
    "        m_hat = self.m / (1 - self.beta1 ** self.t)\n",
    "        v_hat = self.v / (1 - self.beta2 ** self.t)\n",
    "        \n",
    "        # Update parameters\n",
    "        params = params - self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset optimizer state\"\"\"\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.t = 0\n",
    "\n",
    "print(\"Adam Implementation:\")\n",
    "print(\"  m = Œ≤1√óm + (1-Œ≤1)√óg        (momentum)\")\n",
    "print(\"  v = Œ≤2√óv + (1-Œ≤2)√óg¬≤       (variance tracking)\")\n",
    "print(\"  Œ∏ = Œ∏ - lr √ó mÃÇ / (‚àövÃÇ + Œµ)  (adaptive update)\")\n",
    "print(\"\\nAdapts step size per-parameter based on gradient history!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Comparing Optimizers\n",
    "\n",
    "Let's run all three optimizers on the Rosenbrock function and see how they perform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(optimizer, start_point, gradient_fn, n_steps=1000):\n",
    "    \"\"\"\n",
    "    Run optimization and track history.\n",
    "    \n",
    "    Args:\n",
    "        optimizer: Optimizer object with step() method\n",
    "        start_point: Initial parameters\n",
    "        gradient_fn: Function to compute gradients\n",
    "        n_steps: Number of optimization steps\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with trajectory and loss history\n",
    "    \"\"\"\n",
    "    optimizer.reset()\n",
    "    \n",
    "    params = start_point.copy()\n",
    "    history = {'params': [params.copy()], 'loss': [rosenbrock(params[0], params[1])]}\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        grads = gradient_fn(params[0], params[1])\n",
    "        params = optimizer.step(params, grads)\n",
    "        \n",
    "        loss = rosenbrock(params[0], params[1])\n",
    "        history['params'].append(params.copy())\n",
    "        history['loss'].append(loss)\n",
    "        \n",
    "        # Early stopping if converged\n",
    "        if loss < 1e-10:\n",
    "            break\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Starting point (in the \"hard\" region of the valley)\n",
    "start_point = np.array([-1.0, 1.0])\n",
    "\n",
    "# Create optimizers with tuned learning rates\n",
    "optimizers = [\n",
    "    SGD(lr=0.001),                    # Small lr to avoid divergence\n",
    "    SGDMomentum(lr=0.001, momentum=0.9),\n",
    "    Adam(lr=0.1),                      # Adam can handle larger lr\n",
    "]\n",
    "\n",
    "# Run optimization\n",
    "n_steps = 5000\n",
    "histories = {}\n",
    "\n",
    "print(\"Running optimizations...\")\n",
    "print(f\"Start: ({start_point[0]}, {start_point[1]})\")\n",
    "print(f\"Goal:  (1.0, 1.0)\")\n",
    "print(f\"Steps: {n_steps}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for opt in optimizers:\n",
    "    histories[opt.name] = optimize(opt, start_point, rosenbrock_gradient, n_steps)\n",
    "    final_loss = histories[opt.name]['loss'][-1]\n",
    "    final_params = histories[opt.name]['params'][-1]\n",
    "    steps_taken = len(histories[opt.name]['loss']) - 1\n",
    "    \n",
    "    print(f\"\\n{opt.name}:\")\n",
    "    print(f\"  Final position: ({final_params[0]:.6f}, {final_params[1]:.6f})\")\n",
    "    print(f\"  Final loss: {final_loss:.6e}\")\n",
    "    print(f\"  Steps taken: {steps_taken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results!\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Colors for each optimizer\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "# --- Left plot: Trajectories on contour ---\n",
    "levels = np.logspace(-1, 3, 30)\n",
    "axes[0].contour(X, Y, Z, levels=levels, cmap='Greys', alpha=0.5)\n",
    "\n",
    "for (name, hist), color in zip(histories.items(), colors):\n",
    "    path = np.array(hist['params'])\n",
    "    # Plot every nth point to avoid clutter\n",
    "    step = max(1, len(path) // 200)\n",
    "    axes[0].plot(path[::step, 0], path[::step, 1], '-', color=color, \n",
    "                linewidth=1.5, alpha=0.7, label=name)\n",
    "    axes[0].scatter(path[0, 0], path[0, 1], color=color, s=100, \n",
    "                   marker='o', edgecolors='black', zorder=5)\n",
    "    axes[0].scatter(path[-1, 0], path[-1, 1], color=color, s=100, \n",
    "                   marker='*', edgecolors='black', zorder=5)\n",
    "\n",
    "axes[0].scatter([1], [1], color='gold', s=200, marker='*', \n",
    "               edgecolors='black', linewidth=2, label='Optimum', zorder=10)\n",
    "axes[0].set_xlabel('x', fontsize=12)\n",
    "axes[0].set_ylabel('y', fontsize=12)\n",
    "axes[0].set_title('Optimization Trajectories', fontsize=14)\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].set_xlim(-1.5, 1.5)\n",
    "axes[0].set_ylim(-0.5, 2)\n",
    "\n",
    "# --- Right plot: Loss curves ---\n",
    "for (name, hist), color in zip(histories.items(), colors):\n",
    "    losses = hist['loss']\n",
    "    axes[1].semilogy(losses, color=color, linewidth=2, label=name, alpha=0.8)\n",
    "\n",
    "axes[1].axhline(y=1e-6, color='gray', linestyle='--', label='Target: 1e-6')\n",
    "axes[1].set_xlabel('Step', fontsize=12)\n",
    "axes[1].set_ylabel('Loss (log scale)', fontsize=12)\n",
    "axes[1].set_title('Convergence Comparison', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Observations:\")\n",
    "print(\"  - SGD: Slow, struggles in the curved valley\")\n",
    "print(\"  - Momentum: Faster, but may overshoot\")\n",
    "print(\"  - Adam: Adapts to the landscape, converges reliably\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç What Just Happened?\n",
    "\n",
    "**Left plot (Trajectories):**\n",
    "- Shows the path each optimizer takes through parameter space\n",
    "- Notice how SGD zigzags, while Adam takes a more direct path\n",
    "- Stars show start (filled) and end (star shape) points\n",
    "\n",
    "**Right plot (Loss curves):**\n",
    "- Y-axis is log scale - lower is better\n",
    "- Adam typically converges fastest\n",
    "- Momentum helps SGD avoid getting stuck\n",
    "\n",
    "**Key insight:** Adam adapts its step size, which helps in the curved valley!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Why Bias Correction Matters in Adam\n",
    "\n",
    "Early in training, `m` and `v` are initialized to 0, which biases them toward 0.\n",
    "\n",
    "Let's see what happens without bias correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamNoBiasCorrection:\n",
    "    \"\"\"Adam WITHOUT bias correction (for demonstration)\"\"\"\n",
    "    \n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.name = \"Adam (no bias correction)\"\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m = np.zeros_like(params)\n",
    "            self.v = np.zeros_like(params)\n",
    "        \n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * grads\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (grads ** 2)\n",
    "        \n",
    "        # No bias correction!\n",
    "        return params - self.lr * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "\n",
    "# Compare with and without bias correction\n",
    "adam_with = Adam(lr=0.1)\n",
    "adam_without = AdamNoBiasCorrection(lr=0.1)\n",
    "\n",
    "hist_with = optimize(adam_with, start_point, rosenbrock_gradient, 1000)\n",
    "hist_without = optimize(adam_without, start_point, rosenbrock_gradient, 1000)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.semilogy(hist_with['loss'][:200], 'b-', linewidth=2, label='Adam (with bias correction)')\n",
    "plt.semilogy(hist_without['loss'][:200], 'r--', linewidth=2, label='Adam (without bias correction)')\n",
    "plt.xlabel('Step', fontsize=12)\n",
    "plt.ylabel('Loss (log scale)', fontsize=12)\n",
    "plt.title('Effect of Bias Correction in Adam', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Without bias correction:\")\n",
    "print(\"  - Steps are too small early in training\")\n",
    "print(\"  - Takes longer to get moving\")\n",
    "print(\"  - Bias correction fixes this!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Learning Rate Too High\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong: Learning rate causes divergence\n",
    "optimizer = SGD(lr=1.0)  # Rosenbrock has large gradients!\n",
    "\n",
    "# ‚úÖ Right: Start small and tune\n",
    "optimizer = SGD(lr=0.001)  # Safe starting point\n",
    "```\n",
    "\n",
    "**Why:** Large learning rates can overshoot the minimum and cause the loss to explode.\n",
    "\n",
    "### Mistake 2: Forgetting to Reset State\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong: Reusing optimizer without reset\n",
    "opt = Adam(lr=0.001)\n",
    "train_model_1(opt)  # First training\n",
    "train_model_2(opt)  # Oops! Still has state from model 1!\n",
    "\n",
    "# ‚úÖ Right: Reset between uses\n",
    "opt = Adam(lr=0.001)\n",
    "train_model_1(opt)\n",
    "opt.reset()  # Clear momentum/variance\n",
    "train_model_2(opt)\n",
    "```\n",
    "\n",
    "### Mistake 3: Wrong Epsilon Value\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong: epsilon too large changes behavior\n",
    "optimizer = Adam(lr=0.001, epsilon=1.0)  # Defeats adaptive learning!\n",
    "\n",
    "# ‚úÖ Right: Keep epsilon small\n",
    "optimizer = Adam(lr=0.001, epsilon=1e-8)  # Standard value\n",
    "```\n",
    "\n",
    "**Why:** epsilon is just for numerical stability; making it large changes the algorithm's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself\n",
    "\n",
    "### Exercise 1: Implement RMSprop\n",
    "\n",
    "RMSprop is like Adam but without the momentum term:\n",
    "\n",
    "$$v_t = \\beta \\cdot v_{t-1} + (1-\\beta) \\cdot g_t^2$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{v_t} + \\epsilon} \\cdot g_t$$\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "Start from the Adam implementation and:\n",
    "1. Remove the first moment (`m`) calculations\n",
    "2. Remove bias correction (RMSprop doesn't use it)\n",
    "3. Divide the gradient by sqrt(v) + epsilon\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# YOUR CODE HERE: Implement RMSprop\n\nclass RMSprop:\n    \"\"\"\n    RMSprop optimizer.\n    \n    Update rules:\n        v = Œ≤ √ó v + (1-Œ≤) √ó g¬≤\n        Œ∏ = Œ∏ - lr √ó g / (‚àöv + Œµ)\n    \"\"\"\n    \n    def __init__(self, lr=0.01, beta=0.9, epsilon=1e-8):\n        self.lr = lr\n        self.beta = beta\n        self.epsilon = epsilon\n        self.v = None\n        self.name = f\"RMSprop (lr={lr})\"\n    \n    def step(self, params, grads):\n        # TODO: Implement RMSprop step\n        # 1. Initialize v if None (use np.zeros_like)\n        # 2. Update v: v = beta * v + (1-beta) * grads**2\n        # 3. Update params: params = params - lr * grads / (sqrt(v) + epsilon)\n        raise NotImplementedError(\"Implement the RMSprop step method\")\n    \n    def reset(self):\n        self.v = None\n\n# Test your implementation (uncomment after implementing)\n# rmsprop = RMSprop(lr=0.01)\n# hist_rmsprop = optimize(rmsprop, start_point, rosenbrock_gradient, 5000)\n# print(f\"RMSprop final loss: {hist_rmsprop['loss'][-1]:.6e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: AdamW (Adam with Weight Decay)\n",
    "\n",
    "AdamW adds weight decay (L2 regularization) SEPARATELY from the gradient:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} - \\eta \\cdot \\lambda \\cdot \\theta_t$$\n",
    "\n",
    "Where $\\lambda$ is the weight decay coefficient.\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "Add one line to the Adam step:\n",
    "```python\n",
    "params = params - self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "params = params - self.lr * self.weight_decay * params  # Add this!\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# YOUR CODE HERE: Implement AdamW\n\nclass AdamW:\n    \"\"\"Adam with decoupled weight decay (AdamW)\"\"\"\n    \n    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, weight_decay=0.01):\n        self.lr = lr\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n        self.weight_decay = weight_decay\n        self.m = None\n        self.v = None\n        self.t = 0\n        self.name = f\"AdamW (lr={lr}, wd={weight_decay})\"\n    \n    def step(self, params, grads):\n        # TODO: Implement AdamW step\n        # 1. Initialize m and v if None\n        # 2. Increment timestep t\n        # 3. Update m and v (same as Adam)\n        # 4. Compute bias-corrected m_hat and v_hat\n        # 5. Update params with Adam step\n        # 6. Apply weight decay: params = params - lr * weight_decay * params\n        raise NotImplementedError(\"Implement the AdamW step method\")\n    \n    def reset(self):\n        self.m = None\n        self.v = None\n        self.t = 0\n\n# Test AdamW (uncomment after implementing)\n# adamw = AdamW(lr=0.1, weight_decay=0.01)\n# hist_adamw = optimize(adamw, start_point, rosenbrock_gradient, 5000)\n# print(f\"AdamW final loss: {hist_adamw['loss'][-1]:.6e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "\n",
    "- ‚úÖ **SGD**: Simple gradient descent - just follow the gradient\n",
    "- ‚úÖ **Momentum**: Accumulate velocity to overcome oscillations\n",
    "- ‚úÖ **Adam**: Adaptive learning rates + momentum for robust training\n",
    "- ‚úÖ **Bias correction**: Why it matters early in training\n",
    "- ‚úÖ How to compare optimizers visually\n",
    "\n",
    "**Key insight:** Modern optimizers like Adam work well because they adapt to the loss landscape!\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [Why Momentum Really Works](https://distill.pub/2017/momentum/) - Beautiful visualizations\n",
    "- [Adam Paper](https://arxiv.org/abs/1412.6980) - Original Adam paper\n",
    "- [AdamW Paper](https://arxiv.org/abs/1711.05101) - Decoupled weight decay\n",
    "- [An overview of gradient descent optimization](https://ruder.io/optimizing-gradient-descent/) - Comprehensive survey\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Cleanup complete!\")\n",
    "print(\"\\n‚û°Ô∏è  Next: Lab 1.4.3 - Loss Landscape Visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}