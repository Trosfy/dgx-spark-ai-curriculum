{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.1.2: Memory Architecture Lab - SOLUTIONS\n",
    "\n",
    "This notebook contains solutions to the exercises in the Memory Architecture Lab.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself #1 Solution\n",
    "\n",
    "**Task:** Try allocating larger tensors (60-100 GB). What's the maximum you can allocate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import time\n",
    "\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "def allocate_tensor_gb(size_gb: float, dtype=torch.float32):\n",
    "    bytes_per_element = torch.tensor([], dtype=dtype).element_size()\n",
    "    num_elements = int(size_gb * 1e9 / bytes_per_element)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tensor = torch.empty(num_elements, dtype=dtype, device='cuda')\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    actual_size = tensor.element_size() * tensor.nelement() / 1e9\n",
    "    return tensor, actual_size, elapsed\n",
    "\n",
    "# Solution: Test large allocations\n",
    "large_sizes = [60, 70, 80, 90, 100]\n",
    "\n",
    "print(\"Large Tensor Allocation Test\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Size (GB)':<12} {'Status':<15} {'Time (s)':<12}\")\n",
    "print(\"-\" * 39)\n",
    "\n",
    "max_successful = 0\n",
    "\n",
    "for size_gb in large_sizes:\n",
    "    clear_memory()\n",
    "    \n",
    "    try:\n",
    "        tensor, actual_size, alloc_time = allocate_tensor_gb(size_gb)\n",
    "        print(f\"{size_gb:<12} {'SUCCESS':<15} {alloc_time:.3f}\")\n",
    "        max_successful = size_gb\n",
    "        del tensor\n",
    "    except RuntimeError as e:\n",
    "        print(f\"{size_gb:<12} {'FAILED':<15} -\")\n",
    "\n",
    "clear_memory()\n",
    "print(f\"\\nMaximum successful allocation: {max_successful} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Results:**\n",
    "- On a fresh system with cleared buffer cache, you should be able to allocate ~100GB\n",
    "- The exact limit depends on:\n",
    "  - Current buffer cache usage (run `sync; echo 3 > /proc/sys/vm/drop_caches` to clear)\n",
    "  - Other running processes\n",
    "  - PyTorch memory overhead\n",
    "\n",
    "**Typical output:**\n",
    "```\n",
    "Size (GB)    Status          Time (s)    \n",
    "---------------------------------------\n",
    "60           SUCCESS         0.015\n",
    "70           SUCCESS         0.018\n",
    "80           SUCCESS         0.021\n",
    "90           SUCCESS         0.024\n",
    "100          SUCCESS         0.027\n",
    "\n",
    "Maximum successful allocation: 100 GB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself #2 Solution\n",
    "\n",
    "**Task:** Calculate memory requirements for a 70B model in different precisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Calculate memory requirements\n",
    "\n",
    "params_70b = 70_000_000_000  # 70 billion parameters\n",
    "\n",
    "# Memory calculation for different precisions\n",
    "# Formula: memory = num_params * bytes_per_param\n",
    "\n",
    "precisions = {\n",
    "    \"FP32 (float32)\": 4,       # 4 bytes per parameter\n",
    "    \"FP16 (float16)\": 2,       # 2 bytes per parameter\n",
    "    \"BF16 (bfloat16)\": 2,      # 2 bytes per parameter\n",
    "    \"INT8 (int8)\": 1,          # 1 byte per parameter\n",
    "    \"INT4 (int4)\": 0.5,        # 0.5 bytes per parameter\n",
    "}\n",
    "\n",
    "print(\"Memory Requirements for 70B Parameter Model\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Precision':<20} {'Bytes/Param':<15} {'Total Memory':<15} {'Fits in 128GB?'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for name, bytes_per_param in precisions.items():\n",
    "    memory_bytes = params_70b * bytes_per_param\n",
    "    memory_gb = memory_bytes / 1e9\n",
    "    fits = \"YES\" if memory_gb < 120 else \"NO\"  # Leave some headroom\n",
    "    \n",
    "    print(f\"{name:<20} {bytes_per_param:<15} {memory_gb:.1f} GB{'':<8} {fits}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 55)\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"- FP32 requires 280GB - DOES NOT fit\")\n",
    "print(\"- FP16/BF16 requires 140GB - TIGHT FIT (may work with optimizations)\")\n",
    "print(\"- INT8 requires 70GB - FITS COMFORTABLY\")\n",
    "print(\"- INT4 requires 35GB - FITS WITH ROOM TO SPARE\")\n",
    "print(\"\\nThis is why quantization is essential for running large models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Considerations:**\n",
    "\n",
    "1. **Inference Memory Overhead:**\n",
    "   - KV Cache: Additional memory for attention caching\n",
    "   - Activation memory: Intermediate computation results\n",
    "   - Typically add 10-20% overhead\n",
    "\n",
    "2. **Training Memory Overhead:**\n",
    "   - Gradients: Same size as model (2x)\n",
    "   - Optimizer states: Adam needs 2x more (4x total with model)\n",
    "   - Activations for backprop: Variable, can be huge\n",
    "   - **Training 70B on DGX Spark**: Requires gradient checkpointing, LoRA, or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Solution\n",
    "\n",
    "**Task:** Create a memory stress test that allocates until failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_stress_test(increment_gb: float = 5.0, max_attempts: int = 30):\n",
    "    \"\"\"\n",
    "    Stress test GPU memory by allocating tensors until failure.\n",
    "    \n",
    "    Args:\n",
    "        increment_gb: Size of each allocation in GB\n",
    "        max_attempts: Maximum number of allocations to attempt\n",
    "    \n",
    "    Returns:\n",
    "        Maximum memory allocated in GB\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import gc\n",
    "    \n",
    "    print(\"Memory Stress Test\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Increment: {increment_gb} GB per allocation\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    tensors = []\n",
    "    total_gb = 0\n",
    "    \n",
    "    # Clear before starting\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    try:\n",
    "        for i in range(max_attempts):\n",
    "            # Allocate tensor\n",
    "            bytes_per_element = 4  # float32\n",
    "            num_elements = int(increment_gb * 1e9 / bytes_per_element)\n",
    "            \n",
    "            tensor = torch.empty(num_elements, dtype=torch.float32, device='cuda')\n",
    "            tensors.append(tensor)\n",
    "            \n",
    "            total_gb += increment_gb\n",
    "            \n",
    "            # Get actual memory stats\n",
    "            allocated = torch.cuda.memory_allocated() / 1e9\n",
    "            reserved = torch.cuda.memory_reserved() / 1e9\n",
    "            \n",
    "            print(f\"  Allocation {i+1}: +{increment_gb} GB (Total: {total_gb:.1f} GB, Reserved: {reserved:.1f} GB)\")\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(f\"\\n  ALLOCATION FAILED at {total_gb + increment_gb:.1f} GB\")\n",
    "        print(f\"  Error: {str(e)[:60]}...\")\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        print(\"\\nCleaning up...\")\n",
    "        for t in tensors:\n",
    "            del t\n",
    "        tensors.clear()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n✅ Maximum successful allocation: {total_gb:.1f} GB\")\n",
    "    return total_gb\n",
    "\n",
    "# Run the stress test\n",
    "# Note: This may take a while and use a lot of memory!\n",
    "# max_mem = memory_stress_test(increment_gb=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Binary search for maximum allocation\n",
    "def find_max_allocation(low_gb: float = 50, high_gb: float = 120) -> float:\n",
    "    \"\"\"\n",
    "    Binary search to find maximum single allocation size.\n",
    "    \n",
    "    Returns:\n",
    "        Maximum allocation size in GB\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import gc\n",
    "    \n",
    "    print(\"Finding maximum single allocation...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    max_successful = 0\n",
    "    \n",
    "    while high_gb - low_gb > 1:\n",
    "        mid = (low_gb + high_gb) / 2\n",
    "        \n",
    "        try:\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            num_elements = int(mid * 1e9 / 4)\n",
    "            tensor = torch.empty(num_elements, dtype=torch.float32, device='cuda')\n",
    "            del tensor\n",
    "            \n",
    "            print(f\"  {mid:.1f} GB: SUCCESS\")\n",
    "            max_successful = mid\n",
    "            low_gb = mid\n",
    "            \n",
    "        except RuntimeError:\n",
    "            print(f\"  {mid:.1f} GB: FAILED\")\n",
    "            high_gb = mid\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n✅ Maximum single allocation: ~{max_successful:.0f} GB\")\n",
    "    return max_successful\n",
    "\n",
    "# Uncomment to run:\n",
    "# find_max_allocation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Unified Memory** allows allocations up to ~100GB on DGX Spark\n",
    "2. **Buffer cache** must be cleared before large model loading\n",
    "3. **BFloat16** is the recommended dtype for DGX Spark (native Blackwell support)\n",
    "4. **70B models** fit in INT4/INT8 quantization easily\n",
    "5. **Memory overhead** from PyTorch caching is typically 5-10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup resources and release GPU memory\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Cleanup any remaining tensors\n",
    "gc.collect()\n",
    "\n",
    "# Clear CUDA cache if available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
