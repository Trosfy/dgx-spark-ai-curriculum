{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1.3.5: Profiling Workshop\n",
    "\n",
    "**Module:** 1.3 - CUDA Python & GPU Programming  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê (Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Profile GPU code using PyTorch Profiler\n",
    "- [ ] Understand Nsight Systems timeline analysis\n",
    "- [ ] Identify common bottlenecks (data loading, CPU‚ÜîGPU sync)\n",
    "- [ ] Apply optimizations based on profiling results\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Labs 1.3.1-1.3.4\n",
    "- Knowledge of: Basic PyTorch training loops\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**\"You can't improve what you can't measure.\"** - Peter Drucker\n",
    "\n",
    "Professional ML engineers spend significant time profiling and optimizing:\n",
    "\n",
    "| Company | Optimization Impact |\n",
    "|---------|--------------------|\n",
    "| OpenAI | Reduced GPT-4 training costs by 3x through optimizations |\n",
    "| Google | TensorFlow optimization team saves millions in compute |\n",
    "| Meta | PyTorch 2.0 compile gives 2x speedup on many workloads |\n",
    "\n",
    "**Common bottlenecks discovered through profiling:**\n",
    "- Data loading: 40% of training time wasted waiting for data\n",
    "- CPU‚ÜîGPU transfers: Unnecessary synchronization points\n",
    "- Memory copies: Data not staying on GPU between operations\n",
    "- Kernel launch overhead: Too many small kernels\n",
    "- Suboptimal algorithms: Wrong approach for the hardware\n",
    "\n",
    "**NVIDIA provides world-class profiling tools:**\n",
    "- **Nsight Systems**: Timeline view, CPU‚ÜîGPU interactions\n",
    "- **Nsight Compute**: Deep kernel analysis\n",
    "- **PyTorch Profiler**: Integration with CUDA events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What is Profiling?\n",
    "\n",
    "> **Imagine you're a detective** investigating why dinner takes 2 hours to cook when it should take 30 minutes.\n",
    ">\n",
    "> You set up cameras in the kitchen and watch the recording:\n",
    "> - \"Hmm, you spent 45 minutes looking for the spatula...\"\n",
    "> - \"You waited 30 minutes for the oven to preheat... while doing nothing!\"\n",
    "> - \"The rice cooker was done, but you didn't notice for 20 minutes.\"\n",
    ">\n",
    "> **Profiling** is like having cameras in your code. It shows:\n",
    "> - Which parts take the most time (the \"hot spots\")\n",
    "> - Where you're waiting unnecessarily (synchronization)\n",
    "> - What resources are being used (memory, compute)\n",
    ">\n",
    "> Once you SEE the problem, you can FIX it!\n",
    "\n",
    "### Profiling Tool Hierarchy\n",
    "\n",
    "```\n",
    "Level 1: High-Level Overview (Nsight Systems)\n",
    "‚îú‚îÄ‚îÄ What is CPU doing? What is GPU doing?\n",
    "‚îú‚îÄ‚îÄ Are they working in parallel or waiting for each other?\n",
    "‚îú‚îÄ‚îÄ Where are the gaps (idle time)?\n",
    "‚îî‚îÄ‚îÄ Timeline view: see everything at a glance\n",
    "\n",
    "Level 2: Kernel Deep Dive (Nsight Compute)\n",
    "‚îú‚îÄ‚îÄ How efficient is this specific kernel?\n",
    "‚îú‚îÄ‚îÄ Is it memory-bound or compute-bound?\n",
    "‚îú‚îÄ‚îÄ Are there bank conflicts or uncoalesced access?\n",
    "‚îî‚îÄ‚îÄ What's the occupancy?\n",
    "\n",
    "Level 3: Code-Level (PyTorch Profiler)\n",
    "‚îú‚îÄ‚îÄ Which PyTorch operations are slow?\n",
    "‚îú‚îÄ‚îÄ How much time in forward vs backward?\n",
    "‚îú‚îÄ‚îÄ Memory usage over time\n",
    "‚îî‚îÄ‚îÄ Easy to integrate in Python code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport time\nimport os\nfrom typing import List, Tuple\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nprint(f\"‚úÖ PyTorch {torch.__version__}\")\nprint(f\"   CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"   Device: {torch.cuda.get_device_name()}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# PyTorch Profiler - with fallback for older PyTorch versions\ntry:\n    from torch.profiler import profile, record_function, ProfilerActivity\n    HAS_PROFILER = True\n    print(f\"\\n‚úÖ PyTorch Profiler available\")\nexcept ImportError:\n    HAS_PROFILER = False\n    print(f\"\\n‚ö†Ô∏è PyTorch Profiler not available (requires PyTorch >= 1.8)\")\n    print(\"   Some profiling examples will use basic timing instead.\")\n    print(\"   For full profiler support, use NGC container: nvcr.io/nvidia/pytorch:25.11-py3\")\n    \n    # Create dummy classes for compatibility\n    class ProfilerActivity:\n        CPU = \"cpu\"\n        CUDA = \"cuda\"\n    \n    from contextlib import contextmanager\n    @contextmanager\n    def profile(*args, **kwargs):\n        yield None\n    \n    @contextmanager  \n    def record_function(name):\n        yield\n\n# Check for Nsight tools\nnsight_sys = os.system('which nsys > /dev/null 2>&1') == 0\nnsight_compute = os.system('which ncu > /dev/null 2>&1') == 0\nprint(f\"\\n   Nsight Systems available: {'‚úÖ' if nsight_sys else '‚ùå'}\")\nprint(f\"   Nsight Compute available: {'‚úÖ' if nsight_compute else '‚ùå'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Creating a Training Pipeline to Profile\n",
    "\n",
    "Let's create a realistic but simple training pipeline with intentional bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \"\"\"Simple neural network for profiling demo.\"\"\"\n",
    "    def __init__(self, input_dim: int = 784, hidden_dim: int = 256, output_dim: int = 10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "# Create synthetic dataset (like MNIST but simpler)\n",
    "def create_synthetic_data(n_samples: int = 60000, input_dim: int = 784, n_classes: int = 10):\n",
    "    \"\"\"Create synthetic classification data.\"\"\"\n",
    "    X = torch.randn(n_samples, input_dim)\n",
    "    y = torch.randint(0, n_classes, (n_samples,))\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "\n",
    "# Training function with profiling hooks\n",
    "def train_epoch_slow(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Training loop with INTENTIONAL BOTTLENECKS for demonstration.\n",
    "    \n",
    "    Bottlenecks:\n",
    "    1. Data transfer inside training loop\n",
    "    2. Unnecessary synchronization\n",
    "    3. CPU operations mixed with GPU\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        # BOTTLENECK 1: Data transfer inside loop (should use pin_memory)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # BOTTLENECK 2: Unnecessary .item() causes CPU-GPU sync\n",
    "        batch_loss = loss.item()  # Forces synchronization!\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # BOTTLENECK 3: CPU computation in hot loop\n",
    "        if batch_idx % 100 == 0:\n",
    "            # This forces another sync and wastes time\n",
    "            accuracy = (output.argmax(1) == target).float().mean().item()\n",
    "            print(f\"Batch {batch_idx}, Loss: {batch_loss:.4f}, Acc: {accuracy:.2%}\", end='\\r')\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training components defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: PyTorch Profiler Basics\n",
    "\n",
    "PyTorch's built-in profiler is the easiest way to start profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Small dataset for quick profiling\n",
    "dataset = create_synthetic_data(n_samples=10000)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "print(f\"Dataset: {len(dataset)} samples\")\n",
    "print(f\"Batches per epoch: {len(dataloader)}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Profile the slow training function\nprint(\"üìä Profiling SLOW training loop...\")\nprint(\"=\"*60)\n\nif HAS_PROFILER:\n    with profile(\n        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n        record_shapes=True,\n        profile_memory=True,\n        with_stack=True\n    ) as prof:\n        # Run one epoch\n        loss = train_epoch_slow(model, dataloader, criterion, optimizer, device)\n\n    print(f\"\\n\\nEpoch complete. Average loss: {loss:.4f}\")\n\n    # Print profiling results\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä Top 20 Operations by CUDA Time\")\n    print(\"=\"*60)\n    print(prof.key_averages().table(\n        sort_by=\"cuda_time_total\", \n        row_limit=20\n    ))\nelse:\n    # Fallback: basic timing\n    print(\"(Using basic timing - install PyTorch >= 1.8 for full profiler)\")\n    start = time.perf_counter()\n    loss = train_epoch_slow(model, dataloader, criterion, optimizer, device)\n    torch.cuda.synchronize()\n    elapsed = time.perf_counter() - start\n    print(f\"\\n\\nEpoch complete. Average loss: {loss:.4f}\")\n    print(f\"Total time: {elapsed:.3f} seconds\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Also show CPU time\nif HAS_PROFILER:\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä Top 20 Operations by CPU Time\")\n    print(\"=\"*60)\n    print(prof.key_averages().table(\n        sort_by=\"cpu_time_total\", \n        row_limit=20\n    ))\nelse:\n    print(\"(Skipped - PyTorch Profiler not available)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Reading the Profiler Output\n",
    "\n",
    "**Key columns:**\n",
    "- **Name**: The operation (e.g., `aten::linear`, `aten::to`)\n",
    "- **Self CPU / Self CUDA**: Time spent in this operation only\n",
    "- **CPU / CUDA total**: Time including child operations\n",
    "- **# Calls**: How many times it was called\n",
    "\n",
    "**What to look for:**\n",
    "1. **`aten::to`**: Data transfers - should be minimized\n",
    "2. **`cudaStreamSynchronize`**: Blocking synchronizations\n",
    "3. **High call counts**: Potential for batching\n",
    "4. **CPU-heavy operations**: Move to GPU if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Using record_function for Custom Labels\n",
    "\n",
    "Add custom labels to understand what each part of your code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch_labeled(model, dataloader, criterion, optimizer, device):\n    \"\"\"\n    Training loop with labeled sections for better profiling.\n    \"\"\"\n    model.train()\n    total_loss = 0.0\n    \n    for batch_idx, (data, target) in enumerate(dataloader):\n        with record_function(\"DATA_TRANSFER\"):\n            data = data.to(device)\n            target = target.to(device)\n        \n        with record_function(\"FORWARD_PASS\"):\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n        \n        with record_function(\"SYNC_AND_LOG\"):\n            batch_loss = loss.item()\n            total_loss += batch_loss\n        \n        with record_function(\"BACKWARD_PASS\"):\n            loss.backward()\n        \n        with record_function(\"OPTIMIZER_STEP\"):\n            optimizer.step()\n    \n    return total_loss / len(dataloader)\n\n\n# Profile with labels\nprint(\"üìä Profiling with LABELED sections...\")\nprint(\"=\"*60)\n\nif HAS_PROFILER:\n    with profile(\n        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n        record_shapes=True,\n    ) as prof:\n        loss = train_epoch_labeled(model, dataloader, criterion, optimizer, device)\n\n    print(f\"\\nEpoch complete. Average loss: {loss:.4f}\")\n\n    # Show only our custom labels\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä Custom Section Timings\")\n    print(\"=\"*60)\n    print(prof.key_averages().table(\n        sort_by=\"cpu_time_total\", \n        row_limit=10\n    ))\nelse:\n    # Fallback\n    print(\"(Using basic timing - record_function labels require PyTorch Profiler)\")\n    start = time.perf_counter()\n    loss = train_epoch_labeled(model, dataloader, criterion, optimizer, device)\n    torch.cuda.synchronize()\n    elapsed = time.perf_counter() - start\n    print(f\"\\nEpoch complete. Average loss: {loss:.4f}\")\n    print(f\"Total time: {elapsed:.3f} seconds\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Identifying and Fixing Bottlenecks\n",
    "\n",
    "Now let's create an optimized version and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch_optimized(model, dataloader, criterion, optimizer, device):\n    \"\"\"\n    OPTIMIZED training loop.\n    \n    Fixes:\n    1. Use non_blocking transfers (async)\n    2. Avoid unnecessary .item() calls\n    3. Accumulate loss on GPU, sync only at end\n    \"\"\"\n    model.train()\n    total_loss = torch.tensor(0.0, device=device)  # Keep on GPU!\n    \n    for batch_idx, (data, target) in enumerate(dataloader):\n        # FIX 1: non_blocking=True allows async transfer\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n        \n        optimizer.zero_grad(set_to_none=True)  # Faster than zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        \n        # FIX 2: Accumulate on GPU, no sync!\n        total_loss += loss.detach()  # detach to avoid keeping graph\n        \n        loss.backward()\n        optimizer.step()\n    \n    # FIX 3: Only sync at the very end\n    return (total_loss / len(dataloader)).item()\n\n\n# Create optimized dataloader with pin_memory\ndataloader_optimized = DataLoader(\n    dataset, \n    batch_size=64, \n    shuffle=True, \n    num_workers=2,      # Parallel data loading\n    pin_memory=True,    # Faster CPU->GPU transfer\n    persistent_workers=True  # Keep workers alive\n)\n\nprint(\"üìä Profiling OPTIMIZED training loop...\")\nprint(\"=\"*60)\n\n# Warm up\n_ = train_epoch_optimized(model, dataloader_optimized, criterion, optimizer, device)\n\nif HAS_PROFILER:\n    with profile(\n        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n        record_shapes=True,\n    ) as prof_opt:\n        loss = train_epoch_optimized(model, dataloader_optimized, criterion, optimizer, device)\n\n    print(f\"\\nEpoch complete. Average loss: {loss:.4f}\")\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä Optimized - Top Operations\")\n    print(\"=\"*60)\n    print(prof_opt.key_averages().table(\n        sort_by=\"cuda_time_total\", \n        row_limit=15\n    ))\nelse:\n    start = time.perf_counter()\n    loss = train_epoch_optimized(model, dataloader_optimized, criterion, optimizer, device)\n    torch.cuda.synchronize()\n    elapsed = time.perf_counter() - start\n    print(f\"\\nEpoch complete. Average loss: {loss:.4f}\")\n    print(f\"Optimized time: {elapsed:.3f} seconds\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Slow vs Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark both versions\n",
    "print(\"‚è±Ô∏è  Benchmarking: Slow vs Optimized\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reset model\n",
    "model = SimpleNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Time slow version\n",
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "for _ in range(3):\n",
    "    _ = train_epoch_slow(model, dataloader, criterion, optimizer, device)\n",
    "torch.cuda.synchronize()\n",
    "time_slow = (time.perf_counter() - start) / 3\n",
    "\n",
    "# Reset model\n",
    "model = SimpleNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Time optimized version\n",
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "for _ in range(3):\n",
    "    _ = train_epoch_optimized(model, dataloader_optimized, criterion, optimizer, device)\n",
    "torch.cuda.synchronize()\n",
    "time_optimized = (time.perf_counter() - start) / 3\n",
    "\n",
    "print(f\"\\n\\nSlow version:      {time_slow:.3f} seconds/epoch\")\n",
    "print(f\"Optimized version: {time_optimized:.3f} seconds/epoch\")\n",
    "print(f\"\\nüöÄ Speedup: {time_slow/time_optimized:.2f}x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Memory Profiling\n",
    "\n",
    "Understanding memory usage is crucial for fitting large models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_memory():\n",
    "    \"\"\"Profile memory usage during training.\"\"\"\n",
    "    # Reset\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    # Create larger model for more interesting memory profile\n",
    "    model_large = nn.Sequential(\n",
    "        nn.Linear(784, 2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, 2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, 2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, 10)\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer_large = optim.Adam(model_large.parameters(), lr=0.001)\n",
    "    \n",
    "    # Large batch for memory pressure\n",
    "    dataset_large = create_synthetic_data(n_samples=10000)\n",
    "    dataloader_large = DataLoader(dataset_large, batch_size=512, shuffle=True)\n",
    "    \n",
    "    print(\"üìä Memory Usage During Training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Track memory at each stage\n",
    "    stages = []\n",
    "    \n",
    "    # After model creation\n",
    "    stages.append((\"After model creation\", torch.cuda.memory_allocated() / 1e6))\n",
    "    \n",
    "    # Get one batch\n",
    "    data, target = next(iter(dataloader_large))\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    stages.append((\"After data transfer\", torch.cuda.memory_allocated() / 1e6))\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model_large(data)\n",
    "    stages.append((\"After forward pass\", torch.cuda.memory_allocated() / 1e6))\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = nn.CrossEntropyLoss()(output, target)\n",
    "    stages.append((\"After loss computation\", torch.cuda.memory_allocated() / 1e6))\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    stages.append((\"After backward pass\", torch.cuda.memory_allocated() / 1e6))\n",
    "    \n",
    "    # Optimizer step\n",
    "    optimizer_large.step()\n",
    "    stages.append((\"After optimizer step\", torch.cuda.memory_allocated() / 1e6))\n",
    "    \n",
    "    # Clear gradients\n",
    "    optimizer_large.zero_grad(set_to_none=True)\n",
    "    stages.append((\"After zero_grad\", torch.cuda.memory_allocated() / 1e6))\n",
    "    \n",
    "    # Print\n",
    "    print(f\"\\n{'Stage':<30} {'Memory (MB)':<15} {'Delta (MB)':<15}\")\n",
    "    print(\"-\"*60)\n",
    "    prev = 0\n",
    "    for stage, mem in stages:\n",
    "        delta = mem - prev\n",
    "        print(f\"{stage:<30} {mem:<15.1f} {delta:>+14.1f}\")\n",
    "        prev = mem\n",
    "    \n",
    "    print(f\"\\nüìä Peak memory: {torch.cuda.max_memory_allocated() / 1e6:.1f} MB\")\n",
    "    print(f\"   Current memory: {torch.cuda.memory_allocated() / 1e6:.1f} MB\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model_large, optimizer_large, data, target, output, loss\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "profile_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Memory Profile Insights\n",
    "\n",
    "**Memory breakdown:**\n",
    "1. **Model parameters**: Constant overhead (weights and biases)\n",
    "2. **Activations**: Forward pass saves intermediate results for backward\n",
    "3. **Gradients**: Same size as parameters\n",
    "4. **Optimizer states**: Adam uses 2x parameters (momentum + variance)\n",
    "\n",
    "**Memory estimation formula:**\n",
    "```\n",
    "Training memory ‚âà Parameters √ó 16-20 bytes (mixed precision)\n",
    "                  or\n",
    "                  Parameters √ó 24-32 bytes (FP32)\n",
    "```\n",
    "\n",
    "> **üöÄ DGX Spark Advantage:** With 128GB of **unified memory**, the CPU and GPU share the same physical memory pool. This eliminates explicit memory copies for large tensors that exceed traditional GPU VRAM. The system handles page migration transparently, though explicit `.to(device)` calls are still recommended for optimal performance.\n",
    "\n",
    "For a 7B parameter model:\n",
    "- Parameters: 7B √ó 2 bytes (BF16) = 14 GB  ‚Üê Use BF16 on Blackwell for native Tensor Core support!\n",
    "- Gradients: 14 GB\n",
    "- Adam states: 28 GB\n",
    "- Activations: Variable (depends on batch size, sequence length)\n",
    "- **Total: 56+ GB** just for weights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Nsight Systems Command Line\n",
    "\n",
    "For deeper analysis, use NVIDIA's Nsight Systems from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standalone script for Nsight profiling\n",
    "nsight_script = '''\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"Script to profile with Nsight Systems.\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Same model as before\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda')\n",
    "    model = SimpleNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    # Synthetic data\n",
    "    X = torch.randn(10000, 784)\n",
    "    y = torch.randint(0, 10, (10000,))\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, \n",
    "                           num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # Train 3 epochs\n",
    "    for epoch in range(3):\n",
    "        model.train()\n",
    "        for data, target in dataloader:\n",
    "            data = data.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss = criterion(model(data), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} complete\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save the script\n",
    "script_path = '/tmp/nsight_demo.py'\n",
    "with open(script_path, 'w') as f:\n",
    "    f.write(nsight_script)\n",
    "\n",
    "print(f\"Script saved to: {script_path}\")\n",
    "print(\"\\nüìä Nsight Systems Usage\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"To profile this script, run from terminal:\")\n",
    "print()\n",
    "print(f\"  nsys profile -o training_report python {script_path}\")\n",
    "print()\n",
    "print(\"Useful nsys options:\")\n",
    "print(\"  --trace=cuda,nvtx,osrt       # What to trace\")\n",
    "print(\"  --cuda-memory-usage=true     # Track memory\")\n",
    "print(\"  --python-backtrace=cuda      # Python stack traces\")\n",
    "print(\"  --sample=cpu                 # CPU sampling\")\n",
    "print()\n",
    "print(\"View the report:\")\n",
    "print(\"  nsys-ui training_report.nsys-rep  # GUI viewer\")\n",
    "print(\"  nsys stats training_report.nsys-rep  # CLI stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Common Bottlenecks Checklist\n",
    "\n",
    "Use this checklist when profiling your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã GPU Performance Optimization Checklist\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checklist = [\n",
    "    (\"Data Loading\", [\n",
    "        \"‚úì Using num_workers > 0 in DataLoader?\",\n",
    "        \"‚úì Using pin_memory=True for CUDA?\",\n",
    "        \"‚úì Using persistent_workers=True?\",\n",
    "        \"‚úì Data preprocessing on GPU (CuPy) where possible?\",\n",
    "    ]),\n",
    "    (\"Data Transfer\", [\n",
    "        \"‚úì Using non_blocking=True for .to(device)?\",\n",
    "        \"‚úì Minimizing CPU‚ÜîGPU transfers?\",\n",
    "        \"‚úì Keeping tensors on GPU between operations?\",\n",
    "        \"‚úì Using DLPack for zero-copy framework interop?\",\n",
    "    ]),\n",
    "    (\"Synchronization\", [\n",
    "        \"‚úì Avoiding unnecessary .item() or .cpu() in training loop?\",\n",
    "        \"‚úì Accumulating metrics on GPU?\",\n",
    "        \"‚úì Only syncing for logging/checkpointing?\",\n",
    "        \"‚úì Using async operations where possible?\",\n",
    "    ]),\n",
    "    (\"Memory\", [\n",
    "        \"‚úì Using set_to_none=True in zero_grad()?\",\n",
    "        \"‚úì Using gradient checkpointing for large models?\",\n",
    "        \"‚úì Using mixed precision (AMP)?\",\n",
    "        \"‚úì Clearing cache between experiments?\",\n",
    "    ]),\n",
    "    (\"Compute\", [\n",
    "        \"‚úì Using torch.compile() for PyTorch 2.0+?\",\n",
    "        \"‚úì Batch size large enough for GPU utilization?\",\n",
    "        \"‚úì Using fused optimizers (e.g., FusedAdam)?\",\n",
    "        \"‚úì Enabling TensorFloat-32 on Ampere+?\",\n",
    "    ]),\n",
    "]\n",
    "\n",
    "for section, items in checklist:\n",
    "    print(f\"\\nüîπ {section}\")\n",
    "    for item in items:\n",
    "        print(f\"   {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Profiling in Debug Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° Always profile in release/production mode!\")\n",
    "print()\n",
    "print(\"   ‚ùå WRONG:\")\n",
    "print(\"      CUDA_LAUNCH_BLOCKING=1 python train.py  # Disables async!\")\n",
    "print(\"      torch.autograd.set_detect_anomaly(True)  # Huge slowdown!\")\n",
    "print()\n",
    "print(\"   ‚úÖ CORRECT:\")\n",
    "print(\"      python train.py  # Normal execution\")\n",
    "print(\"      # Or with profiling:\")\n",
    "print(\"      nsys profile python train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Not Warming Up Before Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° GPU kernels need warm-up!\")\n",
    "print()\n",
    "print(\"   First kernel launch: compilation + memory allocation\")\n",
    "print(\"   Subsequent launches: cached and faster\")\n",
    "print()\n",
    "print(\"   ‚úÖ Always do 1-3 warm-up iterations before timing!\")\n",
    "print()\n",
    "print(\"   Example:\")\n",
    "print(\"   # Warm up\")\n",
    "print(\"   for _ in range(3):\")\n",
    "print(\"       _ = model(dummy_input)\")\n",
    "print(\"   torch.cuda.synchronize()\")\n",
    "print(\"   \")\n",
    "print(\"   # Now benchmark\")\n",
    "print(\"   start = time.time()\")\n",
    "print(\"   ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 3: Measuring Only One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° Always measure multiple runs and report statistics!\")\n",
    "print()\n",
    "print(\"   ‚ùå WRONG: 'It took 5.2 seconds'\")\n",
    "print()\n",
    "print(\"   ‚úÖ CORRECT: 'Mean: 5.2s ¬± 0.3s (n=10)'\")\n",
    "print()\n",
    "print(\"   Example:\")\n",
    "print(\"   times = []\")\n",
    "print(\"   for _ in range(10):\")\n",
    "print(\"       start = time.perf_counter()\")\n",
    "print(\"       # ... operation ...\")\n",
    "print(\"       torch.cuda.synchronize()\")\n",
    "print(\"       times.append(time.perf_counter() - start)\")\n",
    "print(\"   print(f'Mean: {np.mean(times):.2f}s ¬± {np.std(times):.2f}s')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Profile Your Own Code\n",
    "\n",
    "**Challenge:** Create and profile a CNN training loop.\n",
    "\n",
    "1. Create a simple CNN for image classification\n",
    "2. Profile it using PyTorch Profiler\n",
    "3. Identify the top 3 bottlenecks\n",
    "4. Apply optimizations and measure improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and profile a CNN\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: Define CNN layers\n",
    "        # Hint: Use Conv2d, MaxPool2d, Linear\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass\n",
    "\n",
    "\n",
    "# Create synthetic image data\n",
    "# Images: (batch, channels=3, height=32, width=32)\n",
    "# Labels: (batch,) integers 0-9\n",
    "\n",
    "# TODO: Create DataLoader with and without optimizations\n",
    "\n",
    "# TODO: Profile and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "- ‚úÖ **PyTorch Profiler** - Easy Python-native profiling\n",
    "- ‚úÖ **Custom labels** - `record_function` for clarity\n",
    "- ‚úÖ **Memory profiling** - Track GPU memory usage\n",
    "- ‚úÖ **Common bottlenecks** - Data loading, sync, transfers\n",
    "- ‚úÖ **Nsight Systems** - Command-line deep profiling\n",
    "- ‚úÖ **Optimization checklist** - Systematic approach\n",
    "\n",
    "You can now identify and fix performance bottlenecks in GPU code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [PyTorch Profiler Documentation](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)\n",
    "- [Nsight Systems Documentation](https://docs.nvidia.com/nsight-systems/)\n",
    "- [Nsight Compute Documentation](https://docs.nvidia.com/nsight-compute/)\n",
    "- [NVIDIA Deep Learning Performance Guide](https://docs.nvidia.com/deeplearning/performance/index.html)\n",
    "- [PyTorch Performance Tuning Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Clean up\n",
    "del model, dataloader, dataset\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"‚úÖ GPU memory cleared!\")\n",
    "print(\"\\nüéì Module 1.3: CUDA Python & GPU Programming - COMPLETE!\")\n",
    "print(\"\\n‚û°Ô∏è Next: Module 1.4: Mathematics for Deep Learning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}