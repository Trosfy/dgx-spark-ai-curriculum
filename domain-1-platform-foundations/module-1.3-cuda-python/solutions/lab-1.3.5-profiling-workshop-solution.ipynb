{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 1.3.5: Profiling Workshop - SOLUTIONS\n\nThis notebook contains complete solutions to the exercises in Lab 1.3.5.\n\n---\n\n## üéØ Learning Objectives Checklist\n\nBy completing this lab, you should now be able to:\n- [x] Profile GPU code using PyTorch Profiler\n- [x] Understand Nsight Systems timeline analysis\n- [x] Identify common bottlenecks (data loading, CPU‚ÜîGPU sync)\n- [x] Apply optimizations based on profiling results\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: CNN Training Loop with Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    SOLUTION: Simple CNN for image classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Conv block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # 32 -> 16\n",
    "            \n",
    "            # Conv block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # 16 -> 8\n",
    "            \n",
    "            # Conv block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # 8 -> 4\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Test model\n",
    "model = SimpleCNN().to(device)\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "output = model(dummy_input)\n",
    "print(f\"Model output shape: {output.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic CIFAR-like data\n",
    "def create_synthetic_image_data(n_samples: int = 10000, \n",
    "                                 img_size: int = 32, \n",
    "                                 n_classes: int = 10):\n",
    "    \"\"\"Create synthetic image classification data.\"\"\"\n",
    "    X = torch.randn(n_samples, 3, img_size, img_size)\n",
    "    y = torch.randint(0, n_classes, (n_samples,))\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_synthetic_image_data(n_samples=10000)\n",
    "print(f\"Dataset: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_slow(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Slow training loop with bottlenecks.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for data, target in dataloader:\n",
    "        # Bottleneck: blocking transfer\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Bottleneck: sync with .item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def train_epoch_optimized(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    SOLUTION: Optimized training loop.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    for data, target in dataloader:\n",
    "        # Fix 1: non_blocking transfer\n",
    "        data = data.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "        \n",
    "        # Fix 2: set_to_none is faster\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Fix 3: accumulate on GPU\n",
    "        total_loss += loss.detach()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return (total_loss / len(dataloader)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile slow version\n",
    "print(\"üìä Profiling SLOW training loop\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Slow dataloader (no optimizations)\n",
    "dataloader_slow = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "    _ = train_epoch_slow(model, dataloader_slow, criterion, optimizer, device)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile optimized version\n",
    "print(\"\\nüìä Profiling OPTIMIZED training loop\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Optimized dataloader\n",
    "dataloader_fast = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True, \n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Warm up\n",
    "_ = train_epoch_optimized(model, dataloader_fast, criterion, optimizer, device)\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    ") as prof_opt:\n",
    "    _ = train_epoch_optimized(model, dataloader_fast, criterion, optimizer, device)\n",
    "\n",
    "print(prof_opt.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark comparison\n",
    "print(\"\\n‚è±Ô∏è Benchmark: Slow vs Optimized\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Slow\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "for _ in range(3):\n",
    "    _ = train_epoch_slow(model, dataloader_slow, criterion, optimizer, device)\n",
    "torch.cuda.synchronize()\n",
    "time_slow = (time.perf_counter() - start) / 3\n",
    "\n",
    "# Optimized\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Warm up\n",
    "_ = train_epoch_optimized(model, dataloader_fast, criterion, optimizer, device)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.perf_counter()\n",
    "for _ in range(3):\n",
    "    _ = train_epoch_optimized(model, dataloader_fast, criterion, optimizer, device)\n",
    "torch.cuda.synchronize()\n",
    "time_optimized = (time.perf_counter() - start) / 3\n",
    "\n",
    "print(f\"Slow version:      {time_slow:.3f} seconds/epoch\")\n",
    "print(f\"Optimized version: {time_optimized:.3f} seconds/epoch\")\n",
    "print(f\"\\nüöÄ Speedup: {time_slow/time_optimized:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Optimizations Applied:\n",
    "\n",
    "1. **DataLoader optimizations:**\n",
    "   - `num_workers=2`: Parallel data loading\n",
    "   - `pin_memory=True`: Faster CPU‚ÜíGPU transfers\n",
    "   - `persistent_workers=True`: Don't restart workers each epoch\n",
    "\n",
    "2. **Transfer optimizations:**\n",
    "   - `non_blocking=True`: Async data transfer\n",
    "\n",
    "3. **Training loop optimizations:**\n",
    "   - `zero_grad(set_to_none=True)`: Faster than setting to zero\n",
    "   - Accumulate loss on GPU: Avoid `.item()` sync\n",
    "\n",
    "4. **Memory optimizations:**\n",
    "   - `loss.detach()`: Don't keep computation graph for loss accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model, optimizer, dataset, dataloader_slow, dataloader_fast\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"‚úÖ Cleanup complete\")\n",
    "print(\"\\nüéì Module 1.3: CUDA Python & GPU Programming - COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}