{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lab 1.7.1: Core Tensor Implementation\n",
    "\n",
    "**Module:** 1.7 - Domain 1 Capstone: MicroGrad+  \n",
    "**Time:** 3 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand how automatic differentiation works under the hood\n",
    "- [ ] Build a Tensor class that tracks operations for backpropagation\n",
    "- [ ] Implement the backward pass using reverse-mode autodiff\n",
    "- [ ] Verify your gradients against numerical approximations\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Modules 1.1-1.6 (Python, CUDA, Math, Neural Network Fundamentals)\n",
    "- Knowledge of: Calculus (chain rule), Python classes, NumPy\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "Every deep learning framework (PyTorch, TensorFlow, JAX) has an automatic differentiation engine at its core. When you call `loss.backward()` in PyTorch, it's using the same principles we'll implement here!\n",
    "\n",
    "Understanding autograd helps you:\n",
    "- Debug gradient issues in training\n",
    "- Write custom layers correctly\n",
    "- Understand why certain operations break gradient flow\n",
    "- Appreciate the engineering behind modern ML frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: Automatic Differentiation\n",
    "\n",
    "> **Imagine you're baking a cake** with multiple ingredients and steps.\n",
    ">\n",
    "> If the cake tastes terrible, you want to know: \"Was it too much salt? Not enough sugar? Overcooked?\"\n",
    ">\n",
    "> **Automatic differentiation is like a magical recipe tracker:**\n",
    "> 1. As you cook, it writes down every step: \"Added 2 cups flour, mixed for 3 minutes, baked at 350¬∞F\"\n",
    "> 2. When the cake is done, it can trace back: \"The burnt taste came from the oven being too hot\"\n",
    "> 3. It tells you exactly how much to change each setting to improve the result!\n",
    ">\n",
    "> **In AI terms:**\n",
    "> - The \"cake\" is your model's prediction\n",
    "> - The \"ingredients\" are your model parameters (weights)\n",
    "> - The \"burnt taste\" is the loss (error)\n",
    "> - The \"how much to change\" is the gradient\n",
    ">\n",
    "> Autograd builds a computation graph as you calculate, then walks backward through it to find gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding the Computation Graph\n",
    "\n",
    "### Concept Explanation\n",
    "\n",
    "When we compute something like `c = a * b + a`, we're implicitly building a **computation graph**:\n",
    "\n",
    "```\n",
    "    a ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ> [*] ‚îÄ‚îÄ‚îÄ> temp ‚îÄ‚îÄ‚îÄ> [+] ‚îÄ‚îÄ‚îÄ> c\n",
    "          ‚îÇ              ^\n",
    "    b ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ\n",
    "    a ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "Each operation creates a new node that knows:\n",
    "1. Its parents (inputs)\n",
    "2. What operation was performed\n",
    "3. How to compute its gradient contribution (the \"local gradient\")\n",
    "\n",
    "### The Chain Rule\n",
    "\n",
    "If `c` depends on `a` through multiple paths, we use the **chain rule**:\n",
    "\n",
    "$$\\frac{\\partial c}{\\partial a} = \\frac{\\partial c}{\\partial \\text{temp}} \\cdot \\frac{\\partial \\text{temp}}{\\partial a} + \\frac{\\partial c}{\\partial a}|_{\\text{direct}}$$\n",
    "\n",
    "For `c = a * b + a`:\n",
    "- Path 1: `a ‚Üí temp ‚Üí c` contributes `b` (since ‚àÇ(a*b)/‚àÇa = b)\n",
    "- Path 2: `a ‚Üí c` contributes `1` (since ‚àÇ(+a)/‚àÇa = 1)\n",
    "- Total: `dc/da = b + 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a minimal example to see the computation graph\n",
    "import numpy as np\n",
    "\n",
    "# Manual computation graph for: c = a * b + a\n",
    "a = 2.0\n",
    "b = 3.0\n",
    "\n",
    "# Forward pass (build the graph)\n",
    "temp = a * b  # temp = 6.0\n",
    "c = temp + a  # c = 8.0\n",
    "\n",
    "# Backward pass (compute gradients)\n",
    "# Starting with dc/dc = 1\n",
    "dc_dc = 1.0\n",
    "\n",
    "# Gradient through addition: c = temp + a\n",
    "dc_dtemp = dc_dc * 1.0  # ‚àÇ(temp + a)/‚àÇtemp = 1\n",
    "dc_da_path2 = dc_dc * 1.0  # ‚àÇ(temp + a)/‚àÇa = 1\n",
    "\n",
    "# Gradient through multiplication: temp = a * b\n",
    "dc_da_path1 = dc_dtemp * b  # ‚àÇ(a * b)/‚àÇa = b\n",
    "dc_db = dc_dtemp * a  # ‚àÇ(a * b)/‚àÇb = a\n",
    "\n",
    "# Total gradients (sum of all paths)\n",
    "dc_da_total = dc_da_path1 + dc_da_path2\n",
    "\n",
    "print(f\"c = {c}\")\n",
    "print(f\"dc/da = {dc_da_total} (expected: b + 1 = {b + 1})\")\n",
    "print(f\"dc/db = {dc_db} (expected: a = {a})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### üîç What Just Happened?\n",
    "\n",
    "We manually traced through the computation graph backward:\n",
    "1. Start at the output `c` with gradient 1\n",
    "2. For each operation, distribute the gradient to inputs using local derivatives\n",
    "3. Sum gradients that arrive at the same variable through different paths\n",
    "\n",
    "Now let's automate this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building the Value Class (Simplified Tensor)\n",
    "\n",
    "We'll start with a simplified `Value` class for scalars before moving to full tensors.\n",
    "\n",
    "### Key Components:\n",
    "1. **data**: The actual numerical value\n",
    "2. **grad**: The gradient (starts at 0)\n",
    "3. **_backward**: A function to compute gradient contributions\n",
    "4. **_prev**: Set of parent nodes (for graph traversal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \"\"\"\n",
    "    A simple scalar value with automatic differentiation support.\n",
    "    This is the educational version before we build full Tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, _children=(), _op=''):\n",
    "        self.data = float(data)\n",
    "        self.grad = 0.0  # Gradient starts at 0\n",
    "        self._backward = lambda: None  # Default: no gradient computation\n",
    "        self._prev = set(_children)  # Parent nodes\n",
    "        self._op = _op  # Operation that created this node (for debugging)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data:.4f}, grad={self.grad:.4f})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        \"\"\"Addition: self + other\"\"\"\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "        \n",
    "        def _backward():\n",
    "            # Gradient of addition: passes gradient unchanged to both inputs\n",
    "            self.grad += out.grad  # d(a+b)/da = 1\n",
    "            other.grad += out.grad  # d(a+b)/db = 1\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"Multiplication: self * other\"\"\"\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "        \n",
    "        def _backward():\n",
    "            # Gradient of multiplication: swap and multiply by out gradient\n",
    "            self.grad += other.data * out.grad  # d(a*b)/da = b\n",
    "            other.grad += self.data * out.grad  # d(a*b)/db = a\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, other):  # Handle: number + Value\n",
    "        return self + other\n",
    "    \n",
    "    def __rmul__(self, other):  # Handle: number * Value\n",
    "        return self * other\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"Compute gradients via reverse-mode autodiff (backpropagation)\"\"\"\n",
    "        # Build topological order (children before parents)\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        \n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        \n",
    "        build_topo(self)\n",
    "        \n",
    "        # Start with gradient of 1 at the output\n",
    "        self.grad = 1.0\n",
    "        \n",
    "        # Walk backward through the graph\n",
    "        for v in reversed(topo):\n",
    "            v._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our Value class\n",
    "a = Value(2.0)\n",
    "b = Value(3.0)\n",
    "c = a * b + a\n",
    "\n",
    "print(f\"Before backward:\")\n",
    "print(f\"  a = {a}\")\n",
    "print(f\"  b = {b}\")\n",
    "print(f\"  c = {c}\")\n",
    "\n",
    "c.backward()\n",
    "\n",
    "print(f\"\\nAfter backward:\")\n",
    "print(f\"  a = {a} (expected grad: {b.data + 1})\")\n",
    "print(f\"  b = {b} (expected grad: {a.data})\")\n",
    "print(f\"  c = {c} (expected grad: 1.0)\")\n",
    "\n",
    "# Verify\n",
    "assert abs(a.grad - 4.0) < 1e-6, f\"a.grad should be 4.0, got {a.grad}\"\n",
    "assert abs(b.grad - 2.0) < 1e-6, f\"b.grad should be 2.0, got {b.grad}\"\n",
    "print(\"\\n Gradients are correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Try It Yourself: Exercise 1\n",
    "\n",
    "Add more operations to the Value class:\n",
    "1. `__sub__` (subtraction)\n",
    "2. `__neg__` (negation: -self)\n",
    "3. `__pow__` (power: self ** n where n is a number)\n",
    "\n",
    "<details>\n",
    "<summary>Hint for subtraction</summary>\n",
    "\n",
    "Subtraction is just addition with negation: `a - b = a + (-b)`\n",
    "Or you can implement it directly with gradient `-1` for the subtracted term.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint for power</summary>\n",
    "\n",
    "The derivative of `x^n` is `n * x^(n-1)`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Extend the Value class with more operations\n",
    "class ValueExtended(Value):\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Negation: -self\"\"\"\n",
    "        # TODO: Implement this\n",
    "        pass\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        \"\"\"Subtraction: self - other\"\"\"\n",
    "        # TODO: Implement this\n",
    "        pass\n",
    "    \n",
    "    def __pow__(self, n):\n",
    "        \"\"\"Power: self ** n (n must be int or float)\"\"\"\n",
    "        # TODO: Implement this\n",
    "        pass\n",
    "\n",
    "# Test your implementation\n",
    "# x = ValueExtended(3.0)\n",
    "# y = x ** 2 - x\n",
    "# y.backward()\n",
    "# print(f\"x = {x}\")  # Should have grad = 2*3 - 1 = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: From Values to Tensors\n",
    "\n",
    "Now let's extend our scalar `Value` to handle multi-dimensional arrays. This is where things get interesting!\n",
    "\n",
    "### Key Challenges:\n",
    "1. **Broadcasting**: `[1, 2, 3] + 5` should add 5 to each element\n",
    "2. **Shape management**: Matrix multiplication has specific dimension requirements\n",
    "3. **Gradient accumulation**: When a tensor is used multiple times, gradients accumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at the full Tensor implementation\n",
    "# We've already built this - let's import and explore it\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Robust path resolution - works regardless of working directory\n",
    "def _find_module_root():\n",
    "    \"\"\"Find the module root directory containing micrograd_plus.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / 'micrograd_plus' / '__init__.py').exists():\n",
    "            return str(parent)\n",
    "    return str(Path.cwd().parent)\n",
    "\n",
    "sys.path.insert(0, _find_module_root())\n",
    "\n",
    "from micrograd_plus import Tensor\n",
    "\n",
    "# Basic operations\n",
    "a = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "b = Tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
    "\n",
    "# Element-wise operations\n",
    "c = a + b\n",
    "print(f\"a + b = {c}\")\n",
    "\n",
    "d = a * b\n",
    "print(f\"a * b = {d}\")\n",
    "\n",
    "# Reduction operations\n",
    "e = (a * b).sum()\n",
    "print(f\"sum(a * b) = {e}\")\n",
    "\n",
    "# Backward pass\n",
    "e.backward()\n",
    "print(f\"\\na.grad = {a.grad}\")  # Should be b.data = [4, 5, 6]\n",
    "print(f\"b.grad = {b.grad}\")  # Should be a.data = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### Understanding Tensor Gradients\n",
    "\n",
    "For `e = sum(a * b)`:\n",
    "\n",
    "$$e = \\sum_i a_i \\cdot b_i$$\n",
    "\n",
    "$$\\frac{\\partial e}{\\partial a_i} = b_i$$\n",
    "\n",
    "$$\\frac{\\partial e}{\\partial b_i} = a_i$$\n",
    "\n",
    "This is exactly what we see in the gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations\n",
    "# Reset gradients\n",
    "a.zero_grad()\n",
    "b.zero_grad()\n",
    "\n",
    "# Create matrices\n",
    "W = Tensor([[1, 2], [3, 4], [5, 6]], requires_grad=True)  # Shape: (3, 2)\n",
    "x = Tensor([[1], [2]], requires_grad=True)  # Shape: (2, 1)\n",
    "\n",
    "print(f\"W.shape = {W.shape}\")\n",
    "print(f\"x.shape = {x.shape}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "y = W @ x\n",
    "print(f\"\\nW @ x = {y}\")  # Shape: (3, 1)\n",
    "print(f\"y.shape = {y.shape}\")\n",
    "\n",
    "# Sum to scalar for backward\n",
    "loss = y.sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"\\nW.grad =\\n{W.grad}\")\n",
    "print(f\"x.grad =\\n{x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### Understanding Matrix Gradient\n",
    "\n",
    "For `y = W @ x` where `y` is summed to a scalar:\n",
    "\n",
    "- `W.grad` should be `ones @ x.T` = `[[1], [1], [1]] @ [[1, 2]]` = `[[1, 2], [1, 2], [1, 2]]`\n",
    "- `x.grad` should be `W.T @ ones` = transposed weights summed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Implementing Key Operations\n",
    "\n",
    "Let's walk through how some key operations are implemented with their gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's trace through how multiplication works in our Tensor class\n",
    "\n",
    "def explain_mul_gradient():\n",
    "    \"\"\"\n",
    "    When we compute c = a * b:\n",
    "    \n",
    "    Forward: c = a * b (element-wise)\n",
    "    \n",
    "    Backward: \n",
    "        dc/da = b  (derivative of a*b w.r.t. a is b)\n",
    "        dc/db = a  (derivative of a*b w.r.t. b is a)\n",
    "        \n",
    "    But we receive dL/dc from upstream (out.grad), so by chain rule:\n",
    "        dL/da = dL/dc * dc/da = out.grad * b\n",
    "        dL/db = dL/dc * dc/db = out.grad * a\n",
    "    \"\"\"\n",
    "    a = Tensor([2.0, 3.0], requires_grad=True)\n",
    "    b = Tensor([4.0, 5.0], requires_grad=True)\n",
    "    \n",
    "    c = a * b  # [8, 15]\n",
    "    loss = c.sum()  # 23\n",
    "    \n",
    "    print(\"Forward pass:\")\n",
    "    print(f\"  a = {a.data}\")\n",
    "    print(f\"  b = {b.data}\")\n",
    "    print(f\"  c = a * b = {c.data}\")\n",
    "    print(f\"  loss = sum(c) = {loss.data}\")\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    print(\"\\nBackward pass:\")\n",
    "    print(f\"  loss.grad = 1 (always starts at 1)\")\n",
    "    print(f\"  c.grad = {c.grad} (gradient from sum is 1s)\")\n",
    "    print(f\"  a.grad = {a.grad} = b.data * c.grad\")\n",
    "    print(f\"  b.grad = {b.grad} = a.data * c.grad\")\n",
    "\n",
    "explain_mul_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a more complex example: a simple neural network layer\n",
    "\n",
    "def explain_linear_layer():\n",
    "    \"\"\"\n",
    "    A linear layer computes: y = x @ W + b\n",
    "    \n",
    "    Shapes:\n",
    "    - x: (batch_size, in_features) e.g., (2, 3)\n",
    "    - W: (in_features, out_features) e.g., (3, 2)\n",
    "    - b: (out_features,) e.g., (2,)\n",
    "    - y: (batch_size, out_features) e.g., (2, 2)\n",
    "    \n",
    "    Gradients:\n",
    "    - dL/dW = x.T @ dL/dy\n",
    "    - dL/db = sum(dL/dy, axis=0)\n",
    "    - dL/dx = dL/dy @ W.T\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Input: batch of 2 samples, 3 features each\n",
    "    x = Tensor(np.random.randn(2, 3), requires_grad=True)\n",
    "    \n",
    "    # Weights and bias\n",
    "    W = Tensor(np.random.randn(3, 2), requires_grad=True)\n",
    "    b = Tensor(np.random.randn(2), requires_grad=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    y = x @ W + b\n",
    "    loss = y.sum()  # Simple loss for demonstration\n",
    "    \n",
    "    print(\"Shapes:\")\n",
    "    print(f\"  x: {x.shape}\")\n",
    "    print(f\"  W: {W.shape}\")\n",
    "    print(f\"  b: {b.shape}\")\n",
    "    print(f\"  y: {y.shape}\")\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    print(\"\\nGradient shapes:\")\n",
    "    print(f\"  x.grad: {x.grad.shape}\")\n",
    "    print(f\"  W.grad: {W.grad.shape}\")\n",
    "    print(f\"  b.grad: {b.grad.shape}\")\n",
    "    \n",
    "    # Verify gradient formula for W: dL/dW = x.T @ dL/dy\n",
    "    # Since loss = sum(y), dL/dy = ones\n",
    "    expected_W_grad = x.data.T @ np.ones((2, 2))\n",
    "    print(f\"\\nW.grad verification:\")\n",
    "    print(f\"  Computed: {W.grad}\")\n",
    "    print(f\"  Expected (x.T @ ones): {expected_W_grad}\")\n",
    "    print(f\"  Match: {np.allclose(W.grad, expected_W_grad)}\")\n",
    "\n",
    "explain_linear_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Handling Broadcasting\n",
    "\n",
    "One of the trickiest parts of tensor autograd is handling **broadcasting**. When shapes don't match exactly, NumPy broadcasts smaller tensors to match larger ones.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "```python\n",
    "a = Tensor([[1, 2, 3],    # Shape: (2, 3)\n",
    "            [4, 5, 6]])\n",
    "b = Tensor([10, 20, 30])  # Shape: (3,)\n",
    "c = a + b                  # Shape: (2, 3) - b is broadcast!\n",
    "```\n",
    "\n",
    "When we compute gradients, `c.grad` has shape `(2, 3)`, but `b.grad` should have shape `(3,)`. We need to **sum over the broadcast dimensions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting example\n",
    "a = Tensor([[1, 2, 3], [4, 5, 6]], requires_grad=True)  # (2, 3)\n",
    "b = Tensor([10, 20, 30], requires_grad=True)  # (3,) - will broadcast to (2, 3)\n",
    "\n",
    "print(f\"a.shape = {a.shape}\")\n",
    "print(f\"b.shape = {b.shape}\")\n",
    "\n",
    "c = a + b\n",
    "print(f\"\\nc = a + b:\")\n",
    "print(f\"c.shape = {c.shape}\")\n",
    "print(f\"c = {c.data}\")\n",
    "\n",
    "loss = c.sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"\\nGradients:\")\n",
    "print(f\"a.grad = {a.grad} (shape: {a.grad.shape})\")\n",
    "print(f\"b.grad = {b.grad} (shape: {b.grad.shape})\")\n",
    "\n",
    "# Notice: b.grad is the sum of gradients over the broadcast dimension\n",
    "# Each row of a received the same b, so b's gradient is the sum of all rows' gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### üîç Why Sum Over Broadcast Dimensions?\n",
    "\n",
    "When `b` is broadcast to match `a`, it's conceptually like:\n",
    "```\n",
    "b_broadcast = [[10, 20, 30],\n",
    "               [10, 20, 30]]  # Same b repeated for each row\n",
    "```\n",
    "\n",
    "Since the same `b[i]` affects multiple outputs, its gradient is the **sum** of all those contributions. This is just the chain rule!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Numerical Gradient Verification\n",
    "\n",
    "How do we know our gradients are correct? We compare them to **numerical gradients** computed using finite differences.\n",
    "\n",
    "### The Idea\n",
    "\n",
    "The derivative is defined as:\n",
    "$$f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x - h)}{2h}$$\n",
    "\n",
    "We can approximate this with a small `h` (typically `1e-5`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd_plus.utils import numerical_gradient, gradient_check\n",
    "\n",
    "def test_gradient(name, f, x):\n",
    "    \"\"\"\n",
    "    Test that analytical gradient matches numerical gradient.\n",
    "    \"\"\"\n",
    "    # Compute analytical gradient\n",
    "    x.zero_grad()\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    analytical = x.grad.copy()\n",
    "    \n",
    "    # Compute numerical gradient\n",
    "    def numpy_f(arr):\n",
    "        return f(Tensor(arr)).data.item()\n",
    "    numerical = numerical_gradient(numpy_f, x.data.copy())\n",
    "    \n",
    "    # Compare\n",
    "    max_error = np.max(np.abs(analytical - numerical))\n",
    "    passed = np.allclose(analytical, numerical, atol=1e-4)\n",
    "    \n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    print(f\"[{status}] {name}: max_error = {max_error:.2e}\")\n",
    "    if not passed:\n",
    "        print(f\"   Analytical: {analytical}\")\n",
    "        print(f\"   Numerical: {numerical}\")\n",
    "    \n",
    "    return passed\n",
    "\n",
    "# Test various operations\n",
    "print(\"Gradient verification:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "x = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "test_gradient(\"sum(x)\", lambda t: t.sum(), Tensor([1.0, 2.0, 3.0], requires_grad=True))\n",
    "test_gradient(\"sum(x^2)\", lambda t: (t ** 2).sum(), Tensor([1.0, 2.0, 3.0], requires_grad=True))\n",
    "test_gradient(\"sum(x * y)\", lambda t: (t * Tensor([4.0, 5.0, 6.0])).sum(), Tensor([1.0, 2.0, 3.0], requires_grad=True))\n",
    "test_gradient(\"mean(x)\", lambda t: t.mean(), Tensor([1.0, 2.0, 3.0], requires_grad=True))\n",
    "test_gradient(\"sum(relu(x))\", lambda t: t.relu().sum(), Tensor([-1.0, 0.0, 1.0], requires_grad=True))\n",
    "test_gradient(\"sum(sigmoid(x))\", lambda t: t.sigmoid().sum(), Tensor([-1.0, 0.0, 1.0], requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test matrix multiplication gradient\n",
    "np.random.seed(42)\n",
    "\n",
    "def test_matmul_gradient():\n",
    "    A = Tensor(np.random.randn(3, 4), requires_grad=True)\n",
    "    B = Tensor(np.random.randn(4, 2), requires_grad=True)\n",
    "    \n",
    "    # Forward\n",
    "    C = A @ B\n",
    "    loss = C.sum()\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    \n",
    "    # Numerical gradient for A\n",
    "    def f_A(arr):\n",
    "        return (Tensor(arr) @ B).sum().data.item()\n",
    "    numerical_A = numerical_gradient(f_A, A.data.copy())\n",
    "    \n",
    "    # Numerical gradient for B\n",
    "    def f_B(arr):\n",
    "        return (A @ Tensor(arr)).sum().data.item()\n",
    "    numerical_B = numerical_gradient(f_B, B.data.copy())\n",
    "    \n",
    "    print(\"Matrix multiplication gradient check:\")\n",
    "    print(f\"  A.grad matches numerical: {np.allclose(A.grad, numerical_A, atol=1e-4)}\")\n",
    "    print(f\"  B.grad matches numerical: {np.allclose(B.grad, numerical_B, atol=1e-4)}\")\n",
    "\n",
    "test_matmul_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Forgetting to Zero Gradients\n",
    "\n",
    "```python\n",
    "# Wrong: gradients accumulate!\n",
    "for i in range(3):\n",
    "    y = (x ** 2).sum()\n",
    "    y.backward()\n",
    "    print(x.grad)  # Keeps growing!\n",
    "\n",
    "# Right: zero gradients before each backward\n",
    "for i in range(3):\n",
    "    x.zero_grad()\n",
    "    y = (x ** 2).sum()\n",
    "    y.backward()\n",
    "    print(x.grad)  # Same each time\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the gradient accumulation problem\n",
    "x = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "print(\"Without zeroing gradients (wrong!):\")\n",
    "for i in range(3):\n",
    "    y = (x ** 2).sum()\n",
    "    y.backward()\n",
    "    print(f\"  Iteration {i+1}: x.grad = {x.grad}\")\n",
    "\n",
    "print(\"\\nWith zeroing gradients (correct):\")\n",
    "for i in range(3):\n",
    "    x.zero_grad()\n",
    "    y = (x ** 2).sum()\n",
    "    y.backward()\n",
    "    print(f\"  Iteration {i+1}: x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### Mistake 2: Calling backward() on Non-Scalar\n",
    "\n",
    "```python\n",
    "# Wrong: backward needs a scalar\n",
    "x = Tensor([1, 2, 3], requires_grad=True)\n",
    "y = x ** 2  # y is a vector!\n",
    "y.backward()  # Error!\n",
    "\n",
    "# Right: reduce to scalar first\n",
    "y = x ** 2\n",
    "loss = y.sum()  # Now it's a scalar\n",
    "loss.backward()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the non-scalar backward error\n",
    "x = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2  # Vector output\n",
    "\n",
    "try:\n",
    "    y.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Fix: reduce to scalar\n",
    "x.zero_grad()\n",
    "y = x ** 2\n",
    "loss = y.sum()\n",
    "loss.backward()\n",
    "print(f\"\\nAfter summing to scalar:\")\n",
    "print(f\"   x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### Mistake 3: Modifying Tensor Data In-Place\n",
    "\n",
    "```python\n",
    "# Wrong: breaks the computation graph\n",
    "x = Tensor([1, 2, 3], requires_grad=True)\n",
    "x.data = x.data * 2  # In-place modification!\n",
    "y = x.sum()\n",
    "y.backward()  # Gradients will be wrong!\n",
    "\n",
    "# Right: create new tensor\n",
    "x = Tensor([1, 2, 3], requires_grad=True)\n",
    "x2 = x * 2  # New tensor, graph is intact\n",
    "y = x2.sum()\n",
    "y.backward()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- How computation graphs track operations for backpropagation\n",
    "- How to implement basic autograd for scalars (Value class)\n",
    "- How to extend autograd to tensors with broadcasting\n",
    "- How to verify gradients using numerical approximation\n",
    "- Common pitfalls and how to avoid them\n",
    "\n",
    "---\n",
    "\n",
    "## Challenge (Optional)\n",
    "\n",
    "Implement these additional operations in a custom Tensor class:\n",
    "\n",
    "1. **Division**: `__truediv__` with proper gradient\n",
    "2. **Exponential**: `exp()` where gradient is `exp(x) * upstream_grad`\n",
    "3. **Log**: `log()` where gradient is `1/x * upstream_grad`\n",
    "4. **Softmax**: A more complex operation that normalizes across an axis\n",
    "\n",
    "For softmax, the gradient is tricky:\n",
    "$$\\frac{\\partial \\text{softmax}(x)_i}{\\partial x_j} = s_i(\\delta_{ij} - s_j)$$\n",
    "\n",
    "Where $s = \\text{softmax}(x)$ and $\\delta_{ij}$ is 1 if $i=j$, else 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Karpathy's micrograd](https://github.com/karpathy/micrograd) - The inspiration for this module\n",
    "- [Karpathy's micrograd video](https://www.youtube.com/watch?v=VMj-3S1tku0) - 2.5 hour deep dive\n",
    "- [PyTorch Autograd Mechanics](https://pytorch.org/docs/stable/notes/autograd.html) - How the pros do it\n",
    "- [Backpropagation in Matrix Form](https://explained.ai/matrix-calculus/) - The math behind matrix gradients\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup - release memory\n",
    "from micrograd_plus.utils import cleanup_notebook\n",
    "cleanup_notebook(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand the core Tensor with autograd, we'll build on this in:\n",
    "- **Lab 1.7.2**: Implementing neural network layers (Linear, ReLU, Softmax, Dropout)\n",
    "- **Lab 1.7.3**: Loss functions and optimizers\n",
    "\n",
    "Each of these will use our Tensor class as the foundation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
