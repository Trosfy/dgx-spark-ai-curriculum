{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Task 2.3: Visualization Dashboard\n\n**Module:** 2 - Python for AI/ML  \n**Time:** 2 hours  \n**Difficulty:** ‚≠ê‚≠ê\n\n---\n\n## üéØ Learning Objectives\n\nBy the end of this notebook, you will:\n- [ ] Create multi-panel figures using Matplotlib subplots\n- [ ] Visualize training/validation loss curves\n- [ ] Create confusion matrix heatmaps with Seaborn\n- [ ] Build feature importance and distribution plots\n- [ ] Apply consistent, publication-ready styling\n\n---\n\n## üìö Prerequisites\n\n- Completed: Tasks 2.1 and 2.2\n- Knowledge of: NumPy, basic Pandas\n\n### Required Packages\n- Python 3.9+\n- NumPy >= 1.21\n- Pandas >= 1.3\n- Matplotlib >= 3.5\n- Seaborn >= 0.11 (optional, but recommended)\n\n---\n\n## üåç Real-World Context\n\n**Why are visualizations crucial for ML?**\n\nNumbers tell part of the story. Visualizations tell the rest:\n\n- **Training curves** reveal if your model is overfitting, underfitting, or just right\n- **Confusion matrices** show exactly where your classifier is making mistakes\n- **Feature importance** helps explain model decisions to stakeholders\n- **Distribution plots** reveal data quality issues before they become model problems\n\n**In industry:**\n- Data scientists present visualizations to justify model choices\n- Engineers use plots to debug model training issues\n- Research papers require publication-quality figures\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßí ELI5: Why Visualize?\n",
    "\n",
    "> **Imagine you're a detective solving a mystery...** üîç\n",
    ">\n",
    "> You have a notebook full of clues (numbers).\n",
    "> But it's easier to see patterns when you:\n",
    "> - Draw a timeline of events (line plot)\n",
    "> - Make a board with photos of suspects (confusion matrix)\n",
    "> - Show which clues are most important (bar chart)\n",
    ">\n",
    "> **In AI terms:** Our brains are visual. A good plot can reveal patterns\n",
    "> that would take hours to find in raw numbers!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Environment Setup and Dependency Checks\n# ============================================================\nimport sys\nimport subprocess\nfrom pathlib import Path\n\n# Determine the notebook's directory for reliable path resolution\ntry:\n    notebook_dir = Path(__vsc_ipynb_file__).parent  # VS Code\nexcept NameError:\n    notebook_dir = Path.cwd()  # Fallback\n\n# Add scripts directory to path\nscripts_dir = (notebook_dir / '../scripts').resolve()\nif scripts_dir.exists() and str(scripts_dir) not in sys.path:\n    sys.path.insert(0, str(scripts_dir))\nelif not scripts_dir.exists():\n    scripts_dir = Path('../scripts').resolve()\n    if scripts_dir.exists() and str(scripts_dir) not in sys.path:\n        sys.path.insert(0, str(scripts_dir))\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Try to import seaborn (optional but recommended)\ntry:\n    import seaborn as sns\n    HAS_SEABORN = True\n    print(f\"Seaborn version: {sns.__version__}\")\nexcept ImportError:\n    HAS_SEABORN = False\n    print(\"‚ö†Ô∏è Seaborn not installed. Some visualizations will use matplotlib fallback.\")\n    print(\"   Install with: pip install seaborn\")\n\n# Set default style with fallback for different matplotlib versions\nstyle_set = False\nfor style_name in ['seaborn-v0_8-whitegrid', 'seaborn-whitegrid', 'ggplot']:\n    try:\n        plt.style.use(style_name)\n        print(f\"Using matplotlib style: {style_name}\")\n        style_set = True\n        break\n    except OSError:\n        continue\n\nif not style_set:\n    print(\"Using default matplotlib style\")\n\n# Configure matplotlib defaults for publication-ready figures\nplt.rcParams['figure.dpi'] = 100\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['axes.labelsize'] = 10\n\nprint(f\"\\nPython version: {sys.version.split()[0]}\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n\n# Check if data files exist\ndata_dir = (notebook_dir / '../data').resolve()\nif not data_dir.exists():\n    data_dir = Path('../data').resolve()\n\nrequired_files = ['sample_training_history.json', 'sample_confusion_data.json']\nmissing_files = [f for f in required_files if not (data_dir / f).exists()]\n\nif missing_files:\n    print(f\"\\n‚ö†Ô∏è Data files not found: {missing_files}\")\n    generator_script = data_dir / 'generate_sample_data.py'\n    if generator_script.exists():\n        print(\"   Generating sample data...\")\n        result = subprocess.run([sys.executable, str(generator_script)], \n                               capture_output=True, text=True, cwd=str(data_dir))\n        if result.returncode == 0:\n            print(\"   ‚úÖ Sample data generated!\")\n        else:\n            print(f\"   ‚ùå Error: {result.stderr}\")\nelse:\n    print(f\"\\n‚úÖ Data files present\")\n\nprint(f\"\\n{'='*50}\")\nprint(\"Welcome to the Visualization Dashboard Lab! üìä\")\nprint(f\"{'='*50}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Training and Validation Curves\n",
    "\n",
    "The most important visualization during model training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic training history data\n",
    "np.random.seed(42)\n",
    "\n",
    "epochs = 100\n",
    "x = np.arange(1, epochs + 1)\n",
    "\n",
    "# Simulate training loss (decreasing with noise)\n",
    "train_loss = 2.5 * np.exp(-0.05 * x) + 0.15 + np.random.normal(0, 0.02, epochs)\n",
    "\n",
    "# Simulate validation loss (decreases then increases = overfitting)\n",
    "val_loss = 2.5 * np.exp(-0.04 * x) + 0.25 + np.random.normal(0, 0.03, epochs)\n",
    "val_loss[50:] += 0.003 * (x[50:] - 50)  # Overfitting after epoch 50\n",
    "\n",
    "# Simulate accuracy (inverse of loss, roughly)\n",
    "train_acc = 1 - 0.4 * np.exp(-0.05 * x) + np.random.normal(0, 0.01, epochs)\n",
    "train_acc = np.clip(train_acc, 0, 1)\n",
    "\n",
    "val_acc = 1 - 0.45 * np.exp(-0.04 * x) + np.random.normal(0, 0.015, epochs)\n",
    "val_acc[50:] -= 0.002 * (x[50:] - 50)\n",
    "val_acc = np.clip(val_acc, 0, 1)\n",
    "\n",
    "print(\"Training history generated!\")\n",
    "print(f\"  Epochs: {epochs}\")\n",
    "print(f\"  Final train loss: {train_loss[-1]:.4f}\")\n",
    "print(f\"  Final val loss: {val_loss[-1]:.4f}\")\n",
    "print(f\"  Best val loss at epoch: {np.argmin(val_loss) + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic training curve\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(x, train_loss, label='Training Loss', color='#2ecc71', linewidth=2)\n",
    "ax.plot(x, val_loss, label='Validation Loss', color='#e74c3c', linewidth=2)\n",
    "\n",
    "# Mark the best epoch\n",
    "best_epoch = np.argmin(val_loss) + 1\n",
    "ax.axvline(x=best_epoch, color='gray', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "ax.scatter([best_epoch], [val_loss[best_epoch-1]], color='#e74c3c', s=100, zorder=5, edgecolors='white', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.set_xlim(1, epochs)\n",
    "\n",
    "# Add annotation for overfitting region\n",
    "ax.annotate('Overfitting region', \n",
    "            xy=(70, val_loss[69]), \n",
    "            xytext=(80, 0.6),\n",
    "            arrowprops=dict(arrowstyle='->', color='gray'),\n",
    "            fontsize=10, color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚ú® The gap between training and validation loss after epoch {best_epoch} indicates overfitting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Professional dual-panel plot (loss + accuracy)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss subplot\n",
    "ax1.plot(x, train_loss, label='Train', color='#3498db', linewidth=2)\n",
    "ax1.plot(x, val_loss, label='Validation', color='#e74c3c', linewidth=2)\n",
    "ax1.fill_between(x, train_loss, val_loss, alpha=0.2, color='red', \n",
    "                  where=(val_loss > train_loss), label='Generalization Gap')\n",
    "ax1.axvline(x=best_epoch, color='gray', linestyle='--', alpha=0.7)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss Curves', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.set_xlim(1, epochs)\n",
    "\n",
    "# Accuracy subplot\n",
    "ax2.plot(x, train_acc, label='Train', color='#3498db', linewidth=2)\n",
    "ax2.plot(x, val_acc, label='Validation', color='#e74c3c', linewidth=2)\n",
    "ax2.axvline(x=best_epoch, color='gray', linestyle='--', alpha=0.7, label=f'Best Epoch')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy Curves', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.set_xlim(1, epochs)\n",
    "ax2.set_ylim(0.5, 1.0)\n",
    "\n",
    "plt.suptitle('Model Training Progress', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç What These Curves Tell Us\n",
    "\n",
    "| Pattern | Meaning | Action |\n",
    "|---------|---------|--------|\n",
    "| Both losses decreasing together | Model is learning well | Keep training |\n",
    "| Train loss ‚Üì, Val loss ‚Üë | Overfitting | Early stopping, regularization |\n",
    "| Both losses high | Underfitting | More epochs, bigger model |\n",
    "| Large gap from start | Too complex model | Simpler architecture |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Confusion Matrix Heatmaps\n",
    "\n",
    "Essential for understanding classification errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sample confusion matrix\n",
    "# 5-class classification (e.g., sentiment: Very Neg, Neg, Neutral, Pos, Very Pos)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_classes = 5\n",
    "class_names = ['Very Negative', 'Negative', 'Neutral', 'Positive', 'Very Positive']\n",
    "\n",
    "# Create a realistic confusion matrix (most predictions on diagonal)\n",
    "cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "n_samples_per_class = 200\n",
    "\n",
    "for i in range(n_classes):\n",
    "    # Most predictions are correct\n",
    "    cm[i, i] = int(n_samples_per_class * (0.6 + 0.2 * np.random.random()))\n",
    "    \n",
    "    # Adjacent class confusion is common in ordinal problems\n",
    "    remaining = n_samples_per_class - cm[i, i]\n",
    "    for j in range(n_classes):\n",
    "        if i != j:\n",
    "            distance = abs(i - j)\n",
    "            prob = 0.4 ** distance\n",
    "            cm[i, j] = int(remaining * prob / sum(0.4 ** abs(i - k) for k in range(n_classes) if k != i))\n",
    "\n",
    "print(\"Confusion Matrix (raw counts):\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic confusion matrix heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(cm, \n",
    "            annot=True, \n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced confusion matrix with percentages side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, \n",
    "            annot=True, \n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            ax=ax1,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "ax1.set_ylabel('True Label')\n",
    "ax1.set_title('Counts', fontweight='bold')\n",
    "\n",
    "# Normalized (percentages per true class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_normalized, \n",
    "            annot=True, \n",
    "            fmt='.1%',\n",
    "            cmap='RdYlGn',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            ax=ax2,\n",
    "            vmin=0, vmax=1,\n",
    "            cbar_kws={'label': 'Recall'})\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "ax2.set_ylabel('True Label')\n",
    "ax2.set_title('Normalized (Recall per Class)', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Confusion Matrix Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.trace(cm) / cm.sum()\n",
    "print(f\"\\nüìä Overall Accuracy: {accuracy:.1%}\")\n",
    "print(\"\\nüìä Per-class Recall:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    recall = cm[i, i] / cm[i, :].sum()\n",
    "    print(f\"   {name}: {recall:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Feature Importance Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature importance data (like from a Random Forest)\n",
    "feature_names = [\n",
    "    'income', 'credit_score', 'age', 'years_employed', \n",
    "    'education_level', 'debt_ratio', 'num_accounts',\n",
    "    'recent_inquiries', 'payment_history', 'utilization'\n",
    "]\n",
    "\n",
    "np.random.seed(42)\n",
    "importances = np.random.exponential(0.1, len(feature_names))\n",
    "importances = importances / importances.sum()  # Normalize to sum to 1\n",
    "\n",
    "# Sort for display\n",
    "sorted_idx = np.argsort(importances)\n",
    "sorted_names = [feature_names[i] for i in sorted_idx]\n",
    "sorted_values = importances[sorted_idx]\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for name, value in zip(feature_names, importances):\n",
    "    print(f\"  {name}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar chart (best for many features)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(sorted_names)))\n",
    "\n",
    "bars = ax.barh(range(len(sorted_names)), sorted_values, color=colors)\n",
    "ax.set_yticks(range(len(sorted_names)))\n",
    "ax.set_yticklabels(sorted_names)\n",
    "ax.set_xlabel('Importance Score', fontsize=12)\n",
    "ax.set_title('Feature Importance', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, sorted_values):\n",
    "    ax.text(value + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "            f'{value:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Distribution Plots and Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction distributions\n",
    "np.random.seed(42)\n",
    "\n",
    "# Two-class predictions with some overlap\n",
    "class_0_preds = np.random.beta(2, 5, 500)  # Tends lower\n",
    "class_1_preds = np.random.beta(5, 2, 500)  # Tends higher\n",
    "\n",
    "all_predictions = np.concatenate([class_0_preds, class_1_preds])\n",
    "all_labels = np.array([0] * 500 + [1] * 500)\n",
    "\n",
    "print(f\"Class 0 predictions: mean={class_0_preds.mean():.3f}, std={class_0_preds.std():.3f}\")\n",
    "print(f\"Class 1 predictions: mean={class_1_preds.mean():.3f}, std={class_1_preds.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlapping histograms by class\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(class_0_preds, bins=30, alpha=0.6, label='Class 0 (Negative)', color='#3498db', density=True)\n",
    "ax.hist(class_1_preds, bins=30, alpha=0.6, label='Class 1 (Positive)', color='#e74c3c', density=True)\n",
    "\n",
    "# Add threshold line\n",
    "ax.axvline(0.5, color='black', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "\n",
    "ax.set_xlabel('Predicted Probability', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Prediction Distribution by True Class', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Overlap in the middle indicates prediction uncertainty.\")\n",
    "print(\"   A well-calibrated model has good separation between classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Building the Complete Dashboard\n",
    "\n",
    "Now let's combine everything into a publication-ready 2x2 dashboard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the complete 2x2 dashboard\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "gs = GridSpec(2, 2, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Panel 1: Training/Validation Loss (top-left)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(x, train_loss, label='Train', color='#3498db', linewidth=2)\n",
    "ax1.plot(x, val_loss, label='Validation', color='#e74c3c', linewidth=2)\n",
    "ax1.axvline(x=best_epoch, color='gray', linestyle='--', alpha=0.7)\n",
    "ax1.scatter([best_epoch], [val_loss[best_epoch-1]], color='#e74c3c', s=80, zorder=5, edgecolors='white', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training & Validation Loss', fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_xlim(1, epochs)\n",
    "\n",
    "# Panel 2: Confusion Matrix (top-right)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "sns.heatmap(cm_normalized, \n",
    "            annot=True, \n",
    "            fmt='.0%',\n",
    "            cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            ax=ax2,\n",
    "            cbar_kws={'label': 'Recall'})\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('True')\n",
    "ax2.set_title('Confusion Matrix (Normalized)', fontweight='bold')\n",
    "\n",
    "# Panel 3: Feature Importance (bottom-left)\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "colors3 = plt.cm.viridis(np.linspace(0.3, 0.9, len(sorted_names)))\n",
    "ax3.barh(range(len(sorted_names)), sorted_values, color=colors3)\n",
    "ax3.set_yticks(range(len(sorted_names)))\n",
    "ax3.set_yticklabels(sorted_names)\n",
    "ax3.set_xlabel('Importance')\n",
    "ax3.set_title('Feature Importance', fontweight='bold')\n",
    "\n",
    "# Panel 4: Prediction Distribution (bottom-right)\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax4.hist(class_0_preds, bins=25, alpha=0.6, label='Class 0', color='#3498db', density=True)\n",
    "ax4.hist(class_1_preds, bins=25, alpha=0.6, label='Class 1', color='#e74c3c', density=True)\n",
    "ax4.axvline(0.5, color='black', linestyle='--', linewidth=1.5, label='Threshold')\n",
    "ax4.set_xlabel('Predicted Probability')\n",
    "ax4.set_ylabel('Density')\n",
    "ax4.set_title('Prediction Distribution', fontweight='bold')\n",
    "ax4.legend()\n",
    "\n",
    "# Add overall title\n",
    "fig.suptitle('Model Analysis Dashboard', fontsize=16, fontweight='bold', y=1.01)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/model_dashboard.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéâ Dashboard saved to '../data/model_dashboard.png'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Exercise\n",
    "\n",
    "**Task:** Create your own custom dashboard with the following panels:\n",
    "\n",
    "1. **Learning Rate Finder curve** (loss vs learning rate, log scale)\n",
    "2. **ROC Curve** (True Positive Rate vs False Positive Rate)\n",
    "3. **Precision-Recall Curve**\n",
    "4. **Calibration Plot** (predicted probability vs actual frequency)\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint for ROC Curve</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--')  # Diagonal\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Create your custom dashboard\n",
    "# Start with:\n",
    "# fig = plt.figure(figsize=(14, 12))\n",
    "# gs = GridSpec(2, 2, figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Not setting figure size before plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Wrong: Tiny unreadable figures\n",
    "# plt.plot(x, y)  # Uses default small size\n",
    "\n",
    "# ‚úÖ Right: Set size first\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# ax.plot(x, y)\n",
    "\n",
    "print(\"üí° Always specify figsize for publication-quality plots!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Missing tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Wrong: Labels cut off\n",
    "# plt.savefig('plot.png')  # Labels might be clipped\n",
    "\n",
    "# ‚úÖ Right: Use tight_layout or bbox_inches\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('plot.png', bbox_inches='tight')\n",
    "\n",
    "print(\"üí° Use tight_layout() or bbox_inches='tight' to prevent label clipping!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 3: Poor color choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Wrong: Red/green (colorblind unfriendly)\n",
    "# ax.plot(x, y1, 'r-')  # Red\n",
    "# ax.plot(x, y2, 'g-')  # Green\n",
    "\n",
    "# ‚úÖ Right: Use colorblind-friendly palette\n",
    "# Colors: Blue (#0077BB), Orange (#EE7733), Cyan (#009988)\n",
    "# ax.plot(x, y1, color='#0077BB')\n",
    "# ax.plot(x, y2, color='#EE7733')\n",
    "\n",
    "print(\"üí° About 8% of men are red-green colorblind!\")\n",
    "print(\"   Use blue/orange or other accessible palettes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Creating training/validation loss curves with best epoch markers\n",
    "- ‚úÖ Building confusion matrix heatmaps with normalization\n",
    "- ‚úÖ Visualizing feature importance with sorted bar charts\n",
    "- ‚úÖ Creating prediction distribution histograms\n",
    "- ‚úÖ Combining plots into a professional 2x2 dashboard\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/)\n",
    "- [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html)\n",
    "- [Data Visualization Best Practices](https://serialmentor.com/dataviz/)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all figures\n",
    "plt.close('all')\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Cleanup complete!\")\n",
    "print(\"\\nüéâ Congratulations! You've mastered ML visualization!\")\n",
    "print(\"   Next up: Task 2.4 - Einsum Mastery\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}