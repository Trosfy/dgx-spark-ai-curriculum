{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 2.6.4: Flux Exploration - Next-Gen Image Generation\n\n**Module:** 2.6 - Diffusion Models  \n**Time:** 2 hours  \n**Difficulty:** ‚≠ê‚≠ê (Beginner-Intermediate)\n\n---\n\n## ‚ö†Ô∏è IMPORTANT: License Requirements\n\n**Before running this notebook, you MUST:**\n1. Visit [black-forest-labs/FLUX.1-schnell](https://huggingface.co/black-forest-labs/FLUX.1-schnell) on Hugging Face\n2. Accept the license agreement (Apache 2.0 for schnell)\n3. Visit [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev) on Hugging Face\n4. Accept the license agreement (non-commercial for dev)\n5. Log in with `huggingface-cli login` if not already authenticated\n\n**Flux-dev is for non-commercial use only!** For commercial use, consider Flux-schnell (Apache 2.0) or Flux-pro (via API).\n\n---\n\n## üéØ Learning Objectives\n\nBy the end of this notebook, you will:\n- [ ] Understand the Flux architecture and how it differs from SDXL\n- [ ] Load and run Flux-dev and Flux-schnell on DGX Spark\n- [ ] Compare quality and speed between Flux variants\n- [ ] Perform side-by-side comparisons with SDXL\n- [ ] Learn when to use each model\n\n---\n\n## üìö Prerequisites\n\n- Completed: Lab 2.6.2 (Stable Diffusion Generation)\n- Knowledge of: Basic diffusion concepts, SDXL usage\n- **Required packages:**\n  - `diffusers>=0.30.0` (Flux support)\n  - `transformers>=4.42.0`\n  - `sentencepiece` (for T5 tokenizer)\n- **Required**: Hugging Face account with Flux model access (see above)\n\n---\n\n## üåç Real-World Context\n\n**Flux represents the next evolution in diffusion models:**\n\n- Created by **Black Forest Labs** (team behind Stable Diffusion)\n- Often produces more photorealistic results than SDXL\n- Different aesthetic, especially for text rendering\n- **Flux-schnell**: Extremely fast (4 steps!)\n- **Flux-dev**: Higher quality, more steps\n\nDGX Spark can run Flux at full precision with room to spare!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßí ELI5: What Makes Flux Different?\n",
    "\n",
    "> **Think of SDXL and Flux like two talented artists:**\n",
    ">\n",
    "> **SDXL** is like a classical painter:\n",
    "> - Uses a U-Net (traditional CNN architecture)\n",
    "> - Works in latent space (64√ó64‚Üí512√ó512)\n",
    "> - Great at many styles, especially artistic\n",
    ">\n",
    "> **Flux** is like a modern digital artist:\n",
    "> - Uses a DiT (Diffusion Transformer) architecture\n",
    "> - Better at understanding complex prompts\n",
    "> - Often more photorealistic\n",
    "> - Better at rendering text in images!\n",
    ">\n",
    "> **The key innovation:** Flux uses Transformers (like ChatGPT uses for text)\n",
    "> for image generation. This gives better long-range understanding.\n",
    "\n",
    "### Architecture Comparison\n",
    "\n",
    "```\n",
    "SDXL Architecture:                 Flux Architecture:\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ    U-Net with     ‚îÇ             ‚îÇ    Diffusion      ‚îÇ\n",
    "‚îÇ  Cross-Attention  ‚îÇ             ‚îÇ   Transformer     ‚îÇ\n",
    "‚îÇ  (CNN-based)      ‚îÇ             ‚îÇ  (DiT-based)      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚îÇ                                  ‚îÇ\n",
    "    Local + Some                      Full Global\n",
    "    Global Context                    Attention\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "import gc\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Diffusers\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "# Visualization\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def show_comparison(images, titles, figsize=(20, 10)):\n",
    "    \"\"\"Display images side by side for comparison.\"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current GPU memory usage.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        return f\"Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB\"\n",
    "    return \"N/A\"\n",
    "\n",
    "def timed_generation(pipe, prompt, **kwargs):\n",
    "    \"\"\"Generate image and return timing info.\"\"\"\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    \n",
    "    image = pipe(prompt=prompt, **kwargs).images[0]\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    return image, elapsed\n",
    "\n",
    "print(\"Helper functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Loading Flux Models\n",
    "\n",
    "### Flux Variants\n",
    "\n",
    "| Variant | Steps | Speed | Quality | Use Case |\n",
    "|---------|-------|-------|---------|----------|\n",
    "| **Flux-schnell** | 4 | Very Fast (~3s) | Good | Quick iterations, previews |\n",
    "| **Flux-dev** | 20-50 | Moderate (~15s) | Excellent | Final renders, quality |\n",
    "| **Flux-pro** | 25+ | Slow | Best | API only (commercial) |\n",
    "\n",
    "**Note:** Flux requires accepting the license on Hugging Face. Visit the model page and accept first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Flux-schnell (fast version)\n",
    "print(\"Loading Flux-schnell...\")\n",
    "print(f\"Memory before: {get_memory_usage()}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pipe_schnell = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-schnell\",\n",
    "    torch_dtype=torch.bfloat16,  # Native Blackwell support\n",
    ")\n",
    "pipe_schnell = pipe_schnell.to(device)\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Flux-schnell loaded in {load_time:.1f} seconds\")\n",
    "print(f\"Memory after: {get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Flux-schnell with a simple prompt\n",
    "prompt = \"A beautiful sunset over a calm ocean, photorealistic\"\n",
    "\n",
    "print(f\"Generating with Flux-schnell...\")\n",
    "\n",
    "generator = torch.Generator(device=device).manual_seed(42)\n",
    "\n",
    "image, gen_time = timed_generation(\n",
    "    pipe_schnell,\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=4,  # Schnell is optimized for 4 steps!\n",
    "    generator=generator,\n",
    "    guidance_scale=0.0,  # Schnell doesn't need guidance\n",
    ")\n",
    "\n",
    "print(f\"‚è±Ô∏è Generation time: {gen_time:.2f}s\")\n",
    "print(f\"üìê Image size: {image.size}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Flux-schnell (4 steps, {gen_time:.1f}s)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Flux-dev\n",
    "\n",
    "Flux-dev is the higher quality version. Let's load it and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up schnell to make room for dev\n",
    "del pipe_schnell\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Memory after cleanup: {get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Flux-dev (higher quality version)\n",
    "print(\"Loading Flux-dev...\")\n",
    "print(f\"Memory before: {get_memory_usage()}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pipe_dev = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "pipe_dev = pipe_dev.to(device)\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Flux-dev loaded in {load_time:.1f} seconds\")\n",
    "print(f\"Memory after: {get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Flux-dev with different step counts\n",
    "prompt = \"A professional portrait of a wise old wizard with a long white beard, wearing ornate robes with celestial patterns, soft dramatic lighting, highly detailed, fantasy art\"\n",
    "\n",
    "step_counts = [20, 35, 50]\n",
    "images = []\n",
    "times = []\n",
    "\n",
    "for steps in step_counts:\n",
    "    print(f\"Generating with {steps} steps...\")\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    \n",
    "    image, gen_time = timed_generation(\n",
    "        pipe_dev,\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=steps,\n",
    "        generator=generator,\n",
    "        guidance_scale=3.5,\n",
    "    )\n",
    "    \n",
    "    images.append(image)\n",
    "    times.append(gen_time)\n",
    "    print(f\"  ‚è±Ô∏è {gen_time:.1f}s\")\n",
    "\n",
    "# Display comparison\n",
    "titles = [f\"Flux-dev ({s} steps, {t:.1f}s)\" for s, t in zip(step_counts, times)]\n",
    "show_comparison(images, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Flux vs SDXL Comparison\n",
    "\n",
    "Let's do a head-to-head comparison on the same prompts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SDXL for comparison\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "print(\"Loading SDXL for comparison...\")\n",
    "\n",
    "pipe_sdxl = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    variant=\"fp16\",\n",
    ")\n",
    "pipe_sdxl = pipe_sdxl.to(device)\n",
    "\n",
    "print(f\"‚úÖ SDXL loaded\")\n",
    "print(f\"Memory: {get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison prompts - testing different aspects\n",
    "comparison_prompts = [\n",
    "    {\n",
    "        \"name\": \"Photorealism\",\n",
    "        \"prompt\": \"A close-up portrait of a middle-aged woman with freckles, natural lighting, professional photography, 8K resolution\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Text Rendering\",\n",
    "        \"prompt\": \"A vintage wooden sign that says 'Welcome to the Future' in elegant script, rustic style\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Complex Scene\",\n",
    "        \"prompt\": \"A busy street market in Morocco at golden hour, spices, fabrics, local vendors, photorealistic, crowded, vibrant colors\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Fantasy Art\",\n",
    "        \"prompt\": \"A majestic dragon perched on a mountain peak at sunset, scales gleaming, fantasy art, highly detailed, epic scale\",\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for test in comparison_prompts:\n",
    "    print(f\"\\nüì∏ Testing: {test['name']}\")\n",
    "    print(f\"   Prompt: {test['prompt'][:60]}...\")\n",
    "    \n",
    "    # Generate with Flux-dev\n",
    "    print(\"   Generating with Flux-dev...\")\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    flux_img, flux_time = timed_generation(\n",
    "        pipe_dev,\n",
    "        prompt=test['prompt'],\n",
    "        num_inference_steps=30,\n",
    "        generator=generator,\n",
    "        guidance_scale=3.5,\n",
    "    )\n",
    "    print(f\"   Flux: {flux_time:.1f}s\")\n",
    "    \n",
    "    # Generate with SDXL\n",
    "    print(\"   Generating with SDXL...\")\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    sdxl_img, sdxl_time = timed_generation(\n",
    "        pipe_sdxl,\n",
    "        prompt=test['prompt'],\n",
    "        num_inference_steps=30,\n",
    "        generator=generator,\n",
    "        guidance_scale=7.5,\n",
    "    )\n",
    "    print(f\"   SDXL: {sdxl_time:.1f}s\")\n",
    "    \n",
    "    results.append({\n",
    "        'name': test['name'],\n",
    "        'flux_img': flux_img,\n",
    "        'flux_time': flux_time,\n",
    "        'sdxl_img': sdxl_img,\n",
    "        'sdxl_time': sdxl_time,\n",
    "    })\n",
    "\n",
    "print(\"\\n‚úÖ All comparisons complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison results\n",
    "fig, axes = plt.subplots(len(results), 2, figsize=(16, 8*len(results)))\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    # Flux result\n",
    "    axes[i, 0].imshow(result['flux_img'])\n",
    "    axes[i, 0].set_title(f\"Flux-dev ({result['flux_time']:.1f}s)\\n{result['name']}\", fontsize=12)\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # SDXL result\n",
    "    axes[i, 1].imshow(result['sdxl_img'])\n",
    "    axes[i, 1].set_title(f\"SDXL ({result['sdxl_time']:.1f}s)\\n{result['name']}\", fontsize=12)\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Flux vs SDXL Comparison\", fontsize=16, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: When to Use Each Model\n",
    "\n",
    "| Aspect | Flux | SDXL |\n",
    "|--------|------|------|\n",
    "| **Photorealism** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Often more realistic | ‚≠ê‚≠ê‚≠ê‚≠ê Very good |\n",
    "| **Text Rendering** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Much better! | ‚≠ê‚≠ê Struggles |\n",
    "| **Artistic Styles** | ‚≠ê‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent |\n",
    "| **Speed (schnell)** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ~3s | N/A |\n",
    "| **Memory Usage** | ~12GB | ~7GB |\n",
    "| **ControlNet/LoRA** | Limited support | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Extensive |\n",
    "| **Community Models** | Growing | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Huge ecosystem |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Text-in-Image Generation\n",
    "\n",
    "One of Flux's standout capabilities is rendering readable text in images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text rendering capabilities\n",
    "text_prompts = [\n",
    "    \"A coffee shop window with 'OPEN' written on a chalkboard sign, cozy atmosphere\",\n",
    "    \"A book cover with the title 'The Last Adventure' in elegant serif font, fantasy style\",\n",
    "    \"A neon sign that says 'CYBER CAFE' in a futuristic cityscape, night scene, rain\",\n",
    "    \"A birthday cake with 'Happy 30th!' written in icing, colorful, celebration\",\n",
    "]\n",
    "\n",
    "flux_images = []\n",
    "sdxl_images = []\n",
    "\n",
    "for prompt in text_prompts:\n",
    "    print(f\"Testing: {prompt[:40]}...\")\n",
    "    \n",
    "    # Flux\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    flux_img = pipe_dev(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=30,\n",
    "        generator=generator,\n",
    "        guidance_scale=3.5,\n",
    "    ).images[0]\n",
    "    flux_images.append(flux_img)\n",
    "    \n",
    "    # SDXL\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    sdxl_img = pipe_sdxl(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=30,\n",
    "        generator=generator,\n",
    "        guidance_scale=7.5,\n",
    "    ).images[0]\n",
    "    sdxl_images.append(sdxl_img)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 24))\n",
    "\n",
    "for i, prompt in enumerate(text_prompts):\n",
    "    axes[i, 0].imshow(flux_images[i])\n",
    "    axes[i, 0].set_title(f\"Flux: {prompt[:30]}...\", fontsize=10)\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(sdxl_images[i])\n",
    "    axes[i, 1].set_title(f\"SDXL: {prompt[:30]}...\", fontsize=10)\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Text Rendering: Flux vs SDXL\", fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Notice how Flux renders text much more accurately!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Flux Generation Settings\n",
    "\n",
    "Let's explore optimal settings for Flux models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different guidance scales for Flux-dev\n",
    "prompt = \"A serene Japanese garden with a red bridge over a koi pond, cherry blossoms, photorealistic\"\n",
    "\n",
    "guidance_scales = [1.0, 2.0, 3.5, 5.0, 7.0]\n",
    "images = []\n",
    "\n",
    "for gs in guidance_scales:\n",
    "    print(f\"Generating with guidance_scale={gs}...\")\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    \n",
    "    image = pipe_dev(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=25,\n",
    "        generator=generator,\n",
    "        guidance_scale=gs,\n",
    "    ).images[0]\n",
    "    \n",
    "    images.append(image)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "for ax, img, gs in zip(axes, images, guidance_scales):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Guidance: {gs}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"Flux-dev Guidance Scale Comparison\", fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Flux-dev Guidance Scale Guide:\")\n",
    "print(\"  - 1.0-2.0: Very creative, may deviate from prompt\")\n",
    "print(\"  - 3.0-4.0: Recommended balance (3.5 is default)\")\n",
    "print(\"  - 5.0-7.0: Stronger prompt adherence, may oversaturate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Performance Benchmarks on DGX Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive benchmark\n",
    "print(\"üöÄ DGX Spark Flux Benchmark\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Clean up SDXL for accurate Flux benchmarks\n",
    "del pipe_sdxl\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "benchmark_prompt = \"A beautiful mountain landscape at sunset, photorealistic, 8K\"\n",
    "\n",
    "# Benchmark Flux-dev at different step counts\n",
    "print(\"\\nFlux-dev Benchmarks:\")\n",
    "for steps in [20, 30, 50]:\n",
    "    times = []\n",
    "    for _ in range(3):  # 3 runs for average\n",
    "        generator = torch.Generator(device=device).manual_seed(42)\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        _ = pipe_dev(\n",
    "            prompt=benchmark_prompt,\n",
    "            num_inference_steps=steps,\n",
    "            generator=generator,\n",
    "            guidance_scale=3.5,\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    avg_time = sum(times) / len(times)\n",
    "    print(f\"  {steps} steps: {avg_time:.2f}s (avg of 3 runs)\")\n",
    "\n",
    "print(f\"\\nMemory Usage: {get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Using SDXL Guidance Scales with Flux\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong: SDXL-style high guidance\n",
    "pipe_dev(prompt=\"...\", guidance_scale=7.5)  # Too high for Flux!\n",
    "\n",
    "# ‚úÖ Right: Flux-appropriate guidance\n",
    "pipe_dev(prompt=\"...\", guidance_scale=3.5)  # Flux default\n",
    "```\n",
    "\n",
    "### Mistake 2: Using Guidance with Schnell\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong: Schnell doesn't need guidance\n",
    "pipe_schnell(prompt=\"...\", guidance_scale=7.5)\n",
    "\n",
    "# ‚úÖ Right: Guidance-free distilled model\n",
    "pipe_schnell(prompt=\"...\", guidance_scale=0.0)\n",
    "```\n",
    "\n",
    "### Mistake 3: Wrong Step Count for Schnell\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong: Too many steps wastes time\n",
    "pipe_schnell(num_inference_steps=50)  # No benefit!\n",
    "\n",
    "# ‚úÖ Right: Schnell is optimized for 4 steps\n",
    "pipe_schnell(num_inference_steps=4)  # Sweet spot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ How Flux differs architecturally from SDXL (DiT vs U-Net)\n",
    "- ‚úÖ Loading and using Flux-schnell (fast) and Flux-dev (quality)\n",
    "- ‚úÖ Optimal settings for Flux (guidance scale, steps)\n",
    "- ‚úÖ Flux's superior text rendering capabilities\n",
    "- ‚úÖ When to choose Flux vs SDXL for different tasks\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Challenge (Optional)\n",
    "\n",
    "1. **Speed Run**: Generate 10 images with Flux-schnell in under 30 seconds\n",
    "2. **Typography**: Create a poster with complex text layout using Flux\n",
    "3. **Style Matching**: Find prompts where SDXL beats Flux and vice versa\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "del pipe_dev\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU memory cleared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to **Lab 2.6.5: LoRA Style Training** to learn how to train custom styles for SDXL!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}