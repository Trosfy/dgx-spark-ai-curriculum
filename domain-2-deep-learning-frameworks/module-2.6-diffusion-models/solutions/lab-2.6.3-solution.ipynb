{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.6.3 Solution\n",
    "\n",
    "This solution notebook contains completed exercises from Lab 2.6.3.\n",
    "\n",
    "**Note:** The main lab notebooks contain fully working code throughout. This solution notebook focuses on the \"Try It Yourself\" exercises and challenges.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Use This Solution\n",
    "\n",
    "1. First attempt the exercises in the main lab notebook\n",
    "2. If stuck, check the hints in the main notebook\n",
    "3. Compare your solution with this reference\n",
    "4. Understand the differences and learn from them\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exercise Solutions\n\n### Challenge 1: Architecture Control\n\n```python\n# Solution: Draw a building outline and generate in 5 architectural styles\n\nimport numpy as np\nimport cv2\nfrom PIL import Image\n\ndef draw_building_outline(size=(1024, 1024)):\n    \"\"\"Draw a simple building outline for ControlNet.\"\"\"\n    img = np.zeros((*size, 3), dtype=np.uint8)\n    \n    # Main building body\n    cv2.rectangle(img, (300, 400), (700, 900), (255, 255, 255), 2)\n    \n    # Roof (triangular)\n    pts = np.array([[250, 400], [500, 150], [750, 400]], np.int32)\n    cv2.polylines(img, [pts], True, (255, 255, 255), 2)\n    \n    # Windows\n    for row in range(2):\n        for col in range(3):\n            x = 350 + col * 120\n            y = 480 + row * 180\n            cv2.rectangle(img, (x, y), (x + 80, y + 120), (255, 255, 255), 2)\n    \n    # Door\n    cv2.rectangle(img, (450, 700), (550, 900), (255, 255, 255), 2)\n    \n    return Image.fromarray(img)\n\n# Create the building sketch\nbuilding_sketch = draw_building_outline()\n\n# Generate in 5 architectural styles\narchitectural_styles = [\n    \"A modern minimalist house, clean lines, glass and concrete, architectural photography\",\n    \"A Victorian Gothic mansion, ornate details, dark atmosphere, dramatic\",\n    \"A Mediterranean villa, terracotta roof, warm colors, sunny day\",\n    \"A Japanese traditional house, wooden architecture, zen garden, peaceful\",\n    \"A futuristic eco-house, living walls, solar panels, sustainable architecture\",\n]\n\nfor i, prompt in enumerate(architectural_styles):\n    generator = torch.Generator(device=\"cuda\").manual_seed(42)\n    image = pipe_canny(\n        prompt=prompt,\n        image=building_sketch,\n        controlnet_conditioning_scale=0.7,\n        num_inference_steps=25,\n        generator=generator,\n    ).images[0]\n    image.save(f\"architecture_style_{i}.png\")\n```\n\n### Challenge 2: Multi-ControlNet (Edges + Depth)\n\n```python\n# Solution: Combine edges and depth for enhanced control\n\nfrom diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline\n\n# Load multiple ControlNets\ncontrolnet_canny = ControlNetModel.from_pretrained(\n    \"diffusers/controlnet-canny-sdxl-1.0\", torch_dtype=torch.bfloat16\n)\ncontrolnet_depth = ControlNetModel.from_pretrained(\n    \"diffusers/controlnet-depth-sdxl-1.0\", torch_dtype=torch.bfloat16\n)\n\n# Create multi-ControlNet pipeline\npipe_multi = StableDiffusionXLControlNetPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\",\n    controlnet=[controlnet_canny, controlnet_depth],\n    torch_dtype=torch.bfloat16,\n)\npipe_multi = pipe_multi.to(\"cuda\")\n\n# Generate with both controls\n# Note: controlnet_conditioning_scale takes a list for multiple controls\nimage = pipe_multi(\n    prompt=\"A fantasy castle, magical atmosphere, detailed\",\n    image=[canny_edges, depth_map],  # Both control images\n    controlnet_conditioning_scale=[0.5, 0.5],  # Balance both\n    num_inference_steps=25,\n).images[0]\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips from This Lab\n",
    "\n",
    "### Best Practices Learned:\n",
    "\n",
    "1. Always set a random seed for reproducible results\n",
    "2. Use negative prompts to avoid common artifacts\n",
    "3. Start with default parameters, then tune\n",
    "4. Save metadata with every generation\n",
    "5. Use bfloat16 on DGX Spark for optimal performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}