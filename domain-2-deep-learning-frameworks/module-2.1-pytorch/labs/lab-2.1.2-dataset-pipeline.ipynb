{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.1.2: Dataset Pipeline - Efficient Data Loading\n",
    "\n",
    "**Module:** 2.1 - Deep Learning with PyTorch  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê (Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Implement a custom `Dataset` class for local image folders\n",
    "- [ ] Create data augmentation transforms using `torchvision.transforms`\n",
    "- [ ] Configure `DataLoader` with optimal worker settings\n",
    "- [ ] Benchmark and optimize data loading for DGX Spark\n",
    "- [ ] Understand memory-mapped datasets for large data\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed: Lab 2.1.1 (Custom Module Lab)\n",
    "- Knowledge of: Python iterators, image file formats\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "Data loading is often the **bottleneck** in deep learning training! If your GPU is waiting for data, you're wasting expensive compute.\n",
    "\n",
    "Real scenarios where data pipelines matter:\n",
    "- **Medical imaging**: Loading huge DICOM files (hundreds of MB each)\n",
    "- **Autonomous vehicles**: Processing millions of driving images\n",
    "- **Recommendation systems**: Streaming user interaction data\n",
    "- **Video analysis**: Extracting frames efficiently\n",
    "\n",
    "With DGX Spark's 128GB unified memory, we can load more data, but we need to do it efficiently!\n",
    "\n",
    "---\n",
    "\n",
    "## ELI5: What is a DataLoader?\n",
    "\n",
    "> **Imagine a restaurant kitchen...** üç≥\n",
    ">\n",
    "> The **Dataset** is like your ingredients pantry - it knows where everything is and how to get it.\n",
    ">\n",
    "> The **DataLoader** is like your kitchen staff:\n",
    "> - They go to the pantry, grab ingredients\n",
    "> - They prepare multiple orders at once (batching)\n",
    "> - Multiple cooks work in parallel (num_workers)\n",
    "> - They shuffle orders to prevent bias (shuffle=True)\n",
    "> - They have a prep station ready for the next order (prefetching)\n",
    ">\n",
    "> The chef (GPU) never has to wait - there's always a prepared batch ready!\n",
    ">\n",
    "> **In AI terms:** Dataset defines HOW to load individual samples. DataLoader handles batching, shuffling, and parallel loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision\nimport torchvision.transforms as T\nfrom torchvision.datasets import ImageFolder\n\nimport os\nimport time\nimport tempfile\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom typing import Tuple, List, Optional, Callable\nfrom collections import defaultdict\nimport multiprocessing\n\n# Check environment\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CPU cores: {multiprocessing.cpu_count()}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Creating a Custom Dataset\n",
    "\n",
    "PyTorch's `Dataset` class requires you to implement three methods:\n",
    "1. `__init__`: Initialize the dataset (load file paths, transforms, etc.)\n",
    "2. `__len__`: Return the total number of samples\n",
    "3. `__getitem__`: Return a single sample given an index\n",
    "\n",
    "Let's start by creating a synthetic dataset for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a sample image folder structure for this tutorial\n# Using a unique temp directory to avoid conflicts with user data\n\n# Create unique temp directory for this session\nSAMPLE_DATA_DIR = tempfile.mkdtemp(prefix='module06_dataset_')\nprint(f\"Using temp directory: {SAMPLE_DATA_DIR}\")\n\ndef create_sample_dataset(root_dir: str, num_images: int = 100):\n    \"\"\"\n    Create a sample dataset with random images for testing.\n    \n    Structure:\n        sample_data/\n            class_0/\n                image_0.jpg\n                image_1.jpg\n                ...\n            class_1/\n                image_0.jpg\n                ...\n    \"\"\"\n    root = Path(root_dir)\n    classes = ['cats', 'dogs', 'birds']\n    \n    for cls in classes:\n        class_dir = root / cls\n        class_dir.mkdir(parents=True, exist_ok=True)\n        \n        for i in range(num_images // len(classes)):\n            # Create a random color image\n            img_array = np.random.randint(0, 255, (64, 64, 3), dtype=np.uint8)\n            img = Image.fromarray(img_array)\n            img.save(class_dir / f'image_{i:04d}.jpg')\n    \n    print(f\"Created sample dataset at '{root_dir}' with {num_images} images\")\n    return root_dir\n\n# Create the sample dataset in the unique temp directory\nsample_data_path = create_sample_dataset(SAMPLE_DATA_DIR, num_images=300)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ImageFolderDataset(Dataset):\n    \"\"\"\n    Custom Dataset for loading images from a folder structure.\n    \n    Expected folder structure:\n        root/\n            class1/\n                img1.jpg\n                img2.jpg\n            class2/\n                img1.jpg\n                ...\n    \n    Args:\n        root_dir: Path to the root directory\n        transform: Optional transform to apply to images\n        extensions: Tuple of valid image extensions\n    \n    Example:\n        >>> dataset = ImageFolderDataset('./data', transform=T.ToTensor())\n        >>> image, label = dataset[0]\n        >>> print(image.shape, label)\n    \"\"\"\n    \n    def __init__(\n        self,\n        root_dir: str,\n        transform: Optional[Callable] = None,\n        extensions: Tuple[str, ...] = ('.jpg', '.jpeg', '.png', '.bmp')\n    ):\n        self.root_dir = Path(root_dir)\n        self.transform = transform\n        self.extensions = extensions\n        \n        # Discover classes (subdirectories)\n        self.classes = sorted([\n            d.name for d in self.root_dir.iterdir()\n            if d.is_dir()\n        ])\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n        \n        # Collect all image paths and labels\n        self.samples = []\n        for class_name in self.classes:\n            class_dir = self.root_dir / class_name\n            for img_path in class_dir.iterdir():\n                if img_path.suffix.lower() in self.extensions:\n                    self.samples.append((\n                        str(img_path),\n                        self.class_to_idx[class_name]\n                    ))\n        \n        print(f\"Found {len(self.samples)} images in {len(self.classes)} classes\")\n    \n    def __len__(self) -> int:\n        \"\"\"Return the total number of samples.\"\"\"\n        return len(self.samples)\n    \n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n        \"\"\"\n        Get a single sample.\n        \n        Args:\n            idx: Index of the sample\n            \n        Returns:\n            Tuple of (image, label)\n        \"\"\"\n        img_path, label = self.samples[idx]\n        \n        # Load image\n        image = Image.open(img_path).convert('RGB')\n        \n        # Apply transforms\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n    \n    def get_class_name(self, label: int) -> str:\n        \"\"\"Get the class name for a given label.\"\"\"\n        return self.classes[label]\n\n\n# Create and test our dataset\nsimple_transform = T.Compose([\n    T.Resize((32, 32)),\n    T.ToTensor(),\n])\n\ndataset = ImageFolderDataset(SAMPLE_DATA_DIR, transform=simple_transform)\n\n# Test it\nimage, label = dataset[0]\nprint(f\"\\nSample image shape: {image.shape}\")\nprint(f\"Sample label: {label} ({dataset.get_class_name(label)})\")\nprint(f\"Image dtype: {image.dtype}\")\nprint(f\"Image range: [{image.min():.3f}, {image.max():.3f}]\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "1. We scanned the directory to find all classes (subdirectories)\n",
    "2. We collected all image paths and their corresponding labels\n",
    "3. When `__getitem__` is called, we load the image on-demand (lazy loading)\n",
    "4. The transform converts the image to a tensor\n",
    "\n",
    "**Key insight:** Images are only loaded when requested, saving memory!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Augmentation Transforms\n",
    "\n",
    "Data augmentation creates variations of training images to:\n",
    "1. **Prevent overfitting** - model sees more diverse examples\n",
    "2. **Improve robustness** - model handles real-world variations\n",
    "3. **Increase effective dataset size** - especially important for small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transforms with augmentation\n",
    "train_transform = T.Compose([\n",
    "    # Resize to slightly larger than target\n",
    "    T.Resize(40),\n",
    "    \n",
    "    # Random crop to target size (32x32 for CIFAR-like)\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    \n",
    "    # Random horizontal flip (50% chance)\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    \n",
    "    # Color jitter - randomly adjust brightness, contrast, saturation\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    \n",
    "    # Random rotation (small angles)\n",
    "    T.RandomRotation(degrees=15),\n",
    "    \n",
    "    # Convert to tensor (scales to [0, 1])\n",
    "    T.ToTensor(),\n",
    "    \n",
    "    # Normalize using ImageNet statistics\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Validation/Test transforms - NO augmentation!\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "print(\"Training transform:\")\n",
    "print(train_transform)\n",
    "\n",
    "print(\"\\nValidation transform:\")\n",
    "print(val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize augmentations\ndef show_augmentations(image_path: str, transform: T.Compose, n_samples: int = 6):\n    \"\"\"Show multiple augmented versions of the same image.\"\"\"\n    \n    original = Image.open(image_path).convert('RGB')\n    \n    fig, axes = plt.subplots(2, n_samples // 2 + 1, figsize=(15, 6))\n    axes = axes.flatten()\n    \n    # Show original\n    axes[0].imshow(original)\n    axes[0].set_title('Original')\n    axes[0].axis('off')\n    \n    # Show augmented versions\n    # Need a transform without normalization for visualization\n    viz_transform = T.Compose([\n        T.Resize(40),\n        T.RandomCrop(32, padding=4),\n        T.RandomHorizontalFlip(p=0.5),\n        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        T.RandomRotation(degrees=15),\n        T.ToTensor(),\n    ])\n    \n    for i in range(1, n_samples + 1):\n        augmented = viz_transform(original)\n        # Convert tensor to displayable format\n        img = augmented.permute(1, 2, 0).numpy()\n        img = np.clip(img, 0, 1)\n        axes[i].imshow(img)\n        axes[i].set_title(f'Augmented {i}')\n        axes[i].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Show augmentations on a sample image\nsample_path = Path(SAMPLE_DATA_DIR) / 'cats' / 'image_0000.jpg'\nshow_augmentations(str(sample_path), train_transform)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Transform: RandAugment\n",
    "\n",
    "RandAugment (from Google) is a modern augmentation strategy that randomly applies N transforms from a pool of options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandAugment is available in newer torchvision versions\n",
    "try:\n",
    "    from torchvision.transforms import autoaugment\n",
    "    \n",
    "    randaugment_transform = T.Compose([\n",
    "        T.Resize(40),\n",
    "        T.RandomCrop(32, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        autoaugment.RandAugment(num_ops=2, magnitude=9),  # Apply 2 random transforms\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    print(\"RandAugment available!\")\n",
    "except ImportError:\n",
    "    print(\"RandAugment not available in this torchvision version\")\n",
    "    randaugment_transform = train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: DataLoader Configuration\n",
    "\n",
    "The DataLoader handles:\n",
    "- **Batching**: Combining samples into batches\n",
    "- **Shuffling**: Randomizing order each epoch\n",
    "- **Parallel loading**: Using multiple worker processes\n",
    "- **Prefetching**: Loading next batches while GPU works\n",
    "\n",
    "### Key Parameters:\n",
    "- `batch_size`: How many samples per batch\n",
    "- `num_workers`: Number of parallel data loading processes\n",
    "- `pin_memory`: Copy data directly to GPU-pinned memory\n",
    "- `prefetch_factor`: Batches to prefetch per worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create datasets with transforms\ntrain_dataset = ImageFolderDataset(SAMPLE_DATA_DIR, transform=train_transform)\n\n# Split into train/val\ntrain_size = int(0.8 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n\nprint(f\"Training samples: {len(train_subset)}\")\nprint(f\"Validation samples: {len(val_subset)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,  # Faster GPU transfer\n",
    "    drop_last=True,   # Drop incomplete final batch\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=64,  # Can use larger batch for validation (no gradients)\n",
    "    shuffle=False,  # No need to shuffle validation data\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# Test the DataLoader\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "\n",
    "print(f\"Batch images shape: {images.shape}\")\n",
    "print(f\"Batch labels shape: {labels.shape}\")\n",
    "print(f\"Number of batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Benchmarking Data Loading\n",
    "\n",
    "Let's find the optimal `num_workers` and `batch_size` for DGX Spark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_dataloader(\n",
    "    dataset: Dataset,\n",
    "    batch_size: int,\n",
    "    num_workers: int,\n",
    "    num_batches: int = 50\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Benchmark DataLoader throughput.\n",
    "    \n",
    "    Returns:\n",
    "        Average time per batch in seconds\n",
    "    \"\"\"\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    # Warmup\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i >= 5:\n",
    "            break\n",
    "    \n",
    "    # Benchmark\n",
    "    start = time.time()\n",
    "    for i, batch in enumerate(loader):\n",
    "        images, labels = batch\n",
    "        # Simulate GPU transfer\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        if i >= num_batches:\n",
    "            break\n",
    "    \n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    return elapsed / num_batches\n",
    "\n",
    "\n",
    "# Benchmark different configurations\n",
    "print(\"Benchmarking DataLoader configurations...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "worker_counts = [0, 2, 4, 8]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "results = defaultdict(dict)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for num_workers in worker_counts:\n",
    "        try:\n",
    "            avg_time = benchmark_dataloader(train_dataset, batch_size, num_workers)\n",
    "            throughput = batch_size / avg_time\n",
    "            results[batch_size][num_workers] = throughput\n",
    "            print(f\"batch_size={batch_size:3d}, workers={num_workers}: \"\n",
    "                  f\"{avg_time*1000:.2f}ms/batch, {throughput:.0f} samples/sec\")\n",
    "        except Exception as e:\n",
    "            print(f\"batch_size={batch_size:3d}, workers={num_workers}: Error - {e}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize benchmark results\n",
    "if results:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        if batch_size in results:\n",
    "            workers = sorted(results[batch_size].keys())\n",
    "            throughputs = [results[batch_size][w] for w in workers]\n",
    "            ax.plot(workers, throughputs, marker='o', label=f'batch_size={batch_size}')\n",
    "    \n",
    "    ax.set_xlabel('Number of Workers')\n",
    "    ax.set_ylabel('Throughput (samples/sec)')\n",
    "    ax.set_title('DataLoader Throughput Benchmark')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGX Spark Optimization Tips\n",
    "\n",
    "1. **`num_workers`**: Start with 4-8 on DGX Spark. Too many workers can cause memory contention.\n",
    "\n",
    "2. **`batch_size`**: With 128GB unified memory, you can use larger batches! Start at 64-128 and increase.\n",
    "\n",
    "3. **`pin_memory=True`**: Always use this on GPU systems - it enables faster CPU-to-GPU transfer.\n",
    "\n",
    "4. **`prefetch_factor`**: Default is 2. Increase to 4 if data loading is the bottleneck.\n",
    "\n",
    "5. **`persistent_workers=True`**: Keep workers alive between epochs (faster but uses more memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized DataLoader for DGX Spark\n",
    "def create_optimized_loaders(\n",
    "    train_dataset: Dataset,\n",
    "    val_dataset: Dataset,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create optimized DataLoaders for DGX Spark.\n",
    "    \n",
    "    Args:\n",
    "        train_dataset: Training dataset\n",
    "        val_dataset: Validation dataset\n",
    "        batch_size: Batch size (default: 128, increase for DGX Spark)\n",
    "        num_workers: Number of data loading workers (default: 4)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_loader, val_loader)\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        persistent_workers=True if num_workers > 0 else False,\n",
    "        prefetch_factor=2 if num_workers > 0 else None,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size * 2,  # Larger batch for validation\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True if num_workers > 0 else False,\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# Create optimized loaders\n",
    "train_loader, val_loader = create_optimized_loaders(\n",
    "    train_subset, val_subset, batch_size=64, num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Val loader: {len(val_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Understanding the Beta Distribution for Mixup\n\n**Mixup** is a data augmentation technique that creates new training samples by blending two existing samples. The key to Mixup is choosing the mixing ratio Œª (lambda).\n\nWe sample Œª from a **Beta distribution**: `Œª ~ Beta(Œ±, Œ±)`\n\nThe **Beta distribution** is a probability distribution on [0, 1] - perfect for mixing ratios!\n- When Œ± = 1.0: Uniform distribution (Œª can be anything from 0 to 1)\n- When Œ± < 1.0: U-shaped (Œª tends toward 0 or 1 - minimal mixing)\n- When Œ± > 1.0: Bell-shaped centered at 0.5 (more aggressive mixing)\n\n**Common Mixup settings:**\n- Œ± = 0.2: Mild mixing (most samples stay close to original)\n- Œ± = 0.4: Moderate mixing\n- Œ± = 1.0: Strong mixing (uniform blending)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize the Beta distribution for different alpha values\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 3))\n\nalphas = [0.2, 0.5, 1.0]\nfor ax, alpha in zip(axes, alphas):\n    # Sample 1000 values from Beta(alpha, alpha)\n    samples = np.random.beta(alpha, alpha, 1000)\n    ax.hist(samples, bins=30, density=True, alpha=0.7, edgecolor='black')\n    ax.set_xlabel('Œª (mixing ratio)')\n    ax.set_ylabel('Density')\n    ax.set_title(f'Beta(Œ±={alpha}, Œ±={alpha})')\n    ax.set_xlim(0, 1)\n\nplt.suptitle('Beta Distribution: How Mixup Samples Œª', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# Quick demo of np.random.beta()\nprint(\"Sample Œª values with Œ±=0.2:\")\nfor i in range(5):\n    lam = np.random.beta(0.2, 0.2)\n    print(f\"  Œª = {lam:.3f} ‚Üí {lam*100:.1f}% of image1, {(1-lam)*100:.1f}% of image2\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Exercise\n",
    "\n",
    "Create a custom dataset that loads images and applies **Mixup** augmentation.\n",
    "\n",
    "Mixup creates new training samples by combining two images:\n",
    "```\n",
    "mixed_image = lambda * image1 + (1 - lambda) * image2\n",
    "mixed_label = lambda * label1 + (1 - lambda) * label2\n",
    "```\n",
    "\n",
    "**Requirements:**\n",
    "1. Implement a `MixupDataset` wrapper class\n",
    "2. The class should wrap any existing dataset\n",
    "3. Implement mixup in `__getitem__`\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "```python\n",
    "class MixupDataset(Dataset):\n",
    "    def __init__(self, dataset, alpha=0.2):\n",
    "        self.dataset = dataset\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Get first sample\n",
    "        img1, label1 = self.dataset[idx]\n",
    "        \n",
    "        # Get random second sample\n",
    "        idx2 = np.random.randint(len(self.dataset))\n",
    "        img2, label2 = self.dataset[idx2]\n",
    "        \n",
    "        # Sample lambda from Beta distribution\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        \n",
    "        # Mix!\n",
    "        mixed_img = lam * img1 + (1 - lam) * img2\n",
    "        # For labels, return both and lambda for loss computation\n",
    "        return mixed_img, (label1, label2, lam)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# YOUR CODE HERE: Implement MixupDataset\nclass MixupDataset(Dataset):\n    \"\"\"\n    Dataset wrapper that applies Mixup augmentation.\n    \n    Mixup creates new training samples by combining two images:\n        mixed_image = lambda * image1 + (1 - lambda) * image2\n        \n    Args:\n        dataset: Base dataset to wrap\n        alpha: Beta distribution parameter (default: 0.2)\n    \n    Returns from __getitem__:\n        Tuple of (mixed_image, (label1, label2, lambda))\n    \"\"\"\n    \n    def __init__(self, dataset: Dataset, alpha: float = 0.2) -> None:\n        \"\"\"Initialize with a base dataset and mixup alpha parameter.\"\"\"\n        # TODO: Store the dataset and alpha\n        # self.dataset = ...\n        # self.alpha = ...\n        raise NotImplementedError(\"Implement __init__: store dataset and alpha\")\n    \n    def __len__(self) -> int:\n        \"\"\"Return the length of the wrapped dataset.\"\"\"\n        # TODO: Return len(self.dataset)\n        raise NotImplementedError(\"Implement __len__: return length of wrapped dataset\")\n    \n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Tuple[int, int, float]]:\n        \"\"\"\n        Get a mixup sample.\n        \n        Steps:\n        1. Get first sample from dataset[idx]\n        2. Get random second sample from dataset\n        3. Sample lambda from Beta(alpha, alpha) distribution\n        4. Mix images: lam * img1 + (1 - lam) * img2\n        5. Return mixed_img, (label1, label2, lam)\n        \n        Returns:\n            Tuple of (mixed_image, (label1, label2, lambda))\n        \"\"\"\n        # TODO: Implement the mixup logic\n        # img1, label1 = self.dataset[idx]\n        # idx2 = np.random.randint(len(self.dataset))\n        # img2, label2 = self.dataset[idx2]\n        # lam = np.random.beta(self.alpha, self.alpha)\n        # mixed_img = lam * img1 + (1 - lam) * img2\n        # return mixed_img, (label1, label2, lam)\n        raise NotImplementedError(\"Implement __getitem__: apply mixup augmentation\")\n\n# Test your implementation (uncomment after implementing)\n# mixup_dataset = MixupDataset(train_dataset, alpha=0.2)\n# mixed_img, (label1, label2, lam) = mixup_dataset[0]\n# print(f\"Mixed image shape: {mixed_img.shape}\")\n# print(f\"Labels: {label1}, {label2}, lambda={lam:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Applying augmentation to validation data\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - augmenting validation data adds noise to metrics\n",
    "val_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),  # NO!\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# ‚úÖ Right - validation should be deterministic\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),  # Deterministic crop\n",
    "    T.ToTensor(),\n",
    "])\n",
    "```\n",
    "\n",
    "### Mistake 2: Wrong number of workers\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - too many workers on limited system\n",
    "loader = DataLoader(dataset, num_workers=32)  # CPU has only 8 cores\n",
    "\n",
    "# ‚úÖ Right - match to available cores\n",
    "import multiprocessing\n",
    "num_workers = min(4, multiprocessing.cpu_count())\n",
    "loader = DataLoader(dataset, num_workers=num_workers)\n",
    "```\n",
    "\n",
    "### Mistake 3: Forgetting `pin_memory` on GPU\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - slower GPU transfer\n",
    "loader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "# ‚úÖ Right - faster GPU transfer\n",
    "loader = DataLoader(dataset, batch_size=64, pin_memory=True)\n",
    "```\n",
    "\n",
    "### Mistake 4: Not handling normalization correctly\n",
    "\n",
    "```python\n",
    "# ‚ùå Wrong - normalizing with wrong statistics\n",
    "transform = T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Generic\n",
    "\n",
    "# ‚úÖ Right - use dataset-specific statistics\n",
    "# For ImageNet pretrained models:\n",
    "transform = T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "# For CIFAR-10:\n",
    "transform = T.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ How to create custom `Dataset` classes\n",
    "- ‚úÖ Data augmentation with `torchvision.transforms`\n",
    "- ‚úÖ Configuring `DataLoader` for optimal performance\n",
    "- ‚úÖ Benchmarking data loading throughput\n",
    "- ‚úÖ DGX Spark-specific optimizations\n",
    "\n",
    "---\n",
    "\n",
    "## Challenge (Optional)\n",
    "\n",
    "Implement a **Prefetching DataLoader** that:\n",
    "1. Runs data loading in a background thread\n",
    "2. Keeps 3-5 batches ready at all times\n",
    "3. Transfers batches to GPU asynchronously\n",
    "\n",
    "This can further improve training speed by overlapping data loading with GPU computation.\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [PyTorch Data Loading Tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)\n",
    "- [torchvision.transforms Documentation](https://pytorch.org/vision/stable/transforms.html)\n",
    "- [RandAugment Paper](https://arxiv.org/abs/1909.13719)\n",
    "- [Mixup Paper](https://arxiv.org/abs/1710.09412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cleanup\nimport shutil\nimport gc\n\n# Remove temp sample data directory\nif os.path.exists(SAMPLE_DATA_DIR):\n    shutil.rmtree(SAMPLE_DATA_DIR)\n    print(f\"Removed temp directory: {SAMPLE_DATA_DIR}\")\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\nprint(\"Cleanup complete!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}