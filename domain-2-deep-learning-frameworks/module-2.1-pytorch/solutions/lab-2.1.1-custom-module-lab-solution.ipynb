{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.1.1: Custom Module Lab - SOLUTIONS\n",
    "\n",
    "This notebook contains complete solutions for the exercises in the Custom Module Lab.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Type, Union, List\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1 Solution: BasicBlock with Dropout\n",
    "\n",
    "Adding dropout regularization to the BasicBlock can help prevent overfitting, especially on smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockWithDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    BasicBlock with optional dropout regularization.\n",
    "    \n",
    "    The dropout is applied after the first ReLU, which is a common position\n",
    "    for regularization in residual networks.\n",
    "    \n",
    "    Args:\n",
    "        in_channels: Number of input channels\n",
    "        out_channels: Number of output channels\n",
    "        stride: Stride for the first convolution (default: 1)\n",
    "        dropout: Dropout probability (default: 0.0, meaning no dropout)\n",
    "    \"\"\"\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        stride: int = 1,\n",
    "        dropout: float = 0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First conv\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Dropout layer - uses Dropout2d for spatial dropout\n",
    "        # Dropout2d drops entire channels, which is more suitable for CNNs\n",
    "        self.dropout = nn.Dropout2d(p=dropout) if dropout > 0 else nn.Identity()\n",
    "        \n",
    "        # Second conv\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels,\n",
    "            kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        \n",
    "        # Apply dropout after first ReLU\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += self.shortcut(identity)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Test the implementation\n",
    "print(\"=== Testing BasicBlockWithDropout ===\")\n",
    "\n",
    "# Test with dropout\n",
    "block = BasicBlockWithDropout(64, 64, dropout=0.1)\n",
    "print(f\"Block structure:\\n{block}\")\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(2, 64, 32, 32)\n",
    "block.train()  # Dropout active\n",
    "y_train = block(x)\n",
    "print(f\"\\nTraining mode - Output shape: {y_train.shape}\")\n",
    "\n",
    "block.eval()  # Dropout inactive\n",
    "with torch.no_grad():\n",
    "    y_eval = block(x)\n",
    "print(f\"Eval mode - Output shape: {y_eval.shape}\")\n",
    "\n",
    "# Verify dropout is being applied (outputs should differ in train mode)\n",
    "block.train()\n",
    "y1 = block(x)\n",
    "y2 = block(x)\n",
    "print(f\"\\nOutputs differ in train mode: {not torch.allclose(y1, y2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Dropout2d Instead of Dropout?\n",
    "\n",
    "- **Dropout**: Drops individual values randomly. For images, this can create \"holes\" in feature maps.\n",
    "- **Dropout2d**: Drops entire channels. This is better for CNNs because neighboring pixels are highly correlated.\n",
    "\n",
    "By dropping whole channels, we force the network to learn redundant representations across channels, improving generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Solution: ResNet with SE Blocks\n",
    "\n",
    "Squeeze-and-Excitation (SE) blocks add channel attention to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation Block.\n",
    "    \n",
    "    This block learns to weight channels based on their global importance.\n",
    "    \n",
    "    Architecture:\n",
    "        1. Squeeze: Global average pooling to get channel-wise statistics\n",
    "        2. Excitation: Two FC layers to learn channel weights\n",
    "        3. Scale: Multiply original features by learned weights\n",
    "    \n",
    "    Args:\n",
    "        channels: Number of input/output channels\n",
    "        reduction: Reduction ratio for the bottleneck FC layer (default: 16)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Ensure we have at least 1 channel in the bottleneck\n",
    "        reduced_channels = max(channels // reduction, 1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, reduced_channels, bias=False)\n",
    "        self.fc2 = nn.Linear(reduced_channels, channels, bias=False)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, channels, _, _ = x.shape\n",
    "        \n",
    "        # Squeeze: Global average pooling\n",
    "        y = self.global_pool(x).view(batch_size, channels)\n",
    "        \n",
    "        # Excitation: FC -> ReLU -> FC -> Sigmoid\n",
    "        y = F.relu(self.fc1(y), inplace=True)\n",
    "        y = torch.sigmoid(self.fc2(y))\n",
    "        \n",
    "        # Reshape for broadcasting\n",
    "        y = y.view(batch_size, channels, 1, 1)\n",
    "        \n",
    "        # Scale: Multiply input by channel weights\n",
    "        return x * y\n",
    "\n",
    "\n",
    "class SEBasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    BasicBlock with Squeeze-and-Excitation attention.\n",
    "    \n",
    "    The SE block is added after the second conv, before the residual addition.\n",
    "    \"\"\"\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        stride: int = 1,\n",
    "        reduction: int = 16\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels,\n",
    "            kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # SE attention\n",
    "        self.se = SEBlock(out_channels, reduction)\n",
    "        \n",
    "        # Shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Apply SE attention\n",
    "        out = self.se(out)\n",
    "        \n",
    "        out += self.shortcut(identity)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Test SE Block\n",
    "print(\"=== Testing SE Block ===\")\n",
    "se = SEBlock(64)\n",
    "x = torch.randn(2, 64, 32, 32)\n",
    "y = se(x)\n",
    "print(f\"SE Block: {x.shape} -> {y.shape}\")\n",
    "print(f\"SE Block parameters: {sum(p.numel() for p in se.parameters()):,}\")\n",
    "\n",
    "# Test SE BasicBlock\n",
    "print(\"\\n=== Testing SE BasicBlock ===\")\n",
    "block = SEBasicBlock(64, 128, stride=2)\n",
    "x = torch.randn(2, 64, 32, 32)\n",
    "y = block(x)\n",
    "print(f\"SE BasicBlock: {x.shape} -> {y.shape}\")\n",
    "print(f\"SE BasicBlock parameters: {sum(p.numel() for p in block.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    SE-ResNet: ResNet with Squeeze-and-Excitation blocks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[SEBasicBlock],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 10,\n",
    "        reduction: int = 16\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, block, channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, channels, stride, self.reduction))\n",
    "        self.in_channels = channels * block.expansion\n",
    "        \n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, channels, 1, self.reduction))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def se_resnet18(num_classes: int = 10, reduction: int = 16) -> SEResNet:\n",
    "    \"\"\"Create SE-ResNet-18 model.\"\"\"\n",
    "    return SEResNet(SEBasicBlock, [2, 2, 2, 2], num_classes, reduction)\n",
    "\n",
    "\n",
    "# Compare parameters\n",
    "print(\"=== Model Comparison ===\")\n",
    "\n",
    "# Standard ResNet-18\n",
    "from typing import Union\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return F.relu(out + self.shortcut(x), inplace=True)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_ch = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(64, 2, 1)\n",
    "        self.layer2 = self._make_layer(128, 2, 2)\n",
    "        self.layer3 = self._make_layer(256, 2, 2)\n",
    "        self.layer4 = self._make_layer(512, 2, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, ch, blocks, stride):\n",
    "        layers = [BasicBlock(self.in_ch, ch, stride)]\n",
    "        self.in_ch = ch\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(self.in_ch, ch))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.layer4(self.layer3(self.layer2(self.layer1(x))))\n",
    "        x = self.avgpool(x)\n",
    "        return self.fc(x.flatten(1))\n",
    "\n",
    "resnet = ResNet18(10)\n",
    "se_resnet = se_resnet18(10)\n",
    "\n",
    "resnet_params = sum(p.numel() for p in resnet.parameters())\n",
    "se_resnet_params = sum(p.numel() for p in se_resnet.parameters())\n",
    "\n",
    "print(f\"ResNet-18: {resnet_params:,} parameters\")\n",
    "print(f\"SE-ResNet-18: {se_resnet_params:,} parameters\")\n",
    "print(f\"SE overhead: {(se_resnet_params - resnet_params):,} parameters ({100*(se_resnet_params/resnet_params - 1):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "1. **SE blocks add minimal overhead** (~2% more parameters)\n",
    "2. **But provide significant accuracy gains** (~1% on ImageNet)\n",
    "3. **The attention mechanism** learns which channels are most important for the task\n",
    "4. **Position matters** - SE is applied after convs but before residual addition\n",
    "\n",
    "---\n",
    "\n",
    "## Alternative Implementation: Using nn.Sequential\n",
    "\n",
    "For simpler blocks, you can use `nn.Sequential` for cleaner code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_block(in_channels: int, out_channels: int, stride: int = 1):\n",
    "    \"\"\"\n",
    "    Alternative BasicBlock implementation using nn.Sequential.\n",
    "    \n",
    "    This is more concise but less flexible than the class-based approach.\n",
    "    \"\"\"\n",
    "    \n",
    "    class BasicBlockSequential(nn.Module):\n",
    "        expansion = 1\n",
    "        \n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.main = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "            \n",
    "            self.shortcut = nn.Identity()\n",
    "            if stride != 1 or in_channels != out_channels:\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                    nn.BatchNorm2d(out_channels),\n",
    "                )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return F.relu(self.main(x) + self.shortcut(x), inplace=True)\n",
    "    \n",
    "    return BasicBlockSequential()\n",
    "\n",
    "\n",
    "# Test\n",
    "block = make_basic_block(64, 128, stride=2)\n",
    "x = torch.randn(2, 64, 32, 32)\n",
    "y = block(x)\n",
    "print(f\"Sequential BasicBlock: {x.shape} -> {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Performance Comparison on CIFAR-10\n",
    "\n",
    "Here's a summary of expected performance for different models:\n",
    "\n",
    "| Model | Parameters | CIFAR-10 Accuracy (100 epochs) |\n",
    "|-------|------------|--------------------------------|\n",
    "| ResNet-18 | 11.2M | ~93-94% |\n",
    "| SE-ResNet-18 | 11.4M | ~94-95% |\n",
    "| ResNet-34 | 21.3M | ~94-95% |\n",
    "| ResNet-50 | 23.5M | ~94-95% |\n",
    "\n",
    "**Note:** The small image size (32×32) of CIFAR-10 means deeper networks don't provide as much benefit as they would on ImageNet (224×224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}