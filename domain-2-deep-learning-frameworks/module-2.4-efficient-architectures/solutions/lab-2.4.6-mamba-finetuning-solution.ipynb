{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.4.6: Mamba Fine-tuning - SOLUTIONS\n",
    "\n",
    "Complete solutions for the Mamba fine-tuning exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom datasets import Dataset\n\ntry:\n    from peft import LoraConfig, get_peft_model, TaskType\n    HAS_PEFT = True\nexcept ImportError:\n    HAS_PEFT = False\n    print('PEFT not installed. Run: pip install peft')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solution: Custom Domain Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Customer Service Domain Dataset\n\ncustomer_service_examples = [\n    {\n        'instruction': 'Respond to a customer complaint about late delivery.',\n        'input': 'My order was supposed to arrive 3 days ago and it still has not arrived!',\n        'output': 'I sincerely apologize for the delay in your delivery. I understand how frustrating this must be. Let me check the status of your order right away and provide you with an updated delivery estimate. Would you like me to expedite the shipping at no extra cost?'\n    },\n    {\n        'instruction': 'Help a customer with a refund request.',\n        'input': 'I want to return this product. It does not work as advertised.',\n        'output': 'I am sorry to hear the product did not meet your expectations. We would be happy to process a full refund for you. Could you please provide your order number? We can also arrange a prepaid return label to be sent to your email.'\n    },\n    {\n        'instruction': 'Answer a question about store hours.',\n        'input': 'What time do you close on Saturdays?',\n        'output': 'Our store hours on Saturdays are 9 AM to 6 PM. Is there anything specific you are planning to visit us for? I would be happy to check if the item you need is in stock.'\n    },\n    {\n        'instruction': 'Respond to a billing inquiry.',\n        'input': 'I see a charge I do not recognize on my statement.',\n        'output': 'I understand your concern about the unrecognized charge. For your security, let me help you review this. Could you please provide the last 4 digits of the card and the date of the charge? I will look into this immediately and ensure any unauthorized charges are reversed.'\n    },\n] * 50  # Repeat for training data\n\nprint(f'Customer Service Dataset: {len(customer_service_examples)} examples')\nprint(f'\\nExample:')\nprint(f'Instruction: {customer_service_examples[0][\"instruction\"]}')\nprint(f'Input: {customer_service_examples[0][\"input\"]}')\nprint(f'Output: {customer_service_examples[0][\"output\"][:100]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for training\ndef format_customer_service(example):\n    return f'''### Customer Query:\n{example['input']}\n\n### Instruction:\n{example['instruction']}\n\n### Response:\n{example['output']}'''\n\nformatted_data = [format_customer_service(ex) for ex in customer_service_examples]\nprint('Formatted example:')\nprint(formatted_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Auto-detect LoRA targets for Mamba\nimport torch.nn as nn\n\ndef find_lora_targets(model):\n    \"\"\"Find linear layers suitable for LoRA.\"\"\"\n    linear_layers = []\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Linear):\n            layer_type = name.split('.')[-1]\n            if layer_type not in linear_layers:\n                linear_layers.append(layer_type)\n    return linear_layers\n\n# LoRA configuration for customer service fine-tuning\nif HAS_PEFT:\n    # Preferred Mamba target modules\n    preferred_targets = ['in_proj', 'out_proj', 'x_proj', 'dt_proj']\n    \n    print('LoRA Configuration:')\n    print(f'  Preferred targets: {preferred_targets}')\n    print('  Note: Actual targets will be auto-detected from model architecture')\n    print('  Example code:')\n    print('''\n    available = find_lora_targets(model)\n    valid_targets = [t for t in preferred_targets if t in available]\n    \n    lora_config = LoraConfig(\n        r=16,\n        lora_alpha=32,\n        target_modules=valid_targets,\n        lora_dropout=0.05,\n        bias=\"none\",\n        task_type=TaskType.CAUSAL_LM,\n    )\n    ''')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (for reference)\ntraining_config = '''\nTrainingArguments(\n    output_dir=\"./mamba-customer-service\",\n    num_train_epochs=3,  # More epochs for domain adaptation\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    bf16=True,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    eval_strategy=\"steps\",\n    eval_steps=50,\n    save_strategy=\"epoch\",\n    gradient_checkpointing=True,\n)\n'''\nprint('Recommended Training Configuration:')\nprint(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation prompts for customer service\neval_prompts = [\n    ('Respond to angry customer', 'This is the worst service I have ever received!'),\n    ('Handle refund request', 'I need my money back immediately.'),\n    ('Answer shipping question', 'How long will it take to receive my order?'),\n    ('Resolve technical issue', 'The website is not letting me complete my purchase.'),\n]\n\nprint('Evaluation Prompts for Fine-tuned Model:')\nprint('=' * 60)\nfor instruction, query in eval_prompts:\n    print(f'\\n Instruction: {instruction}')\n    print(f'   Query: {query}')\n\nprint('\\n After fine-tuning, the model should:')\nprint('- Respond with professional, empathetic tone')\nprint('- Offer specific solutions')\nprint('- Follow customer service best practices')\nprint('- Use consistent formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory comparison for fine-tuning\nprint('\\n Memory Requirements for Mamba Fine-tuning:')\nprint('=' * 60)\n\nmodels = [\n    ('Mamba-130M', 0.13, 0.5),\n    ('Mamba-1.4B', 1.4, 5),\n    ('Mamba-2.8B', 2.8, 10),\n]\n\nprint(f'{\"Model\":<15} {\"Full FT (GB)\":<15} {\"LoRA (GB)\":<15} {\"Savings\":<10}')\nprint('-' * 55)\n\nfor name, params_b, lora_params_m in models:\n    full_ft = params_b * 2 * 6  # model + grad + optimizer\n    lora_ft = (params_b * 2) + (lora_params_m / 1000 * 6)\n    savings = (1 - lora_ft / full_ft) * 100\n    print(f'{name:<15} {full_ft:<15.1f} {lora_ft:<15.1f} {savings:.0f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}