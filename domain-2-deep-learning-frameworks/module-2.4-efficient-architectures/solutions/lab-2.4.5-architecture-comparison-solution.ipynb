{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.4.5: Architecture Comparison - SOLUTIONS\n",
    "\n",
    "Complete solutions for the architecture comparison exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom dataclasses import dataclass\nfrom typing import Dict, List\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solution: Add Another Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extended model configuration\nMODELS_TO_COMPARE = {\n    'mamba-2.8b': {\n        'name': 'state-spaces/mamba-2.8b-hf',\n        'architecture': 'Mamba',  # State Space Models\n        'active_ratio': 1.0,\n    },\n    'phi-2': {\n        'name': 'microsoft/phi-2',\n        'architecture': 'Transformer',\n        'active_ratio': 1.0,\n    },\n    'qwen-moe': {\n        'name': 'Qwen/Qwen1.5-MoE-A2.7B',\n        'architecture': 'MoE',\n        'active_ratio': 0.19,  # 2.7B / 14.3B\n    },\n    # Add TinyLlama for smaller comparison\n    'tinyllama': {\n        'name': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n        'architecture': 'Transformer',\n        'active_ratio': 1.0,\n    },\n}\n\nprint('Extended model comparison:')\nfor name, config in MODELS_TO_COMPARE.items():\n    print(f'  {name}: {config[\"architecture\"]} ({config[\"name\"]})')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulated benchmark results for visualization\n# (Replace with actual benchmarks when running with models)\n\n@dataclass\nclass BenchmarkResult:\n    model_name: str\n    architecture: str\n    total_params_b: float\n    active_params_b: float\n    memory_gb: float\n    perplexity: float\n    tokens_per_second: Dict[int, float]\n    peak_memory: Dict[int, float]\n\n# Simulated results\nresults = [\n    BenchmarkResult(\n        model_name='mamba-2.8b',\n        architecture='Mamba',  # State Space Models\n        total_params_b=2.8,\n        active_params_b=2.8,\n        memory_gb=5.6,\n        perplexity=8.2,\n        tokens_per_second={1024: 45, 4096: 42, 16384: 38},\n        peak_memory={1024: 6.0, 4096: 6.2, 16384: 6.5},\n    ),\n    BenchmarkResult(\n        model_name='phi-2',\n        architecture='Transformer',\n        total_params_b=2.7,\n        active_params_b=2.7,\n        memory_gb=5.4,\n        perplexity=6.8,\n        tokens_per_second={1024: 55, 4096: 35, 16384: 15},\n        peak_memory={1024: 6.0, 4096: 12.0, 16384: 28.0},\n    ),\n    BenchmarkResult(\n        model_name='qwen-moe',\n        architecture='MoE',\n        total_params_b=14.3,\n        active_params_b=2.7,\n        memory_gb=28.6,\n        perplexity=7.5,\n        tokens_per_second={1024: 40, 4096: 32, 16384: 18},\n        peak_memory={1024: 30.0, 4096: 36.0, 16384: 48.0},\n    ),\n    BenchmarkResult(\n        model_name='tinyllama',\n        architecture='Transformer',\n        total_params_b=1.1,\n        active_params_b=1.1,\n        memory_gb=2.2,\n        perplexity=9.5,\n        tokens_per_second={1024: 80, 4096: 60, 16384: 25},\n        peak_memory={1024: 2.5, 4096: 5.0, 16384: 12.0},\n    ),\n]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize extended comparison\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Architecture colors: Mamba (State Space Models), Transformer, MoE\ncolors = {'Mamba': '#27AE60', 'Transformer': '#E74C3C', 'MoE': '#3498DB'}\ncontexts = [1024, 4096, 16384]\n\n# Speed comparison\nax = axes[0, 0]\nfor r in results:\n    ctx = sorted(r.tokens_per_second.keys())\n    speeds = [r.tokens_per_second[c] for c in ctx]\n    ax.plot(ctx, speeds, 'o-', label=r.model_name, \n           color=colors.get(r.architecture, '#9B59B6'), linewidth=2)\nax.set_xlabel('Context Length')\nax.set_ylabel('Tokens/Second')\nax.set_title('Generation Speed', fontweight='bold')\nax.legend()\nax.set_xscale('log', base=2)\nax.grid(True, alpha=0.3)\n\n# Memory comparison\nax = axes[0, 1]\nfor r in results:\n    ctx = sorted(r.peak_memory.keys())\n    mems = [r.peak_memory[c] for c in ctx]\n    ax.plot(ctx, mems, 's-', label=r.model_name,\n           color=colors.get(r.architecture, '#9B59B6'), linewidth=2)\nax.axhline(y=128, color='gray', linestyle='--', label='DGX Spark')\nax.set_xlabel('Context Length')\nax.set_ylabel('Peak Memory (GB)')\nax.set_title('Memory Usage', fontweight='bold')\nax.legend()\nax.set_xscale('log', base=2)\nax.grid(True, alpha=0.3)\n\n# Parameter efficiency\nax = axes[1, 0]\nmodels = [r.model_name for r in results]\nx = np.arange(len(models))\nwidth = 0.35\nbars1 = ax.bar(x - width/2, [r.total_params_b for r in results], width, label='Total', color='#3498DB')\nbars2 = ax.bar(x + width/2, [r.active_params_b for r in results], width, label='Active', color='#27AE60')\nax.set_ylabel('Parameters (Billions)')\nax.set_title('Total vs Active Parameters', fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(models, rotation=15)\nax.legend()\n\n# Perplexity\nax = axes[1, 1]\nax.bar(models, [r.perplexity for r in results], \n       color=[colors.get(r.architecture, '#9B59B6') for r in results])\nax.set_ylabel('Perplexity (lower = better)')\nax.set_title('Model Quality', fontweight='bold')\nax.set_xticklabels(models, rotation=15)\n\nplt.tight_layout()\nplt.show()\n\n# Summary table\nprint('\\n Summary Table:')\nprint('=' * 80)\nfor r in results:\n    print(f'{r.model_name:<15} | {r.architecture:<12} | '\n          f'{r.total_params_b:.1f}B total | {r.active_params_b:.1f}B active | '\n          f'PPL: {r.perplexity:.1f}')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}