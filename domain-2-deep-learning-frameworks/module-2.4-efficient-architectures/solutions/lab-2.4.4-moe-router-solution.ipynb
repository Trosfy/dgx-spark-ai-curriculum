{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.4.4: MoE Router Analysis - SOLUTIONS\n",
    "\n",
    "Complete solutions for the MoE router exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts Demonstrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router weight extraction function\ndef extract_router_weights(model, layer_idx=0):\n    '''\n    Extract router weights from MoE model.\n    \n    For Mixtral: model.model.layers[layer_idx].block_sparse_moe.gate.weight\n    For DeepSeek: model.model.layers[layer_idx].mlp.gate.weight\n    '''\n    for name, module in model.named_modules():\n        if 'gate' in name.lower() and hasattr(module, 'weight'):\n            return module.weight.data.clone()\n    return None\n\n# Load balancing loss implementation\ndef compute_load_balancing_loss(router_logits, num_experts=8):\n    '''\n    Compute auxiliary loss for load balancing.\n    \n    Loss = num_experts * sum(expert_usage^2)\n    \n    This encourages uniform distribution across experts.\n    '''\n    probs = F.softmax(router_logits, dim=-1)\n    expert_usage = probs.mean(dim=0)\n    loss = num_experts * (expert_usage ** 2).sum()\n    return loss\n\n# Demo\nprint('Load Balancing Loss Examples:')\nprint('=' * 50)\n\n# Uniform (ideal)\nuniform = torch.zeros(100, 8)\nprint(f'Uniform routing loss: {compute_load_balancing_loss(uniform):.4f}')\n\n# Imbalanced (bad)\nimbalanced = torch.zeros(100, 8)\nimbalanced[:, 0] = 5.0\nprint(f'Imbalanced routing loss: {compute_load_balancing_loss(imbalanced):.4f}')\n\nprint('\\n Lower loss = better load balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-k routing analysis\ndef analyze_topk_routing(logits, top_k=2):\n    '''\n    Analyze top-k expert selection.\n    '''\n    top_values, top_indices = torch.topk(logits, k=top_k, dim=-1)\n    weights = F.softmax(top_values, dim=-1)\n    \n    # Count expert usage\n    expert_counts = {}\n    for i in range(logits.shape[-1]):\n        expert_counts[i] = (top_indices == i).sum().item()\n    \n    return {\n        'expert_counts': expert_counts,\n        'mean_weight_ratio': (weights[:, 0] / weights[:, 1]).mean().item(),\n        'used_experts': sum(1 for c in expert_counts.values() if c > 0),\n    }\n\n# Demo with synthetic data\nlogits = torch.randn(500, 64)\nlogits[:, :5] += 1.0  # Bias towards first 5 experts\n\nresults = analyze_topk_routing(logits, top_k=2)\n\nprint('\\nTop-2 Routing Analysis:')\nprint(f'Experts used: {results[\"used_experts\"]}/64')\nprint(f'Weight ratio (1st/2nd): {results[\"mean_weight_ratio\"]:.2f}')\n\n# Plot\nplt.figure(figsize=(12, 4))\nplt.bar(range(64), [results['expert_counts'].get(i, 0) for i in range(64)])\nplt.axhline(y=500*2/64, color='red', linestyle='--', label='Expected')\nplt.xlabel('Expert Index')\nplt.ylabel('Selection Count')\nplt.title('Expert Selection Distribution')\nplt.legend()\nplt.tight_layout()\nplt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
