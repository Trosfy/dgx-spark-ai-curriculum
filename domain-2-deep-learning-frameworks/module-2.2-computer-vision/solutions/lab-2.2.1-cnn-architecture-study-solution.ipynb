{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7.1 Solution: CNN Architecture Study\n",
    "\n",
    "**Module:** 7 - Computer Vision  \n",
    "**Type:** Solution Notebook\n",
    "\n",
    "---\n",
    "\n",
    "This notebook contains solutions for the CNN architecture exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 Solution: LeNet with MaxPooling\n",
    "\n",
    "MaxPooling typically works better for object recognition because it keeps the strongest activations (\"Was there an edge here?\") rather than averaging (\"How much edge on average?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5_MaxPool(nn.Module):\n",
    "    \"\"\"\n",
    "    LeNet-5 with MaxPooling instead of AvgPooling.\n",
    "    \n",
    "    MaxPooling typically works better for object recognition because\n",
    "    it keeps the strongest activations (\"Was there an edge here?\")\n",
    "    rather than averaging (\"How much edge on average?\").\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super(LeNet5_MaxPool, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Changed from AvgPool\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "model = LeNet5_MaxPool()\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "print(f\"LeNet5_MaxPool output shape: {model(x).shape}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 Solution: Compare Gradient Flow in ResNet vs Plain Network\n",
    "\n",
    "As depth increases, gradients in plain networks tend to vanish, while residual networks maintain gradient flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainBlock(nn.Module):\n",
    "    \"\"\"Plain convolutional block without skip connection.\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(PlainBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return F.relu(out)  # No skip connection!\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with skip connection.\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return F.relu(out + x)  # Skip connection!\n",
    "\n",
    "\n",
    "def compare_gradient_flow(num_blocks: int = 10):\n",
    "    \"\"\"\n",
    "    Compare gradient magnitudes through stacked blocks.\n",
    "    \n",
    "    As depth increases, gradients in plain networks tend to vanish,\n",
    "    while residual networks maintain gradient flow.\n",
    "    \"\"\"\n",
    "    channels = 64\n",
    "    \n",
    "    # Stack blocks\n",
    "    plain_blocks = nn.Sequential(*[PlainBlock(channels) for _ in range(num_blocks)])\n",
    "    res_blocks = nn.Sequential(*[ResidualBlock(channels) for _ in range(num_blocks)])\n",
    "    \n",
    "    # Create input with gradient tracking\n",
    "    x_plain = torch.randn(1, channels, 32, 32, requires_grad=True)\n",
    "    x_res = torch.randn(1, channels, 32, 32, requires_grad=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    out_plain = plain_blocks(x_plain)\n",
    "    out_res = res_blocks(x_res)\n",
    "    \n",
    "    # Backward pass\n",
    "    out_plain.sum().backward()\n",
    "    out_res.sum().backward()\n",
    "    \n",
    "    # Compare gradient magnitudes\n",
    "    grad_plain = x_plain.grad.abs().mean().item()\n",
    "    grad_res = x_res.grad.abs().mean().item()\n",
    "    \n",
    "    return grad_plain, grad_res\n",
    "\n",
    "# Compare at different depths\n",
    "print(\"Gradient Magnitude Comparison (Higher is Better)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Depth':<10} {'Plain Network':<20} {'ResNet':<20}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for depth in [5, 10, 20, 30]:\n",
    "    grad_plain, grad_res = compare_gradient_flow(depth)\n",
    "    print(f\"{depth:<10} {grad_plain:<20.6f} {grad_res:<20.6f}\")\n",
    "\n",
    "print(\"\\nConclusion: ResNet maintains gradient flow even at great depth!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Solution: Squeeze-and-Excitation ResNet\n",
    "\n",
    "SE blocks learn to weight channels by their importance.\n",
    "Paper: \"Squeeze-and-Excitation Networks\" (Hu et al., 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation block.\n",
    "    \n",
    "    Learns to weight channels by their importance.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excite = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, c, _, _ = x.size()\n",
    "        # Squeeze: global average pooling\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        # Excite: learn channel weights\n",
    "        y = self.excite(y).view(b, c, 1, 1)\n",
    "        # Scale: multiply input by channel weights\n",
    "        return x * y\n",
    "\n",
    "\n",
    "class SEBasicBlock(nn.Module):\n",
    "    \"\"\"ResNet BasicBlock with SE attention.\"\"\"\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, reduction: int = 16):\n",
    "        super(SEBasicBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # SE Block\n",
    "        self.se = SEBlock(out_channels, reduction)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.se(out)  # Apply SE attention\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class SEResNet18(nn.Module):\n",
    "    \"\"\"ResNet-18 with Squeeze-and-Excitation blocks.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super(SEResNet18, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = self._make_layer(64, 2, 1)\n",
    "        self.layer2 = self._make_layer(128, 2, 2)\n",
    "        self.layer3 = self._make_layer(256, 2, 2)\n",
    "        self.layer4 = self._make_layer(512, 2, 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, out_channels: int, num_blocks: int, stride: int) -> nn.Sequential:\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(SEBasicBlock(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Test SE-ResNet\n",
    "se_resnet = SEResNet18(num_classes=10)\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "print(f\"SE-ResNet18 output: {se_resnet(x).shape}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in se_resnet.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this solution notebook, we implemented:\n",
    "\n",
    "1. **LeNet with MaxPooling** - Replaced AvgPool with MaxPool for better feature detection\n",
    "2. **Gradient Flow Comparison** - Demonstrated how ResNet maintains gradient flow at depth\n",
    "3. **SE-ResNet** - Added Squeeze-and-Excitation attention to ResNet blocks\n",
    "\n",
    "Key insights:\n",
    "- MaxPooling preserves strongest activations (better for recognition)\n",
    "- Skip connections are essential for training deep networks\n",
    "- Channel attention (SE blocks) can improve accuracy with minimal overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
