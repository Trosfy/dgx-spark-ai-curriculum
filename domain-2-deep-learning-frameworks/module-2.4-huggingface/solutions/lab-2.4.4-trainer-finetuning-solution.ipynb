{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.4.4 Solutions: Trainer Fine-tuning\n",
    "\n",
    "This notebook contains solutions to the exercises in the Trainer Fine-tuning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import evaluate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solution: Train on AG News\n",
    "\n",
    "Fine-tune a model on the AG News dataset (news category classification):\n",
    "1. Load the `ag_news` dataset\n",
    "2. Create appropriate splits\n",
    "3. Tokenize with a model of your choice\n",
    "4. Configure TrainingArguments\n",
    "5. Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load AG News dataset\n",
    "print(\"Loading AG News dataset...\")\n",
    "ag_news = load_dataset(\"ag_news\")\n",
    "\n",
    "# Use subset for faster training in this demo\n",
    "small_train = ag_news['train'].shuffle(seed=42).select(range(8000))\n",
    "small_test = ag_news['test'].shuffle(seed=42).select(range(2000))\n",
    "\n",
    "print(f\"Train samples: {len(small_train)}\")\n",
    "print(f\"Test samples: {len(small_test)}\")\n",
    "\n",
    "# Show label distribution\n",
    "print(f\"\\nLabels:\")\n",
    "print(\"  0 = World\")\n",
    "print(\"  1 = Sports\")\n",
    "print(\"  2 = Business\")\n",
    "print(\"  3 = Sci/Tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create train/validation split\n",
    "train_val = small_train.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=42,\n",
    "    stratify_by_column='label'\n",
    ")\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_val['train'],\n",
    "    'validation': train_val['test'],\n",
    "    'test': small_test\n",
    "})\n",
    "\n",
    "print(f\"Train: {len(dataset['train'])}\")\n",
    "print(f\"Validation: {len(dataset['validation'])}\")\n",
    "print(f\"Test: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load model and tokenizer for 4-class classification\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,\n",
    "    id2label={0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"},\n",
    "    label2id={\"World\": 0, \"Sports\": 1, \"Business\": 2, \"Sci/Tech\": 3}\n",
    ")\n",
    "\n",
    "print(f\"Model loaded with {model.num_parameters():,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128  # AG News articles are relatively short\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing...\")\n",
    "tokenized = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    "    remove_columns=['text']\n",
    ")\n",
    "\n",
    "# Rename label to labels\n",
    "tokenized = tokenized.rename_column('label', 'labels')\n",
    "\n",
    "print(f\"Columns: {tokenized['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Configure TrainingArguments\n",
    "\n",
    "# Load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy and macro F1 for multi-class.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy.compute(predictions=predictions, references=labels)['accuracy'],\n",
    "        'f1_macro': f1.compute(predictions=predictions, references=labels, average='macro')['f1'],\n",
    "        'f1_weighted': f1.compute(predictions=predictions, references=labels, average='weighted')['f1']\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ag_news_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    bf16=torch.cuda.is_available(),\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "print(\"TrainingArguments configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create Trainer and train\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Time: {train_result.metrics['train_runtime']:.1f}s\")\n",
    "print(f\"Loss: {train_result.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(tokenized['test'])\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for key, value in test_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predictions = trainer.predict(tokenized['test'])\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    pred_labels,\n",
    "    target_names=[\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new examples\n",
    "test_texts = [\n",
    "    \"The president announced new trade agreements with European nations today.\",\n",
    "    \"The Lakers won the championship game in overtime with a buzzer-beater.\",\n",
    "    \"Apple stock surged 10% after announcing record quarterly earnings.\",\n",
    "    \"Scientists discover new exoplanet that may contain water.\"\n",
    "]\n",
    "\n",
    "expected = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "print(\"Testing on new examples:\\n\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device).eval()\n",
    "\n",
    "for text, exp in zip(test_texts, expected):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    pred = torch.argmax(probs, dim=1).item()\n",
    "    conf = probs[0][pred].item()\n",
    "    \n",
    "    pred_label = model.config.id2label[pred]\n",
    "    status = \"✓\" if pred_label == exp else \"✗\"\n",
    "    \n",
    "    print(f\"{status} '{text[:50]}...'\")\n",
    "    print(f\"   Expected: {exp}, Predicted: {pred_label} ({conf:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Solution: Multi-class Emotion Detection\n",
    "\n",
    "Train an emotion classifier using the `emotion` dataset (6 emotions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emotion dataset\n",
    "print(\"Loading emotion dataset...\")\n",
    "emotion = load_dataset(\"emotion\")\n",
    "\n",
    "print(f\"Train: {len(emotion['train'])}\")\n",
    "print(f\"Test: {len(emotion['test'])}\")\n",
    "\n",
    "# Emotions: 0=sadness, 1=joy, 2=love, 3=anger, 4=fear, 5=surprise\n",
    "emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "print(f\"\\nEmotion labels: {emotion_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits and prepare model\n",
    "train_val = emotion['train'].train_test_split(test_size=0.1, seed=42)\n",
    "emotion_dataset = DatasetDict({\n",
    "    'train': train_val['train'],\n",
    "    'validation': train_val['test'],\n",
    "    'test': emotion['test']\n",
    "})\n",
    "\n",
    "# Load fresh model for 6 classes\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=6,\n",
    "    id2label={i: label for i, label in enumerate(emotion_labels)},\n",
    "    label2id={label: i for i, label in enumerate(emotion_labels)}\n",
    ")\n",
    "\n",
    "# Tokenize\n",
    "emotion_tokenized = emotion_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=['text']\n",
    ")\n",
    "emotion_tokenized = emotion_tokenized.rename_column('label', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train emotion classifier\n",
    "emotion_args = TrainingArguments(\n",
    "    output_dir=\"./emotion_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    bf16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "emotion_trainer = Trainer(\n",
    "    model=emotion_model,\n",
    "    args=emotion_args,\n",
    "    train_dataset=emotion_tokenized['train'],\n",
    "    eval_dataset=emotion_tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"Training emotion classifier...\")\n",
    "emotion_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate emotion classifier\n",
    "emotion_results = emotion_trainer.evaluate(emotion_tokenized['test'])\n",
    "\n",
    "print(\"\\nEmotion Classification Results:\")\n",
    "for key, value in emotion_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Check if we achieved >90% accuracy\n",
    "if emotion_results['eval_accuracy'] > 0.90:\n",
    "    print(\"\\n✓ Challenge complete! Achieved >90% accuracy!\")\n",
    "else:\n",
    "    print(f\"\\n✗ Accuracy is {emotion_results['eval_accuracy']:.1%}, target is >90%\")\n",
    "    print(\"  Try: more epochs, different learning rate, or larger model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "for path in [\"./ag_news_results\", \"./emotion_results\"]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "del model, emotion_model, trainer, emotion_trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "print(\"Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this solution notebook, we demonstrated:\n",
    "\n",
    "1. **AG News Classification**:\n",
    "   - 4-class news topic classification\n",
    "   - Custom metrics (macro/weighted F1)\n",
    "   - Detailed evaluation with classification report\n",
    "\n",
    "2. **Emotion Detection**:\n",
    "   - 6-class emotion classification\n",
    "   - Target accuracy >90%\n",
    "\n",
    "Key learnings:\n",
    "- Configure `num_labels` for multi-class\n",
    "- Use appropriate F1 averaging for multi-class\n",
    "- Early stopping prevents overfitting\n",
    "- Classification reports help identify weak classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}