{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.4.2 Solutions: Pipeline Showcase\n",
    "\n",
    "This notebook contains solutions to the exercises in the Pipeline Showcase notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solution: Customer Support Bot\n",
    "\n",
    "Build a simple customer support analyzer that:\n",
    "1. Detects if the customer is angry (sentiment)\n",
    "2. Extracts product names mentioned (NER)\n",
    "3. Generates a helpful response (generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_support_ticket(ticket_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze a customer support ticket.\n",
    "    \n",
    "    Args:\n",
    "        ticket_text: The customer's message\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with sentiment, entities, and generated response\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'ticket': ticket_text,\n",
    "        'sentiment': None,\n",
    "        'entities': [],\n",
    "        'suggested_response': None\n",
    "    }\n",
    "    \n",
    "    # 1. Sentiment Analysis\n",
    "    sentiment_pipe = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "        device=device\n",
    "    )\n",
    "    sentiment_result = sentiment_pipe(ticket_text)[0]\n",
    "    results['sentiment'] = {\n",
    "        'label': sentiment_result['label'],\n",
    "        'score': sentiment_result['score']\n",
    "    }\n",
    "    \n",
    "    # Cleanup\n",
    "    del sentiment_pipe\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # 2. Named Entity Recognition\n",
    "    ner_pipe = pipeline(\n",
    "        \"ner\",\n",
    "        model=\"dslim/bert-base-NER\",\n",
    "        aggregation_strategy=\"simple\",\n",
    "        device=device\n",
    "    )\n",
    "    entities = ner_pipe(ticket_text)\n",
    "    results['entities'] = [\n",
    "        {'text': e['word'], 'type': e['entity_group'], 'confidence': e['score']}\n",
    "        for e in entities\n",
    "    ]\n",
    "    \n",
    "    # Cleanup\n",
    "    del ner_pipe\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # 3. Generate Response based on sentiment\n",
    "    gen_pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"distilgpt2\",\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    if results['sentiment']['label'] == 'NEGATIVE':\n",
    "        prompt = \"Dear valued customer, we sincerely apologize for the inconvenience. We understand your frustration and\"\n",
    "    else:\n",
    "        prompt = \"Dear valued customer, thank you for reaching out! We're delighted to hear from you and\"\n",
    "    \n",
    "    response = gen_pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=gen_pipe.tokenizer.eos_token_id\n",
    "    )\n",
    "    results['suggested_response'] = response[0]['generated_text']\n",
    "    \n",
    "    # Cleanup\n",
    "    del gen_pipe\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample tickets\n",
    "sample_tickets = [\n",
    "    \"I've been waiting 3 weeks for my MacBook to arrive! This is unacceptable!\",\n",
    "    \"Just wanted to say your customer service team was amazing. Thanks!\",\n",
    "    \"The iPhone screen is cracked and it's only been a week since I bought it.\"\n",
    "]\n",
    "\n",
    "print(\"CUSTOMER SUPPORT TICKET ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, ticket in enumerate(sample_tickets, 1):\n",
    "    print(f\"\\n--- Ticket {i} ---\")\n",
    "    result = analyze_support_ticket(ticket)\n",
    "    \n",
    "    print(f\"Ticket: {result['ticket']}\")\n",
    "    print(f\"\\nSentiment: {result['sentiment']['label']} ({result['sentiment']['score']:.2%})\")\n",
    "    \n",
    "    print(f\"\\nEntities found:\")\n",
    "    if result['entities']:\n",
    "        for e in result['entities']:\n",
    "            print(f\"  - {e['text']} ({e['type']}, {e['confidence']:.2%})\")\n",
    "    else:\n",
    "        print(\"  No entities detected\")\n",
    "    \n",
    "    print(f\"\\nSuggested Response:\")\n",
    "    print(f\"  {result['suggested_response'][:200]}...\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Solution: Content Moderation System\n",
    "\n",
    "Create a content moderation pipeline that:\n",
    "1. Detects toxic language\n",
    "2. Extracts mentioned entities\n",
    "3. Summarizes the content for human review\n",
    "4. Generates a moderation decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moderate_content(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze content for moderation.\n",
    "    \n",
    "    Args:\n",
    "        text: Content to moderate\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with moderation analysis\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'original_text': text,\n",
    "        'toxicity': None,\n",
    "        'entities': [],\n",
    "        'summary': None,\n",
    "        'decision': None,\n",
    "        'reason': None\n",
    "    }\n",
    "    \n",
    "    # 1. Toxicity Detection (using sentiment as proxy - in production use toxicity model)\n",
    "    # Note: For real moderation, use models like 'unitary/toxic-bert'\n",
    "    sentiment_pipe = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "        device=device\n",
    "    )\n",
    "    sentiment = sentiment_pipe(text)[0]\n",
    "    # In production, use actual toxicity scores\n",
    "    results['toxicity'] = {\n",
    "        'is_negative': sentiment['label'] == 'NEGATIVE',\n",
    "        'confidence': sentiment['score']\n",
    "    }\n",
    "    del sentiment_pipe\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # 2. Entity Extraction\n",
    "    ner_pipe = pipeline(\"ner\", aggregation_strategy=\"simple\", device=device)\n",
    "    entities = ner_pipe(text)\n",
    "    results['entities'] = [\n",
    "        {'text': e['word'], 'type': e['entity_group']}\n",
    "        for e in entities\n",
    "    ]\n",
    "    del ner_pipe\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # 3. Summarization (for longer texts)\n",
    "    if len(text.split()) > 30:\n",
    "        summarizer = pipeline(\n",
    "            \"summarization\",\n",
    "            model=\"sshleifer/distilbart-cnn-12-6\",\n",
    "            device=device\n",
    "        )\n",
    "        summary = summarizer(text, max_length=50, min_length=10)[0]\n",
    "        results['summary'] = summary['summary_text']\n",
    "        del summarizer\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    else:\n",
    "        results['summary'] = text\n",
    "    \n",
    "    # 4. Decision Logic\n",
    "    if results['toxicity']['is_negative'] and results['toxicity']['confidence'] > 0.9:\n",
    "        results['decision'] = 'FLAG_FOR_REVIEW'\n",
    "        results['reason'] = 'High confidence negative sentiment detected'\n",
    "    elif results['toxicity']['is_negative'] and results['toxicity']['confidence'] > 0.7:\n",
    "        results['decision'] = 'REVIEW_RECOMMENDED'\n",
    "        results['reason'] = 'Moderate negative sentiment detected'\n",
    "    else:\n",
    "        results['decision'] = 'APPROVE'\n",
    "        results['reason'] = 'Content appears acceptable'\n",
    "    \n",
    "    # Check for sensitive entities (e.g., if people are mentioned in negative context)\n",
    "    person_entities = [e for e in results['entities'] if e['type'] == 'PER']\n",
    "    if person_entities and results['toxicity']['is_negative']:\n",
    "        results['decision'] = 'FLAG_FOR_REVIEW'\n",
    "        results['reason'] += f' - Names mentioned: {\", \".join([e[\"text\"] for e in person_entities])}'\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test content moderation\n",
    "test_content = [\n",
    "    \"This product is amazing! Best purchase I've ever made.\",\n",
    "    \"John Smith is the worst manager. He should be fired immediately.\",\n",
    "    \"The weather is nice today and I enjoyed my walk in Central Park.\"\n",
    "]\n",
    "\n",
    "print(\"CONTENT MODERATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for content in test_content:\n",
    "    result = moderate_content(content)\n",
    "    \n",
    "    print(f\"\\nContent: {content[:60]}...\" if len(content) > 60 else f\"\\nContent: {content}\")\n",
    "    print(f\"Decision: {result['decision']}\")\n",
    "    print(f\"Reason: {result['reason']}\")\n",
    "    print(f\"Entities: {[e['text'] for e in result['entities']]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this solution notebook, we demonstrated:\n",
    "\n",
    "1. **Customer Support Bot** that:\n",
    "   - Analyzes sentiment to detect customer mood\n",
    "   - Extracts product/company mentions using NER\n",
    "   - Generates appropriate responses based on sentiment\n",
    "\n",
    "2. **Content Moderation System** that:\n",
    "   - Detects potentially problematic content\n",
    "   - Identifies mentioned entities\n",
    "   - Provides moderation decisions with reasoning\n",
    "\n",
    "Key learnings:\n",
    "- Chain multiple pipelines for complex tasks\n",
    "- Clean up GPU memory between pipelines\n",
    "- Use appropriate models for each subtask\n",
    "- Combine ML outputs with business logic for decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}