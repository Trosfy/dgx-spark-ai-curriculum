{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.5.2 Solution: Multi-Pipeline Customer Feedback Analyzer\n",
    "\n",
    "This notebook provides the complete solution for the \"Try It Yourself\" exercise in Lab 2.5.2.\n",
    "\n",
    "**Task**: Create a function that analyzes customer feedback using multiple pipelines:\n",
    "1. Sentiment analysis\n",
    "2. Named Entity Recognition\n",
    "3. Summarization (for long text)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from typing import Dict, Any, List\n",
    "import json\n",
    "\n",
    "DEVICE = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {'GPU' if DEVICE >= 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Complete Customer Feedback Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerFeedbackAnalyzer:\n",
    "    \"\"\"\n",
    "    Comprehensive customer feedback analyzer using multiple HuggingFace pipelines.\n",
    "    \n",
    "    Features:\n",
    "    - Sentiment analysis\n",
    "    - Named entity extraction\n",
    "    - Text summarization (for long feedback)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, device: int = -1):\n",
    "        \"\"\"\n",
    "        Initialize all pipelines.\n",
    "        \n",
    "        Args:\n",
    "            device: -1 for CPU, 0+ for GPU\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        \n",
    "        print(\"Loading pipelines...\")\n",
    "        \n",
    "        # Sentiment analysis\n",
    "        self.sentiment = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "            device=device\n",
    "        )\n",
    "        print(\"  [OK] Sentiment analyzer loaded\")\n",
    "        \n",
    "        # Named Entity Recognition\n",
    "        self.ner = pipeline(\n",
    "            \"ner\",\n",
    "            model=\"dslim/bert-base-NER\",\n",
    "            aggregation_strategy=\"simple\",\n",
    "            device=device\n",
    "        )\n",
    "        print(\"  [OK] NER loaded\")\n",
    "        \n",
    "        # Summarization\n",
    "        self.summarizer = pipeline(\n",
    "            \"summarization\",\n",
    "            model=\"facebook/bart-large-cnn\",\n",
    "            device=device,\n",
    "            torch_dtype=torch.bfloat16 if device >= 0 else torch.float32\n",
    "        )\n",
    "        print(\"  [OK] Summarizer loaded\")\n",
    "        \n",
    "        print(\"\\nAll pipelines ready!\")\n",
    "    \n",
    "    def analyze(self, text: str, summarize_threshold: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze customer feedback.\n",
    "        \n",
    "        Args:\n",
    "            text: Customer feedback text\n",
    "            summarize_threshold: Word count threshold for summarization\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with analysis results\n",
    "        \"\"\"\n",
    "        result = {\n",
    "            \"original_text\": text,\n",
    "            \"word_count\": len(text.split()),\n",
    "            \"sentiment\": None,\n",
    "            \"entities\": [],\n",
    "            \"summary\": None\n",
    "        }\n",
    "        \n",
    "        # 1. Sentiment Analysis\n",
    "        sentiment_result = self.sentiment(text)[0]\n",
    "        result[\"sentiment\"] = {\n",
    "            \"label\": sentiment_result[\"label\"],\n",
    "            \"score\": round(sentiment_result[\"score\"], 4),\n",
    "            \"is_positive\": sentiment_result[\"label\"] == \"POSITIVE\"\n",
    "        }\n",
    "        \n",
    "        # 2. Named Entity Recognition\n",
    "        entities = self.ner(text)\n",
    "        result[\"entities\"] = [\n",
    "            {\n",
    "                \"text\": ent[\"word\"],\n",
    "                \"type\": ent[\"entity_group\"],\n",
    "                \"confidence\": round(ent[\"score\"], 4)\n",
    "            }\n",
    "            for ent in entities\n",
    "        ]\n",
    "        \n",
    "        # 3. Summarization (if text is long enough)\n",
    "        if result[\"word_count\"] > summarize_threshold:\n",
    "            summary = self.summarizer(\n",
    "                text,\n",
    "                max_length=60,\n",
    "                min_length=20,\n",
    "                do_sample=False\n",
    "            )[0][\"summary_text\"]\n",
    "            result[\"summary\"] = summary\n",
    "        else:\n",
    "            result[\"summary\"] = \"(Text too short for summarization)\"\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def format_report(self, analysis: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Format analysis results as a readable report.\n",
    "        \"\"\"\n",
    "        report = []\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(\"CUSTOMER FEEDBACK ANALYSIS REPORT\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        # Original text\n",
    "        report.append(f\"\\nFEEDBACK ({analysis['word_count']} words):\")\n",
    "        report.append(\"-\" * 40)\n",
    "        text_preview = analysis['original_text'][:200]\n",
    "        if len(analysis['original_text']) > 200:\n",
    "            text_preview += \"...\"\n",
    "        report.append(text_preview)\n",
    "        \n",
    "        # Sentiment\n",
    "        report.append(f\"\\nSENTIMENT:\")\n",
    "        report.append(\"-\" * 40)\n",
    "        sentiment = analysis['sentiment']\n",
    "        emoji = \"\" if sentiment['is_positive'] else \"\"\n",
    "        report.append(f\"  {emoji} {sentiment['label']} (confidence: {sentiment['score']:.1%})\")\n",
    "        \n",
    "        # Entities\n",
    "        report.append(f\"\\nENTITIES FOUND:\")\n",
    "        report.append(\"-\" * 40)\n",
    "        if analysis['entities']:\n",
    "            for ent in analysis['entities']:\n",
    "                report.append(f\"  - {ent['type']:12}: '{ent['text']}' ({ent['confidence']:.1%})\")\n",
    "        else:\n",
    "            report.append(\"  (No entities detected)\")\n",
    "        \n",
    "        # Summary\n",
    "        report.append(f\"\\nSUMMARY:\")\n",
    "        report.append(\"-\" * 40)\n",
    "        report.append(f\"  {analysis['summary']}\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\" * 60)\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Free GPU memory.\"\"\"\n",
    "        del self.sentiment, self.ner, self.summarizer\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = CustomerFeedbackAnalyzer(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample feedback\n",
    "sample_feedback = \"\"\"\n",
    "I bought the iPhone 15 Pro from Apple Store in San Francisco last week. \n",
    "The sales representative John was incredibly helpful and knowledgeable. \n",
    "However, I'm disappointed with the battery life - it barely lasts a full day \n",
    "with normal usage. The camera quality is excellent though, especially for \n",
    "low-light photography. I've contacted Apple Support and they suggested a \n",
    "software update might help. Overall, it's a mixed experience but I'm hopeful \n",
    "the issues will be resolved. Would recommend waiting for the next update \n",
    "before purchasing.\n",
    "\"\"\"\n",
    "\n",
    "# Analyze\n",
    "analysis = analyzer.analyze(sample_feedback)\n",
    "\n",
    "# Print formatted report\n",
    "print(analyzer.format_report(analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with more samples\n",
    "test_feedbacks = [\n",
    "    \"Terrible experience with Amazon delivery. My package arrived damaged and customer service was unhelpful. Never ordering again!\",\n",
    "    \"Microsoft Teams has been fantastic for our remote work. The integration with Office 365 is seamless. Our team in Seattle loves it!\",\n",
    "    \"Met with Dr. Johnson at Mayo Clinic yesterday. The care was exceptional and the diagnosis was thorough. Highly recommend!\"\n",
    "]\n",
    "\n",
    "print(\"\\nAnalyzing multiple feedbacks...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, feedback in enumerate(test_feedbacks, 1):\n",
    "    print(f\"\\n--- Feedback {i} ---\")\n",
    "    analysis = analyzer.analyze(feedback)\n",
    "    \n",
    "    sentiment = analysis['sentiment']\n",
    "    emoji = \"\" if sentiment['is_positive'] else \"\"\n",
    "    \n",
    "    print(f\"Sentiment: {emoji} {sentiment['label']} ({sentiment['score']:.1%})\")\n",
    "    print(f\"Entities: {[e['text'] for e in analysis['entities']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output as JSON for API usage\n",
    "print(\"\\nJSON Output (for API integration):\")\n",
    "print(\"-\" * 60)\n",
    "analysis = analyzer.analyze(sample_feedback)\n",
    "# Remove original text for cleaner JSON\n",
    "json_output = {k: v for k, v in analysis.items() if k != 'original_text'}\n",
    "print(json.dumps(json_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "analyzer.cleanup()\n",
    "print(\"\\nAnalyzer cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Alternative: Simple Function Version\n",
    "\n",
    "If you prefer a simpler function without a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_customer_feedback(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple function to analyze customer feedback.\n",
    "    \n",
    "    Note: This creates pipelines each time - not efficient for batch processing.\n",
    "    Use the class version for production.\n",
    "    \"\"\"\n",
    "    # Create pipelines\n",
    "    sentiment_pipe = pipeline(\"sentiment-analysis\", device=DEVICE)\n",
    "    ner_pipe = pipeline(\"ner\", aggregation_strategy=\"simple\", device=DEVICE)\n",
    "    \n",
    "    result = {\n",
    "        \"original_text\": text,\n",
    "        \"sentiment\": None,\n",
    "        \"entities\": [],\n",
    "        \"summary\": None\n",
    "    }\n",
    "    \n",
    "    # Sentiment\n",
    "    sent = sentiment_pipe(text)[0]\n",
    "    result[\"sentiment\"] = {\n",
    "        \"label\": sent[\"label\"],\n",
    "        \"score\": sent[\"score\"]\n",
    "    }\n",
    "    \n",
    "    # Entities\n",
    "    entities = ner_pipe(text)\n",
    "    result[\"entities\"] = [\n",
    "        {\"text\": e[\"word\"], \"type\": e[\"entity_group\"]}\n",
    "        for e in entities\n",
    "    ]\n",
    "    \n",
    "    # Summarization only if long\n",
    "    if len(text.split()) > 100:\n",
    "        summarizer = pipeline(\"summarization\", device=DEVICE)\n",
    "        result[\"summary\"] = summarizer(text, max_length=60)[0][\"summary_text\"]\n",
    "        del summarizer\n",
    "    \n",
    "    # Cleanup\n",
    "    del sentiment_pipe, ner_pipe\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test\n",
    "# result = analyze_customer_feedback(\"Great product from Apple!\")\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
