{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.5.6: Uploading Models to the Hugging Face Hub\n",
    "\n",
    "**Module:** 2.5 - Hugging Face Ecosystem  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ⭐⭐ (Intermediate)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- [ ] Authenticate with the Hugging Face Hub\n",
    "- [ ] Create a comprehensive model card\n",
    "- [ ] Push a fine-tuned model to the Hub\n",
    "- [ ] Use your uploaded model with `pipeline()`\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed: Labs 2.5.1 through 2.5.5\n",
    "- **HF Account**: Create one at https://huggingface.co/join\n",
    "- **Access Token**: Get one from https://huggingface.co/settings/tokens\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "**Sharing is Caring**: You've just fine-tuned an amazing sentiment classifier. Now you can:\n",
    "- Share it with your team (private models)\n",
    "- Share it with the world (public models)\n",
    "- Use it in any project with one line: `pipeline(\"your-username/your-model\")`\n",
    "\n",
    "The Hub is not just storage - it's your AI portfolio, demonstrating your skills to employers and collaborators!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ELI5: Why Share Models?\n",
    "\n",
    "> **Imagine you baked an amazing cake...**\n",
    ">\n",
    "> You could keep the recipe secret, or you could share it so others can:\n",
    "> - Make the same delicious cake\n",
    "> - Improve upon your recipe\n",
    "> - Give you credit for the original\n",
    ">\n",
    "> The Hugging Face Hub is like a cookbook where everyone can:\n",
    "> - Download your \"recipe\" (model weights)\n",
    "> - See the \"instructions\" (model card)\n",
    "> - Try before they download (hosted inference)\n",
    "> - Build upon your work (fork and modify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import HfApi, login, create_repo, upload_folder\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "\n",
    "print(\"Environment Check\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face Hub\n",
    "# Option 1: Interactive login (recommended)\n",
    "login()\n",
    "\n",
    "# Option 2: Use environment variable\n",
    "# os.environ['HF_TOKEN'] = 'your_token_here'\n",
    "\n",
    "# Option 3: Pass token directly (not recommended for shared notebooks)\n",
    "# login(token='your_token_here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify authentication\n",
    "api = HfApi()\n",
    "user_info = api.whoami()\n",
    "\n",
    "print(f\"\\nLogged in as: {user_info['name']}\")\n",
    "print(f\"Username: {user_info['fullname'] if 'fullname' in user_info else 'N/A'}\")\n",
    "\n",
    "USERNAME = user_info['name']\n",
    "print(f\"\\nYour models will be at: huggingface.co/{USERNAME}/...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Preparing a Model for Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Let's fine-tune a quick sentiment model to upload\n",
    "print(\"Step 1: Load base model and dataset\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load small subset for quick training\n",
    "dataset = load_dataset(\"imdb\")\n",
    "train_data = dataset['train'].shuffle(seed=42).select(range(2000))\n",
    "eval_data = dataset['test'].shuffle(seed=42).select(range(500))\n",
    "\n",
    "print(f\"Base model: {model_name}\")\n",
    "print(f\"Train examples: {len(train_data)}\")\n",
    "print(f\"Eval examples: {len(eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LoRA for efficient fine-tuning\n",
    "print(\"\\nStep 2: Apply LoRA\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"],\n",
    "    modules_to_save=[\"classifier\", \"pre_classifier\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "print(\"\\nStep 3: Tokenize\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized_train = train_data.map(tokenize_fn, batched=True, remove_columns=['text'])\n",
    "tokenized_eval = eval_data.map(tokenize_fn, batched=True, remove_columns=['text'])\n",
    "\n",
    "tokenized_train = tokenized_train.rename_column(\"label\", \"labels\")\n",
    "tokenized_eval = tokenized_eval.rename_column(\"label\", \"labels\")\n",
    "\n",
    "print(\"Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print(\"\\nStep 4: Train\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model_for_upload\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=3e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    bf16=True,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model\n",
    "print(\"\\nStep 5: Final Evaluation\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge LoRA weights and save\n",
    "print(\"\\nStep 6: Merge LoRA and Save\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "save_path = \"./model_for_upload/final\"\n",
    "merged_model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# Check files\n",
    "print(\"\\nSaved files:\")\n",
    "for f in os.listdir(save_path):\n",
    "    size = os.path.getsize(os.path.join(save_path, f)) / 1e6\n",
    "    if size > 0.1:\n",
    "        print(f\"  {f}: {size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Creating a Model Card\n",
    "\n",
    "The **Model Card** is crucial - it tells users everything they need to know about your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive model card\n",
    "model_card_content = f\"\"\"\n",
    "---\n",
    "language:\n",
    "- en\n",
    "license: apache-2.0\n",
    "tags:\n",
    "- sentiment-analysis\n",
    "- text-classification\n",
    "- distilbert\n",
    "- lora\n",
    "- imdb\n",
    "datasets:\n",
    "- imdb\n",
    "metrics:\n",
    "- accuracy\n",
    "base_model: distilbert-base-uncased\n",
    "model-index:\n",
    "- name: imdb-sentiment-classifier\n",
    "  results:\n",
    "  - task:\n",
    "      type: text-classification\n",
    "      name: Sentiment Analysis\n",
    "    dataset:\n",
    "      type: imdb\n",
    "      name: IMDB\n",
    "    metrics:\n",
    "    - type: accuracy\n",
    "      value: {eval_results['eval_accuracy']:.4f}\n",
    "---\n",
    "\n",
    "# IMDB Sentiment Classifier\n",
    "\n",
    "This model is a fine-tuned version of [distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased) on the IMDB movie review dataset for sentiment analysis.\n",
    "\n",
    "## Model Description\n",
    "\n",
    "- **Base Model:** distilbert-base-uncased\n",
    "- **Task:** Binary sentiment classification (positive/negative)\n",
    "- **Dataset:** IMDB movie reviews\n",
    "- **Fine-tuning Method:** LoRA (Low-Rank Adaptation)\n",
    "- **Training Framework:** Hugging Face Transformers + PEFT\n",
    "\n",
    "## Intended Use\n",
    "\n",
    "This model is designed for sentiment analysis of English text, particularly movie reviews and similar entertainment-related content.\n",
    "\n",
    "### Direct Use\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"{USERNAME}/imdb-sentiment-classifier\")\n",
    "result = classifier(\"This movie was absolutely fantastic!\")\n",
    "print(result)\n",
    "# [{{{'label': 'LABEL_1', 'score': 0.98}}}}]  # LABEL_1 = Positive\n",
    "```\n",
    "\n",
    "### Labels\n",
    "\n",
    "- **LABEL_0:** Negative sentiment\n",
    "- **LABEL_1:** Positive sentiment\n",
    "\n",
    "## Training Details\n",
    "\n",
    "### Training Data\n",
    "\n",
    "The model was fine-tuned on a subset of the IMDB dataset:\n",
    "- Training examples: 2,000\n",
    "- Evaluation examples: 500\n",
    "\n",
    "### Training Hyperparameters\n",
    "\n",
    "- **Epochs:** 2\n",
    "- **Batch size:** 32\n",
    "- **Learning rate:** 3e-4\n",
    "- **LoRA rank:** 8\n",
    "- **LoRA alpha:** 16\n",
    "- **Precision:** bfloat16\n",
    "\n",
    "### Training Results\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Accuracy | {eval_results['eval_accuracy']:.4f} |\n",
    "| Eval Loss | {eval_results['eval_loss']:.4f} |\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Trained primarily on movie reviews; may not generalize well to other domains\n",
    "- English only\n",
    "- May reflect biases present in the training data\n",
    "\n",
    "## Environmental Impact\n",
    "\n",
    "- **Hardware:** NVIDIA DGX Spark (128GB unified memory)\n",
    "- **Training time:** ~5 minutes\n",
    "- **Carbon emission:** Minimal (local desktop training)\n",
    "\n",
    "## Citation\n",
    "\n",
    "```bibtex\n",
    "@misc{{imdb-sentiment-classifier,\n",
    "  author = {{{USERNAME}}},\n",
    "  title = {{IMDB Sentiment Classifier}},\n",
    "  year = {{2025}},\n",
    "  publisher = {{Hugging Face}},\n",
    "  journal = {{Hugging Face Hub}},\n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# Save the model card\n",
    "with open(os.path.join(save_path, \"README.md\"), \"w\") as f:\n",
    "    f.write(model_card_content)\n",
    "\n",
    "print(\"Model card created!\")\n",
    "print(\"\\nPreview:\")\n",
    "print(\"-\" * 60)\n",
    "print(model_card_content[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Uploading to the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define repository name\n",
    "REPO_NAME = \"imdb-sentiment-classifier\"\n",
    "REPO_ID = f\"{USERNAME}/{REPO_NAME}\"\n",
    "\n",
    "print(f\"Repository ID: {REPO_ID}\")\n",
    "print(f\"URL: https://huggingface.co/{REPO_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create repository on Hub\n",
    "print(\"\\nCreating repository...\")\n",
    "\n",
    "try:\n",
    "    repo_url = create_repo(\n",
    "        repo_id=REPO_NAME,\n",
    "        repo_type=\"model\",\n",
    "        private=False,  # Set to True for private model\n",
    "        exist_ok=True   # Don't error if it already exists\n",
    "    )\n",
    "    print(f\"Repository created/exists: {repo_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model files\n",
    "print(\"\\nUploading model...\")\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=save_path,\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type=\"model\",\n",
    "    commit_message=\"Upload fine-tuned IMDB sentiment classifier\"\n",
    ")\n",
    "\n",
    "print(f\"\\nModel uploaded to: https://huggingface.co/{REPO_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Use push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method: push_to_hub() from the model itself\n",
    "# This is often simpler:\n",
    "\n",
    "# merged_model.push_to_hub(REPO_ID, commit_message=\"Initial upload\")\n",
    "# tokenizer.push_to_hub(REPO_ID, commit_message=\"Add tokenizer\")\n",
    "\n",
    "# Or use the trainer:\n",
    "# trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Using Your Uploaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now anyone can use your model!\n",
    "from transformers import pipeline\n",
    "\n",
    "print(f\"Loading model from Hub: {REPO_ID}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Load from Hub (this downloads and caches the model)\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=REPO_ID,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the loaded model\n",
    "test_texts = [\n",
    "    \"This movie was an absolute masterpiece! The acting was superb.\",\n",
    "    \"Worst film I've seen in years. A complete waste of time.\",\n",
    "    \"It was okay. Not great, not terrible.\",\n",
    "    \"I can't believe how good this was! Must watch for everyone!\",\n",
    "    \"Boring, predictable, and poorly written.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting your uploaded model:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in test_texts:\n",
    "    result = classifier(text)[0]\n",
    "    label = \"POSITIVE\" if result['label'] == 'LABEL_1' else \"NEGATIVE\"\n",
    "    score = result['score']\n",
    "    \n",
    "    emoji = \"\" if label == \"POSITIVE\" else \"\"\n",
    "    print(f\"{emoji} {label:8} ({score:.1%}): {text[:45]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Managing Your Model on the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model info from Hub\n",
    "print(\"\\nModel Info from Hub:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "model_info = api.model_info(REPO_ID)\n",
    "print(f\"Model ID: {model_info.id}\")\n",
    "print(f\"Author: {model_info.author}\")\n",
    "print(f\"Downloads: {model_info.downloads}\")\n",
    "print(f\"Likes: {model_info.likes}\")\n",
    "print(f\"Tags: {model_info.tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List your models on the Hub\n",
    "print(\"\\nYour models on the Hub:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "my_models = api.list_models(author=USERNAME)\n",
    "for m in my_models:\n",
    "    print(f\"  - {m.id}: {m.downloads} downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model card (add more info, fix typos, etc.)\n",
    "# You can do this directly on the Hub website or via API:\n",
    "\n",
    "# Update specific file\n",
    "# api.upload_file(\n",
    "#     path_or_fileobj=\"./updated_README.md\",\n",
    "#     path_in_repo=\"README.md\",\n",
    "#     repo_id=REPO_ID,\n",
    "#     commit_message=\"Update model card\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Best Practices for Model Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MODEL SHARING BEST PRACTICES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_practices = \"\"\"\n",
    "MODEL CARD:\n",
    "  Include all YAML metadata (language, license, tags, datasets)\n",
    "  Describe intended use and limitations clearly\n",
    "  Add example code that works out of the box\n",
    "  Document training hyperparameters\n",
    "  Include performance metrics with evaluation details\n",
    "  Note environmental impact if significant\n",
    "\n",
    "LICENSING:\n",
    "  Choose an appropriate license (apache-2.0, mit, etc.)\n",
    "  Check base model license compatibility\n",
    "  Consider commercial use implications\n",
    "\n",
    "VERSIONING:\n",
    "  Use meaningful commit messages\n",
    "  Tag important versions\n",
    "  Document changes between versions\n",
    "\n",
    "NAMING:\n",
    "  Use descriptive names: \"task-dataset-model\" format\n",
    "  Examples: \"imdb-sentiment-distilbert\", \"ner-conll03-bert\"\n",
    "  Avoid generic names like \"my-model\" or \"test\"\n",
    "\n",
    "TESTING:\n",
    "  Always test loading from Hub before announcing\n",
    "  Include example inputs/outputs\n",
    "  Verify pipeline() works correctly\n",
    "\n",
    "PRIVATE MODELS:\n",
    "  Use private=True for proprietary models\n",
    "  Share with specific users via organization access\n",
    "  Consider gated models for sensitive content\n",
    "\"\"\"\n",
    "print(best_practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself: Upload a Different Model\n",
    "\n",
    "Upload a model trained on a different task or dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Ideas:\n",
    "# 1. Fine-tune on AG News (4-class classification)\n",
    "# 2. Fine-tune on a NER dataset\n",
    "# 3. Train a different base model (BERT, RoBERTa)\n",
    "#\n",
    "# Steps:\n",
    "# 1. Train your model\n",
    "# 2. Create a comprehensive model card\n",
    "# 3. Upload to Hub\n",
    "# 4. Test loading from Hub\n",
    "# 5. Share the link!\n",
    "\n",
    "# Your code here:\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Missing Model Card\n",
    "\n",
    "```python\n",
    "# Wrong: Upload without README.md\n",
    "model.save_pretrained(path)\n",
    "api.upload_folder(path, repo_id)\n",
    "# Result: No description, no usage examples!\n",
    "\n",
    "# Right: Always include model card\n",
    "with open(f\"{path}/README.md\", \"w\") as f:\n",
    "    f.write(model_card_content)\n",
    "api.upload_folder(path, repo_id)\n",
    "```\n",
    "\n",
    "### Mistake 2: Forgetting the Tokenizer\n",
    "\n",
    "```python\n",
    "# Wrong: Only save model\n",
    "model.save_pretrained(path)\n",
    "\n",
    "# Right: Save both model and tokenizer\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)  # Don't forget!\n",
    "```\n",
    "\n",
    "### Mistake 3: Wrong Pipeline Task\n",
    "\n",
    "```python\n",
    "# Wrong: Users try wrong pipeline\n",
    "classifier = pipeline(\"text-generation\", model=repo_id)  # Error!\n",
    "\n",
    "# Right: Document correct task in model card\n",
    "# In README.md:\n",
    "# ```python\n",
    "# classifier = pipeline(\"text-classification\", model=\"user/model\")\n",
    "# ```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- How to authenticate with the Hugging Face Hub\n",
    "- How to create a comprehensive model card\n",
    "- How to upload models to the Hub\n",
    "- How to use uploaded models with pipeline()\n",
    "- Best practices for model sharing\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the entire Module 2.5: Hugging Face Ecosystem! You now know how to:\n",
    "- Explore and use models from the Hub\n",
    "- Build quick prototypes with pipelines\n",
    "- Process datasets efficiently\n",
    "- Fine-tune models with the Trainer API\n",
    "- Use LoRA for parameter-efficient fine-tuning\n",
    "- Share your models with the world!\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Hub Documentation](https://huggingface.co/docs/hub)\n",
    "- [Model Cards Guide](https://huggingface.co/docs/hub/model-cards)\n",
    "- [Creating Model Repos](https://huggingface.co/docs/hub/repositories-getting-started)\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import gc\n",
    "\n",
    "del model, merged_model, trainer, classifier\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"GPU memory after cleanup: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "print(f\"\\nYour model is live at: https://huggingface.co/{REPO_ID}\")\n",
    "print(\"\\nModule 2.5 complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
