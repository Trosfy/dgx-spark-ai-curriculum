{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab A.2: Bias-Variance Decomposition - SOLUTIONS\n",
    "\n",
    "**Module:** A - Statistical Learning Theory  \n",
    "**Type:** Solution Notebook\n",
    "\n",
    "---\n",
    "\n",
    "This notebook contains complete solutions to all exercises from Lab A.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (same as main notebook)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions from main notebook\n",
    "\n",
    "def true_function(x):\n",
    "    return np.sin(2 * x) + 0.5 * np.cos(4 * x)\n",
    "\n",
    "\n",
    "def generate_data(n_samples, noise_std=0.3, x_min=0, x_max=4, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X = np.random.uniform(x_min, x_max, n_samples)\n",
    "    y = true_function(X) + np.random.normal(0, noise_std, n_samples)\n",
    "    return X.reshape(-1, 1), y\n",
    "\n",
    "\n",
    "def fit_polynomial(X, y, degree):\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree, include_bias=False),\n",
    "        LinearRegression()\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def bootstrap_bias_variance(degree, n_samples=100, noise_std=0.3, \n",
    "                           n_bootstrap=200, n_test_points=50):\n",
    "    X_test = np.linspace(0.5, 3.5, n_test_points).reshape(-1, 1)\n",
    "    y_true_test = true_function(X_test.flatten())\n",
    "    all_predictions = np.zeros((n_bootstrap, n_test_points))\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        X_train, y_train = generate_data(n_samples, noise_std, seed=i)\n",
    "        model = fit_polynomial(X_train, y_train, degree)\n",
    "        all_predictions[i] = model.predict(X_test)\n",
    "    \n",
    "    mean_prediction = np.mean(all_predictions, axis=0)\n",
    "    bias_squared = np.mean((mean_prediction - y_true_test) ** 2)\n",
    "    variance = np.mean(np.var(all_predictions, axis=0))\n",
    "    noise = noise_std ** 2\n",
    "    total_error = bias_squared + variance + noise\n",
    "    \n",
    "    return {\n",
    "        'degree': degree,\n",
    "        'bias_squared': bias_squared,\n",
    "        'variance': variance,\n",
    "        'noise': noise,\n",
    "        'total_error': total_error\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1 Solution: Different Noise Levels\n",
    "\n",
    "**Task:** How does optimal model complexity change with noise level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Test different noise levels\n",
    "\n",
    "noise_levels = [0.1, 0.3, 0.6]\n",
    "degrees_to_test = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "results_by_noise = {}\n",
    "\n",
    "for noise in noise_levels:\n",
    "    print(f\"\\nTesting noise_std = {noise}\")\n",
    "    results = []\n",
    "    for degree in degrees_to_test:\n",
    "        result = bootstrap_bias_variance(degree, noise_std=noise, n_bootstrap=100)\n",
    "        results.append(result)\n",
    "    results_by_noise[noise] = results\n",
    "    \n",
    "    # Find optimal\n",
    "    total_errors = [r['total_error'] for r in results]\n",
    "    optimal_idx = np.argmin(total_errors)\n",
    "    optimal_degree = degrees_to_test[optimal_idx]\n",
    "    print(f\"  Optimal degree: {optimal_degree}\")\n",
    "    print(f\"  Min total error: {total_errors[optimal_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for ax, noise in zip(axes, noise_levels):\n",
    "    results = results_by_noise[noise]\n",
    "    \n",
    "    biases = [r['bias_squared'] for r in results]\n",
    "    variances = [r['variance'] for r in results]\n",
    "    totals = [r['total_error'] for r in results]\n",
    "    \n",
    "    ax.plot(degrees_to_test, biases, 'b-o', label='Bias²', linewidth=2)\n",
    "    ax.plot(degrees_to_test, variances, 'r-o', label='Variance', linewidth=2)\n",
    "    ax.plot(degrees_to_test, totals, 'g-o', label='Total', linewidth=2)\n",
    "    ax.axhline(y=noise**2, color='gray', linestyle='--', label=f'Noise={noise**2:.2f}')\n",
    "    \n",
    "    # Mark optimal\n",
    "    optimal_idx = np.argmin(totals)\n",
    "    ax.scatter([degrees_to_test[optimal_idx]], [totals[optimal_idx]], \n",
    "              s=200, color='gold', edgecolors='black', zorder=5, marker='*')\n",
    "    \n",
    "    ax.set_xlabel('Polynomial Degree')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(f'Noise σ = {noise}\\nOptimal degree = {degrees_to_test[optimal_idx]}', fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xticks(degrees_to_test)\n",
    "\n",
    "plt.suptitle('Effect of Noise Level on Optimal Complexity', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Finding:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Higher noise levels favor SIMPLER models!\")\n",
    "print(\"When noise is high, it's harder to distinguish signal\")\n",
    "print(\"from noise, so simpler models are less likely to\")\n",
    "print(\"overfit to the noise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2 Solution: More Training Data\n",
    "\n",
    "**Task:** Does more data allow more complex models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Test different training set sizes\n",
    "\n",
    "def bootstrap_bias_variance_custom(degree, n_samples, noise_std=0.3, n_bootstrap=100):\n",
    "    \"\"\"Modified to accept variable n_samples.\"\"\"\n",
    "    X_test = np.linspace(0.5, 3.5, 50).reshape(-1, 1)\n",
    "    y_true_test = true_function(X_test.flatten())\n",
    "    all_predictions = np.zeros((n_bootstrap, 50))\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        X_train, y_train = generate_data(n_samples, noise_std, seed=i*1000)\n",
    "        model = fit_polynomial(X_train, y_train, degree)\n",
    "        all_predictions[i] = model.predict(X_test)\n",
    "    \n",
    "    mean_prediction = np.mean(all_predictions, axis=0)\n",
    "    bias_squared = np.mean((mean_prediction - y_true_test) ** 2)\n",
    "    variance = np.mean(np.var(all_predictions, axis=0))\n",
    "    \n",
    "    return {\n",
    "        'bias_squared': bias_squared,\n",
    "        'variance': variance,\n",
    "        'total_error': bias_squared + variance + noise_std**2\n",
    "    }\n",
    "\n",
    "\n",
    "sample_sizes = [50, 200, 500]\n",
    "degrees_to_test = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15]\n",
    "\n",
    "results_by_size = {}\n",
    "\n",
    "for n_samples in sample_sizes:\n",
    "    print(f\"\\nTesting n_samples = {n_samples}\")\n",
    "    results = []\n",
    "    for degree in degrees_to_test:\n",
    "        result = bootstrap_bias_variance_custom(degree, n_samples, n_bootstrap=50)\n",
    "        results.append(result)\n",
    "    results_by_size[n_samples] = results\n",
    "    \n",
    "    # Find optimal\n",
    "    total_errors = [r['total_error'] for r in results]\n",
    "    optimal_idx = np.argmin(total_errors)\n",
    "    optimal_degree = degrees_to_test[optimal_idx]\n",
    "    print(f\"  Optimal degree: {optimal_degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of dataset size\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for ax, n_samples in zip(axes, sample_sizes):\n",
    "    results = results_by_size[n_samples]\n",
    "    \n",
    "    biases = [r['bias_squared'] for r in results]\n",
    "    variances = [r['variance'] for r in results]\n",
    "    totals = [r['total_error'] for r in results]\n",
    "    \n",
    "    ax.plot(degrees_to_test, biases, 'b-o', label='Bias²', linewidth=2)\n",
    "    ax.plot(degrees_to_test, variances, 'r-o', label='Variance', linewidth=2)\n",
    "    ax.plot(degrees_to_test, totals, 'g-o', label='Total', linewidth=2)\n",
    "    \n",
    "    # Mark optimal\n",
    "    optimal_idx = np.argmin(totals)\n",
    "    ax.scatter([degrees_to_test[optimal_idx]], [totals[optimal_idx]], \n",
    "              s=200, color='gold', edgecolors='black', zorder=5, marker='*')\n",
    "    \n",
    "    ax.set_xlabel('Polynomial Degree')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(f'n = {n_samples} samples\\nOptimal degree = {degrees_to_test[optimal_idx]}', fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Effect of Dataset Size on Optimal Complexity', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Finding:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"More data allows MORE COMPLEX models!\")\n",
    "print(\"With more data:\")\n",
    "print(\"  - Variance decreases (more stable estimates)\")\n",
    "print(\"  - Optimal complexity shifts to the RIGHT\")\n",
    "print(\"  - This is why big data enables deep learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Solution: Bagging for Variance Reduction\n",
    "\n",
    "**Task:** Prove that averaging predictions (bagging) reduces variance but not bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Implement and test bagging\n",
    "\n",
    "def bagging_predictor(X_train, y_train, X_test, n_models=10, degree=10):\n",
    "    \"\"\"\n",
    "    Train multiple models on bootstrap samples and average predictions.\n",
    "    \n",
    "    This should reduce variance while keeping bias the same.\n",
    "    \"\"\"\n",
    "    n_samples = len(X_train)\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        # Bootstrap sample (sample with replacement)\n",
    "        indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        X_boot = X_train[indices]\n",
    "        y_boot = y_train[indices]\n",
    "        \n",
    "        # Fit model on bootstrap sample\n",
    "        model = fit_polynomial(X_boot, y_boot, degree)\n",
    "        pred = model.predict(X_test)\n",
    "        all_predictions.append(pred)\n",
    "    \n",
    "    # Average predictions\n",
    "    return np.mean(all_predictions, axis=0)\n",
    "\n",
    "\n",
    "def compute_bagging_bias_variance(degree, n_models, n_bootstrap=100):\n",
    "    \"\"\"\n",
    "    Compute bias and variance for bagged model.\n",
    "    \"\"\"\n",
    "    X_test = np.linspace(0.5, 3.5, 50).reshape(-1, 1)\n",
    "    y_true_test = true_function(X_test.flatten())\n",
    "    all_predictions = np.zeros((n_bootstrap, 50))\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        # Generate new training set\n",
    "        X_train, y_train = generate_data(100, noise_std=0.3, seed=i*1000)\n",
    "        \n",
    "        # Get bagged prediction\n",
    "        pred = bagging_predictor(X_train, y_train, X_test, n_models=n_models, degree=degree)\n",
    "        all_predictions[i] = pred\n",
    "    \n",
    "    mean_prediction = np.mean(all_predictions, axis=0)\n",
    "    bias_squared = np.mean((mean_prediction - y_true_test) ** 2)\n",
    "    variance = np.mean(np.var(all_predictions, axis=0))\n",
    "    \n",
    "    return bias_squared, variance\n",
    "\n",
    "\n",
    "print(\"Comparing single model vs bagged model (degree=10):\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Single model\n",
    "single_result = bootstrap_bias_variance(degree=10, n_bootstrap=100)\n",
    "print(f\"\\nSingle Model:\")\n",
    "print(f\"  Bias²: {single_result['bias_squared']:.4f}\")\n",
    "print(f\"  Variance: {single_result['variance']:.4f}\")\n",
    "\n",
    "# Bagged models with different ensemble sizes\n",
    "for n_models in [5, 10, 20]:\n",
    "    bias, var = compute_bagging_bias_variance(degree=10, n_models=n_models, n_bootstrap=50)\n",
    "    print(f\"\\nBagged ({n_models} models):\")\n",
    "    print(f\"  Bias²: {bias:.4f}\")\n",
    "    print(f\"  Variance: {var:.4f}\")\n",
    "    print(f\"  Variance reduction: {(1 - var/single_result['variance'])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the variance reduction\n",
    "ensemble_sizes = [1, 2, 5, 10, 20, 50]\n",
    "biases = []\n",
    "variances = []\n",
    "\n",
    "print(\"Computing for various ensemble sizes...\")\n",
    "for n in ensemble_sizes:\n",
    "    if n == 1:\n",
    "        # Single model\n",
    "        result = bootstrap_bias_variance(degree=10, n_bootstrap=50)\n",
    "        biases.append(result['bias_squared'])\n",
    "        variances.append(result['variance'])\n",
    "    else:\n",
    "        bias, var = compute_bagging_bias_variance(degree=10, n_models=n, n_bootstrap=30)\n",
    "        biases.append(bias)\n",
    "        variances.append(var)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(ensemble_sizes, biases, 'b-o', linewidth=2, markersize=10, label='Bias²')\n",
    "ax.plot(ensemble_sizes, variances, 'r-o', linewidth=2, markersize=10, label='Variance')\n",
    "\n",
    "# Theoretical variance decay (1/n)\n",
    "theoretical_var = [variances[0] / n for n in ensemble_sizes]\n",
    "ax.plot(ensemble_sizes, theoretical_var, 'r--', linewidth=1, alpha=0.5, label='Theoretical 1/n decay')\n",
    "\n",
    "ax.set_xlabel('Number of Models in Ensemble', fontsize=12)\n",
    "ax.set_ylabel('Error Component', fontsize=12)\n",
    "ax.set_title('Bagging: Variance Reduction with Ensemble Size\\n(Bias stays constant!)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Finding:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Bagging REDUCES VARIANCE but leaves BIAS unchanged!\")\n",
    "print(\"This is because:\")\n",
    "print(\"  - Averaging independent estimates reduces their variance\")\n",
    "print(\"  - But the systematic error (bias) is the same for all models\")\n",
    "print(\"  - Variance decreases roughly as 1/n (n = ensemble size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Notes\n",
    "\n",
    "1. **Exercise 1 (Noise Levels)**:\n",
    "   - Low noise (σ=0.1): Can use more complex models (optimal ~degree 5-6)\n",
    "   - High noise (σ=0.6): Need simpler models (optimal ~degree 2-3)\n",
    "   - High noise makes it harder to distinguish signal from noise\n",
    "\n",
    "2. **Exercise 2 (Dataset Size)**:\n",
    "   - More data → Lower variance → Can use more complex models\n",
    "   - n=50: Optimal degree ~4\n",
    "   - n=500: Optimal degree ~6-8\n",
    "   - This is why big data enables deep learning!\n",
    "\n",
    "3. **Challenge (Bagging)**:\n",
    "   - Bagging reduces variance by averaging independent predictions\n",
    "   - Bias stays constant because all models have the same systematic error\n",
    "   - Variance decreases roughly as 1/n where n = number of models\n",
    "   - This is the theoretical foundation for Random Forests!\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Noise level** affects optimal complexity: higher noise → simpler models\n",
    "2. **More data** reduces variance: larger datasets → can use more complex models\n",
    "3. **Bagging** is a variance reduction technique: average models to reduce instability\n",
    "4. **The fundamental tradeoff** remains: you can't eliminate both bias and variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
