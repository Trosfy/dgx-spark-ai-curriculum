{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 15.5: Reproducibility Audit\n",
    "\n",
    "**Module:** 15 - Benchmarking, Evaluation & MLOps  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand why reproducibility matters in ML\n",
    "- [ ] Identify common sources of non-reproducibility\n",
    "- [ ] Implement reproducibility best practices\n",
    "- [ ] Create a reproducibility checklist for your projects\n",
    "- [ ] Verify training reproducibility across runs\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Tasks 15.1-15.4\n",
    "- Knowledge of: PyTorch training, random seeds\n",
    "- Hardware: DGX Spark or any GPU\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "**Reproducibility is the foundation of scientific ML.** Consider these scenarios:\n",
    "\n",
    "- **Research:** \"We can't reproduce your paper's results\" = career problem\n",
    "- **Production:** \"Why does the model perform differently today?\" = debugging nightmare\n",
    "- **Compliance:** \"Prove this model was trained correctly\" = legal requirement\n",
    "- **Collaboration:** \"I ran your code but got different numbers\" = wasted time\n",
    "\n",
    "**Companies take this seriously:**\n",
    "- **Google:** Has internal reproducibility standards for all ML\n",
    "- **Meta:** Publishes training configs for all major models\n",
    "- **OpenAI:** Provides detailed technical reports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßí ELI5: What is Reproducibility?\n",
    "\n",
    "> **Imagine you're baking cookies.** If you follow the EXACT same recipe:\n",
    "> - Same ingredients (flour, sugar, butter)\n",
    "> - Same amounts (2 cups flour, 1 cup sugar)\n",
    "> - Same oven temperature (350¬∞F)\n",
    "> - Same baking time (12 minutes)\n",
    ">\n",
    "> You should get the SAME cookies every time!\n",
    ">\n",
    "> **But ML is trickier.** Even with the same code, you might get different results because:\n",
    "> - Random numbers are used (like shuffling ingredients randomly)\n",
    "> - Hardware behaves slightly differently (like different ovens)\n",
    "> - Software versions change (like using a new recipe book)\n",
    ">\n",
    "> **Reproducibility means:** Given the same inputs, get the same outputs. Every. Single. Time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sources of Non-Reproducibility\n",
    "\n",
    "Let's understand what can cause different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common sources of non-reproducibility\n",
    "REPRODUCIBILITY_ISSUES = {\n",
    "    \"Random Seeds\": {\n",
    "        \"description\": \"Random number generators not seeded consistently\",\n",
    "        \"affected\": [\"Weight initialization\", \"Data shuffling\", \"Dropout\", \"Data augmentation\"],\n",
    "        \"fix\": \"Set seeds for all random sources (Python, NumPy, PyTorch, CUDA)\"\n",
    "    },\n",
    "    \"GPU Non-Determinism\": {\n",
    "        \"description\": \"CUDA operations with non-deterministic algorithms\",\n",
    "        \"affected\": [\"Convolutions\", \"Attention\", \"Certain reduction ops\"],\n",
    "        \"fix\": \"Use torch.use_deterministic_algorithms(True)\"\n",
    "    },\n",
    "    \"Data Order\": {\n",
    "        \"description\": \"Training data loaded in different orders\",\n",
    "        \"affected\": [\"Model convergence\", \"Final weights\"],\n",
    "        \"fix\": \"Fix random seed for data loaders, save shuffling order\"\n",
    "    },\n",
    "    \"Software Versions\": {\n",
    "        \"description\": \"Different package versions have different behaviors\",\n",
    "        \"affected\": [\"Algorithm implementations\", \"Default parameters\"],\n",
    "        \"fix\": \"Lock dependencies, use containers\"\n",
    "    },\n",
    "    \"Hardware Differences\": {\n",
    "        \"description\": \"Different GPUs/CPUs have different floating point behavior\",\n",
    "        \"affected\": [\"Numerical precision\", \"Optimization paths\"],\n",
    "        \"fix\": \"Document hardware, use consistent environments\"\n",
    "    },\n",
    "    \"Floating Point Precision\": {\n",
    "        \"description\": \"FP operations are not perfectly associative\",\n",
    "        \"affected\": [\"Batch normalization\", \"Loss calculations\"],\n",
    "        \"fix\": \"Use deterministic algorithms, be aware of tolerance\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚ö†Ô∏è Common Sources of Non-Reproducibility:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for issue, details in REPRODUCIBILITY_ISSUES.items():\n",
    "    print(f\"\\nüî¥ {issue}\")\n",
    "    print(f\"   {details['description']}\")\n",
    "    print(f\"   Affects: {', '.join(details['affected'])}\")\n",
    "    print(f\"   Fix: {details['fix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Setting Up Reproducible Training\n",
    "\n",
    "Let's implement a robust seed-setting mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "def set_seed(seed: int, deterministic: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Set all random seeds for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed: The random seed to use\n",
    "        deterministic: If True, use deterministic algorithms (slower but reproducible)\n",
    "    \"\"\"\n",
    "    # Python's built-in random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch CPU\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # PyTorch GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    \n",
    "    # Environment variable for hash randomization\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    # Deterministic behavior (may impact performance)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        # For PyTorch 1.8+\n",
    "        try:\n",
    "            torch.use_deterministic_algorithms(True)\n",
    "        except AttributeError:\n",
    "            pass  # Older PyTorch version\n",
    "    \n",
    "    print(f\"‚úÖ All random seeds set to {seed}\")\n",
    "    print(f\"   Deterministic mode: {deterministic}\")\n",
    "\n",
    "# Test it\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify seed setting works\n",
    "def verify_seed_reproducibility(seed: int = 42, n_tests: int = 3):\n",
    "    \"\"\"Verify that setting seeds produces reproducible random numbers.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_tests):\n",
    "        set_seed(seed)\n",
    "        \n",
    "        result = {\n",
    "            \"python_random\": random.random(),\n",
    "            \"numpy_random\": np.random.rand(),\n",
    "            \"torch_random\": torch.rand(1).item(),\n",
    "        }\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            result[\"cuda_random\"] = torch.rand(1, device=\"cuda\").item()\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # Check all results are the same\n",
    "    all_same = all(r == results[0] for r in results)\n",
    "    \n",
    "    print(f\"\\nüîç Seed Reproducibility Test (seed={seed}):\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for key in results[0].keys():\n",
    "        values = [r[key] for r in results]\n",
    "        same = len(set(values)) == 1\n",
    "        status = \"‚úÖ\" if same else \"‚ùå\"\n",
    "        print(f\"  {status} {key}: {values[0]:.6f}\")\n",
    "    \n",
    "    print(f\"\\n{'‚úÖ All random sources are reproducible!' if all_same else '‚ùå Some sources are not reproducible!'}\")\n",
    "    return all_same\n",
    "\n",
    "verify_seed_reproducibility(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Reproducible Model Training\n",
    "\n",
    "Let's create a reproducible training setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model for testing\n",
    "class SimpleNet(nn.Module):\n",
    "    \"\"\"Simple network for reproducibility testing.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=10, hidden_size=20, output_size=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Create reproducible data\n",
    "def create_reproducible_data(seed: int, n_samples: int = 1000):\n",
    "    \"\"\"Create reproducible synthetic data.\"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    X = torch.randn(n_samples, 10)\n",
    "    # Simple linear relationship with noise\n",
    "    y = (X[:, 0] + X[:, 1] > 0).long()\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = create_reproducible_data(42)\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"First few X values: {X[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def train_model(\n",
    "    seed: int,\n",
    "    n_epochs: int = 5,\n",
    "    learning_rate: float = 0.01,\n",
    "    batch_size: int = 32,\n",
    "    verbose: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Train a model with full reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with training results and final model state\n",
    "    \"\"\"\n",
    "    # Set seed BEFORE everything\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Create data (seeded)\n",
    "    X, y = create_reproducible_data(seed)\n",
    "    \n",
    "    # Create data loader with generator for reproducible shuffling\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        generator=g,  # Reproducible shuffling!\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    # Create model (seeded initialization)\n",
    "    model = SimpleNet()\n",
    "    \n",
    "    # Optimizer and loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "        history.append({\"epoch\": epoch, \"loss\": avg_loss, \"accuracy\": accuracy})\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}: loss={avg_loss:.4f}, acc={accuracy:.4f}\")\n",
    "    \n",
    "    # Get final state\n",
    "    final_weights_hash = hash(tuple(model.fc1.weight.flatten().tolist()[:10]))\n",
    "    \n",
    "    return {\n",
    "        \"final_loss\": history[-1][\"loss\"],\n",
    "        \"final_accuracy\": history[-1][\"accuracy\"],\n",
    "        \"history\": history,\n",
    "        \"weights_hash\": final_weights_hash\n",
    "    }\n",
    "\n",
    "# Train with verbose output\n",
    "result = train_model(seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify reproducibility: train multiple times and compare\n",
    "def verify_training_reproducibility(seed: int = 42, n_runs: int = 3):\n",
    "    \"\"\"Verify that training is reproducible across multiple runs.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\nüî¨ Running {n_runs} training runs with seed={seed}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        result = train_model(seed=seed, verbose=False)\n",
    "        results.append(result)\n",
    "        print(f\"Run {i+1}: loss={result['final_loss']:.6f}, acc={result['final_accuracy']:.6f}\")\n",
    "    \n",
    "    # Compare results\n",
    "    losses = [r[\"final_loss\"] for r in results]\n",
    "    accuracies = [r[\"final_accuracy\"] for r in results]\n",
    "    hashes = [r[\"weights_hash\"] for r in results]\n",
    "    \n",
    "    loss_match = all(abs(l - losses[0]) < 1e-6 for l in losses)\n",
    "    acc_match = all(abs(a - accuracies[0]) < 1e-6 for a in accuracies)\n",
    "    hash_match = len(set(hashes)) == 1\n",
    "    \n",
    "    print(f\"\\nüìä Reproducibility Results:\")\n",
    "    print(f\"  {'‚úÖ' if loss_match else '‚ùå'} Final loss identical: {losses[0]:.6f}\")\n",
    "    print(f\"  {'‚úÖ' if acc_match else '‚ùå'} Final accuracy identical: {accuracies[0]:.6f}\")\n",
    "    print(f\"  {'‚úÖ' if hash_match else '‚ùå'} Model weights identical\")\n",
    "    \n",
    "    is_reproducible = loss_match and acc_match and hash_match\n",
    "    \n",
    "    if is_reproducible:\n",
    "        print(f\"\\nüéâ Training is fully reproducible!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Training has reproducibility issues!\")\n",
    "    \n",
    "    return is_reproducible\n",
    "\n",
    "verify_training_reproducibility(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Environment Reproducibility\n",
    "\n",
    "Capturing the full environment is crucial for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "def capture_environment() -> dict:\n",
    "    \"\"\"Capture the full environment for reproducibility.\"\"\"\n",
    "    \n",
    "    env = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"python\": {\n",
    "            \"version\": sys.version,\n",
    "            \"executable\": sys.executable\n",
    "        },\n",
    "        \"platform\": {\n",
    "            \"system\": platform.system(),\n",
    "            \"release\": platform.release(),\n",
    "            \"machine\": platform.machine(),\n",
    "            \"processor\": platform.processor()\n",
    "        },\n",
    "        \"packages\": {\n",
    "            \"torch\": torch.__version__,\n",
    "            \"numpy\": np.__version__,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # CUDA info\n",
    "    if torch.cuda.is_available():\n",
    "        env[\"cuda\"] = {\n",
    "            \"available\": True,\n",
    "            \"version\": torch.version.cuda,\n",
    "            \"device_count\": torch.cuda.device_count(),\n",
    "            \"device_name\": torch.cuda.get_device_name(0),\n",
    "            \"cudnn_version\": torch.backends.cudnn.version(),\n",
    "            \"cudnn_deterministic\": torch.backends.cudnn.deterministic,\n",
    "            \"cudnn_benchmark\": torch.backends.cudnn.benchmark\n",
    "        }\n",
    "    else:\n",
    "        env[\"cuda\"] = {\"available\": False}\n",
    "    \n",
    "    return env\n",
    "\n",
    "env = capture_environment()\n",
    "\n",
    "print(\"\\nüñ•Ô∏è Environment Snapshot:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import json\n",
    "print(json.dumps(env, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requirements file\n",
    "def generate_requirements():\n",
    "    \"\"\"Generate a requirements.txt for the current environment.\"\"\"\n",
    "    \n",
    "    # Key packages to track\n",
    "    packages = [\n",
    "        \"torch\",\n",
    "        \"numpy\",\n",
    "        \"transformers\",\n",
    "        \"mlflow\",\n",
    "        \"datasets\",\n",
    "    ]\n",
    "    \n",
    "    requirements = []\n",
    "    \n",
    "    for pkg in packages:\n",
    "        try:\n",
    "            version = __import__(pkg).__version__\n",
    "            requirements.append(f\"{pkg}=={version}\")\n",
    "        except (ImportError, AttributeError):\n",
    "            pass\n",
    "    \n",
    "    return \"\\n\".join(requirements)\n",
    "\n",
    "print(\"\\nüìã Requirements:\")\n",
    "print(generate_requirements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker command for reproducible environment\n",
    "print(\"\"\"\n",
    "üê≥ Docker for Reproducibility\n",
    "{'='*50}\n",
    "\n",
    "For DGX Spark, use NGC containers:\n",
    "\n",
    "```bash\n",
    "docker run --gpus all -it --rm \\\n",
    "    -v $HOME/workspace:/workspace \\\n",
    "    -v $HOME/.cache/huggingface:/root/.cache/huggingface \\\n",
    "    --ipc=host \\\n",
    "    nvcr.io/nvidia/pytorch:25.01-py3 \\\n",
    "    python your_training_script.py\n",
    "```\n",
    "\n",
    "Key points:\n",
    "- Always pin the container version (e.g., 25.01-py3, not 'latest')\n",
    "- Mount volumes for persistent data\n",
    "- Use --ipc=host for multi-processing\n",
    "\n",
    "Save your container version in your experiment logs!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: The Reproducibility Checklist\n",
    "\n",
    "A comprehensive checklist for reproducible ML projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPRODUCIBILITY_CHECKLIST = \"\"\"\n",
    "üìã REPRODUCIBILITY CHECKLIST\n",
    "{'='*60}\n",
    "\n",
    "## üé≤ Random Seeds\n",
    "- [ ] Python random seed set\n",
    "- [ ] NumPy random seed set\n",
    "- [ ] PyTorch manual_seed set (CPU)\n",
    "- [ ] PyTorch CUDA seeds set\n",
    "- [ ] PYTHONHASHSEED environment variable set\n",
    "- [ ] DataLoader generator seeded\n",
    "\n",
    "## üîß Deterministic Settings\n",
    "- [ ] torch.backends.cudnn.deterministic = True\n",
    "- [ ] torch.backends.cudnn.benchmark = False\n",
    "- [ ] torch.use_deterministic_algorithms(True) (if available)\n",
    "\n",
    "## üì¶ Environment\n",
    "- [ ] requirements.txt or environment.yml committed\n",
    "- [ ] Docker/container version recorded\n",
    "- [ ] Hardware (GPU model) documented\n",
    "- [ ] OS and driver versions noted\n",
    "\n",
    "## üìä Data\n",
    "- [ ] Data version tracked (hash or version number)\n",
    "- [ ] Train/val/test split reproducible\n",
    "- [ ] Preprocessing deterministic\n",
    "- [ ] Data loading order fixed\n",
    "\n",
    "## üß† Model\n",
    "- [ ] Architecture defined in code (not just checkpoints)\n",
    "- [ ] Hyperparameters logged\n",
    "- [ ] Weight initialization seeded\n",
    "- [ ] All model checkpoints saved\n",
    "\n",
    "## üìù Experiment Tracking\n",
    "- [ ] All parameters logged (MLflow, W&B, etc.)\n",
    "- [ ] Metrics recorded at each step/epoch\n",
    "- [ ] Artifacts (models, plots) saved\n",
    "- [ ] Git commit hash recorded\n",
    "\n",
    "## ‚úÖ Verification\n",
    "- [ ] Training verified reproducible (run twice, compare)\n",
    "- [ ] Evaluation verified reproducible\n",
    "- [ ] Another team member reproduced results\n",
    "\"\"\"\n",
    "\n",
    "print(REPRODUCIBILITY_CHECKLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated reproducibility audit\n",
    "def audit_reproducibility() -> dict:\n",
    "    \"\"\"Audit the current environment for reproducibility.\"\"\"\n",
    "    \n",
    "    audit = {\n",
    "        \"passed\": [],\n",
    "        \"warnings\": [],\n",
    "        \"failed\": []\n",
    "    }\n",
    "    \n",
    "    # Check CUDA deterministic settings\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.backends.cudnn.deterministic:\n",
    "            audit[\"passed\"].append(\"CUDNN deterministic mode enabled\")\n",
    "        else:\n",
    "            audit[\"warnings\"].append(\"CUDNN deterministic mode not enabled\")\n",
    "        \n",
    "        if not torch.backends.cudnn.benchmark:\n",
    "            audit[\"passed\"].append(\"CUDNN benchmark mode disabled\")\n",
    "        else:\n",
    "            audit[\"warnings\"].append(\"CUDNN benchmark mode enabled (may cause non-determinism)\")\n",
    "    \n",
    "    # Check PYTHONHASHSEED\n",
    "    if 'PYTHONHASHSEED' in os.environ:\n",
    "        audit[\"passed\"].append(f\"PYTHONHASHSEED set to {os.environ['PYTHONHASHSEED']}\")\n",
    "    else:\n",
    "        audit[\"warnings\"].append(\"PYTHONHASHSEED not set\")\n",
    "    \n",
    "    # Check for reproducibility-affecting packages\n",
    "    try:\n",
    "        import transformers\n",
    "        audit[\"passed\"].append(f\"Transformers version: {transformers.__version__}\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nüîç Reproducibility Audit Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Passed ({len(audit['passed'])})\")\n",
    "    for item in audit[\"passed\"]:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Warnings ({len(audit['warnings'])})\")\n",
    "    for item in audit[\"warnings\"]:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "    \n",
    "    print(f\"\\n‚ùå Failed ({len(audit['failed'])})\")\n",
    "    for item in audit[\"failed\"]:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "    \n",
    "    return audit\n",
    "\n",
    "audit_reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Logging for Reproducibility with MLflow\n",
    "\n",
    "Let's create a complete reproducible training run with full logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import subprocess\n",
    "\n",
    "def get_git_hash() -> str:\n",
    "    \"\"\"Get current git commit hash.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return result.stdout.strip()[:8] if result.returncode == 0 else \"unknown\"\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "def reproducible_training_run(\n",
    "    seed: int,\n",
    "    experiment_name: str = \"Reproducibility-Demo\",\n",
    "    **training_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Execute a fully reproducible training run with complete logging.\n",
    "    \"\"\"\n",
    "    # Set up MLflow\n",
    "    MLFLOW_DIR = os.path.abspath(\"../mlflow\")\n",
    "    mlflow.set_tracking_uri(f\"file://{MLFLOW_DIR}\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"seed-{seed}\"):\n",
    "        # 1. Log reproducibility settings\n",
    "        mlflow.log_params({\n",
    "            \"seed\": seed,\n",
    "            \"deterministic_mode\": True,\n",
    "        })\n",
    "        \n",
    "        # 2. Log environment\n",
    "        env = capture_environment()\n",
    "        mlflow.log_params({\n",
    "            \"python_version\": env[\"python\"][\"version\"].split()[0],\n",
    "            \"torch_version\": env[\"packages\"][\"torch\"],\n",
    "            \"numpy_version\": env[\"packages\"][\"numpy\"],\n",
    "            \"platform\": env[\"platform\"][\"system\"],\n",
    "        })\n",
    "        \n",
    "        if env[\"cuda\"][\"available\"]:\n",
    "            mlflow.log_params({\n",
    "                \"cuda_version\": env[\"cuda\"][\"version\"],\n",
    "                \"gpu_name\": env[\"cuda\"][\"device_name\"],\n",
    "            })\n",
    "        \n",
    "        # 3. Log git info\n",
    "        mlflow.set_tag(\"git_commit\", get_git_hash())\n",
    "        \n",
    "        # 4. Log training parameters\n",
    "        mlflow.log_params(training_kwargs)\n",
    "        \n",
    "        # 5. Save environment file as artifact\n",
    "        env_path = \"/tmp/environment.json\"\n",
    "        with open(env_path, 'w') as f:\n",
    "            json.dump(env, f, indent=2, default=str)\n",
    "        mlflow.log_artifact(env_path)\n",
    "        \n",
    "        # 6. Run training\n",
    "        result = train_model(seed=seed, **training_kwargs)\n",
    "        \n",
    "        # 7. Log metrics\n",
    "        for epoch_data in result[\"history\"]:\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": epoch_data[\"loss\"], \"accuracy\": epoch_data[\"accuracy\"]},\n",
    "                step=epoch_data[\"epoch\"]\n",
    "            )\n",
    "        \n",
    "        mlflow.log_metrics({\n",
    "            \"final_loss\": result[\"final_loss\"],\n",
    "            \"final_accuracy\": result[\"final_accuracy\"]\n",
    "        })\n",
    "        \n",
    "        # 8. Log model weights hash for verification\n",
    "        mlflow.log_param(\"weights_hash\", result[\"weights_hash\"])\n",
    "        \n",
    "        print(f\"\\n‚úÖ Reproducible run complete!\")\n",
    "        print(f\"   Seed: {seed}\")\n",
    "        print(f\"   Final accuracy: {result['final_accuracy']:.4f}\")\n",
    "        print(f\"   Weights hash: {result['weights_hash']}\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Run it!\n",
    "result = reproducible_training_run(\n",
    "    seed=42,\n",
    "    n_epochs=5,\n",
    "    learning_rate=0.01,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úã Try It Yourself: Exercise\n",
    "\n",
    "**Task:** Verify the reproducibility of a training pipeline.\n",
    "\n",
    "1. Run `reproducible_training_run` with seed=123, 3 times\n",
    "2. Verify all three runs have identical final metrics\n",
    "3. Change one setting (e.g., remove deterministic mode) and observe the difference\n",
    "4. Document your findings\n",
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "Try modifying the `set_seed` function to disable deterministic settings:\n",
    "```python\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "```\n",
    "Then compare results.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Run 3 times with seed=123\n",
    "\n",
    "# Step 2: Compare results\n",
    "\n",
    "# Step 3: Disable deterministic mode and compare\n",
    "\n",
    "# Step 4: Document findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Setting Seed Only Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Wrong: Setting seed only at start of script\n",
    "# set_seed(42)\n",
    "# ... many operations ...\n",
    "# model = create_model()  # Seed state may have drifted\n",
    "\n",
    "# ‚úÖ Right: Set seed immediately before the operation you want to reproduce\n",
    "# set_seed(42)\n",
    "# model = create_model()  # Deterministic\n",
    "# set_seed(42)  # Reset if needed for next reproducible op\n",
    "\n",
    "print(\"Set seed as close as possible to the operation you want to reproduce!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistake 2: Forgetting DataLoader Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ‚ùå Wrong: Using num_workers > 0 without seeding\n# dataloader = DataLoader(dataset, num_workers=4)  # Non-reproducible!\n\n# ‚úÖ Right: Seed each worker\ndef worker_init_fn(worker_id):\n    \"\"\"Initialize each DataLoader worker with a unique but reproducible seed.\"\"\"\n    seed = torch.initial_seed() % 2**32\n    np.random.seed(seed)\n    random.seed(seed)\n\n# Usage:\n# dataloader = DataLoader(\n#     dataset,\n#     num_workers=4,\n#     worker_init_fn=worker_init_fn,  # Each worker gets seeded!\n#     generator=torch.Generator().manual_seed(42)\n# )\n\nprint(\"Always use worker_init_fn when num_workers > 0!\")\n\n# üí° Note: This function is also available in the scripts module:\n# from scripts.reproducibility import worker_init_fn"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Sources of non-reproducibility in ML\n",
    "- ‚úÖ How to properly set all random seeds\n",
    "- ‚úÖ Deterministic training settings\n",
    "- ‚úÖ Environment capture and logging\n",
    "- ‚úÖ The reproducibility checklist\n",
    "- ‚úÖ Verification techniques\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [PyTorch Reproducibility Guide](https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "- [NVIDIA Deep Learning Examples](https://github.com/NVIDIA/DeepLearningExamples)\n",
    "- [Papers With Code - ML Reproducibility Challenge](https://paperswithcode.com/rc2022)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Module 15 Summary\n",
    "\n",
    "Congratulations on completing Module 15! You've learned:\n",
    "\n",
    "1. **Benchmarking (15.1):** How to evaluate LLMs with standard benchmarks\n",
    "2. **Custom Evaluation (15.2):** Building task-specific evaluation frameworks\n",
    "3. **MLflow (15.3):** Experiment tracking and visualization\n",
    "4. **Model Registry (15.4):** Version control for models\n",
    "5. **Reproducibility (15.5):** Ensuring consistent results\n",
    "\n",
    "These skills form the foundation of professional ML engineering. Every serious ML team uses these practices!\n",
    "\n",
    "**Next Steps:**\n",
    "- Apply these practices to your own projects\n",
    "- Set up a central MLflow server for your team\n",
    "- Create custom benchmarks for your use cases\n",
    "- Build CI/CD pipelines with reproducibility checks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}