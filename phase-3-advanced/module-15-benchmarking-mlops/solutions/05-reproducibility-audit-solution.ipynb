{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 15.5 Solution: Reproducibility Audit\n",
    "\n",
    "This notebook provides solutions for the reproducibility verification exercise.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solution: Verify Training Reproducibility\n",
    "\n",
    "**Task:** Verify that training is reproducible and observe what happens when deterministic settings are disabled.\n",
    "\n",
    "Requirements:\n",
    "1. Run `reproducible_training_run` with seed=123, 3 times\n",
    "2. Verify all three runs have identical final metrics\n",
    "3. Disable deterministic mode and compare\n",
    "4. Document findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Dict, Any\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int, deterministic: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Set all random seeds for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed: The random seed to use\n",
    "        deterministic: If True, use deterministic algorithms\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        try:\n",
    "            torch.use_deterministic_algorithms(True)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    else:\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        try:\n",
    "            torch.use_deterministic_algorithms(False)\n",
    "        except AttributeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \"\"\"Simple network for reproducibility testing.\"\"\"\n",
    "    def __init__(self, input_size=10, hidden_size=20, output_size=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "def create_data(seed: int, n_samples: int = 1000):\n",
    "    \"\"\"Create reproducible synthetic data.\"\"\"\n",
    "    set_seed(seed)\n",
    "    X = torch.randn(n_samples, 10)\n",
    "    y = (X[:, 0] + X[:, 1] > 0).long()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    seed: int,\n",
    "    deterministic: bool = True,\n",
    "    n_epochs: int = 5,\n",
    "    learning_rate: float = 0.01,\n",
    "    batch_size: int = 32\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train a model with configurable reproducibility settings.\n",
    "    \n",
    "    Args:\n",
    "        seed: Random seed\n",
    "        deterministic: Whether to use deterministic algorithms\n",
    "        n_epochs: Number of training epochs\n",
    "        learning_rate: Learning rate\n",
    "        batch_size: Batch size\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with training results\n",
    "    \"\"\"\n",
    "    # Set seed with deterministic settings\n",
    "    set_seed(seed, deterministic=deterministic)\n",
    "    \n",
    "    # Create data\n",
    "    X, y = create_data(seed)\n",
    "    \n",
    "    # Create DataLoader with seeded generator\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    \n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        generator=g\n",
    "    )\n",
    "    \n",
    "    # Create model (seeded initialization)\n",
    "    model = SimpleNet()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "        history.append({\"epoch\": epoch, \"loss\": avg_loss, \"accuracy\": accuracy})\n",
    "    \n",
    "    # Get final weights hash for comparison\n",
    "    weights_hash = hash(tuple(model.fc1.weight.flatten().tolist()[:10]))\n",
    "    \n",
    "    return {\n",
    "        \"final_loss\": history[-1][\"loss\"],\n",
    "        \"final_accuracy\": history[-1][\"accuracy\"],\n",
    "        \"history\": history,\n",
    "        \"weights_hash\": weights_hash,\n",
    "        \"deterministic\": deterministic\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Run 3 times with seed=123 (deterministic mode)\n",
    "\n",
    "SEED = 123\n",
    "N_RUNS = 3\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT 1: DETERMINISTIC MODE (Expected: Identical Results)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "deterministic_results = []\n",
    "\n",
    "for i in range(N_RUNS):\n",
    "    result = train_model(seed=SEED, deterministic=True)\n",
    "    deterministic_results.append(result)\n",
    "    print(f\"\\nRun {i+1}:\")\n",
    "    print(f\"   Final Loss: {result['final_loss']:.6f}\")\n",
    "    print(f\"   Final Accuracy: {result['final_accuracy']:.6f}\")\n",
    "    print(f\"   Weights Hash: {result['weights_hash']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Verify all three runs have identical results\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICATION: Are Results Identical?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "losses = [r['final_loss'] for r in deterministic_results]\n",
    "accuracies = [r['final_accuracy'] for r in deterministic_results]\n",
    "hashes = [r['weights_hash'] for r in deterministic_results]\n",
    "\n",
    "loss_identical = all(abs(l - losses[0]) < 1e-9 for l in losses)\n",
    "acc_identical = all(abs(a - accuracies[0]) < 1e-9 for a in accuracies)\n",
    "hash_identical = len(set(hashes)) == 1\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Status':<10} {'Values'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Final Loss':<20} {'âœ… SAME' if loss_identical else 'âŒ DIFF':<10} {losses[0]:.6f}\")\n",
    "print(f\"{'Final Accuracy':<20} {'âœ… SAME' if acc_identical else 'âŒ DIFF':<10} {accuracies[0]:.6f}\")\n",
    "print(f\"{'Weights Hash':<20} {'âœ… SAME' if hash_identical else 'âŒ DIFF':<10} {hashes[0]}\")\n",
    "\n",
    "all_identical = loss_identical and acc_identical and hash_identical\n",
    "print(f\"\\nğŸ¯ Overall: {'âœ… FULLY REPRODUCIBLE' if all_identical else 'âŒ NOT REPRODUCIBLE'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Disable deterministic mode and compare\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 2: NON-DETERMINISTIC MODE (Expected: Varying Results)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "non_deterministic_results = []\n",
    "\n",
    "for i in range(N_RUNS):\n",
    "    result = train_model(seed=SEED, deterministic=False)\n",
    "    non_deterministic_results.append(result)\n",
    "    print(f\"\\nRun {i+1}:\")\n",
    "    print(f\"   Final Loss: {result['final_loss']:.6f}\")\n",
    "    print(f\"   Final Accuracy: {result['final_accuracy']:.6f}\")\n",
    "    print(f\"   Weights Hash: {result['weights_hash']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare non-deterministic results\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Non-Deterministic Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nd_losses = [r['final_loss'] for r in non_deterministic_results]\n",
    "nd_accuracies = [r['final_accuracy'] for r in non_deterministic_results]\n",
    "nd_hashes = [r['weights_hash'] for r in non_deterministic_results]\n",
    "\n",
    "nd_loss_identical = all(abs(l - nd_losses[0]) < 1e-9 for l in nd_losses)\n",
    "nd_acc_identical = all(abs(a - nd_accuracies[0]) < 1e-9 for a in nd_accuracies)\n",
    "nd_hash_identical = len(set(nd_hashes)) == 1\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Status':<10} {'Min':<12} {'Max':<12} {'Range'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Final Loss':<20} {'âœ… SAME' if nd_loss_identical else 'âš ï¸ VARIES':<10} \"\n",
    "      f\"{min(nd_losses):.6f}   {max(nd_losses):.6f}   {max(nd_losses)-min(nd_losses):.6f}\")\n",
    "print(f\"{'Final Accuracy':<20} {'âœ… SAME' if nd_acc_identical else 'âš ï¸ VARIES':<10} \"\n",
    "      f\"{min(nd_accuracies):.6f}   {max(nd_accuracies):.6f}   {max(nd_accuracies)-min(nd_accuracies):.6f}\")\n",
    "print(f\"{'Weights Hash':<20} {'âœ… SAME' if nd_hash_identical else 'âš ï¸ VARIES':<10} \"\n",
    "      f\"{len(set(nd_hashes))} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Document findings\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINDINGS & DOCUMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "findings = f\"\"\"\n",
    "ğŸ“‹ REPRODUCIBILITY EXPERIMENT REPORT\n",
    "\n",
    "Seed Used: {SEED}\n",
    "Number of Runs: {N_RUNS}\n",
    "Model: SimpleNet (10->20->2)\n",
    "Training: 5 epochs, lr=0.01, batch_size=32\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "EXPERIMENT 1: DETERMINISTIC MODE\n",
    "  Settings:\n",
    "    - torch.backends.cudnn.deterministic = True\n",
    "    - torch.backends.cudnn.benchmark = False\n",
    "    - torch.use_deterministic_algorithms(True)\n",
    "  \n",
    "  Results:\n",
    "    - Final Loss: {deterministic_results[0]['final_loss']:.6f} (identical across runs: {'YES' if loss_identical else 'NO'})\n",
    "    - Final Accuracy: {deterministic_results[0]['final_accuracy']:.6f} (identical: {'YES' if acc_identical else 'NO'})\n",
    "    - Weights: {'IDENTICAL' if hash_identical else 'VARYING'}\n",
    "  \n",
    "  Conclusion: {'âœ… FULLY REPRODUCIBLE' if all_identical else 'âŒ NOT REPRODUCIBLE'}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "EXPERIMENT 2: NON-DETERMINISTIC MODE\n",
    "  Settings:\n",
    "    - torch.backends.cudnn.deterministic = False\n",
    "    - torch.backends.cudnn.benchmark = True\n",
    "    - Deterministic algorithms disabled\n",
    "  \n",
    "  Results:\n",
    "    - Loss Range: {min(nd_losses):.6f} to {max(nd_losses):.6f} (Î”={max(nd_losses)-min(nd_losses):.6f})\n",
    "    - Accuracy Range: {min(nd_accuracies):.6f} to {max(nd_accuracies):.6f} (Î”={max(nd_accuracies)-min(nd_accuracies):.6f})\n",
    "    - Unique Weight Hashes: {len(set(nd_hashes))}\n",
    "  \n",
    "  Conclusion: âš ï¸ RESULTS VARY BETWEEN RUNS\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "KEY INSIGHTS:\n",
    "\n",
    "1. DETERMINISTIC MODE IS ESSENTIAL for reproducibility\n",
    "   - Same seed + deterministic settings = identical results\n",
    "   - This is crucial for research papers and debugging\n",
    "\n",
    "2. NON-DETERMINISTIC MODE trades reproducibility for speed\n",
    "   - CUDNN benchmark mode finds faster algorithms\n",
    "   - Results vary due to non-deterministic GPU operations\n",
    "\n",
    "3. VARIATION MAGNITUDE\n",
    "   - Accuracy varied by ~{max(nd_accuracies)-min(nd_accuracies):.2%}\n",
    "   - This seems small but matters for reproducibility\n",
    "\n",
    "4. RECOMMENDATIONS:\n",
    "   - Use deterministic mode for: research, debugging, CI/CD tests\n",
    "   - Use non-deterministic for: production training (faster)\n",
    "   - Always document which mode was used\n",
    "\"\"\"\n",
    "\n",
    "print(findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss comparison\n",
    "runs = range(1, N_RUNS + 1)\n",
    "ax1 = axes[0]\n",
    "ax1.bar([r - 0.2 for r in runs], losses, width=0.35, label='Deterministic', color='green', alpha=0.8)\n",
    "ax1.bar([r + 0.2 for r in runs], nd_losses, width=0.35, label='Non-Deterministic', color='orange', alpha=0.8)\n",
    "ax1.set_xlabel('Run Number')\n",
    "ax1.set_ylabel('Final Loss')\n",
    "ax1.set_title('Loss Comparison Across Runs')\n",
    "ax1.legend()\n",
    "ax1.set_xticks(runs)\n",
    "\n",
    "# Plot 2: Accuracy comparison\n",
    "ax2 = axes[1]\n",
    "ax2.bar([r - 0.2 for r in runs], [a * 100 for a in accuracies], width=0.35, \n",
    "        label='Deterministic', color='green', alpha=0.8)\n",
    "ax2.bar([r + 0.2 for r in runs], [a * 100 for a in nd_accuracies], width=0.35, \n",
    "        label='Non-Deterministic', color='orange', alpha=0.8)\n",
    "ax2.set_xlabel('Run Number')\n",
    "ax2.set_ylabel('Final Accuracy (%)')\n",
    "ax2.set_title('Accuracy Comparison Across Runs')\n",
    "ax2.legend()\n",
    "ax2.set_xticks(runs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/reproducibility_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Deterministic mode produces identical results** across runs with the same seed\n",
    "2. **Non-deterministic mode causes variation** due to GPU algorithm selection\n",
    "3. **The variation is small but measurable** - important for scientific reproducibility\n",
    "4. **Setting multiple seeds is necessary** - Python, NumPy, PyTorch, CUDA all need to be seeded\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. Always set seeds at the start of experiments\n",
    "2. Use deterministic mode for reproducible research\n",
    "3. Document your random seeds and settings\n",
    "4. Verify reproducibility by running experiments multiple times\n",
    "5. Log seeds with MLflow or other experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâœ… Solution complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
