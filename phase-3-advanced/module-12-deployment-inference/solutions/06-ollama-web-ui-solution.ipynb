{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 12.6: Ollama Web UI - Solutions\n",
    "\n",
    "This notebook provides solutions for the exercises in the Ollama Web UI notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Create a Custom Preset\n",
    "\n",
    "Design a model preset for a specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Custom preset examples for different use cases\n",
    "\n",
    "# Example 1: Technical Documentation Assistant\n",
    "tech_docs_preset = {\n",
    "    \"name\": \"Tech Docs Writer\",\n",
    "    \"base_model\": \"llama3.1:8b\",\n",
    "    \"system_prompt\": \"\"\"You are a technical documentation specialist with expertise in clear, \n",
    "concise writing. Your role is to help create and improve technical documentation.\n",
    "\n",
    "Guidelines:\n",
    "1. Use clear, simple language - avoid jargon unless necessary\n",
    "2. Structure content with headers, bullet points, and numbered steps\n",
    "3. Include code examples with proper formatting and comments\n",
    "4. Add warnings and notes for important information\n",
    "5. Assume the reader is a developer but explain non-obvious concepts\n",
    "\n",
    "Format your responses in Markdown.\"\"\",\n",
    "    \"parameters\": {\n",
    "        \"temperature\": 0.4,  # Lower for consistency\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 2048\n",
    "    }\n",
    "}\n",
    "\n",
    "# Example 2: SQL Query Helper\n",
    "sql_helper_preset = {\n",
    "    \"name\": \"SQL Expert\",\n",
    "    \"base_model\": \"llama3.1:8b\",\n",
    "    \"system_prompt\": \"\"\"You are an expert SQL developer specializing in PostgreSQL, MySQL, and SQLite.\n",
    "\n",
    "When helping with SQL:\n",
    "1. Write optimized, readable queries\n",
    "2. Explain the query logic step by step\n",
    "3. Suggest indexes when relevant\n",
    "4. Warn about potential performance issues\n",
    "5. Always use parameterized queries for security\n",
    "\n",
    "Format queries with proper indentation and add comments for complex parts.\n",
    "If the user's requirements are unclear, ask clarifying questions.\"\"\",\n",
    "    \"parameters\": {\n",
    "        \"temperature\": 0.2,  # Very low for precise SQL\n",
    "        \"top_p\": 0.85,\n",
    "        \"max_tokens\": 1024\n",
    "    }\n",
    "}\n",
    "\n",
    "# Example 3: Learning Tutor\n",
    "tutor_preset = {\n",
    "    \"name\": \"Patient Tutor\",\n",
    "    \"base_model\": \"llama3.1:8b\",\n",
    "    \"system_prompt\": \"\"\"You are a patient, encouraging tutor who helps people learn new concepts.\n",
    "\n",
    "Teaching approach:\n",
    "1. Start with simple explanations, then add complexity\n",
    "2. Use analogies and real-world examples\n",
    "3. Ask questions to check understanding\n",
    "4. Celebrate progress and encourage curiosity\n",
    "5. Break complex topics into digestible chunks\n",
    "\n",
    "Adapt your explanations based on the learner's responses.\n",
    "If they're struggling, try a different approach rather than repeating.\"\"\",\n",
    "    \"parameters\": {\n",
    "        \"temperature\": 0.7,  # Balanced for natural dialogue\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 1500\n",
    "    }\n",
    "}\n",
    "\n",
    "presets = [tech_docs_preset, sql_helper_preset, tutor_preset]\n",
    "\n",
    "print(\"Custom Preset Examples:\")\n",
    "print(\"=\" * 60)\n",
    "for preset in presets:\n",
    "    print(f\"\\nðŸ“Œ {preset['name']}\")\n",
    "    print(f\"   Temperature: {preset['parameters']['temperature']}\")\n",
    "    print(f\"   Max Tokens: {preset['parameters']['max_tokens']}\")\n",
    "    print(f\"   System Prompt Preview: {preset['system_prompt'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Set Up RAG\n",
    "\n",
    "Configure RAG and test it with a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: RAG Setup Checklist (completed)\n",
    "\n",
    "rag_setup_completed = {\n",
    "    \"Step 1: Install embedding model\": {\n",
    "        \"command\": \"ollama pull nomic-embed-text\",\n",
    "        \"status\": \"âœ… Completed\",\n",
    "        \"notes\": \"384-dim embeddings, good balance of speed/quality\"\n",
    "    },\n",
    "    \"Step 2: Configure in Open WebUI\": {\n",
    "        \"location\": \"Settings â†’ Documents\",\n",
    "        \"settings\": {\n",
    "            \"Embedding Model\": \"nomic-embed-text\",\n",
    "            \"Chunk Size\": 1000,\n",
    "            \"Chunk Overlap\": 100,\n",
    "            \"Top K\": 5\n",
    "        },\n",
    "        \"status\": \"âœ… Configured\"\n",
    "    },\n",
    "    \"Step 3: Upload test document\": {\n",
    "        \"document_type\": \"PDF or Markdown\",\n",
    "        \"example\": \"Company handbook, technical spec, or research paper\",\n",
    "        \"status\": \"âœ… Uploaded\"\n",
    "    },\n",
    "    \"Step 4: Test retrieval\": {\n",
    "        \"test_queries\": [\n",
    "            \"What are the main topics covered in this document?\",\n",
    "            \"Based on the document, what is the policy on [specific topic]?\",\n",
    "            \"Summarize section X of the uploaded document.\"\n",
    "        ],\n",
    "        \"verification\": \"Check that citations appear in responses\",\n",
    "        \"status\": \"âœ… Verified\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"RAG Setup Completed:\")\n",
    "print(\"=\" * 60)\n",
    "for step, details in rag_setup_completed.items():\n",
    "    print(f\"\\n{step}\")\n",
    "    print(f\"   Status: {details['status']}\")\n",
    "    if 'settings' in details:\n",
    "        for k, v in details['settings'].items():\n",
    "            print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices for RAG with Open WebUI\n",
    "\n",
    "rag_best_practices = {\n",
    "    \"Document Preparation\": [\n",
    "        \"Use structured documents with clear headings\",\n",
    "        \"Ensure text is extractable (not scanned images)\",\n",
    "        \"Break very long documents into logical sections\",\n",
    "        \"Remove headers/footers that repeat on every page\"\n",
    "    ],\n",
    "    \"Chunk Settings\": [\n",
    "        \"Chunk size 800-1200 for most documents\",\n",
    "        \"Increase overlap (100-200) for dense technical content\",\n",
    "        \"Use smaller chunks (500-800) for Q&A on specific facts\"\n",
    "    ],\n",
    "    \"Query Strategies\": [\n",
    "        \"Be specific: 'According to the document...' works well\",\n",
    "        \"Ask follow-up questions referencing previous answers\",\n",
    "        \"Request quotes: 'Quote the relevant section...'\"\n",
    "    ],\n",
    "    \"Troubleshooting\": [\n",
    "        \"If retrieval fails, try re-uploading the document\",\n",
    "        \"Check if embedding model is properly selected\",\n",
    "        \"Increase Top K if relevant info is being missed\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"RAG Best Practices:\")\n",
    "print(\"=\" * 60)\n",
    "for category, tips in rag_best_practices.items():\n",
    "    print(f\"\\nðŸ“Œ {category}:\")\n",
    "    for tip in tips:\n",
    "        print(f\"   â€¢ {tip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: API Integration with Open WebUI\n",
    "\n",
    "You can also interact with Open WebUI programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using Open WebUI's API (if enabled)\n",
    "import requests\n",
    "\n",
    "OPEN_WEBUI_URL = \"http://localhost:3000\"\n",
    "\n",
    "def chat_with_open_webui(prompt: str, api_key: str = None):\n",
    "    \"\"\"\n",
    "    Send a chat request to Open WebUI.\n",
    "    \n",
    "    Note: API access must be enabled in Open WebUI settings.\n",
    "    Generate an API key in Settings â†’ Account.\n",
    "    \"\"\"\n",
    "    headers = {}\n",
    "    if api_key:\n",
    "        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OPEN_WEBUI_URL}/api/chat\",\n",
    "            json={\n",
    "                \"model\": \"llama3.1:8b\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"stream\": False\n",
    "            },\n",
    "            headers=headers,\n",
    "            timeout=60\n",
    "        )\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "print(\"API Integration Example\")\n",
    "print(\"Use chat_with_open_webui(prompt, api_key) to interact programmatically\")\n",
    "print(\"\\nNote: Generate an API key in Open WebUI â†’ Settings â†’ Account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Custom presets** let you save configurations for different use cases\n",
    "2. **Temperature affects output**: Lower for precision, higher for creativity\n",
    "3. **RAG works best** with structured, text-extractable documents\n",
    "4. **Open WebUI** provides both UI and API access for flexibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
