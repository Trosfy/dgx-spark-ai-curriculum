{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 14.4: Document AI Pipeline\n",
    "\n",
    "**Module:** 14 - Multimodal AI  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ⭐⭐⭐⭐\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand the Document AI pipeline architecture\n",
    "- [ ] Extract text from PDFs using OCR\n",
    "- [ ] Process document layouts (tables, figures, text blocks)\n",
    "- [ ] Use VLMs for document understanding\n",
    "- [ ] Build a complete Document Q&A system\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed: Tasks 14.1-14.3\n",
    "- Knowledge of: VLMs, RAG fundamentals\n",
    "- Running in: NGC PyTorch container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "Document AI transforms how businesses handle paperwork:\n",
    "\n",
    "**Industry Applications:**\n",
    "- **Legal**: Extract clauses from contracts, compare documents\n",
    "- **Finance**: Parse invoices, receipts, and financial statements\n",
    "- **Healthcare**: Process medical records and lab reports\n",
    "- **Insurance**: Automate claims processing from forms\n",
    "- **Research**: Extract data from scientific papers\n",
    "\n",
    "**Why DGX Spark?**\n",
    "- Process large PDF batches locally\n",
    "- Keep sensitive documents on-premise\n",
    "- Run VLMs for complex document understanding\n",
    "- No per-page API costs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ELI5: How Does Document AI Work?\n",
    "\n",
    "> **Imagine you're teaching a robot to read a messy desk full of papers:**\n",
    ">\n",
    "> 1. **Take a Photo** (PDF to Image): First, we convert the document to pictures\n",
    ">\n",
    "> 2. **Find the Words** (OCR): The robot looks for text - like playing \"Where's Waldo\" but for letters\n",
    ">\n",
    "> 3. **Understand the Layout** (Layout Analysis): Figure out what's a title, what's a table, what's a paragraph\n",
    ">\n",
    "> 4. **Read and Remember** (Extraction): Pull out the important information\n",
    ">\n",
    "> 5. **Answer Questions** (Q&A): Now you can ask \"What's the total amount?\" and the robot knows!\n",
    ">\n",
    "> **In AI terms:**\n",
    "> - **OCR (Optical Character Recognition)**: Convert images of text to actual text\n",
    "> - **Layout Analysis**: Detect document structure (headers, tables, figures)\n",
    "> - **VLM Integration**: Use vision-language models to understand context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install pymupdf pdf2image pytesseract pillow -q\n",
    "# !apt-get install -y tesseract-ocr poppler-utils  # System dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "print(\"=\" * 50)\n",
    "print(\"GPU Configuration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Total Memory: {total_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    print(\"GPU memory cleared!\")\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get GPU memory usage.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "        return f\"Allocated: {allocated:.2f}GB\"\n",
    "    return \"No GPU\"\n",
    "\n",
    "print(\"Utility functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Creating Sample Documents\n",
    "\n",
    "Let's create some sample documents to work with. We'll create synthetic invoices and reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_invoice() -> Image.Image:\n",
    "    \"\"\"\n",
    "    Create a sample invoice image for testing.\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image of a fake invoice\n",
    "    \"\"\"\n",
    "    # Create a white image\n",
    "    img = Image.new('RGB', (800, 1000), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Try to use a nicer font, fall back to default\n",
    "    try:\n",
    "        font_large = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 28)\n",
    "        font_medium = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 18)\n",
    "        font_small = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 14)\n",
    "    except:\n",
    "        font_large = ImageFont.load_default()\n",
    "        font_medium = ImageFont.load_default()\n",
    "        font_small = ImageFont.load_default()\n",
    "    \n",
    "    # Header\n",
    "    draw.text((50, 30), \"INVOICE\", fill='navy', font=font_large)\n",
    "    draw.text((600, 30), \"#INV-2024-0042\", fill='black', font=font_medium)\n",
    "    \n",
    "    # Company info\n",
    "    draw.text((50, 80), \"TechCorp Solutions Inc.\", fill='black', font=font_medium)\n",
    "    draw.text((50, 105), \"123 Innovation Street\", fill='gray', font=font_small)\n",
    "    draw.text((50, 125), \"San Francisco, CA 94105\", fill='gray', font=font_small)\n",
    "    \n",
    "    # Bill To\n",
    "    draw.text((50, 180), \"Bill To:\", fill='black', font=font_medium)\n",
    "    draw.text((50, 205), \"Acme Corporation\", fill='black', font=font_small)\n",
    "    draw.text((50, 225), \"456 Business Ave\", fill='gray', font=font_small)\n",
    "    draw.text((50, 245), \"New York, NY 10001\", fill='gray', font=font_small)\n",
    "    \n",
    "    # Date info\n",
    "    draw.text((500, 180), \"Date: December 15, 2024\", fill='black', font=font_small)\n",
    "    draw.text((500, 200), \"Due: January 15, 2025\", fill='black', font=font_small)\n",
    "    \n",
    "    # Table header\n",
    "    y = 320\n",
    "    draw.rectangle([50, y, 750, y+30], fill='lightgray')\n",
    "    draw.text((60, y+5), \"Description\", fill='black', font=font_small)\n",
    "    draw.text((400, y+5), \"Qty\", fill='black', font=font_small)\n",
    "    draw.text((500, y+5), \"Unit Price\", fill='black', font=font_small)\n",
    "    draw.text((650, y+5), \"Amount\", fill='black', font=font_small)\n",
    "    \n",
    "    # Table rows\n",
    "    items = [\n",
    "        (\"AI Development Services\", \"40\", \"$150.00\", \"$6,000.00\"),\n",
    "        (\"Model Training (GPU hours)\", \"100\", \"$25.00\", \"$2,500.00\"),\n",
    "        (\"Data Preprocessing\", \"20\", \"$75.00\", \"$1,500.00\"),\n",
    "        (\"Technical Consultation\", \"8\", \"$200.00\", \"$1,600.00\"),\n",
    "        (\"Cloud Infrastructure Setup\", \"1\", \"$500.00\", \"$500.00\")\n",
    "    ]\n",
    "    \n",
    "    y = 360\n",
    "    for desc, qty, unit, amount in items:\n",
    "        draw.text((60, y), desc, fill='black', font=font_small)\n",
    "        draw.text((400, y), qty, fill='black', font=font_small)\n",
    "        draw.text((500, y), unit, fill='black', font=font_small)\n",
    "        draw.text((650, y), amount, fill='black', font=font_small)\n",
    "        draw.line([(50, y+25), (750, y+25)], fill='lightgray', width=1)\n",
    "        y += 35\n",
    "    \n",
    "    # Totals\n",
    "    y = 560\n",
    "    draw.text((500, y), \"Subtotal:\", fill='black', font=font_small)\n",
    "    draw.text((650, y), \"$12,100.00\", fill='black', font=font_small)\n",
    "    \n",
    "    draw.text((500, y+25), \"Tax (8.5%):\", fill='black', font=font_small)\n",
    "    draw.text((650, y+25), \"$1,028.50\", fill='black', font=font_small)\n",
    "    \n",
    "    draw.line([(500, y+50), (750, y+50)], fill='black', width=2)\n",
    "    \n",
    "    draw.text((500, y+60), \"Total Due:\", fill='black', font=font_medium)\n",
    "    draw.text((650, y+60), \"$13,128.50\", fill='navy', font=font_medium)\n",
    "    \n",
    "    # Payment info\n",
    "    y = 700\n",
    "    draw.text((50, y), \"Payment Information:\", fill='black', font=font_medium)\n",
    "    draw.text((50, y+30), \"Bank: First National Bank\", fill='gray', font=font_small)\n",
    "    draw.text((50, y+50), \"Account: 1234567890\", fill='gray', font=font_small)\n",
    "    draw.text((50, y+70), \"Routing: 987654321\", fill='gray', font=font_small)\n",
    "    \n",
    "    # Footer\n",
    "    draw.text((50, 920), \"Thank you for your business!\", fill='navy', font=font_medium)\n",
    "    draw.text((50, 950), \"Questions? Contact: billing@techcorp.example.com\", fill='gray', font=font_small)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Create and display the sample invoice\n",
    "invoice_image = create_sample_invoice()\n",
    "\n",
    "# Display at reduced size\n",
    "display_image = invoice_image.copy()\n",
    "display_image.thumbnail((500, 625))\n",
    "display(display_image)\n",
    "\n",
    "print(f\"\\nInvoice image size: {invoice_image.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_report() -> Image.Image:\n",
    "    \"\"\"\n",
    "    Create a sample report with a table and chart placeholder.\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image of a fake report\n",
    "    \"\"\"\n",
    "    img = Image.new('RGB', (800, 1000), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    try:\n",
    "        font_large = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 24)\n",
    "        font_medium = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 16)\n",
    "        font_small = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 12)\n",
    "    except:\n",
    "        font_large = ImageFont.load_default()\n",
    "        font_medium = ImageFont.load_default()\n",
    "        font_small = ImageFont.load_default()\n",
    "    \n",
    "    # Title\n",
    "    draw.text((50, 30), \"Q4 2024 Performance Report\", fill='darkblue', font=font_large)\n",
    "    draw.line([(50, 65), (750, 65)], fill='darkblue', width=2)\n",
    "    \n",
    "    # Executive Summary\n",
    "    draw.text((50, 85), \"Executive Summary\", fill='black', font=font_medium)\n",
    "    summary = \"\"\"The fourth quarter of 2024 showed strong performance across all key metrics.\n",
    "Revenue increased by 23% compared to Q3, with particularly strong growth in the\n",
    "AI services division. Customer satisfaction scores remained high at 94%.\"\"\"\n",
    "    \n",
    "    y = 115\n",
    "    for line in summary.split('\\n'):\n",
    "        draw.text((50, y), line.strip(), fill='gray', font=font_small)\n",
    "        y += 18\n",
    "    \n",
    "    # Key Metrics section\n",
    "    draw.text((50, 200), \"Key Metrics\", fill='black', font=font_medium)\n",
    "    \n",
    "    # Draw a simple bar chart\n",
    "    metrics = [(\"Revenue\", 85), (\"Growth\", 72), (\"Satisfaction\", 94), (\"Efficiency\", 78)]\n",
    "    x_start = 80\n",
    "    y_base = 350\n",
    "    bar_width = 80\n",
    "    \n",
    "    for i, (name, value) in enumerate(metrics):\n",
    "        x = x_start + i * 150\n",
    "        bar_height = int(value * 1.2)\n",
    "        \n",
    "        # Draw bar\n",
    "        color = ['steelblue', 'seagreen', 'coral', 'mediumpurple'][i]\n",
    "        draw.rectangle([x, y_base - bar_height, x + bar_width, y_base], fill=color)\n",
    "        \n",
    "        # Draw label and value\n",
    "        draw.text((x + 10, y_base + 10), name, fill='black', font=font_small)\n",
    "        draw.text((x + 25, y_base - bar_height - 20), f\"{value}%\", fill='black', font=font_small)\n",
    "    \n",
    "    # Draw axes\n",
    "    draw.line([(60, y_base), (700, y_base)], fill='black', width=2)\n",
    "    draw.line([(60, 220), (60, y_base)], fill='black', width=2)\n",
    "    \n",
    "    # Data Table\n",
    "    draw.text((50, 420), \"Quarterly Breakdown\", fill='black', font=font_medium)\n",
    "    \n",
    "    # Table\n",
    "    y = 450\n",
    "    draw.rectangle([50, y, 700, y+25], fill='lightgray')\n",
    "    headers = [\"Quarter\", \"Revenue\", \"Expenses\", \"Profit\", \"Growth\"]\n",
    "    x_positions = [60, 180, 300, 440, 580]\n",
    "    \n",
    "    for x, header in zip(x_positions, headers):\n",
    "        draw.text((x, y+5), header, fill='black', font=font_small)\n",
    "    \n",
    "    rows = [\n",
    "        (\"Q1 2024\", \"$2.1M\", \"$1.4M\", \"$700K\", \"+12%\"),\n",
    "        (\"Q2 2024\", \"$2.4M\", \"$1.5M\", \"$900K\", \"+15%\"),\n",
    "        (\"Q3 2024\", \"$2.8M\", \"$1.6M\", \"$1.2M\", \"+18%\"),\n",
    "        (\"Q4 2024\", \"$3.4M\", \"$1.8M\", \"$1.6M\", \"+23%\")\n",
    "    ]\n",
    "    \n",
    "    y = 480\n",
    "    for row in rows:\n",
    "        for x, cell in zip(x_positions, row):\n",
    "            draw.text((x, y), cell, fill='black', font=font_small)\n",
    "        draw.line([(50, y+20), (700, y+20)], fill='lightgray', width=1)\n",
    "        y += 30\n",
    "    \n",
    "    # Conclusions\n",
    "    draw.text((50, 630), \"Key Findings\", fill='black', font=font_medium)\n",
    "    findings = [\n",
    "        \"1. Revenue growth accelerated each quarter, reaching 23% in Q4\",\n",
    "        \"2. Profit margins improved from 33% to 47% over the year\",\n",
    "        \"3. Customer satisfaction maintained above 90% threshold\",\n",
    "        \"4. Operational efficiency gains from AI automation\"\n",
    "    ]\n",
    "    \n",
    "    y = 660\n",
    "    for finding in findings:\n",
    "        draw.text((50, y), finding, fill='gray', font=font_small)\n",
    "        y += 25\n",
    "    \n",
    "    # Footer\n",
    "    draw.line([(50, 850), (750, 850)], fill='lightgray', width=1)\n",
    "    draw.text((50, 870), \"Prepared by: Analytics Team | Date: December 2024\", fill='gray', font=font_small)\n",
    "    draw.text((50, 890), \"Classification: Internal Use Only\", fill='gray', font=font_small)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Create and display the report\n",
    "report_image = create_sample_report()\n",
    "\n",
    "display_image = report_image.copy()\n",
    "display_image.thumbnail((500, 625))\n",
    "display(display_image)\n",
    "\n",
    "print(f\"\\nReport image size: {report_image.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Document Understanding with VLMs\n",
    "\n",
    "Modern VLMs like Qwen2-VL have excellent document understanding capabilities. Let's use them to extract information from our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "print(\"Loading Qwen2-VL for document understanding...\")\n",
    "print(f\"Memory before: {get_memory_usage()}\")\n",
    "start_time = time.time()\n",
    "\n",
    "doc_processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n",
    "\n",
    "doc_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\"\\nModel loaded in {load_time:.1f} seconds!\")\n",
    "print(f\"Memory after: {get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document(image: Image.Image, question: str, max_tokens: int = 500) -> str:\n",
    "    \"\"\"\n",
    "    Analyze a document image and answer a question about it.\n",
    "    \n",
    "    Args:\n",
    "        image: Document image\n",
    "        question: Question about the document\n",
    "        max_tokens: Maximum response length\n",
    "        \n",
    "    Returns:\n",
    "        Answer from the VLM\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": question}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    text = doc_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = doc_processor(text=[text], images=[image], return_tensors=\"pt\", padding=True)\n",
    "    inputs = inputs.to(doc_model.device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.inference_mode():\n",
    "        output_ids = doc_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.3  # Lower temperature for factual extraction\n",
    "        )\n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
    "    response = doc_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    print(f\"[Generated in {generation_time:.1f}s]\")\n",
    "    return response\n",
    "\n",
    "print(\"analyze_document() function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the invoice\n",
    "print(\"=\" * 50)\n",
    "print(\"INVOICE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "question1 = \"What is the total amount due on this invoice? Also tell me the invoice number and due date.\"\n",
    "\n",
    "print(f\"\\nQuestion: {question1}\")\n",
    "print(\"-\" * 50)\n",
    "answer1 = analyze_document(invoice_image, question1)\n",
    "print(f\"\\nAnswer: {answer1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structured information\n",
    "question2 = \"\"\"Extract all line items from this invoice as a structured list.\n",
    "For each item, provide: description, quantity, unit price, and total amount.\n",
    "Format as a numbered list.\"\"\"\n",
    "\n",
    "print(f\"Question: {question2}\")\n",
    "print(\"-\" * 50)\n",
    "answer2 = analyze_document(invoice_image, question2)\n",
    "print(f\"\\nAnswer: {answer2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the report\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"REPORT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "question3 = \"What was the revenue growth in Q4 2024? What are the key findings mentioned in this report?\"\n",
    "\n",
    "print(f\"\\nQuestion: {question3}\")\n",
    "print(\"-\" * 50)\n",
    "answer3 = analyze_document(report_image, question3)\n",
    "print(f\"\\nAnswer: {answer3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table data\n",
    "question4 = \"\"\"Read the quarterly breakdown table and extract the data.\n",
    "What was the profit in each quarter? Calculate the total annual profit.\"\"\"\n",
    "\n",
    "print(f\"Question: {question4}\")\n",
    "print(\"-\" * 50)\n",
    "answer4 = analyze_document(report_image, question4)\n",
    "print(f\"\\nAnswer: {answer4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Building a Document Q&A Pipeline\n",
    "\n",
    "Let's create a complete pipeline that can:\n",
    "1. Accept document images\n",
    "2. Store them with metadata\n",
    "3. Answer questions across multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentQA:\n",
    "    \"\"\"\n",
    "    Document Question-Answering Pipeline.\n",
    "    \n",
    "    Handles multiple documents and answers questions using VLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, processor):\n",
    "        \"\"\"\n",
    "        Initialize the Document QA system.\n",
    "        \n",
    "        Args:\n",
    "            model: Loaded VLM model\n",
    "            processor: VLM processor\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.processor = processor\n",
    "        self.documents = {}  # Store documents by ID\n",
    "        \n",
    "    def add_document(self, doc_id: str, image: Image.Image, metadata: Dict = None):\n",
    "        \"\"\"\n",
    "        Add a document to the collection.\n",
    "        \n",
    "        Args:\n",
    "            doc_id: Unique identifier for the document\n",
    "            image: Document image\n",
    "            metadata: Optional metadata (title, date, type, etc.)\n",
    "        \"\"\"\n",
    "        self.documents[doc_id] = {\n",
    "            'image': image,\n",
    "            'metadata': metadata or {},\n",
    "            'added_at': time.time()\n",
    "        }\n",
    "        print(f\"Added document: {doc_id}\")\n",
    "        \n",
    "    def get_document_summary(self, doc_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Get a summary of a document.\n",
    "        \n",
    "        Args:\n",
    "            doc_id: Document identifier\n",
    "            \n",
    "        Returns:\n",
    "            Summary text\n",
    "        \"\"\"\n",
    "        if doc_id not in self.documents:\n",
    "            return f\"Document '{doc_id}' not found\"\n",
    "            \n",
    "        image = self.documents[doc_id]['image']\n",
    "        \n",
    "        prompt = \"Provide a brief summary of this document. What type of document is it and what are the key points?\"\n",
    "        \n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "        text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = self.processor(text=[text], images=[image], return_tensors=\"pt\", padding=True)\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            output_ids = self.model.generate(**inputs, max_new_tokens=200, temperature=0.3)\n",
    "        \n",
    "        generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
    "        return self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    def ask(self, question: str, doc_id: Optional[str] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Ask a question about document(s).\n",
    "        \n",
    "        Args:\n",
    "            question: The question to ask\n",
    "            doc_id: Specific document to query (None = search all)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with answer and source documents\n",
    "        \"\"\"\n",
    "        if doc_id:\n",
    "            # Query specific document\n",
    "            if doc_id not in self.documents:\n",
    "                return {'answer': f\"Document '{doc_id}' not found\", 'sources': []}\n",
    "            \n",
    "            docs_to_query = {doc_id: self.documents[doc_id]}\n",
    "        else:\n",
    "            # Query all documents\n",
    "            docs_to_query = self.documents\n",
    "        \n",
    "        if not docs_to_query:\n",
    "            return {'answer': \"No documents in collection\", 'sources': []}\n",
    "        \n",
    "        # For simplicity, we'll create a combined view of all documents\n",
    "        # In production, you'd use retrieval to find relevant documents first\n",
    "        \n",
    "        answers = []\n",
    "        sources = []\n",
    "        \n",
    "        for did, doc in docs_to_query.items():\n",
    "            image = doc['image']\n",
    "            \n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image},\n",
    "                    {\"type\": \"text\", \"text\": f\"{question}\\n\\nIf this document doesn't contain relevant information, just say 'Not found in this document'.\"}\n",
    "                ]\n",
    "            }]\n",
    "            \n",
    "            text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            inputs = self.processor(text=[text], images=[image], return_tensors=\"pt\", padding=True)\n",
    "            inputs = inputs.to(self.model.device)\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                output_ids = self.model.generate(**inputs, max_new_tokens=300, temperature=0.3)\n",
    "            \n",
    "            generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
    "            answer = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            \n",
    "            if \"not found\" not in answer.lower():\n",
    "                answers.append(f\"From {did}: {answer}\")\n",
    "                sources.append(did)\n",
    "        \n",
    "        if not answers:\n",
    "            final_answer = \"I couldn't find relevant information in the documents.\"\n",
    "        else:\n",
    "            final_answer = \"\\n\\n\".join(answers)\n",
    "        \n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': final_answer,\n",
    "            'sources': sources\n",
    "        }\n",
    "    \n",
    "    def extract_fields(self, doc_id: str, fields: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Extract specific fields from a document.\n",
    "        \n",
    "        Args:\n",
    "            doc_id: Document identifier\n",
    "            fields: List of field names to extract\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of extracted field values\n",
    "        \"\"\"\n",
    "        if doc_id not in self.documents:\n",
    "            return {'error': f\"Document '{doc_id}' not found\"}\n",
    "        \n",
    "        image = self.documents[doc_id]['image']\n",
    "        \n",
    "        fields_str = \"\\n\".join([f\"- {field}\" for field in fields])\n",
    "        prompt = f\"\"\"Extract the following fields from this document. \n",
    "Return the values in a structured format.\n",
    "\n",
    "Fields to extract:\n",
    "{fields_str}\n",
    "\n",
    "Format your response as:\n",
    "Field Name: Value\"\"\"\n",
    "        \n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }]\n",
    "        \n",
    "        text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = self.processor(text=[text], images=[image], return_tensors=\"pt\", padding=True)\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            output_ids = self.model.generate(**inputs, max_new_tokens=300, temperature=0.1)\n",
    "        \n",
    "        generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
    "        response = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Parse the response into a dictionary\n",
    "        extracted = {}\n",
    "        for line in response.split('\\n'):\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                extracted[key.strip()] = value.strip()\n",
    "        \n",
    "        return extracted\n",
    "    \n",
    "    def list_documents(self) -> List[str]:\n",
    "        \"\"\"List all document IDs in the collection.\"\"\"\n",
    "        return list(self.documents.keys())\n",
    "\n",
    "print(\"DocumentQA class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Document QA system\n",
    "doc_qa = DocumentQA(doc_model, doc_processor)\n",
    "\n",
    "# Add our documents\n",
    "doc_qa.add_document(\"invoice_001\", invoice_image, {\n",
    "    'type': 'invoice',\n",
    "    'title': 'TechCorp Invoice',\n",
    "    'date': '2024-12-15'\n",
    "})\n",
    "\n",
    "doc_qa.add_document(\"report_q4_2024\", report_image, {\n",
    "    'type': 'report',\n",
    "    'title': 'Q4 2024 Performance Report',\n",
    "    'date': '2024-12'\n",
    "})\n",
    "\n",
    "print(f\"\\nDocuments in collection: {doc_qa.list_documents()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summaries\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DOCUMENT SUMMARIES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for doc_id in doc_qa.list_documents():\n",
    "    print(f\"\\n{doc_id}:\")\n",
    "    print(\"-\" * 40)\n",
    "    summary = doc_qa.get_document_summary(doc_id)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific fields from the invoice\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FIELD EXTRACTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fields = [\n",
    "    \"Invoice Number\",\n",
    "    \"Company Name\",\n",
    "    \"Total Amount\",\n",
    "    \"Due Date\",\n",
    "    \"Number of Line Items\"\n",
    "]\n",
    "\n",
    "extracted = doc_qa.extract_fields(\"invoice_001\", fields)\n",
    "\n",
    "print(\"\\nExtracted Fields:\")\n",
    "for field, value in extracted.items():\n",
    "    print(f\"  {field}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask questions across all documents\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CROSS-DOCUMENT Q&A\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "question = \"What financial information is available in these documents? Summarize the key numbers.\"\n",
    "\n",
    "print(f\"\\nQuestion: {question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "result = doc_qa.ask(question)\n",
    "print(f\"\\nAnswer: {result['answer']}\")\n",
    "print(f\"\\nSources: {result['sources']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself: Create Your Own Document Pipeline\n",
    "\n",
    "1. Create a new type of document (e.g., receipt, contract, form)\n",
    "2. Add it to the DocumentQA system\n",
    "3. Extract specific fields from it\n",
    "\n",
    "<details>\n",
    "<summary>Hint: Creating a simple receipt</summary>\n",
    "\n",
    "```python\n",
    "def create_receipt():\n",
    "    img = Image.new('RGB', (400, 600), 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    draw.text((50, 30), \"RECEIPT\", fill='black')\n",
    "    draw.text((50, 60), \"Coffee Shop\", fill='gray')\n",
    "    draw.text((50, 100), \"Latte         $4.50\", fill='black')\n",
    "    draw.text((50, 130), \"Muffin        $3.00\", fill='black')\n",
    "    draw.text((50, 170), \"Total:        $7.50\", fill='black')\n",
    "    draw.text((50, 200), \"Date: 2024-12-15\", fill='gray')\n",
    "    \n",
    "    return img\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create your own document and add it to the system!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Image Resolution Too Low\n",
    "\n",
    "```python\n",
    "# Wrong - text becomes unreadable\n",
    "small_image = doc_image.resize((200, 200))\n",
    "answer = analyze_document(small_image, question)  # Poor results\n",
    "\n",
    "# Right - maintain readable resolution\n",
    "answer = analyze_document(doc_image, question)  # Full resolution\n",
    "# Or resize proportionally while keeping text readable\n",
    "doc_image.thumbnail((1200, 1600), Image.LANCZOS)  # Better\n",
    "```\n",
    "\n",
    "### Mistake 2: Not Being Specific in Questions\n",
    "\n",
    "```python\n",
    "# Wrong - vague question\n",
    "answer = analyze_document(invoice, \"What's in here?\")  # Generic answer\n",
    "\n",
    "# Right - specific question\n",
    "answer = analyze_document(invoice, \"What is the total amount due and the due date?\")  # Precise answer\n",
    "```\n",
    "\n",
    "### Mistake 3: Ignoring Document Structure\n",
    "\n",
    "```python\n",
    "# Wrong - asking about multiple things in one question\n",
    "answer = analyze_document(doc, \"Extract all fields, summarize, and compare to other docs\")\n",
    "\n",
    "# Right - break down into specific tasks\n",
    "summary = analyze_document(doc, \"Summarize this document briefly.\")\n",
    "fields = analyze_document(doc, \"Extract: Company Name, Amount, Date\")\n",
    "```\n",
    "\n",
    "### Mistake 4: Not Handling Handwritten or Low-Quality Scans\n",
    "\n",
    "```python\n",
    "# Wrong - assuming perfect input\n",
    "answer = analyze_document(blurry_scan, question)  # May fail\n",
    "\n",
    "# Right - add robustness hints\n",
    "answer = analyze_document(blurry_scan, \n",
    "    f\"{question}\\n\\nNote: The image quality may be low. Do your best to read it.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- How Document AI pipelines work\n",
    "- How to use VLMs for document understanding\n",
    "- How to extract structured information from documents\n",
    "- How to build a Document Q&A system\n",
    "- How to query across multiple documents\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **VLMs are powerful for documents**: They understand both text and layout\n",
    "2. **Be specific in questions**: Clear questions get better answers\n",
    "3. **Image quality matters**: Keep resolution high enough for text to be readable\n",
    "4. **Structure helps**: Breaking tasks into steps improves accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge (Optional)\n",
    "\n",
    "### Build a Document Comparison System\n",
    "\n",
    "Create a function that:\n",
    "1. Takes two documents as input\n",
    "2. Identifies similarities and differences\n",
    "3. Highlights any discrepancies in numbers or key fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CHALLENGE CODE HERE\n",
    "\n",
    "def compare_documents(doc_id1: str, doc_id2: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare two documents and identify similarities and differences.\n",
    "    \n",
    "    Args:\n",
    "        doc_id1: First document ID\n",
    "        doc_id2: Second document ID\n",
    "        \n",
    "    Returns:\n",
    "        Comparison results\n",
    "    \"\"\"\n",
    "    # TODO: Implement document comparison\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Document Understanding with LLMs](https://huggingface.co/blog/document-ai)\n",
    "- [Qwen2-VL Paper](https://arxiv.org/abs/2409.12191)\n",
    "- [LayoutLM for Document Understanding](https://arxiv.org/abs/1912.13318)\n",
    "- [PyMuPDF Documentation](https://pymupdf.readthedocs.io/)\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "del doc_model\n",
    "del doc_processor\n",
    "del doc_qa\n",
    "\n",
    "clear_gpu_memory()\n",
    "print(f\"Final memory state: {get_memory_usage()}\")\n",
    "print(\"\\nNotebook complete! Ready for the next task.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
