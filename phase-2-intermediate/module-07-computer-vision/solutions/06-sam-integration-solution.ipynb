{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 7.6 Solution: SAM Integration\n",
        "\n",
        "**Module:** 7 - Computer Vision  \n",
        "**Type:** Solution Notebook\n",
        "\n",
        "---\n",
        "\n",
        "This notebook contains solutions for Segment Anything Model (SAM) exercises, including an interactive Magic Wand tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise Solution: Magic Wand Tool\n",
        "\n",
        "An interactive segmentation tool using SAM that supports:\n",
        "- Positive clicks (include region)\n",
        "- Negative clicks (exclude region)\n",
        "- Undo/Redo functionality\n",
        "- Grow/Shrink mask options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MagicWand:\n",
        "    \"\"\"\n",
        "    Interactive \"Magic Wand\" tool using SAM.\n",
        "    \n",
        "    Allows iterative refinement with positive and negative clicks,\n",
        "    similar to Photoshop's magic wand tool but with SAM's power.\n",
        "    \n",
        "    Usage:\n",
        "        wand = MagicWand(sam_predictor)\n",
        "        wand.set_image(image)\n",
        "        \n",
        "        # Click to select\n",
        "        wand.click((x, y), is_positive=True)   # Include this region\n",
        "        wand.click((x, y), is_positive=False)  # Exclude this region\n",
        "        \n",
        "        # Refine\n",
        "        wand.grow()    # Get larger mask option\n",
        "        wand.shrink()  # Get smaller mask option\n",
        "        wand.undo()    # Remove last click\n",
        "        \n",
        "        # Visualize\n",
        "        wand.visualize()\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, sam_predictor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sam_predictor: SamPredictor instance from segment-anything\n",
        "        \"\"\"\n",
        "        self.predictor = sam_predictor\n",
        "        self.reset()\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"Clear all clicks and masks.\"\"\"\n",
        "        self.positive_points = []\n",
        "        self.negative_points = []\n",
        "        self.current_mask = None\n",
        "        self.all_masks = []  # History of masks for grow/shrink\n",
        "        self.mask_history = []  # For undo functionality\n",
        "    \n",
        "    def set_image(self, image: np.ndarray):\n",
        "        \"\"\"\n",
        "        Set the image to segment.\n",
        "        \n",
        "        Args:\n",
        "            image: RGB image as numpy array [H, W, 3]\n",
        "        \"\"\"\n",
        "        self.predictor.set_image(image)\n",
        "        self.image = image\n",
        "        self.reset()\n",
        "        print(f\"Image set: {image.shape}\")\n",
        "    \n",
        "    def click(self, point: Tuple[int, int], is_positive: bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Add a click point and update the mask.\n",
        "        \n",
        "        Args:\n",
        "            point: (x, y) coordinates in image space\n",
        "            is_positive: True for \"include\", False for \"exclude\"\n",
        "        \n",
        "        Returns:\n",
        "            Updated binary mask\n",
        "        \"\"\"\n",
        "        # Save state for undo\n",
        "        self.mask_history.append({\n",
        "            'positive': self.positive_points.copy(),\n",
        "            'negative': self.negative_points.copy(),\n",
        "            'mask': self.current_mask\n",
        "        })\n",
        "        \n",
        "        if is_positive:\n",
        "            self.positive_points.append(point)\n",
        "            print(f\"Added positive point at {point}\")\n",
        "        else:\n",
        "            self.negative_points.append(point)\n",
        "            print(f\"Added negative point at {point}\")\n",
        "        \n",
        "        self._update_mask()\n",
        "        return self.current_mask\n",
        "    \n",
        "    def undo(self) -> Optional[np.ndarray]:\n",
        "        \"\"\"Undo last click.\"\"\"\n",
        "        if self.mask_history:\n",
        "            state = self.mask_history.pop()\n",
        "            self.positive_points = state['positive']\n",
        "            self.negative_points = state['negative']\n",
        "            self.current_mask = state['mask']\n",
        "            print(\"Undone last action\")\n",
        "        else:\n",
        "            print(\"Nothing to undo\")\n",
        "        \n",
        "        return self.current_mask\n",
        "    \n",
        "    def grow(self) -> Optional[np.ndarray]:\n",
        "        \"\"\"\n",
        "        Get a larger mask (if available from multi-mask output).\n",
        "        \n",
        "        SAM outputs multiple masks at different granularities.\n",
        "        This selects the largest one.\n",
        "        \"\"\"\n",
        "        if len(self.all_masks) > 1:\n",
        "            areas = [m.sum() for m in self.all_masks]\n",
        "            largest_idx = areas.index(max(areas))\n",
        "            self.current_mask = self.all_masks[largest_idx]\n",
        "            print(f\"Grew mask to size {self.current_mask.sum()} pixels\")\n",
        "        else:\n",
        "            print(\"Only one mask available\")\n",
        "        return self.current_mask\n",
        "    \n",
        "    def shrink(self) -> Optional[np.ndarray]:\n",
        "        \"\"\"\n",
        "        Get a smaller mask (if available from multi-mask output).\n",
        "        \n",
        "        SAM outputs multiple masks at different granularities.\n",
        "        This selects the smallest one.\n",
        "        \"\"\"\n",
        "        if len(self.all_masks) > 1:\n",
        "            areas = [m.sum() for m in self.all_masks]\n",
        "            smallest_idx = areas.index(min(areas))\n",
        "            self.current_mask = self.all_masks[smallest_idx]\n",
        "            print(f\"Shrunk mask to size {self.current_mask.sum()} pixels\")\n",
        "        else:\n",
        "            print(\"Only one mask available\")\n",
        "        return self.current_mask\n",
        "    \n",
        "    def _update_mask(self):\n",
        "        \"\"\"Update mask based on all accumulated points.\"\"\"\n",
        "        if not self.positive_points and not self.negative_points:\n",
        "            self.current_mask = None\n",
        "            return\n",
        "        \n",
        "        # Combine all points with labels\n",
        "        all_points = self.positive_points + self.negative_points\n",
        "        labels = [1] * len(self.positive_points) + [0] * len(self.negative_points)\n",
        "        \n",
        "        # Run SAM prediction\n",
        "        masks, scores, _ = self.predictor.predict(\n",
        "            point_coords=np.array(all_points),\n",
        "            point_labels=np.array(labels),\n",
        "            multimask_output=True\n",
        "        )\n",
        "        \n",
        "        # Store all masks for grow/shrink functionality\n",
        "        self.all_masks = [masks[i] for i in range(len(masks))]\n",
        "        \n",
        "        # Use highest scoring mask as default\n",
        "        best_idx = scores.argmax()\n",
        "        self.current_mask = masks[best_idx]\n",
        "        \n",
        "        print(f\"Updated mask (score: {scores[best_idx]:.3f}, area: {self.current_mask.sum()} pixels)\")\n",
        "    \n",
        "    def get_mask(self) -> Optional[np.ndarray]:\n",
        "        \"\"\"Get the current mask.\"\"\"\n",
        "        return self.current_mask\n",
        "    \n",
        "    def visualize(self, figsize: Tuple[int, int] = (14, 6)):\n",
        "        \"\"\"Visualize current state with clicks and mask overlay.\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
        "        \n",
        "        # Image with click points\n",
        "        axes[0].imshow(self.image)\n",
        "        \n",
        "        # Plot positive points (green stars)\n",
        "        for p in self.positive_points:\n",
        "            axes[0].scatter(p[0], p[1], c='green', s=200, marker='*', \n",
        "                           edgecolors='white', linewidths=2, label='Positive')\n",
        "        \n",
        "        # Plot negative points (red X)\n",
        "        for p in self.negative_points:\n",
        "            axes[0].scatter(p[0], p[1], c='red', s=200, marker='x', \n",
        "                           linewidths=3, label='Negative')\n",
        "        \n",
        "        axes[0].set_title(f'Clicks: {len(self.positive_points)} positive, {len(self.negative_points)} negative')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Image with mask overlay\n",
        "        axes[1].imshow(self.image)\n",
        "        \n",
        "        if self.current_mask is not None:\n",
        "            # Create semi-transparent colored mask\n",
        "            colored_mask = np.zeros((*self.current_mask.shape, 4))\n",
        "            colored_mask[self.current_mask] = [0.3, 0.7, 0.3, 0.6]  # Green overlay\n",
        "            axes[1].imshow(colored_mask)\n",
        "            \n",
        "            # Draw mask boundary\n",
        "            from scipy import ndimage\n",
        "            try:\n",
        "                boundary = ndimage.binary_dilation(self.current_mask) ^ self.current_mask\n",
        "                boundary_mask = np.zeros((*boundary.shape, 4))\n",
        "                boundary_mask[boundary] = [1, 1, 1, 1]  # White boundary\n",
        "                axes[1].imshow(boundary_mask)\n",
        "            except ImportError:\n",
        "                pass  # scipy not available\n",
        "        \n",
        "        axes[1].set_title('Current Mask')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    def get_stats(self) -> Dict:\n",
        "        \"\"\"Get statistics about current selection.\"\"\"\n",
        "        stats = {\n",
        "            'positive_clicks': len(self.positive_points),\n",
        "            'negative_clicks': len(self.negative_points),\n",
        "            'mask_area': self.current_mask.sum() if self.current_mask is not None else 0,\n",
        "            'available_masks': len(self.all_masks),\n",
        "            'undo_available': len(self.mask_history)\n",
        "        }\n",
        "        \n",
        "        if self.current_mask is not None:\n",
        "            total_pixels = self.current_mask.size\n",
        "            stats['mask_percentage'] = 100 * stats['mask_area'] / total_pixels\n",
        "        \n",
        "        return stats\n",
        "\n",
        "\n",
        "print(\"MagicWand class defined successfully!\")\n",
        "print(\"\\nUsage:\")\n",
        "print(\"  from segment_anything import sam_model_registry, SamPredictor\")\n",
        "print(\"  sam = sam_model_registry['vit_b'](checkpoint='sam_vit_b.pth')\")\n",
        "print(\"  predictor = SamPredictor(sam)\")\n",
        "print(\"  \")\n",
        "print(\"  wand = MagicWand(predictor)\")\n",
        "print(\"  wand.set_image(image)\")\n",
        "print(\"  wand.click((100, 150), is_positive=True)\")\n",
        "print(\"  wand.click((200, 250), is_positive=False)\")\n",
        "print(\"  wand.visualize()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise Solution: Box Prompt Interface\n",
        "\n",
        "SAM can also segment objects using bounding box prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BoxSelector:\n",
        "    \"\"\"\n",
        "    Box-based object selection using SAM.\n",
        "    \n",
        "    Draw a bounding box around an object, SAM will segment it.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, sam_predictor):\n",
        "        self.predictor = sam_predictor\n",
        "        self.image = None\n",
        "        self.boxes = []\n",
        "        self.masks = []\n",
        "    \n",
        "    def set_image(self, image: np.ndarray):\n",
        "        \"\"\"Set image for segmentation.\"\"\"\n",
        "        self.predictor.set_image(image)\n",
        "        self.image = image\n",
        "        self.boxes = []\n",
        "        self.masks = []\n",
        "    \n",
        "    def add_box(self, box: Tuple[int, int, int, int]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Add a bounding box and get segmentation.\n",
        "        \n",
        "        Args:\n",
        "            box: (x1, y1, x2, y2) coordinates\n",
        "        \n",
        "        Returns:\n",
        "            Segmentation mask\n",
        "        \"\"\"\n",
        "        masks, scores, _ = self.predictor.predict(\n",
        "            point_coords=None,\n",
        "            point_labels=None,\n",
        "            box=np.array(box),\n",
        "            multimask_output=False\n",
        "        )\n",
        "        \n",
        "        self.boxes.append(box)\n",
        "        self.masks.append(masks[0])\n",
        "        \n",
        "        return masks[0]\n",
        "    \n",
        "    def visualize(self):\n",
        "        \"\"\"Visualize all boxes and their masks.\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "        \n",
        "        # Show boxes on image\n",
        "        axes[0].imshow(self.image)\n",
        "        for i, box in enumerate(self.boxes):\n",
        "            x1, y1, x2, y2 = box\n",
        "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
        "                                  fill=False, edgecolor='red', linewidth=2)\n",
        "            axes[0].add_patch(rect)\n",
        "            axes[0].text(x1, y1-5, f'Box {i+1}', color='red', fontsize=10)\n",
        "        axes[0].set_title('Bounding Boxes')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Show combined masks\n",
        "        axes[1].imshow(self.image)\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, len(self.masks)))\n",
        "        \n",
        "        for mask, color in zip(self.masks, colors):\n",
        "            colored_mask = np.zeros((*mask.shape, 4))\n",
        "            colored_mask[mask] = [*color[:3], 0.5]\n",
        "            axes[1].imshow(colored_mask)\n",
        "        \n",
        "        axes[1].set_title('Segmented Objects')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "print(\"BoxSelector class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise Solution: Automatic Mask Generation\n",
        "\n",
        "SAM can automatically segment all objects in an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def automatic_segmentation(\n",
        "    sam_model,\n",
        "    image: np.ndarray,\n",
        "    points_per_side: int = 32,\n",
        "    pred_iou_thresh: float = 0.88,\n",
        "    stability_score_thresh: float = 0.95,\n",
        "    min_mask_region_area: int = 100\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Automatically segment all objects in an image.\n",
        "    \n",
        "    Args:\n",
        "        sam_model: SAM model instance\n",
        "        image: Input image [H, W, 3]\n",
        "        points_per_side: Grid density for automatic point sampling\n",
        "        pred_iou_thresh: Predicted IoU threshold for mask quality\n",
        "        stability_score_thresh: Stability score threshold\n",
        "        min_mask_region_area: Minimum mask area in pixels\n",
        "    \n",
        "    Returns:\n",
        "        List of masks with metadata\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from segment_anything import SamAutomaticMaskGenerator\n",
        "        \n",
        "        mask_generator = SamAutomaticMaskGenerator(\n",
        "            model=sam_model,\n",
        "            points_per_side=points_per_side,\n",
        "            pred_iou_thresh=pred_iou_thresh,\n",
        "            stability_score_thresh=stability_score_thresh,\n",
        "            min_mask_region_area=min_mask_region_area\n",
        "        )\n",
        "        \n",
        "        masks = mask_generator.generate(image)\n",
        "        \n",
        "        print(f\"Found {len(masks)} objects\")\n",
        "        \n",
        "        # Sort by area (largest first)\n",
        "        masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
        "        \n",
        "        return masks\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"Please install segment-anything: pip install segment-anything\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def visualize_automatic_masks(image: np.ndarray, masks: List[Dict]):\n",
        "    \"\"\"\n",
        "    Visualize automatically generated masks.\n",
        "    \n",
        "    Args:\n",
        "        image: Original image\n",
        "        masks: List of mask dictionaries from SamAutomaticMaskGenerator\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image)\n",
        "    \n",
        "    # Generate random colors for each mask\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    for mask_data in masks:\n",
        "        mask = mask_data['segmentation']\n",
        "        color = np.random.random(3)\n",
        "        \n",
        "        # Create colored overlay\n",
        "        colored_mask = np.zeros((*mask.shape, 4))\n",
        "        colored_mask[mask] = [*color, 0.4]\n",
        "        plt.imshow(colored_mask)\n",
        "    \n",
        "    plt.title(f'Automatic Segmentation: {len(masks)} objects found')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print mask statistics\n",
        "    print(\"\\nMask Statistics:\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"{'#':<5} {'Area':<15} {'IoU Score':<15} {'Stability':<15}\")\n",
        "    print(\"-\"*50)\n",
        "    for i, m in enumerate(masks[:10]):  # Show top 10\n",
        "        print(f\"{i+1:<5} {m['area']:<15} {m['predicted_iou']:<15.3f} {m['stability_score']:<15.3f}\")\n",
        "\n",
        "\n",
        "print(\"Automatic segmentation functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise Solution: Mask Refinement\n",
        "\n",
        "Post-processing techniques to refine SAM masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def refine_mask(\n",
        "    mask: np.ndarray,\n",
        "    remove_small_regions: bool = True,\n",
        "    fill_holes: bool = True,\n",
        "    smooth_boundary: bool = True,\n",
        "    min_area: int = 500\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Refine a binary mask using morphological operations.\n",
        "    \n",
        "    Args:\n",
        "        mask: Binary mask [H, W]\n",
        "        remove_small_regions: Remove connected components smaller than min_area\n",
        "        fill_holes: Fill holes in the mask\n",
        "        smooth_boundary: Apply morphological closing to smooth boundaries\n",
        "        min_area: Minimum area for region removal\n",
        "    \n",
        "    Returns:\n",
        "        Refined binary mask\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from scipy import ndimage\n",
        "        import cv2\n",
        "    except ImportError:\n",
        "        print(\"scipy and cv2 required for mask refinement\")\n",
        "        return mask\n",
        "    \n",
        "    refined = mask.copy().astype(np.uint8)\n",
        "    \n",
        "    # Remove small connected components\n",
        "    if remove_small_regions:\n",
        "        labeled, num_features = ndimage.label(refined)\n",
        "        for i in range(1, num_features + 1):\n",
        "            component = labeled == i\n",
        "            if component.sum() < min_area:\n",
        "                refined[component] = 0\n",
        "    \n",
        "    # Fill holes\n",
        "    if fill_holes:\n",
        "        refined = ndimage.binary_fill_holes(refined).astype(np.uint8)\n",
        "    \n",
        "    # Smooth boundaries with morphological closing\n",
        "    if smooth_boundary:\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "        refined = cv2.morphologyEx(refined, cv2.MORPH_CLOSE, kernel)\n",
        "    \n",
        "    return refined.astype(bool)\n",
        "\n",
        "\n",
        "def compare_masks(original: np.ndarray, refined: np.ndarray, image: np.ndarray):\n",
        "    \"\"\"\n",
        "    Compare original and refined masks side by side.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    # Original\n",
        "    axes[0].imshow(image)\n",
        "    colored = np.zeros((*original.shape, 4))\n",
        "    colored[original] = [1, 0, 0, 0.5]  # Red\n",
        "    axes[0].imshow(colored)\n",
        "    axes[0].set_title(f'Original (area: {original.sum()})')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Refined\n",
        "    axes[1].imshow(image)\n",
        "    colored = np.zeros((*refined.shape, 4))\n",
        "    colored[refined] = [0, 1, 0, 0.5]  # Green\n",
        "    axes[1].imshow(colored)\n",
        "    axes[1].set_title(f'Refined (area: {refined.sum()})')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # Difference\n",
        "    added = refined & ~original  # New regions\n",
        "    removed = original & ~refined  # Removed regions\n",
        "    \n",
        "    axes[2].imshow(image)\n",
        "    colored = np.zeros((*original.shape, 4))\n",
        "    colored[added] = [0, 1, 0, 0.7]  # Green = added\n",
        "    colored[removed] = [1, 0, 0, 0.7]  # Red = removed\n",
        "    axes[2].imshow(colored)\n",
        "    axes[2].set_title('Difference (green=added, red=removed)')\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"Mask refinement functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise Solution: SAM with Object Detection\n",
        "\n",
        "Combining YOLO object detection with SAM segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_and_segment(\n",
        "    image: np.ndarray,\n",
        "    yolo_model,\n",
        "    sam_predictor,\n",
        "    classes: Optional[List[str]] = None,\n",
        "    conf_threshold: float = 0.5\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Use YOLO for detection and SAM for segmentation.\n",
        "    \n",
        "    Best of both worlds:\n",
        "    - YOLO: Fast, accurate object detection with class labels\n",
        "    - SAM: High-quality segmentation masks\n",
        "    \n",
        "    Args:\n",
        "        image: Input image\n",
        "        yolo_model: YOLO model instance\n",
        "        sam_predictor: SAM predictor instance\n",
        "        classes: Optional list of class names to detect\n",
        "        conf_threshold: Detection confidence threshold\n",
        "    \n",
        "    Returns:\n",
        "        List of dictionaries with class, bbox, confidence, and mask\n",
        "    \"\"\"\n",
        "    # Set image for SAM\n",
        "    sam_predictor.set_image(image)\n",
        "    \n",
        "    # Run YOLO detection\n",
        "    results = yolo_model(image, conf=conf_threshold)\n",
        "    \n",
        "    # Process each detection\n",
        "    detections = []\n",
        "    \n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            # Get detection info\n",
        "            cls_id = int(box.cls)\n",
        "            cls_name = yolo_model.names[cls_id]\n",
        "            \n",
        "            # Filter by class if specified\n",
        "            if classes and cls_name not in classes:\n",
        "                continue\n",
        "            \n",
        "            conf = float(box.conf)\n",
        "            bbox = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
        "            \n",
        "            # Use bbox as SAM prompt\n",
        "            masks, scores, _ = sam_predictor.predict(\n",
        "                point_coords=None,\n",
        "                point_labels=None,\n",
        "                box=bbox,\n",
        "                multimask_output=False\n",
        "            )\n",
        "            \n",
        "            detections.append({\n",
        "                'class': cls_name,\n",
        "                'confidence': conf,\n",
        "                'bbox': bbox.tolist(),\n",
        "                'mask': masks[0],\n",
        "                'mask_score': float(scores[0])\n",
        "            })\n",
        "    \n",
        "    print(f\"Detected and segmented {len(detections)} objects\")\n",
        "    return detections\n",
        "\n",
        "\n",
        "def visualize_detections(image: np.ndarray, detections: List[Dict]):\n",
        "    \"\"\"\n",
        "    Visualize detection boxes and segmentation masks.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    # Detection boxes\n",
        "    axes[0].imshow(image)\n",
        "    for det in detections:\n",
        "        x1, y1, x2, y2 = det['bbox']\n",
        "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                             fill=False, edgecolor='lime', linewidth=2)\n",
        "        axes[0].add_patch(rect)\n",
        "        axes[0].text(x1, y1-5, f\"{det['class']} {det['confidence']:.0%}\",\n",
        "                    color='lime', fontsize=10, backgroundcolor='black')\n",
        "    axes[0].set_title('YOLO Detections')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Segmentation masks\n",
        "    axes[1].imshow(image)\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(detections)))\n",
        "    \n",
        "    for det, color in zip(detections, colors):\n",
        "        mask = det['mask']\n",
        "        colored_mask = np.zeros((*mask.shape, 4))\n",
        "        colored_mask[mask] = [*color[:3], 0.5]\n",
        "        axes[1].imshow(colored_mask)\n",
        "        \n",
        "        # Add label at mask centroid\n",
        "        y_coords, x_coords = np.where(mask)\n",
        "        if len(x_coords) > 0:\n",
        "            cx, cy = x_coords.mean(), y_coords.mean()\n",
        "            axes[1].text(cx, cy, det['class'], color='white', fontsize=10,\n",
        "                        ha='center', va='center', backgroundcolor='black')\n",
        "    \n",
        "    axes[1].set_title('SAM Segmentation Masks')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"YOLO + SAM integration functions defined!\")\n",
        "print(\"\\nUsage:\")\n",
        "print(\"  from ultralytics import YOLO\")\n",
        "print(\"  from segment_anything import sam_model_registry, SamPredictor\")\n",
        "print(\"  \")\n",
        "print(\"  yolo = YOLO('yolov8s.pt')\")\n",
        "print(\"  sam = sam_model_registry['vit_b'](checkpoint='sam_vit_b.pth')\")\n",
        "print(\"  predictor = SamPredictor(sam)\")\n",
        "print(\"  \")\n",
        "print(\"  detections = detect_and_segment(image, yolo, predictor)\")\n",
        "print(\"  visualize_detections(image, detections)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Key concepts covered:\n",
        "\n",
        "1. **Magic Wand Tool**: Interactive point-based segmentation with:\n",
        "   - Positive/negative clicks\n",
        "   - Grow/shrink mask options\n",
        "   - Undo functionality\n",
        "\n",
        "2. **Box Prompts**: Bounding box-based segmentation\n",
        "\n",
        "3. **Automatic Segmentation**: Segment all objects without prompts\n",
        "\n",
        "4. **Mask Refinement**: Post-processing with morphological operations\n",
        "\n",
        "5. **YOLO + SAM**: Combining detection and segmentation\n",
        "\n",
        "SAM provides state-of-the-art segmentation that works with various input prompts (points, boxes, masks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"Cleanup complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
