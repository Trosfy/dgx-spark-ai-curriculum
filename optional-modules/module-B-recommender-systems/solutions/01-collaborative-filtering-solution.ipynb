{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab B.1 Solutions: Collaborative Filtering Fundamentals\n",
    "\n",
    "This notebook contains complete solutions to the exercises from Lab B.1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_dir = Path.cwd().parent if 'solutions' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(module_dir / 'scripts'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from data_utils import download_movielens, train_test_split_by_time, RatingsDataset\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ratings_df, movies_df = download_movielens('100k')\n",
    "train_df, test_df = train_test_split_by_time(ratings_df, test_ratio=0.2)\n",
    "\n",
    "num_users = ratings_df['user_id'].nunique()\n",
    "num_items = ratings_df['item_id'].nunique()\n",
    "\n",
    "train_dataset = RatingsDataset(train_df)\n",
    "test_dataset = RatingsDataset(test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1 Solution: Hyperparameter Tuning\n",
    "\n",
    "Compare different embedding dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        nn.init.normal_(self.user_embeddings.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embeddings.weight, std=0.01)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_emb = self.user_embeddings(user_ids)\n",
    "        item_emb = self.item_embeddings(item_ids)\n",
    "        interaction = (user_emb * item_emb).sum(dim=1)\n",
    "        prediction = (\n",
    "            interaction +\n",
    "            self.user_bias(user_ids).squeeze() +\n",
    "            self.item_bias(item_ids).squeeze() +\n",
    "            self.global_bias\n",
    "        )\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(embedding_dim, num_epochs=20):\n",
    "    \"\"\"Train MF model with given embedding dimension and return best RMSE.\"\"\"\n",
    "    model = MatrixFactorization(num_users, num_items, embedding_dim).to(device)\n",
    "    model.global_bias.data = torch.tensor([train_df['rating'].mean()])\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-5)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for users, items, ratings in train_loader:\n",
    "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "            predictions = model(users, items)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for users, items, ratings in test_loader:\n",
    "                users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "                predictions = model(users, items)\n",
    "                total_loss += criterion(predictions, ratings).item() * len(users)\n",
    "        \n",
    "        rmse = np.sqrt(total_loss / len(test_dataset))\n",
    "        best_rmse = min(best_rmse, rmse)\n",
    "    \n",
    "    return best_rmse\n",
    "\n",
    "\n",
    "# Test different embedding dimensions\n",
    "embedding_dims = [16, 32, 64, 128, 256]\n",
    "results = {}\n",
    "\n",
    "for dim in embedding_dims:\n",
    "    print(f\"\\nTesting embedding_dim = {dim}...\")\n",
    "    rmse = train_and_evaluate(dim, num_epochs=20)\n",
    "    results[dim] = rmse\n",
    "    print(f\"  Best RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "for dim, rmse in sorted(results.items()):\n",
    "    print(f\"  dim={dim:3d}: RMSE = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plt.figure(figsize=(10, 5))\n",
    "dims = list(results.keys())\n",
    "rmses = list(results.values())\n",
    "\n",
    "plt.plot(dims, rmses, 'bo-', markersize=10, linewidth=2)\n",
    "plt.xlabel('Embedding Dimension')\n",
    "plt.ylabel('Test RMSE')\n",
    "plt.title('Effect of Embedding Dimension on RMSE')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log', base=2)\n",
    "\n",
    "# Mark the best\n",
    "best_dim = min(results, key=results.get)\n",
    "plt.axvline(x=best_dim, color='red', linestyle='--', label=f'Best: dim={best_dim}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Best embedding dimension: {best_dim} with RMSE = {results[best_dim]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2 Solution: Regularization Impact\n",
    "\n",
    "Compare different weight decay values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_regularization(weight_decay, num_epochs=20):\n",
    "    \"\"\"Train with specified regularization and return train/test metrics.\"\"\"\n",
    "    model = MatrixFactorization(num_users, num_items, embedding_dim=64).to(device)\n",
    "    model.global_bias.data = torch.tensor([train_df['rating'].mean()])\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    test_rmses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for users, items, ratings in train_loader:\n",
    "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "            predictions = model(users, items)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * len(users)\n",
    "        \n",
    "        train_losses.append(epoch_loss / len(train_dataset))\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for users, items, ratings in test_loader:\n",
    "                users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "                predictions = model(users, items)\n",
    "                test_loss += criterion(predictions, ratings).item() * len(users)\n",
    "        \n",
    "        test_rmses.append(np.sqrt(test_loss / len(test_dataset)))\n",
    "    \n",
    "    return train_losses, test_rmses\n",
    "\n",
    "\n",
    "# Test different regularization strengths\n",
    "weight_decays = [0, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "all_results = {}\n",
    "\n",
    "for wd in weight_decays:\n",
    "    print(f\"Training with weight_decay = {wd}...\")\n",
    "    train_losses, test_rmses = train_with_regularization(wd, num_epochs=30)\n",
    "    all_results[wd] = {'train': train_losses, 'test': test_rmses}\n",
    "    print(f\"  Final RMSE: {test_rmses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regularization effects\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(weight_decays)))\n",
    "\n",
    "for wd, color in zip(weight_decays, colors):\n",
    "    label = f'wd={wd}' if wd > 0 else 'No reg'\n",
    "    axes[0].plot(all_results[wd]['train'], color=color, label=label)\n",
    "    axes[1].plot(all_results[wd]['test'], color=color, label=label)\n",
    "\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Training Loss')\n",
    "axes[0].set_title('Training Loss by Regularization')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Test RMSE')\n",
    "axes[1].set_title('Test RMSE by Regularization')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Observations:\")\n",
    "print(\"   - No regularization: Lowest training loss but may overfit\")\n",
    "print(\"   - Moderate regularization (1e-5): Good balance\")\n",
    "print(\"   - Strong regularization (1e-3): Higher training loss, may underfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: SVD++ Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPlusPlus(nn.Module):\n",
    "    \"\"\"\n",
    "    SVD++ incorporates implicit feedback: which items a user has rated.\n",
    "    \n",
    "    r_ui = global_bias + user_bias + item_bias + \n",
    "           q_i^T * (p_u + (1/sqrt(|N(u)|)) * sum(y_j for j in N(u)))\n",
    "    \n",
    "    where N(u) is the set of items user u has rated.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        # Standard MF components\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        # SVD++ addition: implicit factor vectors\n",
    "        self.implicit_factors = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for emb in [self.user_embeddings, self.item_embeddings, self.implicit_factors]:\n",
    "            nn.init.normal_(emb.weight, std=0.01)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "        \n",
    "    def forward(self, user_ids, item_ids, user_rated_items_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_ids: (batch_size,) tensor\n",
    "            item_ids: (batch_size,) tensor\n",
    "            user_rated_items_list: List of lists, each containing item IDs rated by user\n",
    "        \"\"\"\n",
    "        batch_size = len(user_ids)\n",
    "        \n",
    "        # Standard embeddings\n",
    "        p_u = self.user_embeddings(user_ids)  # (batch, dim)\n",
    "        q_i = self.item_embeddings(item_ids)  # (batch, dim)\n",
    "        \n",
    "        # Compute implicit contribution for each user\n",
    "        implicit_sum = torch.zeros_like(p_u)\n",
    "        \n",
    "        for idx, rated_items in enumerate(user_rated_items_list):\n",
    "            if len(rated_items) > 0:\n",
    "                rated_tensor = torch.LongTensor(rated_items).to(user_ids.device)\n",
    "                y_j = self.implicit_factors(rated_tensor)  # (num_rated, dim)\n",
    "                implicit_sum[idx] = y_j.sum(dim=0) / np.sqrt(len(rated_items))\n",
    "        \n",
    "        # Enhanced user representation\n",
    "        user_repr = p_u + implicit_sum\n",
    "        \n",
    "        # Interaction\n",
    "        interaction = (user_repr * q_i).sum(dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        prediction = (\n",
    "            self.global_bias +\n",
    "            self.user_bias(user_ids).squeeze() +\n",
    "            self.item_bias(item_ids).squeeze() +\n",
    "            interaction\n",
    "        )\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "print(\"âœ… SVD++ implemented!\")\n",
    "print(\"\\nNote: SVD++ requires tracking which items each user has rated.\")\n",
    "print(\"This is more complex but typically improves RMSE by 1-3%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Embedding dimension**: 64-128 is typically optimal for MovieLens 100K. Larger dimensions may overfit.\n",
    "\n",
    "2. **Regularization**: L2 regularization (weight_decay) helps prevent overfitting. 1e-5 is a good starting point.\n",
    "\n",
    "3. **SVD++**: Incorporating implicit feedback (which items are rated) improves performance but adds complexity.\n",
    "\n",
    "4. **Trade-offs**: There's always a balance between model complexity and generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
