{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab A.1: VC Dimension Exploration\n",
    "\n",
    "**Module:** A - Statistical Learning Theory  \n",
    "**Time:** 1.5 hours  \n",
    "**Difficulty:** ⭐⭐⭐⭐ (Advanced)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand what it means to \"shatter\" a dataset\n",
    "- [ ] Compute VC dimension for linear classifiers\n",
    "- [ ] Visualize why 4 points cannot be shattered by lines in 2D\n",
    "- [ ] Explore VC dimension for polynomial classifiers\n",
    "- [ ] Connect VC dimension to generalization guarantees\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed: Module 1.4 (Math Foundations)\n",
    "- Completed: Module 1.5 (Neural Networks basics)\n",
    "- Knowledge of: Linear algebra, basic classification concepts\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "Imagine you're building a spam classifier. You have 1,000 training emails. How confident can you be that your model will work on the millions of emails it will see in production? This isn't just a philosophical question - it has a mathematical answer.\n",
    "\n",
    "**VC dimension** is one of the most important theoretical tools for answering: *\"Will my model generalize?\"* Companies like Google and Meta use these insights to decide how much training data they need before deploying models to billions of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ELI5: What is VC Dimension?\n",
    "\n",
    "> **Imagine you're playing a game with crayons...** \n",
    ">\n",
    "> You put some dots on paper. Your friend colors each dot either red or blue, in any pattern they want. Your job is to draw ONE LINE that separates all red dots from all blue dots.\n",
    ">\n",
    "> With **2 dots**, you can always win! No matter how your friend colors them, you can draw a line between them.\n",
    ">\n",
    "> With **3 dots** (in a triangle), you can still always win! Even if one dot is a different color than the other two, you can find a line that works.\n",
    ">\n",
    "> But with **4 dots** in a square? Your friend can beat you! If they color opposite corners the same (like a checkerboard), NO straight line can separate them.\n",
    ">\n",
    "> **The VC dimension is the BIGGEST number of dots where you can ALWAYS win, no matter how your friend colors them.**\n",
    ">\n",
    "> For straight lines in 2D: VC dimension = 3\n",
    ">\n",
    "> **In AI terms:** A model with higher VC dimension can fit more complex patterns, but needs more training data to generalize reliably. It's the model's \"expressiveness\" measured mathematically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setting Up Our Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from typing import List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For linear separability checking\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Set nice plotting defaults\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Environment ready for VC dimension exploration!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Understanding Shattering\n",
    "\n",
    "### What Does \"Shattering\" Mean?\n",
    "\n",
    "A hypothesis class $\\mathcal{H}$ **shatters** a set of points if it can perfectly classify those points under **every possible labeling**.\n",
    "\n",
    "For $n$ points, there are $2^n$ possible binary labelings. If we can find a hypothesis in $\\mathcal{H}$ that correctly classifies each of those $2^n$ labelings, we say $\\mathcal{H}$ shatters those points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_linearly_separate(points: np.ndarray, labels: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a set of 2D points with given labels can be linearly separated.\n",
    "    \n",
    "    We use a hard-margin SVM (very high C) to check if perfect separation exists.\n",
    "    \n",
    "    Args:\n",
    "        points: Array of shape (n, 2) with point coordinates\n",
    "        labels: Array of shape (n,) with binary labels (0 or 1)\n",
    "        \n",
    "    Returns:\n",
    "        True if linearly separable, False otherwise\n",
    "    \"\"\"\n",
    "    # Edge case: all same label is trivially separable\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        return True\n",
    "    \n",
    "    # Use hard-margin SVM (very high C = no slack allowed)\n",
    "    clf = SVC(kernel='linear', C=1e10, max_iter=10000)\n",
    "    \n",
    "    try:\n",
    "        clf.fit(points, labels)\n",
    "        predictions = clf.predict(points)\n",
    "        return np.all(predictions == labels)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_if_shattered(points: np.ndarray) -> Tuple[bool, List[Tuple]]:\n",
    "    \"\"\"\n",
    "    Check if a linear classifier can shatter the given points.\n",
    "    \n",
    "    Args:\n",
    "        points: Array of shape (n, 2) with point coordinates\n",
    "        \n",
    "    Returns:\n",
    "        (is_shattered, list of failed labelings)\n",
    "    \"\"\"\n",
    "    n = len(points)\n",
    "    all_labelings = list(product([0, 1], repeat=n))\n",
    "    \n",
    "    failed_labelings = []\n",
    "    \n",
    "    for labeling in all_labelings:\n",
    "        labels = np.array(labeling)\n",
    "        if not can_linearly_separate(points, labels):\n",
    "            failed_labelings.append(labeling)\n",
    "    \n",
    "    is_shattered = len(failed_labelings) == 0\n",
    "    return is_shattered, failed_labelings\n",
    "\n",
    "\n",
    "print(\"Shattering functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Shatter 2 Points\n",
    "\n",
    "With 2 points, we have $2^2 = 4$ possible labelings. Can a line handle all of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two points\n",
    "points_2 = np.array([[0, 0], [2, 2]])\n",
    "\n",
    "# Check all 4 labelings\n",
    "is_shattered, failed = check_if_shattered(points_2)\n",
    "\n",
    "print(f\"Can 2 points be shattered by a line? {is_shattered}\")\n",
    "print(f\"Number of failed labelings: {len(failed)}\")\n",
    "\n",
    "# Visualize all 4 labelings\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "labelings = list(product([0, 1], repeat=2))\n",
    "\n",
    "for ax, labeling in zip(axes, labelings):\n",
    "    colors = ['blue' if l == 0 else 'red' for l in labeling]\n",
    "    ax.scatter(points_2[:, 0], points_2[:, 1], c=colors, s=200, edgecolors='black', linewidths=2)\n",
    "    ax.set_title(f\"Labels: {labeling}\", fontsize=12)\n",
    "    ax.set_xlim(-1, 3)\n",
    "    ax.set_ylim(-1, 3)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.suptitle(\"All 4 Labelings of 2 Points - All Linearly Separable!\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "For 2 points, we can always draw a line that separates them, regardless of their colors! This means 2 points **can be shattered** by linear classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Shattering 3 Points (The Magic Number in 2D)\n",
    "\n",
    "Now let's try 3 points. We have $2^3 = 8$ possible labelings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three points in \"general position\" (not collinear)\n",
    "points_3 = np.array([\n",
    "    [0, 0],\n",
    "    [2, 0],\n",
    "    [1, 1.5]\n",
    "])\n",
    "\n",
    "# Check shattering\n",
    "is_shattered, failed = check_if_shattered(points_3)\n",
    "\n",
    "print(f\"Can 3 points be shattered by a line? {is_shattered}\")\n",
    "print(f\"Number of failed labelings: {len(failed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_labelings_with_separator(points: np.ndarray, title: str = \"\"):\n",
    "    \"\"\"\n",
    "    Visualize all possible labelings and show separating lines where possible.\n",
    "    \"\"\"\n",
    "    n = len(points)\n",
    "    labelings = list(product([0, 1], repeat=n))\n",
    "    n_labelings = len(labelings)\n",
    "    \n",
    "    # Determine grid size\n",
    "    cols = 4\n",
    "    rows = (n_labelings + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "    axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
    "    \n",
    "    for idx, (ax, labeling) in enumerate(zip(axes, labelings)):\n",
    "        labels = np.array(labeling)\n",
    "        colors = ['blue' if l == 0 else 'red' for l in labels]\n",
    "        \n",
    "        # Plot points\n",
    "        ax.scatter(points[:, 0], points[:, 1], c=colors, s=200, edgecolors='black', linewidths=2, zorder=5)\n",
    "        \n",
    "        # Try to find and plot separator\n",
    "        separable = can_linearly_separate(points, labels)\n",
    "        \n",
    "        if separable and len(np.unique(labels)) > 1:\n",
    "            # Fit SVM to get the decision boundary\n",
    "            clf = SVC(kernel='linear', C=1e10)\n",
    "            clf.fit(points, labels)\n",
    "            \n",
    "            # Create mesh for decision boundary\n",
    "            x_min, x_max = points[:, 0].min() - 1, points[:, 0].max() + 1\n",
    "            y_min, y_max = points[:, 1].min() - 1, points[:, 1].max() + 1\n",
    "            \n",
    "            xx = np.linspace(x_min, x_max, 100)\n",
    "            \n",
    "            # Decision boundary: w0*x + w1*y + b = 0  =>  y = -(w0*x + b)/w1\n",
    "            w = clf.coef_[0]\n",
    "            b = clf.intercept_[0]\n",
    "            \n",
    "            if abs(w[1]) > 1e-10:  # Not vertical\n",
    "                yy = -(w[0] * xx + b) / w[1]\n",
    "                mask = (yy >= y_min) & (yy <= y_max)\n",
    "                ax.plot(xx[mask], yy[mask], 'g-', linewidth=2, label='Separator')\n",
    "            else:  # Vertical line\n",
    "                x_line = -b / w[0]\n",
    "                ax.axvline(x=x_line, color='g', linewidth=2)\n",
    "            \n",
    "            ax.set_title(f\"{labeling}\\nSeparable\", fontsize=10, color='green')\n",
    "        else:\n",
    "            status = \"Trivial\" if len(np.unique(labels)) == 1 else \"NOT Separable\"\n",
    "            title_color = 'gray' if len(np.unique(labels)) == 1 else 'red'\n",
    "            ax.set_title(f\"{labeling}\\n{status}\", fontsize=10, color=title_color)\n",
    "        \n",
    "        # Set axis limits\n",
    "        margin = 0.5\n",
    "        ax.set_xlim(points[:, 0].min() - margin, points[:, 0].max() + margin)\n",
    "        ax.set_ylim(points[:, 1].min() - margin, points[:, 1].max() + margin)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for ax in axes[n_labelings:]:\n",
    "        ax.set_visible(False)\n",
    "    \n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=14, fontweight='bold', y=1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize all 8 labelings of 3 points\n",
    "visualize_all_labelings_with_separator(points_3, \"All 8 Labelings of 3 Points - All Separable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Key Insight\n",
    "\n",
    "3 points in **general position** (not all on a line) CAN be shattered by linear classifiers in 2D. This means:\n",
    "\n",
    "$$\\text{VC}(\\text{linear classifiers in 2D}) \\geq 3$$\n",
    "\n",
    "But can we shatter 4 points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: The XOR Problem - Why 4 Points Can't Be Shattered\n",
    "\n",
    "This is the famous result that proves $\\text{VC}(\\text{linear classifiers in 2D}) = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four points in a square\n",
    "points_4 = np.array([\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "# Check shattering\n",
    "is_shattered, failed = check_if_shattered(points_4)\n",
    "\n",
    "print(f\"Can 4 points be shattered by a line? {is_shattered}\")\n",
    "print(f\"Number of failed labelings: {len(failed)}\")\n",
    "print(f\"\\nFailed labelings (XOR-like patterns):\")\n",
    "for f in failed:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize specifically the XOR problem\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# XOR pattern 1: (0,0,1,1) - diagonal corners\n",
    "xor_pattern_1 = np.array([0, 1, 1, 0])  # Top-left and bottom-right are class 0\n",
    "colors_1 = ['blue' if l == 0 else 'red' for l in xor_pattern_1]\n",
    "\n",
    "axes[0].scatter(points_4[:, 0], points_4[:, 1], c=colors_1, s=400, edgecolors='black', linewidths=3)\n",
    "for i, (x, y) in enumerate(points_4):\n",
    "    axes[0].annotate(f'({x},{y})', (x, y), textcoords=\"offset points\", xytext=(0,-25), ha='center', fontsize=10)\n",
    "axes[0].set_title(\"XOR Pattern 1\\nNo line can separate!\", fontsize=14, color='red', fontweight='bold')\n",
    "axes[0].set_xlim(-0.5, 1.5)\n",
    "axes[0].set_ylim(-0.5, 1.5)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# XOR pattern 2: (1,0,0,1) - the other diagonal\n",
    "xor_pattern_2 = np.array([1, 0, 0, 1])  # Top-right and bottom-left are class 0\n",
    "colors_2 = ['blue' if l == 0 else 'red' for l in xor_pattern_2]\n",
    "\n",
    "axes[1].scatter(points_4[:, 0], points_4[:, 1], c=colors_2, s=400, edgecolors='black', linewidths=3)\n",
    "for i, (x, y) in enumerate(points_4):\n",
    "    axes[1].annotate(f'({x},{y})', (x, y), textcoords=\"offset points\", xytext=(0,-25), ha='center', fontsize=10)\n",
    "axes[1].set_title(\"XOR Pattern 2\\nNo line can separate!\", fontsize=14, color='red', fontweight='bold')\n",
    "axes[1].set_xlim(-0.5, 1.5)\n",
    "axes[1].set_ylim(-0.5, 1.5)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "plt.suptitle(\"The XOR Problem: Why VC Dimension of Linear Classifiers in 2D = 3\", fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNo matter how you tilt or position a line, you CANNOT separate opposite corners!\")\n",
    "print(\"This proves VC(2D linear classifiers) = 3, not 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "The XOR pattern (opposite corners having the same label) is the classic example of a non-linearly-separable problem. Since there exists at least one labeling that cannot be achieved, 4 points **cannot be shattered**.\n",
    "\n",
    "Therefore:\n",
    "- 3 points CAN be shattered\n",
    "- 4 points CANNOT be shattered\n",
    "\n",
    "$$\\boxed{\\text{VC}(\\text{linear classifiers in 2D}) = 3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: The General Formula - VC Dimension in d Dimensions\n",
    "\n",
    "### The Beautiful Result\n",
    "\n",
    "For linear classifiers (hyperplanes) in $d$-dimensional space:\n",
    "\n",
    "$$\\text{VC}(\\text{linear classifiers in } \\mathbb{R}^d) = d + 1$$\n",
    "\n",
    "This makes intuitive sense:\n",
    "- In 2D: VC = 3 (we just proved this!)\n",
    "- In 3D: VC = 4 (a plane can shatter 4 points)\n",
    "- In 100D: VC = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc_dimension_linear_classifier(d: int) -> int:\n",
    "    \"\"\"\n",
    "    VC dimension of linear classifiers in d-dimensional space.\n",
    "    \n",
    "    Args:\n",
    "        d: Dimensionality of the input space\n",
    "        \n",
    "    Returns:\n",
    "        VC dimension (d + 1)\n",
    "    \"\"\"\n",
    "    return d + 1\n",
    "\n",
    "\n",
    "# Let's verify this intuition\n",
    "print(\"VC Dimension of Linear Classifiers:\")\n",
    "print(\"=\" * 40)\n",
    "for d in [1, 2, 3, 10, 100, 1000]:\n",
    "    vc = vc_dimension_linear_classifier(d)\n",
    "    print(f\"  {d:4d}D space: VC = {vc:5d}\")\n",
    "\n",
    "print(\"\\nImplication: A linear model with 1000 features can 'memorize'\")\n",
    "print(\"any labeling of up to 1001 training points perfectly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Polynomial Classifiers - Increasing VC Dimension\n",
    "\n",
    "What if we use polynomial decision boundaries instead of lines? The VC dimension increases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.preprocessing import PolynomialFeatures\n\n# ============================================================\n# Understanding PolynomialFeatures\n# ============================================================\n# PolynomialFeatures transforms input features into polynomial terms.\n# For example, with degree=2 and features [x1, x2]:\n#   Input:  [x1, x2]\n#   Output: [1, x1, x2, x1², x1*x2, x2²]\n#\n# This allows linear models to learn non-linear decision boundaries!\n# The \"kernel trick\" in SVMs is related - it implicitly does this.\n#\n# Key parameters:\n#   - degree: Maximum polynomial degree (e.g., 2 for quadratic)\n#   - include_bias: Whether to include a column of 1s (intercept term)\n#\n# Example:\n#   poly = PolynomialFeatures(degree=2)\n#   X_poly = poly.fit_transform(X)  # Transform features\n# ============================================================\n\ndef can_polynomial_separate(points: np.ndarray, labels: np.ndarray, degree: int) -> bool:\n    \"\"\"\n    Check if points can be separated using a polynomial decision boundary.\n    \n    We achieve this by mapping to polynomial feature space and using linear SVM.\n    \"\"\"\n    if len(np.unique(labels)) == 1:\n        return True\n    \n    # Transform to polynomial features\n    poly = PolynomialFeatures(degree=degree)\n    points_poly = poly.fit_transform(points)\n    \n    # Linear SVM in polynomial space = polynomial SVM in original space\n    clf = SVC(kernel='linear', C=1e10, max_iter=50000)\n    \n    try:\n        clf.fit(points_poly, labels)\n        predictions = clf.predict(points_poly)\n        return np.all(predictions == labels)\n    except Exception:\n        return False\n\n\ndef check_polynomial_shattering(points: np.ndarray, degree: int) -> Tuple[bool, int, int]:\n    \"\"\"\n    Check if polynomial classifier can shatter the given points.\n    \n    Returns:\n        (is_shattered, successful_labelings, total_labelings)\n    \"\"\"\n    n = len(points)\n    all_labelings = list(product([0, 1], repeat=n))\n    \n    successful = 0\n    for labeling in all_labelings:\n        labels = np.array(labeling)\n        if can_polynomial_separate(points, labels, degree):\n            successful += 1\n    \n    return successful == len(all_labelings), successful, len(all_labelings)\n\n\nprint(\"Polynomial shattering functions defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on our 4 points with different polynomial degrees\n",
    "print(\"Shattering 4 points with polynomial classifiers:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for degree in [1, 2, 3]:\n",
    "    is_shattered, success, total = check_polynomial_shattering(points_4, degree)\n",
    "    status = \"YES\" if is_shattered else \"NO\"\n",
    "    print(f\"  Degree {degree}: {success}/{total} labelings separable - Shattered? {status}\")\n",
    "\n",
    "print(\"\\nDegree 2 polynomials CAN shatter 4 points (they handle XOR)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### NumPy Array Manipulation for Visualization\n\nThe following cell uses some common NumPy patterns for creating decision boundary plots:\n\n```python\n# np.meshgrid() - Creates coordinate grids for plotting\nxx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 200), np.linspace(-0.5, 1.5, 200))\n# xx and yy are 2D arrays of x and y coordinates\n\n# .ravel() - Flattens an array to 1D (same as .flatten() but may share memory)\nxx.ravel()  # [x1, x2, x3, ...] all x-coordinates in a row\n\n# np.c_[] - Column-stacks arrays (combines as columns)\nnp.c_[xx.ravel(), yy.ravel()]  # Creates (N, 2) array of [x, y] pairs\n\n# .reshape() - Changes array shape\nZ.reshape(xx.shape)  # Reshapes 1D predictions back to 2D grid for plotting\n```\n\nThese patterns are essential for visualizing classifier decision boundaries!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize polynomial decision boundary solving XOR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# XOR labels\n",
    "xor_labels = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Fit polynomial SVM (degree 2)\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1e10)\n",
    "clf_poly.fit(points_4, xor_labels)\n",
    "\n",
    "# Create mesh for visualization\n",
    "xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 200), np.linspace(-0.5, 1.5, 200))\n",
    "Z = clf_poly.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')\n",
    "plt.contour(xx, yy, Z, colors='green', linewidths=2)\n",
    "\n",
    "colors = ['blue' if l == 0 else 'red' for l in xor_labels]\n",
    "plt.scatter(points_4[:, 0], points_4[:, 1], c=colors, s=400, edgecolors='black', linewidths=3, zorder=5)\n",
    "\n",
    "for i, (x, y) in enumerate(points_4):\n",
    "    plt.annotate(f'Class {xor_labels[i]}', (x, y), textcoords=\"offset points\", xytext=(0, 20), \n",
    "                ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.title(\"Polynomial (Degree 2) Classifier Solving XOR!\\nHigher VC dimension = More expressive\", \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"The curved decision boundary (hyperbola) separates the XOR pattern!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VC Dimension of Polynomial Classifiers\n",
    "\n",
    "For polynomial classifiers of degree $k$ in $d$ dimensions:\n",
    "\n",
    "$$\\text{VC} = \\binom{d + k}{k}$$\n",
    "\n",
    "This grows quickly with both dimension and polynomial degree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from math import comb\n\n# ============================================================\n# Understanding math.comb (Binomial Coefficient)\n# ============================================================\n# math.comb(n, k) computes \"n choose k\" = C(n,k) = n! / (k! * (n-k)!)\n# This counts the number of ways to choose k items from n items.\n#\n# Examples:\n#   comb(5, 2) = 10  (ways to choose 2 items from 5)\n#   comb(4, 2) = 6   (ways to choose 2 items from 4)\n#\n# In polynomial classifiers, comb(d+k, k) gives the number of\n# monomials up to degree k, which equals the VC dimension.\n# ============================================================\n\ndef vc_dimension_polynomial(d: int, k: int) -> int:\n    \"\"\"\n    VC dimension of polynomial classifiers of degree k in d dimensions.\n    \n    This equals the number of monomials up to degree k,\n    which is C(d+k, k) = (d+k)! / (d! * k!)\n    \n    Args:\n        d: Input dimensionality\n        k: Polynomial degree\n        \n    Returns:\n        VC dimension\n    \"\"\"\n    return comb(d + k, k)\n\n\nprint(\"VC Dimension of Polynomial Classifiers:\")\nprint(\"=\" * 50)\nprint(f\"{'Dimension':>10} | {'Degree 1':>10} | {'Degree 2':>10} | {'Degree 3':>10}\")\nprint(\"-\" * 50)\n\nfor d in [2, 5, 10, 50, 100]:\n    vc1 = vc_dimension_polynomial(d, 1)\n    vc2 = vc_dimension_polynomial(d, 2)\n    vc3 = vc_dimension_polynomial(d, 3)\n    print(f\"{d:>10} | {vc1:>10,} | {vc2:>10,} | {vc3:>10,}\")\n\nprint(\"\\nHigher VC dimension = More expressive but needs more data!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Neural Networks and VC Dimension\n",
    "\n",
    "What about neural networks? This is where things get interesting!\n",
    "\n",
    "### ELI5: Neural Network VC Dimension\n",
    "\n",
    "> **Imagine building with LEGO blocks...** \n",
    ">\n",
    "> A neural network is like having a box of LEGO bricks. The more bricks (parameters) you have, the more complex structures you can build. A network with 1 million parameters can build almost anything - it's incredibly expressive.\n",
    ">\n",
    "> The VC dimension of neural networks roughly grows with the number of parameters. More parameters = higher VC dimension = can fit more complex patterns.\n",
    ">\n",
    "> **But here's the puzzle:** Modern networks have billions of parameters (huge VC dimension) but still generalize! Theory says they shouldn't, but they do. This is one of the biggest open questions in deep learning theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_nn_vc_dimension(n_weights: int, n_layers: int) -> str:\n",
    "    \"\"\"\n",
    "    Estimate VC dimension of a neural network.\n",
    "    \n",
    "    Classical bound (loose): O(W * L * log(W))\n",
    "    where W = number of weights, L = number of layers\n",
    "    \n",
    "    Note: This is a theoretical upper bound; actual effective \n",
    "    capacity is often much lower due to implicit regularization.\n",
    "    \n",
    "    Args:\n",
    "        n_weights: Total number of trainable parameters\n",
    "        n_layers: Number of layers\n",
    "        \n",
    "    Returns:\n",
    "        String describing the VC dimension bound\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # Classical bound from Bartlett et al.\n",
    "    upper_bound = n_weights * n_layers * math.log(n_weights)\n",
    "    \n",
    "    # Simpler bound: O(W^2) for networks with sign/threshold activations\n",
    "    simple_bound = n_weights ** 2\n",
    "    \n",
    "    return f\"O({n_weights:,} × {n_layers} × log({n_weights:,})) ≈ {upper_bound:,.0f}\"\n",
    "\n",
    "\n",
    "print(\"VC Dimension Estimates for Neural Networks:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Some example architectures\n",
    "architectures = [\n",
    "    (\"Small MLP (784→100→10)\", 784*100 + 100 + 100*10 + 10, 2),\n",
    "    (\"ResNet-18\", 11_700_000, 18),\n",
    "    (\"GPT-2 Small (124M)\", 124_000_000, 12),\n",
    "    (\"LLaMA-7B\", 7_000_000_000, 32),\n",
    "    (\"GPT-4 (estimated)\", 1_800_000_000_000, 120),\n",
    "]\n",
    "\n",
    "for name, weights, layers in architectures:\n",
    "    vc_est = estimate_nn_vc_dimension(weights, layers)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Parameters: {weights:,}\")\n",
    "    print(f\"  VC bound: {vc_est}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Key Insight: These bounds are HUGE, yet models generalize!\")\n",
    "print(\"Modern theory uses 'effective' capacity measures instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: From VC Dimension to Generalization Bounds\n",
    "\n",
    "The whole point of VC dimension is to bound generalization error! Here's the famous result:\n",
    "\n",
    "### The Fundamental Theorem of Statistical Learning\n",
    "\n",
    "With probability at least $1 - \\delta$:\n",
    "\n",
    "$$\\text{Test Error} \\leq \\text{Training Error} + O\\left(\\sqrt{\\frac{\\text{VC} \\cdot \\log(n/\\text{VC}) + \\log(1/\\delta)}{n}}\\right)$$\n",
    "\n",
    "where $n$ is the number of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generalization_bound(vc_dim: int, n_samples: int, delta: float = 0.05) -> float:\n",
    "    \"\"\"\n",
    "    Compute the generalization gap bound based on VC dimension.\n",
    "    \n",
    "    This tells us: with probability (1 - delta), the difference between\n",
    "    test error and training error is at most this value.\n",
    "    \n",
    "    Args:\n",
    "        vc_dim: VC dimension of the hypothesis class\n",
    "        n_samples: Number of training samples\n",
    "        delta: Confidence parameter (default 0.05 for 95% confidence)\n",
    "        \n",
    "    Returns:\n",
    "        Upper bound on generalization gap\n",
    "    \"\"\"\n",
    "    if n_samples <= vc_dim:\n",
    "        return 1.0  # Bound is trivial\n",
    "    \n",
    "    # Simplified VC bound\n",
    "    gap = np.sqrt((vc_dim * np.log(2 * n_samples / vc_dim) + np.log(4 / delta)) / n_samples)\n",
    "    return min(gap, 1.0)  # Cap at 1.0\n",
    "\n",
    "\n",
    "# Visualize how the bound changes with training set size\n",
    "vc_dims = [3, 10, 100, 1000]\n",
    "n_samples_range = np.logspace(1, 6, 100).astype(int)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for vc in vc_dims:\n",
    "    bounds = [generalization_bound(vc, n) for n in n_samples_range]\n",
    "    plt.plot(n_samples_range, bounds, label=f'VC = {vc}', linewidth=2)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of Training Samples', fontsize=12)\n",
    "plt.ylabel('Generalization Gap Bound', fontsize=12)\n",
    "plt.title('Generalization Bound Decreases with More Data\\n(Higher VC = Need More Data)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: Higher VC dimension requires more training data for same guarantee!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical implications\n",
    "print(\"Practical Generalization Bounds:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scenarios = [\n",
    "    (\"Linear classifier, 100D, 10K samples\", 101, 10_000),\n",
    "    (\"Polynomial (deg 2), 100D, 10K samples\", 5151, 10_000),\n",
    "    (\"Linear classifier, 100D, 100K samples\", 101, 100_000),\n",
    "    (\"Neural net (1K params), 10K samples\", 10_000, 10_000),\n",
    "    (\"Neural net (1K params), 1M samples\", 10_000, 1_000_000),\n",
    "]\n",
    "\n",
    "for name, vc, n in scenarios:\n",
    "    bound = generalization_bound(vc, n)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Generalization gap bound: {bound:.4f} ({bound*100:.1f}%)\")\n",
    "    if bound < 0.05:\n",
    "        print(f\"  Strong generalization expected!\")\n",
    "    elif bound < 0.2:\n",
    "        print(f\"  Moderate generalization expected.\")\n",
    "    else:\n",
    "        print(f\"  Weak guarantee - need more data or simpler model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Try It Yourself\n",
    "\n",
    "### Exercise 1: Custom Point Configuration\n",
    "\n",
    "Create 5 points in 2D and check if they can be shattered by linear classifiers. Explain your finding.\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "Since VC = 3 for 2D linear classifiers, 5 points definitely cannot be shattered. The question is: how many labelings fail?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Create 5 points and check shattering\n",
    "\n",
    "points_5 = np.array([\n",
    "    # Add your 5 points here\n",
    "    # [x1, y1],\n",
    "    # [x2, y2],\n",
    "    # ...\n",
    "])\n",
    "\n",
    "# Uncomment and run:\n",
    "# is_shattered, failed = check_if_shattered(points_5)\n",
    "# print(f\"Shattered: {is_shattered}\")\n",
    "# print(f\"Failed labelings: {len(failed)} out of {2**5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Data Requirements Calculator\n",
    "\n",
    "You're building a spam classifier with a 500-dimensional feature space (500 word features). Using a linear classifier:\n",
    "\n",
    "1. What is the VC dimension?\n",
    "2. How many training emails do you need for a generalization gap bound of 10%?\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "For linear classifiers in d dimensions, VC = d + 1. Then solve for n in the generalization bound formula.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "\n",
    "d = 500  # Feature dimensionality\n",
    "\n",
    "# Q1: What is the VC dimension?\n",
    "vc_dim = None  # Your answer\n",
    "\n",
    "# Q2: How many samples for 10% generalization gap?\n",
    "# Try different values and find where bound < 0.10\n",
    "target_gap = 0.10\n",
    "n_samples = None  # Your answer\n",
    "\n",
    "# Verify:\n",
    "# print(f\"VC dimension: {vc_dim}\")\n",
    "# print(f\"Required samples: {n_samples}\")\n",
    "# print(f\"Achieved bound: {generalization_bound(vc_dim, n_samples):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Confusing VC Dimension with Model Accuracy\n",
    "\n",
    "```python\n",
    "# WRONG thinking:\n",
    "# \"Higher VC dimension = better model\"\n",
    "\n",
    "# RIGHT thinking:\n",
    "# \"Higher VC dimension = more expressive, but needs more data\"\n",
    "# A model that's TOO expressive will overfit with limited data!\n",
    "```\n",
    "\n",
    "**Why:** VC dimension measures capacity, not quality. A model with infinite VC dimension can fit any training set perfectly but will memorize rather than generalize.\n",
    "\n",
    "### Mistake 2: Thinking VC Bounds Are Tight\n",
    "\n",
    "```python\n",
    "# WRONG:\n",
    "# \"Theory says I need 1 million samples, so I must collect 1 million\"\n",
    "\n",
    "# RIGHT:\n",
    "# \"Theory gives worst-case bounds. In practice, I often need far less.\"\n",
    "# Modern neural nets violate classical VC predictions routinely!\n",
    "```\n",
    "\n",
    "**Why:** VC bounds are worst-case guarantees. Real data has structure that models exploit. Use theory for intuition, not precise predictions.\n",
    "\n",
    "### Mistake 3: Ignoring Implicit Regularization\n",
    "\n",
    "```python\n",
    "# WRONG:\n",
    "# \"My neural net has 1B parameters, VC dimension is astronomical,\n",
    "#  therefore it must overfit\"\n",
    "\n",
    "# RIGHT:\n",
    "# \"SGD, dropout, batch norm, and early stopping provide implicit\n",
    "#  regularization that reduces effective capacity far below VC bounds\"\n",
    "```\n",
    "\n",
    "**Why:** Modern deep learning exploits many regularization mechanisms that classical VC theory doesn't account for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- **Shattering**: A hypothesis class shatters points if it can achieve all possible labelings\n",
    "- **VC Dimension**: The maximum number of points that can be shattered\n",
    "- **Linear classifiers in 2D have VC = 3** (XOR proves 4 fails)\n",
    "- **General formula**: Linear in d dimensions has VC = d + 1\n",
    "- **Generalization bound**: Decreases with more data, increases with VC dimension\n",
    "- **Neural network paradox**: Huge VC dimension but still generalize!\n",
    "\n",
    "---\n",
    "\n",
    "## Challenge (Optional)\n",
    "\n",
    "### Advanced: Empirical VC Dimension Estimation\n",
    "\n",
    "Implement a function that empirically estimates the VC dimension of a given classifier by testing shattering on randomly sampled point configurations.\n",
    "\n",
    "```python\n",
    "def estimate_vc_empirically(classifier_factory, d=2, max_points=10, n_trials=100):\n",
    "    \"\"\"\n",
    "    Empirically estimate VC dimension by testing shattering.\n",
    "    \n",
    "    Args:\n",
    "        classifier_factory: Function that returns a fresh classifier\n",
    "        d: Dimensionality of points\n",
    "        max_points: Maximum number of points to try\n",
    "        n_trials: Number of random configurations to test per point count\n",
    "        \n",
    "    Returns:\n",
    "        Estimated VC dimension (highest n where shattering succeeded)\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) - Chapter 6 (VC Dimension)\n",
    "- [CS229 Stanford Lecture Notes](https://cs229.stanford.edu/notes2022fall/main_notes.pdf) - Learning Theory section\n",
    "- [Original Vapnik-Chervonenkis Paper (1971)](https://link.springer.com/article/10.1007/BF01037268) - Historical importance\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any large variables\n",
    "import gc\n",
    "\n",
    "# Close all matplotlib figures\n",
    "plt.close('all')\n",
    "\n",
    "# Garbage collection\n",
    "gc.collect()\n",
    "\n",
    "print(\"Cleanup complete!\")\n",
    "print(\"\\nNext up: Lab A.2 - Bias-Variance Decomposition\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}