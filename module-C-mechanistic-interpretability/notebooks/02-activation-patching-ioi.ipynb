{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab C.2: Activation Patching on IOI\n",
    "\n",
    "**Module:** C - Mechanistic Interpretability  \n",
    "**Time:** 2 hours  \n",
    "**Difficulty:** ⭐⭐⭐⭐ (Advanced)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Understand the IOI (Indirect Object Identification) task\n",
    "- [ ] Implement activation patching to identify causal components\n",
    "- [ ] Find which layers and heads are crucial for IOI\n",
    "- [ ] Create heatmaps of component importance\n",
    "- [ ] Compare your findings to published IOI circuit research\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed: Lab C.1 (TransformerLens Setup)\n",
    "- Knowledge of: Attention patterns, caching activations\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "**Why IOI?** The Indirect Object Identification task is the \"fruit fly\" of mechanistic interpretability - a simple, well-defined task where we can fully reverse-engineer the model's algorithm. The [original IOI paper](https://arxiv.org/abs/2211.00593) is considered a landmark in interpretability research.\n",
    "\n",
    "Understanding how to find circuits in simple tasks gives us the tools to tackle more complex behaviors like:\n",
    "- Why does the model hallucinate?\n",
    "- How does it do multi-step reasoning?\n",
    "- Where does it store factual knowledge?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5: What is Activation Patching?\n",
    "\n",
    "> **Imagine you're a detective investigating a crime**. You have two scenarios:\n",
    ">\n",
    "> 1. **Clean scenario**: The crime happened (model predicts correctly)\n",
    "> 2. **Corrupted scenario**: The crime didn't happen (model predicts incorrectly)\n",
    ">\n",
    "> **Activation patching** is like swapping one piece of evidence at a time from the \"no crime\" scenario into the \"crime\" scenario. If swapping that one piece suddenly makes everyone think no crime happened, you've found crucial evidence!\n",
    ">\n",
    "> **For neural networks:**\n",
    "> - Clean run: \"John and Mary...\" → model predicts \"Mary\"\n",
    "> - Corrupted run: \"Mary and John...\" → model predicts \"John\"\n",
    "> - Patching: Replace layer 5's activations from corrupted into clean\n",
    "> - If prediction changes from \"Mary\" to \"John\" → Layer 5 is crucial!\n",
    ">\n",
    "> This is **causal intervention** - we're not just observing, we're actively changing things to prove what matters!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5: The IOI Task\n",
    "\n",
    "> **Consider this sentence:** \"John and Mary went to the store. John gave a book to ___\"\n",
    ">\n",
    "> **Who should fill in the blank?** Mary! Because:\n",
    "> 1. John already appeared as the giver\n",
    "> 2. Mary is the other person mentioned\n",
    "> 3. So Mary must be the receiver\n",
    ">\n",
    "> **This is Indirect Object Identification (IOI)**:\n",
    "> - The subject (John) does an action\n",
    "> - The indirect object (Mary) receives the action\n",
    "> - The model must figure out that \"to ___\" should be Mary, not John\n",
    ">\n",
    "> **Why is this interesting?** It requires the model to:\n",
    "> 1. Track who's mentioned (John and Mary)\n",
    "> 2. Notice John appears twice (as subject)\n",
    "> 3. Conclude Mary should fill the blank (by elimination)\n",
    ">\n",
    "> A simple task, but it reveals sophisticated circuitry!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and IOI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from typing import List, Dict, Optional, Tuple, Callable\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "import random\n",
    "\n",
    "# TransformerLens\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "torch.set_grad_enabled(False)  # We don't need gradients for interpretability\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Loaded GPT-2 Small: {model.cfg.n_layers} layers, {model.cfg.n_heads} heads/layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IOI dataset\n",
    "# Clean: \"[Name1] and [Name2] ... [Name1] gave ... to\" -> [Name2]\n",
    "# Corrupted: Same but with names swapped in key positions\n",
    "\n",
    "@dataclass\n",
    "class IOIExample:\n",
    "    \"\"\"A single IOI example with clean and corrupted versions.\"\"\"\n",
    "    clean: str\n",
    "    corrupted: str\n",
    "    answer: str  # The correct completion (e.g., \" Mary\")\n",
    "    wrong_answer: str  # What corrupted version would predict\n",
    "    \n",
    "def create_ioi_dataset(n_samples: int = 100, seed: int = 42) -> List[IOIExample]:\n",
    "    \"\"\"\n",
    "    Create IOI dataset with clean and corrupted examples.\n",
    "    \n",
    "    Clean: \"John and Mary went to the store. John gave a book to\" -> \"Mary\"\n",
    "    Corrupted: \"John and Mary went to the store. Mary gave a book to\" -> \"John\"\n",
    "    \n",
    "    The corruption swaps which name appears as the subject of the second sentence.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    names = [\"John\", \"Mary\", \"Alice\", \"Bob\", \"James\", \"Emma\", \n",
    "             \"Michael\", \"Sarah\", \"David\", \"Lisa\", \"Tom\", \"Kate\"]\n",
    "    places = [\"store\", \"park\", \"beach\", \"library\", \"cafe\", \"museum\", \"restaurant\"]\n",
    "    objects = [\"book\", \"ball\", \"key\", \"letter\", \"gift\", \"phone\", \"bag\", \"drink\"]\n",
    "    \n",
    "    dataset = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Pick two different names\n",
    "        name1, name2 = random.sample(names, 2)\n",
    "        place = random.choice(places)\n",
    "        obj = random.choice(objects)\n",
    "        \n",
    "        # Clean: Name1 is the subject, so Name2 is the answer\n",
    "        clean = f\"{name1} and {name2} went to the {place}. {name1} gave a {obj} to\"\n",
    "        \n",
    "        # Corrupted: Name2 is the subject, so Name1 would be the answer\n",
    "        corrupted = f\"{name1} and {name2} went to the {place}. {name2} gave a {obj} to\"\n",
    "        \n",
    "        dataset.append(IOIExample(\n",
    "            clean=clean,\n",
    "            corrupted=corrupted,\n",
    "            answer=f\" {name2}\",\n",
    "            wrong_answer=f\" {name1}\"\n",
    "        ))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Create dataset\n",
    "ioi_dataset = create_ioi_dataset(n_samples=50)\n",
    "\n",
    "# Show example\n",
    "example = ioi_dataset[0]\n",
    "print(\"IOI Example:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Clean:     '{example.clean}'\")\n",
    "print(f\"Answer:    '{example.answer}'\")\n",
    "print()\n",
    "print(f\"Corrupted: '{example.corrupted}'\")\n",
    "print(f\"Would predict: '{example.wrong_answer}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the model actually does IOI correctly\n",
    "def test_ioi_accuracy(model, dataset: List[IOIExample], n_test: int = 10) -> float:\n",
    "    \"\"\"Test how well the model does on IOI.\"\"\"\n",
    "    correct = 0\n",
    "    \n",
    "    for ex in dataset[:n_test]:\n",
    "        tokens = model.to_tokens(ex.clean)\n",
    "        logits = model(tokens)\n",
    "        \n",
    "        # Get prediction\n",
    "        pred_token = logits[0, -1, :].argmax().item()\n",
    "        pred_str = model.tokenizer.decode(pred_token)\n",
    "        \n",
    "        # Check if correct\n",
    "        if pred_str.strip() == ex.answer.strip():\n",
    "            correct += 1\n",
    "            status = \"✓\"\n",
    "        else:\n",
    "            status = \"✗\"\n",
    "        \n",
    "        print(f\"{status} Predicted '{pred_str}', expected '{ex.answer}'\")\n",
    "    \n",
    "    accuracy = correct / n_test\n",
    "    print(f\"\\nAccuracy: {accuracy:.0%}\")\n",
    "    return accuracy\n",
    "\n",
    "print(\"Testing model on IOI task:\")\n",
    "print(\"=\" * 60)\n",
    "accuracy = test_ioi_accuracy(model, ioi_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "GPT-2 Small does surprisingly well on IOI! It's learned to track which name is the subject and predict the other name as the indirect object. Now let's figure out *how* it does this.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Activation Patching\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "1. **Run clean prompt** → Get correct prediction \"Mary\"\n",
    "2. **Run corrupted prompt** → Get incorrect prediction \"John\"\n",
    "3. **Patch**: Run clean prompt, but replace some activations with values from corrupted run\n",
    "4. **Measure**: How much does the prediction change?\n",
    "\n",
    "If patching layer X makes the model predict \"John\" instead of \"Mary\", then layer X is crucial for the IOI task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's understand the patching process step by step\n",
    "ex = ioi_dataset[0]\n",
    "\n",
    "# Tokenize both versions\n",
    "clean_tokens = model.to_tokens(ex.clean)\n",
    "corrupted_tokens = model.to_tokens(ex.corrupted)\n",
    "\n",
    "print(\"Clean tokens:\")\n",
    "print(model.to_str_tokens(clean_tokens))\n",
    "print(f\"\\nCorrupted tokens:\")\n",
    "print(model.to_str_tokens(corrupted_tokens))\n",
    "\n",
    "# Note: The token positions should be the same for both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get answer token IDs\n",
    "answer_token = model.to_single_token(ex.answer)\n",
    "wrong_token = model.to_single_token(ex.wrong_answer)\n",
    "\n",
    "print(f\"Answer token: '{ex.answer}' -> ID {answer_token}\")\n",
    "print(f\"Wrong token: '{ex.wrong_answer}' -> ID {wrong_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run both and cache activations\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "\n",
    "# Get probabilities for the answer\n",
    "clean_probs = torch.softmax(clean_logits[0, -1, :], dim=-1)\n",
    "corrupted_probs = torch.softmax(corrupted_logits[0, -1, :], dim=-1)\n",
    "\n",
    "print(f\"Clean prediction:\")\n",
    "print(f\"  P('{ex.answer}'): {clean_probs[answer_token].item():.2%}\")\n",
    "print(f\"  P('{ex.wrong_answer}'): {clean_probs[wrong_token].item():.2%}\")\n",
    "\n",
    "print(f\"\\nCorrupted prediction:\")\n",
    "print(f\"  P('{ex.answer}'): {corrupted_probs[answer_token].item():.2%}\")\n",
    "print(f\"  P('{ex.wrong_answer}'): {corrupted_probs[wrong_token].item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Metric: Logit Difference\n",
    "\n",
    "We'll use **logit difference** as our metric:\n",
    "- Clean run: logit(Mary) - logit(John) = positive (prefers Mary)\n",
    "- Corrupted run: logit(Mary) - logit(John) = negative (prefers John)\n",
    "\n",
    "When we patch, we measure how much the logit difference changes from clean to corrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_diff(logits, answer_token, wrong_token, position=-1):\n",
    "    \"\"\"\n",
    "    Compute logit difference: logit(correct) - logit(incorrect)\n",
    "    Positive = prefers correct, Negative = prefers incorrect\n",
    "    \"\"\"\n",
    "    return (logits[0, position, answer_token] - logits[0, position, wrong_token]).item()\n",
    "\n",
    "clean_logit_diff = compute_logit_diff(clean_logits, answer_token, wrong_token)\n",
    "corrupted_logit_diff = compute_logit_diff(corrupted_logits, answer_token, wrong_token)\n",
    "\n",
    "print(f\"Clean logit diff: {clean_logit_diff:.2f} (positive = prefers '{ex.answer}')\")\n",
    "print(f\"Corrupted logit diff: {corrupted_logit_diff:.2f} (negative = prefers '{ex.wrong_answer}')\")\n",
    "print(f\"\\nDifference: {clean_logit_diff - corrupted_logit_diff:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Implementing Activation Patching\n",
    "\n",
    "Now let's implement patching! We'll patch activations from the corrupted run into the clean run and measure how it affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_residual_stream(\n",
    "    model: HookedTransformer,\n",
    "    clean_tokens: torch.Tensor,\n",
    "    corrupted_cache: dict,\n",
    "    layer: int,\n",
    "    position: Optional[int] = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Patch the residual stream at a specific layer.\n",
    "    \n",
    "    Args:\n",
    "        model: The transformer model\n",
    "        clean_tokens: Tokens for clean run\n",
    "        corrupted_cache: Cached activations from corrupted run\n",
    "        layer: Which layer to patch\n",
    "        position: Which position to patch (None = all positions)\n",
    "    \n",
    "    Returns:\n",
    "        Logits after patching\n",
    "    \"\"\"\n",
    "    def patch_hook(activation, hook):\n",
    "        # activation shape: [batch, seq, d_model]\n",
    "        corrupted_activation = corrupted_cache[hook.name]\n",
    "        \n",
    "        if position is None:\n",
    "            # Patch all positions\n",
    "            return corrupted_activation\n",
    "        else:\n",
    "            # Patch only specific position\n",
    "            activation[:, position, :] = corrupted_activation[:, position, :]\n",
    "            return activation\n",
    "    \n",
    "    # Run with hook\n",
    "    hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    patched_logits = model.run_with_hooks(\n",
    "        clean_tokens,\n",
    "        fwd_hooks=[(hook_name, patch_hook)]\n",
    "    )\n",
    "    \n",
    "    return patched_logits\n",
    "\n",
    "# Test patching layer 5\n",
    "patched_logits = patch_residual_stream(model, clean_tokens, corrupted_cache, layer=5)\n",
    "patched_logit_diff = compute_logit_diff(patched_logits, answer_token, wrong_token)\n",
    "\n",
    "print(f\"Original clean logit diff: {clean_logit_diff:.2f}\")\n",
    "print(f\"Patched (layer 5) logit diff: {patched_logit_diff:.2f}\")\n",
    "print(f\"Effect: {clean_logit_diff - patched_logit_diff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_patching_effect(\n",
    "    clean_logit_diff: float,\n",
    "    corrupted_logit_diff: float,\n",
    "    patched_logit_diff: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute normalized patching effect.\n",
    "    \n",
    "    Effect = 0: Patching had no effect (still behaves like clean)\n",
    "    Effect = 1: Patching fully corrupted behavior (behaves like corrupted)\n",
    "    \n",
    "    Formula: (clean - patched) / (clean - corrupted)\n",
    "    \"\"\"\n",
    "    return (clean_logit_diff - patched_logit_diff) / (clean_logit_diff - corrupted_logit_diff + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch every layer and measure effects\n",
    "layer_effects = []\n",
    "\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    patched_logits = patch_residual_stream(model, clean_tokens, corrupted_cache, layer=layer)\n",
    "    patched_diff = compute_logit_diff(patched_logits, answer_token, wrong_token)\n",
    "    effect = compute_patching_effect(clean_logit_diff, corrupted_logit_diff, patched_diff)\n",
    "    layer_effects.append(effect)\n",
    "    \n",
    "# Plot\n",
    "fig = px.bar(\n",
    "    x=list(range(model.cfg.n_layers)),\n",
    "    y=layer_effects,\n",
    "    title=\"Residual Stream Patching Effects by Layer\",\n",
    "    labels={\"x\": \"Layer\", \"y\": \"Patching Effect (0=none, 1=full)\"}\n",
    ")\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Layer Effects\n",
    "\n",
    "- **High effect** (close to 1): This layer is crucial - patching it breaks the IOI behavior\n",
    "- **Low effect** (close to 0): This layer doesn't matter much for IOI\n",
    "- **Negative effect**: Patching this layer actually helps (rare, but interesting)\n",
    "\n",
    "Typically, we see effects concentrated in specific layers where the IOI circuit operates.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Head-Level Patching\n",
    "\n",
    "Now let's go deeper - instead of patching entire layers, let's patch individual attention heads to find exactly which heads matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_attention_head(\n",
    "    model: HookedTransformer,\n",
    "    clean_tokens: torch.Tensor,\n",
    "    corrupted_cache: dict,\n",
    "    layer: int,\n",
    "    head: int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Patch a specific attention head's output.\n",
    "    \n",
    "    We patch the 'z' tensor which is the weighted combination of values,\n",
    "    before the output projection.\n",
    "    \"\"\"\n",
    "    def patch_hook(activation, hook):\n",
    "        # activation shape: [batch, seq, n_heads, d_head]\n",
    "        corrupted_activation = corrupted_cache[hook.name]\n",
    "        activation[:, :, head, :] = corrupted_activation[:, :, head, :]\n",
    "        return activation\n",
    "    \n",
    "    hook_name = f\"blocks.{layer}.attn.hook_z\"\n",
    "    patched_logits = model.run_with_hooks(\n",
    "        clean_tokens,\n",
    "        fwd_hooks=[(hook_name, patch_hook)]\n",
    "    )\n",
    "    \n",
    "    return patched_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch every head and measure effects\n",
    "n_layers = model.cfg.n_layers\n",
    "n_heads = model.cfg.n_heads\n",
    "\n",
    "head_effects = np.zeros((n_layers, n_heads))\n",
    "\n",
    "print(\"Computing head patching effects...\")\n",
    "for layer in range(n_layers):\n",
    "    for head in range(n_heads):\n",
    "        patched_logits = patch_attention_head(model, clean_tokens, corrupted_cache, layer, head)\n",
    "        patched_diff = compute_logit_diff(patched_logits, answer_token, wrong_token)\n",
    "        effect = compute_patching_effect(clean_logit_diff, corrupted_logit_diff, patched_diff)\n",
    "        head_effects[layer, head] = effect\n",
    "    print(f\"  Layer {layer} done\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize head effects as a heatmap\n",
    "fig = px.imshow(\n",
    "    head_effects,\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Effect\"},\n",
    "    color_continuous_scale=\"RdBu_r\",\n",
    "    color_continuous_midpoint=0,\n",
    "    title=\"Attention Head Patching Effects (IOI Task)\"\n",
    ")\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most important heads\n",
    "print(\"Most important attention heads for IOI:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Flatten and sort\n",
    "flat_effects = head_effects.flatten()\n",
    "sorted_indices = np.argsort(np.abs(flat_effects))[::-1]\n",
    "\n",
    "for i, idx in enumerate(sorted_indices[:15]):\n",
    "    layer = idx // n_heads\n",
    "    head = idx % n_heads\n",
    "    effect = head_effects[layer, head]\n",
    "    direction = \"→ corrupts\" if effect > 0 else \"→ helps\"\n",
    "    print(f\"{i+1:2d}. L{layer}H{head}: effect = {effect:.3f} {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Head Effects\n",
    "\n",
    "From the IOI paper, we expect to find:\n",
    "\n",
    "1. **Name Mover Heads** (positive effect): These heads move the correct name to the output\n",
    "   - They attend from the final position to the indirect object name\n",
    "   - Patching them breaks the correct prediction\n",
    "\n",
    "2. **Negative/Inhibition Heads** (negative effect): These heads suppress the wrong name\n",
    "   - They help by reducing the probability of the subject name\n",
    "   - Patching them actually helps (less common)\n",
    "\n",
    "3. **Backup Heads**: Heads that do the same job as name movers but kick in when needed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Aggregating Over the Dataset\n",
    "\n",
    "Let's run patching on multiple examples to get robust results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_patching_experiment(\n",
    "    model: HookedTransformer,\n",
    "    dataset: List[IOIExample],\n",
    "    n_samples: int = 20\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Run head patching experiment over multiple examples.\n",
    "    Returns aggregated effects [n_layers, n_heads].\n",
    "    \"\"\"\n",
    "    n_layers = model.cfg.n_layers\n",
    "    n_heads = model.cfg.n_heads\n",
    "    \n",
    "    all_effects = np.zeros((n_layers, n_heads))\n",
    "    \n",
    "    for i, ex in enumerate(dataset[:n_samples]):\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Processing example {i+1}/{n_samples}...\")\n",
    "        \n",
    "        # Tokenize\n",
    "        clean_tokens = model.to_tokens(ex.clean)\n",
    "        corrupted_tokens = model.to_tokens(ex.corrupted)\n",
    "        \n",
    "        # Get answer tokens\n",
    "        answer_token = model.to_single_token(ex.answer)\n",
    "        wrong_token = model.to_single_token(ex.wrong_answer)\n",
    "        \n",
    "        # Run both\n",
    "        clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "        corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "        \n",
    "        # Baselines\n",
    "        clean_diff = compute_logit_diff(clean_logits, answer_token, wrong_token)\n",
    "        corrupted_diff = compute_logit_diff(corrupted_logits, answer_token, wrong_token)\n",
    "        \n",
    "        # Skip if the model doesn't get this one right\n",
    "        if clean_diff <= 0:\n",
    "            continue\n",
    "        \n",
    "        # Patch each head\n",
    "        for layer in range(n_layers):\n",
    "            for head in range(n_heads):\n",
    "                patched_logits = patch_attention_head(\n",
    "                    model, clean_tokens, corrupted_cache, layer, head\n",
    "                )\n",
    "                patched_diff = compute_logit_diff(patched_logits, answer_token, wrong_token)\n",
    "                effect = compute_patching_effect(clean_diff, corrupted_diff, patched_diff)\n",
    "                all_effects[layer, head] += effect\n",
    "        \n",
    "        # Clean up\n",
    "        del clean_cache, corrupted_cache\n",
    "    \n",
    "    # Average\n",
    "    all_effects /= n_samples\n",
    "    \n",
    "    return all_effects\n",
    "\n",
    "# Run experiment\n",
    "print(\"Running patching experiment on dataset...\")\n",
    "print(\"(This will take a few minutes)\\n\")\n",
    "\n",
    "aggregated_effects = run_patching_experiment(model, ioi_dataset, n_samples=20)\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize aggregated results\n",
    "fig = px.imshow(\n",
    "    aggregated_effects,\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Avg Effect\"},\n",
    "    color_continuous_scale=\"RdBu_r\",\n",
    "    color_continuous_midpoint=0,\n",
    "    title=\"Aggregated Head Patching Effects (IOI Task, 20 examples)\"\n",
    ")\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most important heads from aggregated results\n",
    "print(\"Most important attention heads (aggregated over dataset):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "flat_effects = aggregated_effects.flatten()\n",
    "sorted_indices = np.argsort(np.abs(flat_effects))[::-1]\n",
    "\n",
    "name_movers = []\n",
    "negative_heads = []\n",
    "\n",
    "for i, idx in enumerate(sorted_indices[:20]):\n",
    "    layer = idx // n_heads\n",
    "    head = idx % n_heads\n",
    "    effect = aggregated_effects[layer, head]\n",
    "    \n",
    "    if effect > 0.05:\n",
    "        name_movers.append((layer, head, effect))\n",
    "    elif effect < -0.05:\n",
    "        negative_heads.append((layer, head, effect))\n",
    "\n",
    "print(\"\\nName Mover Heads (positive effect - moving the correct answer):\")\n",
    "for layer, head, effect in sorted(name_movers, key=lambda x: -x[2]):\n",
    "    print(f\"  L{layer}H{head}: {effect:.3f}\")\n",
    "\n",
    "print(\"\\nNegative Heads (negative effect - inhibiting wrong answer):\")\n",
    "for layer, head, effect in sorted(negative_heads, key=lambda x: x[2]):\n",
    "    print(f\"  L{layer}H{head}: {effect:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Comparing to Published Results\n",
    "\n",
    "The original IOI paper identified specific head roles. Let's compare our findings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known IOI circuit heads from the literature\n",
    "# (From \"Interpretability in the Wild\" paper)\n",
    "\n",
    "IOI_CIRCUIT = {\n",
    "    \"name_mover\": [\n",
    "        (9, 9), (9, 6), (10, 0)  # L9H9, L9H6, L10H0\n",
    "    ],\n",
    "    \"negative\": [\n",
    "        (10, 7), (11, 10)  # L10H7, L11H10\n",
    "    ],\n",
    "    \"s_inhibition\": [\n",
    "        (7, 3), (7, 9), (8, 6), (8, 10)\n",
    "    ],\n",
    "    \"induction\": [\n",
    "        (5, 5), (6, 9)\n",
    "    ],\n",
    "    \"duplicate_token\": [\n",
    "        (0, 1), (3, 0)\n",
    "    ],\n",
    "    \"previous_token\": [\n",
    "        (2, 2), (4, 11)\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Known IOI Circuit Heads from Literature:\")\n",
    "print(\"=\" * 50)\n",
    "for role, heads in IOI_CIRCUIT.items():\n",
    "    head_strs = \", \".join([f\"L{l}H{h}\" for l, h in heads])\n",
    "    print(f\"{role}: {head_strs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate our heatmap with known circuit heads\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add heatmap\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=aggregated_effects,\n",
    "    colorscale=\"RdBu_r\",\n",
    "    zmid=0,\n",
    "    colorbar_title=\"Effect\"\n",
    "))\n",
    "\n",
    "# Add annotations for known circuit heads\n",
    "colors = {\n",
    "    \"name_mover\": \"green\",\n",
    "    \"negative\": \"red\",\n",
    "    \"s_inhibition\": \"purple\",\n",
    "    \"induction\": \"orange\",\n",
    "    \"duplicate_token\": \"cyan\",\n",
    "    \"previous_token\": \"yellow\"\n",
    "}\n",
    "\n",
    "for role, heads in IOI_CIRCUIT.items():\n",
    "    for layer, head in heads:\n",
    "        # Add circle marker\n",
    "        fig.add_shape(\n",
    "            type=\"circle\",\n",
    "            x0=head-0.4, x1=head+0.4,\n",
    "            y0=layer-0.4, y1=layer+0.4,\n",
    "            line=dict(color=colors[role], width=2)\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Head Patching Effects with Known IOI Circuit Heads Marked\",\n",
    "    xaxis_title=\"Head\",\n",
    "    yaxis_title=\"Layer\",\n",
    "    width=900,\n",
    "    height=700\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nLegend:\")\n",
    "for role, color in colors.items():\n",
    "    print(f\"  {color}: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Our Results to Literature\n",
    "\n",
    "The heads we identified should overlap significantly with the known IOI circuit! Common findings:\n",
    "\n",
    "1. **Name Mover Heads** (L9H9, L9H6, L10H0) have high positive effect\n",
    "2. **Negative Heads** (L10H7, L11H10) may show negative effect\n",
    "3. **Earlier layer heads** contribute indirectly by setting up the computation\n",
    "\n",
    "Some variation is expected due to:\n",
    "- Random sampling of examples\n",
    "- Different corruption strategies\n",
    "- Backup circuits that can compensate\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself\n",
    "\n",
    "### Exercise 1: MLP Patching\n",
    "Patch MLP layers instead of attention heads. Which layers are most important?\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Use `f\"blocks.{layer}.hook_mlp_out\"` as the hook name. MLPs don't have heads, so you patch the entire layer.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Implement MLP patching\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Position-Specific Patching\n",
    "Patch only specific positions (e.g., just the name positions) instead of all positions. Does this reveal which positions carry the important information?\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Modify the patch function to only patch specific token positions. First find where the names appear in the token list.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Implement position-specific patching\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Attention Pattern Analysis\n",
    "For the identified name mover heads, visualize their attention patterns. Do they actually attend to the indirect object name?\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Use `cache[\"pattern\", layer][0, head]` to get the attention pattern. Look at which positions the final token attends to.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# Visualize attention patterns for name mover heads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Mistakes\n",
    "\n",
    "### Mistake 1: Forgetting to Use Corrupted Cache\n",
    "```python\n",
    "# Wrong: Patching with clean cache (does nothing!)\n",
    "activation = clean_cache[hook.name]  # No change!\n",
    "\n",
    "# Correct: Patch with corrupted cache\n",
    "activation = corrupted_cache[hook.name]  # Introduces counterfactual\n",
    "```\n",
    "**Why:** The whole point is to see what happens when we inject \"corrupted\" information!\n",
    "\n",
    "### Mistake 2: Not Normalizing Effects\n",
    "```python\n",
    "# Wrong: Using raw logit differences\n",
    "effect = clean_diff - patched_diff  # Scale depends on example!\n",
    "\n",
    "# Correct: Normalize by the clean-corrupted gap\n",
    "effect = (clean_diff - patched_diff) / (clean_diff - corrupted_diff)\n",
    "```\n",
    "**Why:** Normalization makes effects comparable across examples with different logit scales.\n",
    "\n",
    "### Mistake 3: Only Looking at One Example\n",
    "```python\n",
    "# Wrong: Drawing conclusions from one example\n",
    "effect = run_patching(example_1)  # Could be an outlier!\n",
    "\n",
    "# Correct: Aggregate over many examples\n",
    "effects = [run_patching(ex) for ex in dataset]\n",
    "mean_effect = np.mean(effects)\n",
    "```\n",
    "**Why:** Single examples can be noisy. Aggregation gives robust results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- What the IOI task is and why it's important for interpretability\n",
    "- How activation patching works as a causal intervention\n",
    "- How to patch residual stream, attention heads, and other components\n",
    "- How to interpret patching results and identify important circuit components\n",
    "- How your findings compare to published IOI circuit research\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge (Optional)\n",
    "\n",
    "**Replicate Path Patching**\n",
    "\n",
    "Instead of patching a head's entire output, try patching the *specific path* through which a head's output reaches the answer. This involves:\n",
    "\n",
    "1. Identifying which later heads read from the name mover heads\n",
    "2. Patching only the contribution from source head to target head\n",
    "\n",
    "This more precisely isolates the causal mechanism. See the IOI paper for details on path patching methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Path patching\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Interpretability in the Wild (IOI Paper)](https://arxiv.org/abs/2211.00593)\n",
    "- [Causal Scrubbing](https://www.lesswrong.com/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing) - A more rigorous patching methodology\n",
    "- [ROME: Rank-One Model Editing](https://rome.baulab.info/) - Using patching to edit facts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "del clean_cache, corrupted_cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Memory cleared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In **Lab C.3**, we'll study **Induction Heads** - a fundamental circuit for in-context learning. Induction heads are one of the most important discoveries in mechanistic interpretability, explaining how models learn to copy patterns!\n",
    "\n",
    "**Next:** [Lab C.3: Induction Head Analysis](03-induction-head-analysis.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
