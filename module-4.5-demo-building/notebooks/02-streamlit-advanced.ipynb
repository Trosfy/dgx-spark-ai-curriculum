{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.5.2: Advanced Streamlit - Multi-Page Apps & Performance\n",
    "\n",
    "**Module:** 4.5 - Demo Building & Prototyping  \n",
    "**Time:** 2-3 hours  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- [ ] Build multi-page Streamlit applications\n",
    "- [ ] Master session state for conversation and settings persistence\n",
    "- [ ] Implement caching strategies for models and data\n",
    "- [ ] Optimize performance with lazy loading and async operations\n",
    "- [ ] Create polished, production-ready Streamlit apps\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completed: Task 4.5.1 (Gradio Advanced) or equivalent Gradio knowledge\n",
    "- Knowledge of: Python, basic understanding of web concepts\n",
    "- Familiarity with: LLM APIs (for chat examples)\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Real-World Context\n",
    "\n",
    "Your team loves the quick prototype you made in Gradio. But now the Product Manager says:\n",
    "\n",
    "*\"We need a dashboard with multiple pages - analytics, chat history, admin settings. And it needs to remember user preferences. Can we do that?\"*\n",
    "\n",
    "Streamlit excels at exactly this. While Gradio is great for ML demos, Streamlit shines for:\n",
    "- Multi-page data applications\n",
    "- Complex state management\n",
    "- Dashboard-style layouts\n",
    "- Long-running data science workflows\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßí ELI5: Gradio vs Streamlit\n",
    "\n",
    "> **Gradio** is like a microwave - pop in your model, press a button, get results. Perfect for quick demos.\n",
    ">\n",
    "> **Streamlit** is like a full kitchen - more setup, but you can cook anything. Multiple burners (pages), a fridge for storage (session state), and you decide exactly how the kitchen looks.\n",
    ">\n",
    "> Both are great! Use Gradio for \"look at my model\" demos. Use Streamlit for \"look at my complete application\" demos.\n",
    "\n",
    "---\n",
    "\n",
    "## Important: How Streamlit Works Differently\n",
    "\n",
    "Unlike Gradio (which uses callbacks), Streamlit **re-runs your entire script** from top to bottom every time anything changes. This has implications:\n",
    "\n",
    "1. **Variables reset** - Use `st.session_state` to persist data\n",
    "2. **Models reload** - Use `@st.cache_resource` to cache expensive objects\n",
    "3. **Data recalculates** - Use `@st.cache_data` to cache computed results\n",
    "\n",
    "Understanding this \"rerun\" model is key to writing efficient Streamlit apps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Streamlit Basics Refresher\n",
    "\n",
    "Since Streamlit runs as a standalone script (not in a notebook), we'll write our examples as Python files. Let's start with a basic refresher.\n",
    "\n",
    "### Installing Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Streamlit\n",
    "!pip install -q streamlit>=1.30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Streamlit App Structure\n",
    "\n",
    "Here's the simplest Streamlit app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a basic Streamlit app to a file\n",
    "basic_app = '''\n",
    "import streamlit as st\n",
    "\n",
    "# Page configuration (must be first Streamlit command)\n",
    "st.set_page_config(\n",
    "    page_title=\"My First App\",\n",
    "    page_icon=\"üöÄ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Title and description\n",
    "st.title(\"üöÄ My First Streamlit App\")\n",
    "st.markdown(\"Welcome to Streamlit! This is a basic example.\")\n",
    "\n",
    "# Sidebar\n",
    "with st.sidebar:\n",
    "    st.header(\"Settings\")\n",
    "    name = st.text_input(\"Your Name\", value=\"Professor Spark\")\n",
    "    enthusiasm = st.slider(\"Enthusiasm Level\", 1, 10, 5)\n",
    "\n",
    "# Main content\n",
    "st.subheader(f\"Hello, {name}!\")\n",
    "st.write(\"!\" * enthusiasm)\n",
    "\n",
    "# Columns for layout\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "    st.metric(\"Temperature\", \"72¬∞F\", \"+2¬∞F\")\n",
    "\n",
    "with col2:\n",
    "    st.metric(\"Humidity\", \"45%\", \"-5%\")\n",
    "\n",
    "with col3:\n",
    "    st.metric(\"Wind\", \"12 mph\", \"0 mph\")\n",
    "\n",
    "# Interactive elements\n",
    "if st.button(\"Click Me!\"):\n",
    "    st.balloons()\n",
    "    st.success(\"üéâ You clicked the button!\")\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "with open('/tmp/basic_app.py', 'w') as f:\n",
    "    f.write(basic_app)\n",
    "\n",
    "print(\"Basic app saved to /tmp/basic_app.py\")\n",
    "print(\"\\nTo run it, open a terminal and type:\")\n",
    "print(\"  streamlit run /tmp/basic_app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Streamlit Apps\n",
    "\n",
    "Streamlit apps run as web servers. To launch:\n",
    "\n",
    "```bash\n",
    "# From terminal\n",
    "streamlit run app.py\n",
    "\n",
    "# With custom port\n",
    "streamlit run app.py --server.port 8501\n",
    "\n",
    "# For DGX Spark (allow external access)\n",
    "streamlit run app.py --server.address 0.0.0.0 --server.port 8501\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Multi-Page Applications\n",
    "\n",
    "### üßí ELI5: Multi-Page Apps\n",
    "\n",
    "> Think of your app like a book. The main page is the cover, and each page in the `pages/` folder is a chapter. Streamlit automatically creates a navigation menu from your chapter files.\n",
    "\n",
    "### File Structure\n",
    "\n",
    "```\n",
    "my_app/\n",
    "‚îú‚îÄ‚îÄ Home.py                    # Main entry point (shows first)\n",
    "‚îú‚îÄ‚îÄ pages/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 1_üí¨_Chat.py          # Page 1: Chat interface\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 2_üìä_Analytics.py     # Page 2: Analytics dashboard\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 3_‚öôÔ∏è_Settings.py      # Page 3: Settings\n",
    "‚îú‚îÄ‚îÄ utils/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ helpers.py             # Shared utility functions\n",
    "‚îî‚îÄ‚îÄ .streamlit/\n",
    "    ‚îî‚îÄ‚îÄ config.toml            # Streamlit configuration\n",
    "```\n",
    "\n",
    "### Key Rules:\n",
    "1. The `pages/` folder must be named exactly `pages`\n",
    "2. Files are sorted alphabetically (use numbers for ordering: `1_Page.py`, `2_Page.py`)\n",
    "3. Emojis in filenames show in the sidebar navigation\n",
    "4. Underscores become spaces in the nav (e.g., `1_My_Page.py` ‚Üí \"My Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create multi-page app structure\n",
    "app_dir = '/tmp/streamlit_multipage'\n",
    "os.makedirs(f'{app_dir}/pages', exist_ok=True)\n",
    "os.makedirs(f'{app_dir}/.streamlit', exist_ok=True)\n",
    "\n",
    "# Home.py - Main entry point\n",
    "home_page = '''\n",
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"AI Assistant\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Initialize session state (only happens once)\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"settings\" not in st.session_state:\n",
    "    st.session_state.settings = {\n",
    "        \"model\": \"llama3.1:8b\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"theme\": \"light\"\n",
    "    }\n",
    "\n",
    "st.title(\"ü§ñ AI Assistant\")\n",
    "st.markdown(\"\"\"\n",
    "Welcome to the AI Assistant demo! This multi-page application showcases:\n",
    "\n",
    "- **üí¨ Chat**: Conversational AI interface\n",
    "- **üìä Analytics**: Usage metrics and performance\n",
    "- **‚öôÔ∏è Settings**: Configure the assistant\n",
    "\n",
    "Use the sidebar to navigate between pages.\n",
    "\"\"\")\n",
    "\n",
    "# Quick stats from session state\n",
    "col1, col2, col3 = st.columns(3)\n",
    "col1.metric(\"Messages\", len(st.session_state.messages))\n",
    "col2.metric(\"Model\", st.session_state.settings[\"model\"].split(\":\")[0])\n",
    "col3.metric(\"Temperature\", st.session_state.settings[\"temperature\"])\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.info(\"üëà Use the sidebar to navigate to different pages.\")\n",
    "'''\n",
    "\n",
    "with open(f'{app_dir}/Home.py', 'w') as f:\n",
    "    f.write(home_page)\n",
    "\n",
    "print(\"‚úÖ Created Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat page\n",
    "chat_page = '''\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "st.set_page_config(page_title=\"Chat\", page_icon=\"üí¨\")\n",
    "\n",
    "st.title(\"üí¨ Chat with AI\")\n",
    "\n",
    "# Ensure session state is initialized\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"settings\" not in st.session_state:\n",
    "    st.session_state.settings = {\"model\": \"llama3.1:8b\", \"temperature\": 0.7}\n",
    "\n",
    "# Sidebar: Current settings\n",
    "with st.sidebar:\n",
    "    st.subheader(\"Current Settings\")\n",
    "    st.write(f\"Model: {st.session_state.settings['model']}\")\n",
    "    st.write(f\"Temperature: {st.session_state.settings['temperature']}\")\n",
    "    \n",
    "    if st.button(\"Clear Chat\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Ask something...\"):\n",
    "    # Add user message\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(prompt)\n",
    "    \n",
    "    # Generate response (simulated)\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            time.sleep(1)  # Simulate API call\n",
    "            \n",
    "            # In a real app, call your LLM here\n",
    "            response = f\"Echo from {st.session_state.settings['model']}: {prompt}\"\n",
    "            st.write(response)\n",
    "    \n",
    "    # Add assistant message\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "'''\n",
    "\n",
    "with open(f'{app_dir}/pages/1_üí¨_Chat.py', 'w') as f:\n",
    "    f.write(chat_page)\n",
    "\n",
    "print(\"‚úÖ Created pages/1_üí¨_Chat.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytics page\n",
    "analytics_page = '''\n",
    "import streamlit as st\n",
    "import random\n",
    "\n",
    "st.set_page_config(page_title=\"Analytics\", page_icon=\"üìä\")\n",
    "\n",
    "st.title(\"üìä Analytics\")\n",
    "\n",
    "# Ensure session state is initialized\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Calculate metrics from session state\n",
    "total_messages = len(st.session_state.messages)\n",
    "user_messages = sum(1 for m in st.session_state.messages if m[\"role\"] == \"user\")\n",
    "ai_messages = total_messages - user_messages\n",
    "\n",
    "# Metrics row\n",
    "col1, col2, col3, col4 = st.columns(4)\n",
    "col1.metric(\"Total Messages\", total_messages)\n",
    "col2.metric(\"User Messages\", user_messages)\n",
    "col3.metric(\"AI Responses\", ai_messages)\n",
    "col4.metric(\"Avg Response Time\", \"1.2s\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Chat history\n",
    "st.subheader(\"üìù Conversation History\")\n",
    "\n",
    "if not st.session_state.messages:\n",
    "    st.info(\"No messages yet. Start a conversation in the Chat page!\")\n",
    "else:\n",
    "    for i, msg in enumerate(st.session_state.messages):\n",
    "        role_emoji = \"üë§\" if msg[\"role\"] == \"user\" else \"ü§ñ\"\n",
    "        st.text(f\"{role_emoji} {msg['role'].title()}: {msg['content'][:100]}...\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Simulated charts\n",
    "st.subheader(\"üìà Usage Over Time\")\n",
    "\n",
    "# Generate some fake data for the demo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "chart_data = pd.DataFrame(\n",
    "    np.random.randn(20, 3) * 10 + 50,\n",
    "    columns=[\"Messages\", \"Tokens\", \"Response Time (ms)\"]\n",
    ")\n",
    "\n",
    "st.line_chart(chart_data)\n",
    "\n",
    "# Export button\n",
    "st.markdown(\"---\")\n",
    "if st.button(\"üì• Export Chat History\"):\n",
    "    if st.session_state.messages:\n",
    "        export_text = \"\\\\n\".join([f\"{m['role']}: {m['content']}\" for m in st.session_state.messages])\n",
    "        st.download_button(\n",
    "            \"Download as TXT\",\n",
    "            export_text,\n",
    "            file_name=\"chat_history.txt\",\n",
    "            mime=\"text/plain\"\n",
    "        )\n",
    "    else:\n",
    "        st.warning(\"No messages to export.\")\n",
    "'''\n",
    "\n",
    "with open(f'{app_dir}/pages/2_üìä_Analytics.py', 'w') as f:\n",
    "    f.write(analytics_page)\n",
    "\n",
    "print(\"‚úÖ Created pages/2_üìä_Analytics.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings page\n",
    "settings_page = '''\n",
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(page_title=\"Settings\", page_icon=\"‚öôÔ∏è\")\n",
    "\n",
    "st.title(\"‚öôÔ∏è Settings\")\n",
    "\n",
    "# Ensure session state is initialized\n",
    "if \"settings\" not in st.session_state:\n",
    "    st.session_state.settings = {\n",
    "        \"model\": \"llama3.1:8b\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"theme\": \"light\"\n",
    "    }\n",
    "\n",
    "st.subheader(\"Model Configuration\")\n",
    "\n",
    "# Model selection\n",
    "model = st.selectbox(\n",
    "    \"Select Model\",\n",
    "    [\"llama3.1:8b\", \"llama3.1:70b\", \"mistral:7b\", \"codellama:13b\"],\n",
    "    index=[\"llama3.1:8b\", \"llama3.1:70b\", \"mistral:7b\", \"codellama:13b\"].index(\n",
    "        st.session_state.settings[\"model\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Temperature\n",
    "temperature = st.slider(\n",
    "    \"Temperature\",\n",
    "    min_value=0.0,\n",
    "    max_value=1.0,\n",
    "    value=st.session_state.settings[\"temperature\"],\n",
    "    step=0.1,\n",
    "    help=\"Higher = more creative, Lower = more focused\"\n",
    ")\n",
    "\n",
    "# Max tokens\n",
    "max_tokens = st.number_input(\n",
    "    \"Max Tokens\",\n",
    "    min_value=100,\n",
    "    max_value=4000,\n",
    "    value=1000,\n",
    "    step=100\n",
    ")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"Appearance\")\n",
    "\n",
    "# Theme (visual only in this demo)\n",
    "theme = st.radio(\n",
    "    \"Theme\",\n",
    "    [\"light\", \"dark\"],\n",
    "    index=0 if st.session_state.settings[\"theme\"] == \"light\" else 1\n",
    ")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Save button\n",
    "if st.button(\"üíæ Save Settings\", type=\"primary\"):\n",
    "    st.session_state.settings = {\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"theme\": theme\n",
    "    }\n",
    "    st.success(\"‚úÖ Settings saved!\")\n",
    "    st.balloons()\n",
    "\n",
    "# Show current settings\n",
    "with st.expander(\"Current Settings (Debug)\"):\n",
    "    st.json(st.session_state.settings)\n",
    "'''\n",
    "\n",
    "with open(f'{app_dir}/pages/3_‚öôÔ∏è_Settings.py', 'w') as f:\n",
    "    f.write(settings_page)\n",
    "\n",
    "print(\"‚úÖ Created pages/3_‚öôÔ∏è_Settings.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit config file\n",
    "config = '''\n",
    "[theme]\n",
    "primaryColor = \"#007bff\"\n",
    "backgroundColor = \"#ffffff\"\n",
    "secondaryBackgroundColor = \"#f0f2f6\"\n",
    "textColor = \"#262730\"\n",
    "font = \"sans serif\"\n",
    "\n",
    "[server]\n",
    "maxUploadSize = 200\n",
    "enableCORS = false\n",
    "'''\n",
    "\n",
    "with open(f'{app_dir}/.streamlit/config.toml', 'w') as f:\n",
    "    f.write(config)\n",
    "\n",
    "print(\"‚úÖ Created .streamlit/config.toml\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Multi-page app created!\")\n",
    "print(\"\\nTo run it:\")\n",
    "print(f\"  cd {app_dir}\")\n",
    "print(\"  streamlit run Home.py\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Session State Deep Dive\n",
    "\n",
    "### üßí ELI5: Session State\n",
    "\n",
    "> Imagine you're playing a video game. When you pause and unpause, you expect your score, inventory, and position to still be there. That's \"state\".\n",
    ">\n",
    "> In Streamlit, every time you click something, the whole app re-runs (like the game restarting). `st.session_state` is like a save file - it keeps your data between re-runs.\n",
    ">\n",
    "> Without it, every click would reset everything!\n",
    "\n",
    "### Session State Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session state examples\n",
    "session_state_examples = '''\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"üîß Session State Patterns\")\n",
    "\n",
    "# Pattern 1: Initialize with default values\n",
    "st.header(\"Pattern 1: Safe Initialization\")\n",
    "\n",
    "# ‚úÖ CORRECT: Check before initializing\n",
    "if \"counter\" not in st.session_state:\n",
    "    st.session_state.counter = 0\n",
    "\n",
    "# ‚ùå WRONG: This resets the counter every rerun!\n",
    "# st.session_state.counter = 0\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    if st.button(\"+1\"):\n",
    "        st.session_state.counter += 1\n",
    "with col2:\n",
    "    if st.button(\"-1\"):\n",
    "        st.session_state.counter -= 1\n",
    "\n",
    "st.metric(\"Counter\", st.session_state.counter)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Pattern 2: Dictionary-style vs attribute-style\n",
    "st.header(\"Pattern 2: Access Styles\")\n",
    "\n",
    "if \"user_data\" not in st.session_state:\n",
    "    st.session_state.user_data = {\"name\": \"Unknown\", \"score\": 0}\n",
    "\n",
    "st.code(\"\"\"\n",
    "# Both work:\n",
    "st.session_state.counter        # Attribute style\n",
    "st.session_state[\"counter\"]     # Dictionary style\n",
    "\n",
    "# For complex keys, use dictionary style:\n",
    "st.session_state[\"user-data\"]   # Dashes not allowed in attribute style\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Pattern 3: Callback functions\n",
    "st.header(\"Pattern 3: Callbacks with Session State\")\n",
    "\n",
    "if \"form_data\" not in st.session_state:\n",
    "    st.session_state.form_data = \"\"\n",
    "\n",
    "def on_input_change():\n",
    "    \"\"\"Callback that runs when input changes.\"\"\"\n",
    "    # Access the input value from session state (set by key parameter)\n",
    "    st.session_state.form_data = f\"You typed: {st.session_state.my_input}\"\n",
    "\n",
    "st.text_input(\n",
    "    \"Type something\",\n",
    "    key=\"my_input\",  # This creates st.session_state.my_input\n",
    "    on_change=on_input_change  # Called when value changes\n",
    ")\n",
    "\n",
    "st.write(st.session_state.form_data)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Pattern 4: Clearing state\n",
    "st.header(\"Pattern 4: Clearing State\")\n",
    "\n",
    "if st.button(\"Reset Everything\"):\n",
    "    # Clear specific keys\n",
    "    for key in [\"counter\", \"user_data\", \"form_data\"]:\n",
    "        if key in st.session_state:\n",
    "            del st.session_state[key]\n",
    "    st.rerun()\n",
    "\n",
    "# Debug: Show all session state\n",
    "with st.expander(\"üîç View All Session State\"):\n",
    "    st.json(dict(st.session_state))\n",
    "'''\n",
    "\n",
    "with open('/tmp/session_state_examples.py', 'w') as f:\n",
    "    f.write(session_state_examples)\n",
    "\n",
    "print(\"Session state examples saved to /tmp/session_state_examples.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat History with Session State\n",
    "\n",
    "The most common use case: maintaining conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete chat implementation with session state\n",
    "chat_with_state = '''\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "st.set_page_config(page_title=\"Chat Demo\", page_icon=\"üí¨\")\n",
    "\n",
    "st.title(\"üí¨ Chat with Memory\")\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"assistant\", \"content\": \"Hello! How can I help you today?\"}\n",
    "    ]\n",
    "\n",
    "# Display chat messages\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# Accept user input\n",
    "if prompt := st.chat_input(\"What's on your mind?\"):\n",
    "    # Add user message to history\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    # Display user message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    # Generate response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        message_placeholder = st.empty()\n",
    "        full_response = \"\"\n",
    "        \n",
    "        # Simulate streaming response\n",
    "        response_text = f\"I understood: \\'{prompt}\\'. This is a demo response that streams character by character!\"\n",
    "        \n",
    "        for char in response_text:\n",
    "            full_response += char\n",
    "            message_placeholder.markdown(full_response + \"‚ñå\")\n",
    "            time.sleep(0.02)\n",
    "        \n",
    "        message_placeholder.markdown(full_response)\n",
    "    \n",
    "    # Add assistant response to history\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n",
    "\n",
    "# Sidebar with controls\n",
    "with st.sidebar:\n",
    "    st.subheader(\"Chat Controls\")\n",
    "    \n",
    "    st.write(f\"Messages: {len(st.session_state.messages)}\")\n",
    "    \n",
    "    if st.button(\"üóëÔ∏è Clear History\"):\n",
    "        st.session_state.messages = [\n",
    "            {\"role\": \"assistant\", \"content\": \"Hello! How can I help you today?\"}\n",
    "        ]\n",
    "        st.rerun()\n",
    "    \n",
    "    if st.button(\"üì• Export Chat\"):\n",
    "        chat_export = \"\\\\n\\\\n\".join([\n",
    "            f\"{m['role'].upper()}: {m['content']}\" \n",
    "            for m in st.session_state.messages\n",
    "        ])\n",
    "        st.download_button(\n",
    "            \"Download\",\n",
    "            chat_export,\n",
    "            file_name=\"chat_export.txt\"\n",
    "        )\n",
    "'''\n",
    "\n",
    "with open('/tmp/chat_with_state.py', 'w') as f:\n",
    "    f.write(chat_with_state)\n",
    "\n",
    "print(\"Chat with state example saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Caching Strategies\n",
    "\n",
    "### üßí ELI5: Caching\n",
    "\n",
    "> Imagine you're asked the same math problem 100 times. The first time, you solve it. The next 99 times, you just remember the answer.\n",
    ">\n",
    "> Caching is \"remembering\" expensive computations so you don't repeat them. In Streamlit:\n",
    "> - `@st.cache_data`: Remember the RESULT of a function (good for data)\n",
    "> - `@st.cache_resource`: Remember an OBJECT (good for models, database connections)\n",
    "\n",
    "### Cache Types Comparison\n",
    "\n",
    "| Feature | `@st.cache_data` | `@st.cache_resource` |\n",
    "|---------|------------------|----------------------|\n",
    "| Purpose | Data (DataFrames, lists, dicts) | Resources (models, connections) |\n",
    "| Serialization | Yes (copies data) | No (returns same object) |\n",
    "| Thread-safe | Yes | No (be careful!) |\n",
    "| Use for | API responses, computations | ML models, DB connections |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching examples\n",
    "caching_examples = '''\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "st.title(\"‚ö° Caching Demo\")\n",
    "\n",
    "# @st.cache_data - For data (DataFrames, lists, results)\n",
    "st.header(\"1. @st.cache_data - Caching Data\")\n",
    "\n",
    "@st.cache_data  # Cache the result\n",
    "def expensive_data_computation(n):\n",
    "    \"\"\"Simulate an expensive data computation.\"\"\"\n",
    "    time.sleep(2)  # Simulate slow computation\n",
    "    return {\"result\": n ** 2, \"computed_at\": time.strftime(\"%H:%M:%S\")}\n",
    "\n",
    "num = st.number_input(\"Enter a number\", value=5, min_value=1, max_value=100)\n",
    "\n",
    "start = time.time()\n",
    "result = expensive_data_computation(num)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "st.write(f\"Result: {result['result']}\")\n",
    "st.write(f\"Computed at: {result['computed_at']}\")\n",
    "st.write(f\"‚è±Ô∏è Took: {elapsed:.2f} seconds (first call ~2s, cached calls ~0s)\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# @st.cache_data with TTL (time to live)\n",
    "st.header(\"2. @st.cache_data with TTL\")\n",
    "\n",
    "@st.cache_data(ttl=60)  # Cache expires after 60 seconds\n",
    "def fetch_api_data():\n",
    "    \"\"\"Simulate fetching data from an API.\"\"\"\n",
    "    time.sleep(1)\n",
    "    return {\"data\": \"fresh_data\", \"timestamp\": time.strftime(\"%H:%M:%S\")}\n",
    "\n",
    "if st.button(\"Fetch API Data\"):\n",
    "    data = fetch_api_data()\n",
    "    st.json(data)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# @st.cache_resource - For resources (models, connections)\n",
    "st.header(\"3. @st.cache_resource - Caching Resources\")\n",
    "\n",
    "@st.cache_resource  # Load once, reuse everywhere\n",
    "def load_model():\n",
    "    \"\"\"Simulate loading a large ML model.\"\"\"\n",
    "    st.write(\"‚è≥ Loading model... (only happens once!)\")\n",
    "    time.sleep(3)  # Simulate slow model loading\n",
    "    \n",
    "    # In real code:\n",
    "    # from transformers import pipeline\n",
    "    # return pipeline(\"text-generation\", model=\"gpt2\")\n",
    "    \n",
    "    return {\"model\": \"fake_model\", \"loaded_at\": time.strftime(\"%H:%M:%S\")}\n",
    "\n",
    "st.info(\"Click the button to use the model. First click loads it, subsequent clicks reuse it.\")\n",
    "\n",
    "if st.button(\"Use Model\"):\n",
    "    start = time.time()\n",
    "    model = load_model()\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    st.success(f\"Model ready! Loaded at: {model['loaded_at']}\")\n",
    "    st.write(f\"‚è±Ô∏è Took: {elapsed:.2f} seconds\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Clearing cache\n",
    "st.header(\"4. Clearing Cache\")\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    if st.button(\"Clear Data Cache\"):\n",
    "        st.cache_data.clear()\n",
    "        st.success(\"Data cache cleared!\")\n",
    "        \n",
    "with col2:\n",
    "    if st.button(\"Clear Resource Cache\"):\n",
    "        st.cache_resource.clear()\n",
    "        st.success(\"Resource cache cleared!\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Best practices\n",
    "st.header(\"üìö Best Practices\")\n",
    "st.markdown(\"\"\"\n",
    "1. **Use `@st.cache_data` for:**\n",
    "   - DataFrames, lists, dictionaries\n",
    "   - API responses\n",
    "   - Computation results\n",
    "\n",
    "2. **Use `@st.cache_resource` for:**\n",
    "   - ML models (HuggingFace, PyTorch, etc.)\n",
    "   - Database connections\n",
    "   - Expensive-to-create objects\n",
    "\n",
    "3. **Common patterns:**\n",
    "   ```python\n",
    "   @st.cache_resource\n",
    "   def load_llm():\n",
    "       import ollama\n",
    "       return ollama.Client()\n",
    "   \n",
    "   @st.cache_data(ttl=3600)  # Refresh every hour\n",
    "   def get_embeddings(text):\n",
    "       client = load_llm()\n",
    "       return client.embeddings(model=\"nomic-embed-text\", prompt=text)\n",
    "   ```\n",
    "\"\"\")\n",
    "'''\n",
    "\n",
    "with open('/tmp/caching_examples.py', 'w') as f:\n",
    "    f.write(caching_examples)\n",
    "\n",
    "print(\"Caching examples saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Performance Optimization\n",
    "\n",
    "### Common Performance Issues\n",
    "\n",
    "1. **Model reloads on every interaction** ‚Üí Use `@st.cache_resource`\n",
    "2. **Slow data loading** ‚Üí Use `@st.cache_data`\n",
    "3. **UI freezes during computation** ‚Üí Use spinners and progress bars\n",
    "4. **Unnecessary reruns** ‚Üí Use session state wisely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimization patterns\n",
    "performance_patterns = '''\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "st.title(\"üöÄ Performance Patterns\")\n",
    "\n",
    "# Pattern 1: Lazy Loading\n",
    "st.header(\"1. Lazy Loading\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Don\\'t load everything upfront. Load resources only when needed.\n",
    "\"\"\")\n",
    "\n",
    "@st.cache_resource\n",
    "def load_heavy_resource():\n",
    "    time.sleep(2)\n",
    "    return \"Heavy resource loaded!\"\n",
    "\n",
    "if st.checkbox(\"I need the heavy resource\"):\n",
    "    with st.spinner(\"Loading...\"):\n",
    "        resource = load_heavy_resource()\n",
    "        st.success(resource)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Pattern 2: Progress Indicators\n",
    "st.header(\"2. Progress Indicators\")\n",
    "\n",
    "if st.button(\"Run Long Process\"):\n",
    "    progress_bar = st.progress(0)\n",
    "    status_text = st.empty()\n",
    "    \n",
    "    for i in range(100):\n",
    "        time.sleep(0.02)\n",
    "        progress_bar.progress(i + 1)\n",
    "        status_text.text(f\"Processing: {i+1}%\")\n",
    "    \n",
    "    status_text.text(\"Done!\")\n",
    "    st.balloons()\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Pattern 3: Fragment-based Updates (Streamlit 1.33+)\n",
    "st.header(\"3. Avoiding Full Reruns\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Use `st.fragment` to update only parts of the app (Streamlit 1.33+):\n",
    "\n",
    "```python\n",
    "@st.fragment\n",
    "def my_component():\n",
    "    # Only this part reruns when interacted with\n",
    "    if st.button(\"Click me\"):\n",
    "        st.write(\"Clicked!\")\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Pattern 4: Container Updates\n",
    "st.header(\"4. Using Containers for Updates\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Use `st.empty()` and `st.container()` for dynamic updates:\n",
    "\"\"\")\n",
    "\n",
    "container = st.container()\n",
    "button = st.button(\"Update Container\")\n",
    "\n",
    "if button:\n",
    "    with container:\n",
    "        st.write(f\"Updated at {time.strftime('%H:%M:%S')}\")\n",
    "        st.metric(\"Random Value\", f\"{time.time() % 100:.2f}\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Pattern 5: Batch Operations\n",
    "st.header(\"5. Batch Operations\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Instead of multiple small operations, batch them:\n",
    "\n",
    "```python\n",
    "# ‚ùå Slow - multiple state updates\n",
    "for item in items:\n",
    "    st.session_state.items.append(process(item))\n",
    "    st.rerun()  # Reruns after each!\n",
    "\n",
    "# ‚úÖ Fast - batch the updates\n",
    "processed = [process(item) for item in items]\n",
    "st.session_state.items.extend(processed)\n",
    "st.rerun()  # Single rerun\n",
    "```\n",
    "\"\"\")\n",
    "'''\n",
    "\n",
    "with open('/tmp/performance_patterns.py', 'w') as f:\n",
    "    f.write(performance_patterns)\n",
    "\n",
    "print(\"Performance patterns saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Complete Example - AI Agent Playground\n",
    "\n",
    "Let's build a more complete example that combines everything we've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete agent playground example\n",
    "agent_playground = '''\n",
    "import streamlit as st\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"AI Agent Playground\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Initialize session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"tools_enabled\" not in st.session_state:\n",
    "    st.session_state.tools_enabled = {\n",
    "        \"calculator\": True,\n",
    "        \"web_search\": True,\n",
    "        \"code_executor\": False\n",
    "    }\n",
    "\n",
    "# Mock tool implementations\n",
    "def mock_calculator(expression):\n",
    "    \"\"\"Mock calculator tool.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)  # In real code, use a safer evaluator\n",
    "        return {\"tool\": \"calculator\", \"input\": expression, \"output\": result}\n",
    "    except:\n",
    "        return {\"tool\": \"calculator\", \"input\": expression, \"error\": \"Invalid expression\"}\n",
    "\n",
    "def mock_web_search(query):\n",
    "    \"\"\"Mock web search tool.\"\"\"\n",
    "    return {\n",
    "        \"tool\": \"web_search\",\n",
    "        \"input\": query,\n",
    "        \"output\": f\"Mock results for: {query}\"\n",
    "    }\n",
    "\n",
    "def mock_agent_response(message, tools_enabled):\n",
    "    \"\"\"Simulate an agent response with tool calls.\"\"\"\n",
    "    tool_calls = []\n",
    "    thinking = \"\"\n",
    "    \n",
    "    # Simulate thinking\n",
    "    thinking = f\"Analyzing user request: \\'{message}\\'\\\\n\"\n",
    "    \n",
    "    # Detect if tools are needed (simple keyword matching)\n",
    "    if \"calculate\" in message.lower() and tools_enabled.get(\"calculator\"):\n",
    "        # Extract a simple expression\n",
    "        thinking += \"User wants a calculation. Using calculator tool.\\\\n\"\n",
    "        tool_calls.append(mock_calculator(\"2 + 2\"))\n",
    "    \n",
    "    if \"search\" in message.lower() and tools_enabled.get(\"web_search\"):\n",
    "        thinking += \"User wants to search. Using web search tool.\\\\n\"\n",
    "        tool_calls.append(mock_web_search(message))\n",
    "    \n",
    "    thinking += \"Formulating response based on available information.\"\n",
    "    \n",
    "    response = f\"Based on your request, here\\'s my response: {message}\"\n",
    "    \n",
    "    return {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response,\n",
    "        \"thinking\": thinking,\n",
    "        \"tool_calls\": tool_calls\n",
    "    }\n",
    "\n",
    "# Main title\n",
    "st.title(\"ü§ñ AI Agent Playground\")\n",
    "\n",
    "# Sidebar: Tool Configuration\n",
    "with st.sidebar:\n",
    "    st.header(\"üîß Tool Configuration\")\n",
    "    \n",
    "    st.session_state.tools_enabled[\"calculator\"] = st.checkbox(\n",
    "        \"üìä Calculator\",\n",
    "        value=st.session_state.tools_enabled[\"calculator\"],\n",
    "        help=\"Enable mathematical calculations\"\n",
    "    )\n",
    "    \n",
    "    st.session_state.tools_enabled[\"web_search\"] = st.checkbox(\n",
    "        \"üîç Web Search\",\n",
    "        value=st.session_state.tools_enabled[\"web_search\"],\n",
    "        help=\"Enable web search capability\"\n",
    "    )\n",
    "    \n",
    "    st.session_state.tools_enabled[\"code_executor\"] = st.checkbox(\n",
    "        \"üíª Code Executor\",\n",
    "        value=st.session_state.tools_enabled[\"code_executor\"],\n",
    "        help=\"Enable code execution (disabled by default)\"\n",
    "    )\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    if st.button(\"üóëÔ∏è Clear Conversation\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    st.caption(f\"Messages: {len(st.session_state.messages)}\")\n",
    "\n",
    "# Main chat area\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "        \n",
    "        # Show tool calls if present\n",
    "        if \"tool_calls\" in message and message[\"tool_calls\"]:\n",
    "            with st.expander(\"üîß Tool Calls\", expanded=False):\n",
    "                for tool in message[\"tool_calls\"]:\n",
    "                    st.code(json.dumps(tool, indent=2), language=\"json\")\n",
    "        \n",
    "        # Show thinking if present\n",
    "        if \"thinking\" in message and message[\"thinking\"]:\n",
    "            with st.expander(\"üí≠ Thinking Process\", expanded=False):\n",
    "                st.markdown(message[\"thinking\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Ask me anything... (try \\'calculate\\' or \\'search\\')\"):\n",
    "    # Add user message\n",
    "    user_msg = {\"role\": \"user\", \"content\": prompt}\n",
    "    st.session_state.messages.append(user_msg)\n",
    "    \n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    # Generate agent response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            time.sleep(1)  # Simulate processing\n",
    "            response = mock_agent_response(prompt, st.session_state.tools_enabled)\n",
    "        \n",
    "        st.markdown(response[\"content\"])\n",
    "        \n",
    "        if response[\"tool_calls\"]:\n",
    "            with st.expander(\"üîß Tool Calls\", expanded=True):\n",
    "                for tool in response[\"tool_calls\"]:\n",
    "                    st.code(json.dumps(tool, indent=2), language=\"json\")\n",
    "        \n",
    "        if response[\"thinking\"]:\n",
    "            with st.expander(\"üí≠ Thinking Process\", expanded=False):\n",
    "                st.markdown(response[\"thinking\"])\n",
    "    \n",
    "    st.session_state.messages.append(response)\n",
    "'''\n",
    "\n",
    "with open('/tmp/agent_playground.py', 'w') as f:\n",
    "    f.write(agent_playground)\n",
    "\n",
    "print(\"Agent playground saved to /tmp/agent_playground.py\")\n",
    "print(\"\\nTo run: streamlit run /tmp/agent_playground.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "### Mistake 1: Initializing State Wrong\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG - Resets every rerun!\n",
    "st.session_state.counter = 0\n",
    "\n",
    "# ‚úÖ RIGHT - Only initialize if not present\n",
    "if \"counter\" not in st.session_state:\n",
    "    st.session_state.counter = 0\n",
    "```\n",
    "\n",
    "### Mistake 2: Not Caching Expensive Operations\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG - Model loads on every interaction!\n",
    "model = load_large_model()\n",
    "\n",
    "# ‚úÖ RIGHT - Load once, cache forever\n",
    "@st.cache_resource\n",
    "def get_model():\n",
    "    return load_large_model()\n",
    "\n",
    "model = get_model()\n",
    "```\n",
    "\n",
    "### Mistake 3: Blocking the UI\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG - UI freezes with no feedback\n",
    "result = slow_function()  # User sees nothing for 30 seconds\n",
    "\n",
    "# ‚úÖ RIGHT - Show progress\n",
    "with st.spinner(\"Processing...\"):\n",
    "    result = slow_function()\n",
    "```\n",
    "\n",
    "### Mistake 4: Wrong File Structure for Multi-page Apps\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG - Files don't appear in navigation\n",
    "my_app/\n",
    "‚îú‚îÄ‚îÄ main.py\n",
    "‚îî‚îÄ‚îÄ other_pages/    # Wrong folder name!\n",
    "    ‚îî‚îÄ‚îÄ page1.py\n",
    "\n",
    "# ‚úÖ RIGHT - Use exact folder name 'pages'\n",
    "my_app/\n",
    "‚îú‚îÄ‚îÄ Home.py         # Entry point (or main.py, app.py)\n",
    "‚îî‚îÄ‚îÄ pages/          # Exact name required\n",
    "    ‚îî‚îÄ‚îÄ 1_Page.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Checkpoint\n",
    "\n",
    "You've learned:\n",
    "- ‚úÖ Multi-page Streamlit app structure\n",
    "- ‚úÖ Session state for persistent data\n",
    "- ‚úÖ `@st.cache_data` for caching computations\n",
    "- ‚úÖ `@st.cache_resource` for caching models/resources\n",
    "- ‚úÖ Performance optimization patterns\n",
    "- ‚úÖ Building a complete agent playground\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Challenge (Optional)\n",
    "\n",
    "Build a **Data Explorer App** with:\n",
    "1. **Home page**: Upload CSV files (store in session state)\n",
    "2. **Explore page**: View data, filter, sort (use `@st.cache_data`)\n",
    "3. **Analyze page**: Show charts and statistics\n",
    "4. **Settings page**: Configure display preferences\n",
    "\n",
    "Requirements:\n",
    "- Uploaded data persists across page navigation\n",
    "- Analysis results are cached\n",
    "- Smooth progress indicators for large files\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Further Reading\n",
    "\n",
    "- [Streamlit Documentation](https://docs.streamlit.io/)\n",
    "- [Multi-page Apps Guide](https://docs.streamlit.io/library/get-started/multipage-apps)\n",
    "- [Session State Guide](https://docs.streamlit.io/library/api-reference/session-state)\n",
    "- [Caching Guide](https://docs.streamlit.io/library/advanced-features/caching)\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files if needed\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# List created files\n",
    "temp_files = [\n",
    "    '/tmp/basic_app.py',\n",
    "    '/tmp/session_state_examples.py',\n",
    "    '/tmp/chat_with_state.py',\n",
    "    '/tmp/caching_examples.py',\n",
    "    '/tmp/performance_patterns.py',\n",
    "    '/tmp/agent_playground.py'\n",
    "]\n",
    "\n",
    "print(\"Created example files:\")\n",
    "for f in temp_files:\n",
    "    if os.path.exists(f):\n",
    "        print(f\"  ‚úÖ {f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Multi-page app: /tmp/streamlit_multipage/\")\n",
    "print(\"\\nüí° Run any example with: streamlit run <filename>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
